{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import zipfile\n",
    "from itertools import chain\n",
    "from typing import Union\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from fastcore.script import call_parse, Param\n",
    "from fastcore.parallel import parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "> Some basic functions used in the chrisrichardmiles library. \n",
    "\n",
    "The main functions of interest are: \n",
    " * `mkdirs_data` to initialize the data directory structure\n",
    " * `get_file_cols_dict` to make a json and/or dictionary of all features available\n",
    " * `save_file` to save features with the data types as the top row of the csv\n",
    " * `load_file` and `load_features` to load in features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def mkdirs_data(data_dir_name: str='data') -> None: \n",
    "    \"\"\"Initializes the data directory structure\"\"\"\n",
    "    os.makedirs(f'{data_dir_name}/raw', exist_ok=True)\n",
    "    os.makedirs(f'{data_dir_name}/interim', exist_ok=True)\n",
    "    os.makedirs(f'{data_dir_name}/features', exist_ok=True)\n",
    "    os.makedirs(f'{data_dir_name}/models', exist_ok=True)\n",
    "    \n",
    "@call_parse\n",
    "def cli_mkdirs_data(data_dir_name: Param('Name of data folder', str)='data') -> None: \n",
    "    mkdirs_data(data_dir_name)\n",
    "    \n",
    "@call_parse\n",
    "def cp_tree(dir1: Param('path to directory to copy', str), \n",
    "            dir2: Param('path to endpoint', str)): \n",
    "    shutil.copytree(dir1, dir2, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def download_kaggle_data(comp_name:str=None):\n",
    "    \"\"\"Downloads competition data using the kaggle api\"\"\"\n",
    "    mkdirs_data()\n",
    "    os.system(f'kaggle competitions download -c {comp_name}')\n",
    "    zf = zipfile.ZipFile(f'{comp_name}.zip')\n",
    "    zf.extractall(f'data/raw')\n",
    "    os.remove(f'{comp_name}.zip')\n",
    "    \n",
    "@call_parse\n",
    "def cli_download_kaggle_data(comp_name:Param('name of kaggle competition', str)=None):\n",
    "    download_kaggle_data(comp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading flies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevent saving over files \n",
    "\n",
    "In order to to make sure we don't accidentally save over a file with the the same name, we have some functions to ensures that certain strings and paths are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def make_unique(name: str, names: \"list or set or dict\") -> str: \n",
    "    \"\"\"Returns name with (x)_ prefix if `name` already in `names`. \n",
    "    This is useful when you want to make sure you don't save over\n",
    "    existing data with the same key `name`.\n",
    "    \"\"\"\n",
    "    if name in names:\n",
    "        x = 1\n",
    "        while f'({x})_' + name in names: x += 1\n",
    "        name = f'({x})_' + name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_unique('d', ['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1)_a'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_unique('a', ['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert make_unique('d', ['a', 'b', 'c']) == 'd'\n",
    "assert make_unique('chris', ['chris', 'dan', 'bill']) == '(1)_chris'\n",
    "assert make_unique('chris', ['chris', 'dan', 'bill', '(1)_chris']) == '(2)_chris'\n",
    "assert make_unique('chris', set(['chris', 'dan', 'bill', '(1)_chris'])) == '(2)_chris'\n",
    "assert make_unique('a', {'a': 1, 'b': 2, 'c': 3}) == '(1)_a'\n",
    "assert make_unique('d', {'a': 1, 'b': 2, 'c': 3}) == 'd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def make_unique_path(path):  \n",
    "    \"\"\"Returns path with prefix '(n)_' before the last element in \n",
    "    path if it is a duplicate. \n",
    "    \"\"\"\n",
    "    pre_path, file_name = os.path.split(path)\n",
    "    file_name = make_unique(file_name, os.listdir(pre_path or '.'))\n",
    "    return os.path.join(pre_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/tmp.csv\n",
      "tmp/(1)_tmp.csv\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('tmp', exist_ok=True)\n",
    "print(make_unique_path('tmp/tmp.csv'))\n",
    "open('tmp/tmp.csv', 'w').close()\n",
    "print(make_unique_path('tmp/tmp.csv'))\n",
    "shutil.rmtree('tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def save_file(df: pd.DataFrame, \n",
    "              path: str, \n",
    "              usecols: list=None,\n",
    "              save_index: bool=False, \n",
    "              save_dtypes: bool=True, \n",
    "              pickle: bool=False) -> None:\n",
    "    \"\"\"Saves `df` to `path` with dtypes as top column if `save_dtypes` \n",
    "    is set to True. Load a files in this structure with `load_file`\n",
    "    \"\"\"\n",
    "    if pickle: \n",
    "        usecols = usecols if usecols else list(df)\n",
    "        path_dir = os.path.split(path)[0] if path.endswith('.csv') else path # For M5 project maintenence\n",
    "        for col in list(df): \n",
    "            df[[col]].to_pickle(os.path.join(path_dir, col + '.pkl'))\n",
    "        return \n",
    "    \n",
    "    path = make_unique_path(path)\n",
    "    if save_dtypes:\n",
    "        df_tmp = df.iloc[[0], :]\n",
    "        if usecols: df_tmp = df_tmp.loc[:, usecols]\n",
    "        if save_index: \n",
    "            df_tmp.reset_index(inplace=True)\n",
    "        df_dtypes = df_tmp.dtypes.to_frame().T\n",
    "        df_dtypes.to_csv(path, index=False)\n",
    "        df.to_csv(path, mode='a', index=save_index, header=False, \n",
    "                  columns=usecols)\n",
    "    else: \n",
    "        df.to_csv(path, index=save_index, columns=usecols)\n",
    "        \n",
    "def load_file(path: str, load_dtypes=True, usecols: list=None) -> pd.DataFrame:\n",
    "    \"\"\"Loads a file into a DataFrame from `path` with dtypes \n",
    "    taken from the top column if `load_dtypes` is set to True. \n",
    "    Loads a files in the structure created with `save_file`.\n",
    "    \"\"\"\n",
    "    if path.endswith('pkl'): \n",
    "        df = pd.read_pickle(path)\n",
    "        return df[usecols] if usecols else df\n",
    "    \n",
    "    if load_dtypes:\n",
    "        dtypes = pd.read_csv(path, nrows=1).iloc[0].to_dict()\n",
    "        return pd.read_csv(path, skiprows=[1], dtype=dtypes, usecols=usecols)\n",
    "    else:\n",
    "        return pd.read_csv(path, usecols=usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the the dataframe to csv with the dtypes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a       int32\n",
       "b    category\n",
       "c     float16\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the csv has the datatypes as the top line when we read it in\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int32</td>\n",
       "      <td>category</td>\n",
       "      <td>float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>foo</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>bar</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a         b        c\n",
       "0  int32  category  float16\n",
       "1      1       foo      1.2\n",
       "2      2       bar      3.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can use `load_file` to read in the csv with the right dtypes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>foo</td>\n",
       "      <td>1.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bar</td>\n",
       "      <td>3.300781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a    b         c\n",
       "0  1  foo  1.200195\n",
       "1  2  bar  3.300781"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "a       int32\n",
       "b    category\n",
       "c     float16\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example\n",
    "df = pd.DataFrame({'a': [1, 2], 'b': ['foo', 'bar'], 'c': [1.2, 3.3]})\n",
    "df = df.astype(dict(zip(['a', 'b', 'c'], ['int32', 'category', np.float16])))\n",
    "print('Saving the the dataframe to csv with the dtypes')\n",
    "display(df.dtypes)\n",
    "save_file(df, 'tmp.csv', pickle=False)\n",
    "print('Now the csv has the datatypes as the top line when we read it in')\n",
    "display(pd.read_csv('tmp.csv'))\n",
    "\n",
    "print('We can use `load_file` to read in the csv with the right dtypes')\n",
    "display(load_file('tmp.csv'))\n",
    "display(load_file('tmp.csv').dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>foo</td>\n",
       "      <td>1.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bar</td>\n",
       "      <td>3.300781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a    b         c\n",
       "0  1  foo  1.200195\n",
       "1  2  bar  3.300781"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_file(df, '.', pickle=True)\n",
    "display(pd.concat([load_file(x + '.pkl') for x in 'abc'], axis=1))\n",
    "!rm a.pkl b.pkl c.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.300781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  a         c\n",
       "0      0  1  1.200195\n",
       "1      1  2  3.300781"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_file(df, 'tmp2.csv', usecols=['a', 'c'], save_index=True, pickle=False)\n",
    "load_file('tmp2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm tmp*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a dictionary and json with file names as keys and list of column names as values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".devcontainer.json\n",
      ".git\n",
      ".gitattributes\n",
      ".gitconfig\n",
      ".github\n",
      ".gitignore\n",
      ".ipynb_checkpoints\n",
      ".pypirc\n",
      "00_core.ipynb\n",
      "CONTRIBUTING.md\n",
      "LICENSE\n",
      "MANIFEST.in\n",
      "Makefile\n",
      "README.md\n",
      "chrisrichardmiles\n",
      "chrisrichardmiles.egg-info\n",
      "data\n",
      "docker-compose.yml\n",
      "docs\n",
      "index.ipynb\n",
      "log.log\n",
      "projects\n",
      "settings.ini\n",
      "setup.py\n",
      "small_data\n"
     ]
    }
   ],
   "source": [
    "for file in sorted(os.listdir('.')):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def get_file_cols_dict(path: str='.', \n",
    "                       path_json: str='', \n",
    "                       ignore_cols: list=['index']):\n",
    "    \"\"\"Explores `path` and returns a dictionary of file names and their columns\n",
    "    for each file in `path`. Only file names that end with \n",
    "    '.csv' and '.pkl' will be considered. Pickle file names\n",
    "    will go in the 'pickles' key of the returned dictionary.\n",
    "    Csv files will see their file name saved as a key with \n",
    "    a list of their column names saved as the corresponding \n",
    "    value.\n",
    "    \"\"\"\n",
    "    \n",
    "    d = {}\n",
    "    for file in sorted(os.listdir(path)): \n",
    "        if file.endswith('.csv'): \n",
    "            cols = pd.read_csv(os.path.join(path, file), nrows=0).columns.tolist()\n",
    "            d[file] = [c for c in cols if c not in ignore_cols]\n",
    "        if file.endswith('.pkl'): \n",
    "            d.setdefault('pickles', []).append(file)\n",
    "    if path_json: \n",
    "        with open(path_json, 'w') as path_json: \n",
    "            json.dump(d, path_json, indent=0)\n",
    "    return d\n",
    "\n",
    "@call_parse\n",
    "def fe_dict(path: Param('path to directory with files', str)='data/features', \n",
    "            path_json: Param('path to json for saving dict', str)='fe_dict.json'):\n",
    "    get_file_cols_dict(path, path_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'feat_1': [1,2,2,4], 'feat_2': [1,1,3,3], 'feat_3': [1,4,3,3]})\n",
    "df2 = pd.DataFrame({'shift_feat_4': [1,9,2,4], 'shift_feat_5': [1,1,3,9], 'shift_feat_6': [1,9,3,3]})\n",
    "df3 = pd.DataFrame({'feat_7': [1,7,2,4], 'feat_8': [7,1,3,3], 'feat_9': [1,7,3,3]})\n",
    "df4 = pd.DataFrame({'feat_10': [1,7,2,4], 'feat_11': [7,1,3,3], 'feat_12': [1,7,3,3], \n",
    "                    'feat_13': ['a', 'b', 'c', 'd']})\n",
    "df4.feat_10 = df4.feat_10.astype('int8')\n",
    "df4.feat_13 = df4.feat_13.astype('category')\n",
    "\n",
    "save_file(df1, 'features_1.csv', pickle=False)\n",
    "save_file(df2, 'shift_features_2.csv', pickle=False)\n",
    "save_file(df3, 'features_3.csv', pickle=False)\n",
    "save_file(df4, 'features_4.csv', save_index=True, pickle=False)\n",
    "save_file(df3, 'features_3_less_cols.csv', usecols=['feat_7'], pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features_1.csv': ['feat_1', 'feat_2', 'feat_3'],\n",
       " 'features_3.csv': ['feat_7', 'feat_8', 'feat_9'],\n",
       " 'features_3_less_cols.csv': ['feat_7'],\n",
       " 'features_4.csv': ['feat_10', 'feat_11', 'feat_12', 'feat_13'],\n",
       " 'shift_features_2.csv': ['shift_feat_4', 'shift_feat_5', 'shift_feat_6']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_cols_dict('.', path_json='tmp_features.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features_1.csv': ['feat_1', 'feat_2', 'feat_3'],\n",
       " 'features_3.csv': ['feat_7', 'feat_8', 'feat_9'],\n",
       " 'features_3_less_cols.csv': ['feat_7'],\n",
       " 'features_4.csv': ['feat_10', 'feat_11', 'feat_12', 'feat_13'],\n",
       " 'shift_features_2.csv': ['shift_feat_4', 'shift_feat_5', 'shift_feat_6']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_file_cols_dict('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_features(path_features: Union[list, str],\n",
    "                  dict_features: Union[dict, str]=None,\n",
    "                  shift_index: int=0, \n",
    "                  reindex_with: \"list like\"=None,\n",
    "                  shift_prefix: Union[str, bool]='shift',\n",
    "                  load_dtypes: bool=True,\n",
    "                  features: list=None,\n",
    "                  pickle: bool=True) -> pd.DataFrame: \n",
    "    \"\"\"Loads the features selected in `dict_features` into a dataframe.\n",
    "    `dict_features` Must be a module that is located in the working \n",
    "    directory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_features: Union[list, str]\n",
    "        path to the folder that holds the features files\n",
    "        \n",
    "    dict_features: Union[dict, str]\n",
    "        dict or path to the json that holds the feature dictionary. Set this\n",
    "        parameter to None if you want to load all csv files, optionally\n",
    "        filtered by `features` list.\n",
    "        \n",
    "    shift_index: int=0\n",
    "        used to shift columns of files starting with `shift_prefix` when training \n",
    "        for prediction periods past day 1.\n",
    "        \n",
    "    shift_prefix: Union[str, bool]='shift'\n",
    "        The prefix of files that should have their index shifted for \n",
    "        proper lag alignment in time series prediction.\n",
    "        Set this to the boolean True to shift index of all files.\n",
    "        \n",
    "    reindex_with: \"list like\"=None \n",
    "        Use anything that works with df.reindex(reindex_with). This is used when you \n",
    "        only need rows for a subset of the orginal data. \n",
    "        \n",
    "    load_dtype: bool=True\n",
    "        This will use the first row for dtypes\n",
    "        \n",
    "    features: list=None\n",
    "        An explicit list of features that you want. Only these will be loaded \n",
    "        if provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(path_features) == list: \n",
    "        df = pd.DataFrame()\n",
    "        for pf in path_features: \n",
    "            args = (pf, dict_features, shift_index, reindex_with, shift_prefix, load_dtypes, features, load_all)\n",
    "            df = pd.concat([df, load_features(*args)], axis=1)\n",
    "        return df if df else None\n",
    "    \n",
    "    if type(dict_features) == str:\n",
    "        with open(dict_features, 'r') as file:\n",
    "            dict_features = json.load(file)\n",
    "    \n",
    "    if not dict_features:\n",
    "        dict_features = get_file_cols_dict(path_features)\n",
    "    \n",
    "    dfs = []\n",
    "    dict_features = dict_features.copy()\n",
    "    for pkl in dict_features.pop('pickles', []): \n",
    "        if features and pkl[:-4] not in features: continue\n",
    "        df = pd.read_pickle(os.path.join(path_features, pkl))\n",
    "        if type(reindex_with) != None: df = df.reindex(reindex_with)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    for pkl in dict_features.pop('shift_pickles', []): \n",
    "        if features and pkl[:-4] not in features: continue\n",
    "        df = pd.read_pickle(os.path.join(path_features, pkl))\n",
    "        df.index = df.index + shift_index\n",
    "        if type(reindex_with) != None: df = df.reindex(reindex_with)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    # Filter dict to keep only keys that are in `path_features`\n",
    "    dict_features = {k: v for k, v in dict_features.items() if k in os.listdir(path_features)}\n",
    "        \n",
    "    for file, f_list in dict_features.items(): \n",
    "        if features: f_list = [f for f in f_list if f in features]\n",
    "        path = os.path.join(path_features, file)\n",
    "        df = load_file(path, load_dtypes, f_list)\n",
    "        if 'index' in df.columns: df.set_index('index', inplace=True)\n",
    "        if file.startswith(shift_prefix) and shift_index: \n",
    "            df.index = df.index + shift_index\n",
    "        if type(reindex_with) != None: df = df.reindex(reindex_with)\n",
    "        dfs.append(df)\n",
    "    if not dfs: \n",
    "        logging.info(\"No data was loaded\")\n",
    "        print(\"No data was loaded\")\n",
    "    return pd.concat(dfs, axis=1) if dfs else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"load_features\" class=\"doc_header\"><code>load_features</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>load_features</code>(**`path_features`**:`Union`\\[`list`, `str`\\], **`dict_features`**:`Union`\\[`dict`, `str`\\]=*`None`*, **`shift_index`**:`int`=*`0`*, **`reindex_with`**:`list like`=*`None`*, **`shift_prefix`**:`Union`\\[`str`, `bool`\\]=*`'shift'`*, **`load_dtypes`**:`bool`=*`True`*, **`features`**:`list`=*`None`*, **`pickle`**:`bool`=*`True`*)\n",
       "\n",
       "Loads the features selected in `dict_features` into a dataframe.\n",
       "`dict_features` Must be a module that is located in the working \n",
       "directory.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "path_features: Union[list, str]\n",
       "    path to the folder that holds the features files\n",
       "    \n",
       "dict_features: Union[dict, str]\n",
       "    dict or path to the json that holds the feature dictionary. Set this\n",
       "    parameter to None if you want to load all csv files, optionally\n",
       "    filtered by `features` list.\n",
       "    \n",
       "shift_index: int=0\n",
       "    used to shift columns of files starting with `shift_prefix` when training \n",
       "    for prediction periods past day 1.\n",
       "    \n",
       "shift_prefix: Union[str, bool]='shift'\n",
       "    The prefix of files that should have their index shifted for \n",
       "    proper lag alignment in time series prediction.\n",
       "    Set this to the boolean True to shift index of all files.\n",
       "    \n",
       "reindex_with: \"list like\"=None \n",
       "    Use anything that works with df.reindex(reindex_with). This is used when you \n",
       "    only need rows for a subset of the orginal data. \n",
       "    \n",
       "load_dtype: bool=True\n",
       "    This will use the first row for dtypes\n",
       "    \n",
       "features: list=None\n",
       "    An explicit list of features that you want. Only these will be loaded \n",
       "    if provided."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "show_doc(load_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily load in our features with the correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>shift_feat_4</th>\n",
       "      <th>shift_feat_5</th>\n",
       "      <th>shift_feat_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2  feat_3  feat_7  feat_8  feat_9  feat_7  feat_10  feat_11  \\\n",
       "0       1       1       1       1       7       1       1        1        7   \n",
       "1       2       1       4       7       1       7       7        7        1   \n",
       "2       2       3       3       2       3       3       2        2        3   \n",
       "3       4       3       3       4       3       3       4        4        3   \n",
       "\n",
       "   feat_12 feat_13  shift_feat_4  shift_feat_5  shift_feat_6  \n",
       "0        1       a             1             1             1  \n",
       "1        7       b             9             1             9  \n",
       "2        3       c             2             3             3  \n",
       "3        3       d             4             9             3  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_features('.', 'tmp_features.json', pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_3  feat_10 feat_13\n",
       "0       1        1       a\n",
       "1       4        7       b\n",
       "2       3        2       c\n",
       "3       3        4       d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "feat_3        int64\n",
       "feat_10        int8\n",
       "feat_13    category\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = load_features('.', 'tmp_features.json', features=['feat_3', 'feat_10', 'feat_13'], pickle=False)\n",
    "display(df)\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we need to shift the index so that our lag features are in the correct allignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>shift_feat_4</th>\n",
       "      <th>shift_feat_5</th>\n",
       "      <th>shift_feat_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>c</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>d</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2  feat_3  feat_7  feat_8  feat_9  feat_7  feat_10  feat_11  \\\n",
       "0     1.0     1.0     1.0     1.0     7.0     1.0     1.0      1.0      7.0   \n",
       "1     2.0     1.0     4.0     7.0     1.0     7.0     7.0      7.0      1.0   \n",
       "2     2.0     3.0     3.0     2.0     3.0     3.0     2.0      2.0      3.0   \n",
       "3     4.0     3.0     3.0     4.0     3.0     3.0     4.0      4.0      3.0   \n",
       "4     NaN     NaN     NaN     NaN     NaN     NaN     NaN      NaN      NaN   \n",
       "\n",
       "   feat_12 feat_13  shift_feat_4  shift_feat_5  shift_feat_6  \n",
       "0      1.0       a           NaN           NaN           NaN  \n",
       "1      7.0       b           1.0           1.0           1.0  \n",
       "2      3.0       c           9.0           1.0           9.0  \n",
       "3      3.0       d           2.0           3.0           3.0  \n",
       "4      NaN     NaN           4.0           9.0           3.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_features('.', 'tmp_features.json', shift_index=1, pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we are loading features for a subset of the data so we only need to load the rows associated with certain indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>shift_feat_4</th>\n",
       "      <th>shift_feat_5</th>\n",
       "      <th>shift_feat_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2  feat_3  feat_7  feat_8  feat_9  feat_7  feat_10  feat_11  \\\n",
       "1       2       1       4       7       1       7       7        7        1   \n",
       "3       4       3       3       4       3       3       4        4        3   \n",
       "\n",
       "   feat_12 feat_13  shift_feat_4  shift_feat_5  shift_feat_6  \n",
       "1        7       b             1             1             1  \n",
       "3        3       d             2             3             3  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_features('.', 'tmp_features.json', shift_index=1, reindex_with=[1, 3], pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a copy of the feature module, easily comment out features we don't want, and use this to load features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp_features_1.json'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copyfile('tmp_features.json', 'tmp_features_1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open `tmp_features_1.json` and delete features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "\"features_1.csv\": [\r\n",
      "\"feat_1\",\r\n",
      "\"feat_2\",\r\n",
      "\"feat_3\"\r\n",
      "],\r\n",
      "\"features_3.csv\": [\r\n",
      "\"feat_7\",\r\n",
      "\"feat_8\",\r\n",
      "\"feat_9\"\r\n",
      "],\r\n",
      "\"features_3_less_cols.csv\": [\r\n",
      "\"feat_7\"\r\n",
      "],\r\n",
      "\"features_4.csv\": [\r\n",
      "\"feat_10\",\r\n",
      "\"feat_11\",\r\n",
      "\"feat_12\",\r\n",
      "\"feat_13\"\r\n",
      "],\r\n",
      "\"shift_features_2.csv\": [\r\n",
      "\"shift_feat_4\",\r\n",
      "\"shift_feat_5\",\r\n",
      "\"shift_feat_6\"\r\n",
      "]\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat tmp_features_1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>shift_feat_4</th>\n",
       "      <th>shift_feat_5</th>\n",
       "      <th>shift_feat_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2  feat_3  feat_7  feat_8  feat_9  feat_7  feat_10  feat_11  \\\n",
       "0       1       1       1       1       7       1       1        1        7   \n",
       "1       2       1       4       7       1       7       7        7        1   \n",
       "2       2       3       3       2       3       3       2        2        3   \n",
       "3       4       3       3       4       3       3       4        4        3   \n",
       "\n",
       "   feat_12 feat_13  shift_feat_4  shift_feat_5  shift_feat_6  \n",
       "0        1       a             1             1             1  \n",
       "1        7       b             9             1             9  \n",
       "2        3       c             2             3             3  \n",
       "3        3       d             4             9             3  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_features('.', 'tmp_features_1.json', pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.csv\n",
    "!rm tmp*.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed and memory functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paralel runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pool_func(function, input_list: list, verbose=False, n_cpu=99):\n",
    "    \"\"\"Uses the Pool function from the package 'multiprocessing'\n",
    "    to run `function` over the list `input_list`.  The `function`\n",
    "    should only take \"\"\"\n",
    "\n",
    "    n_cpu = min(n_cpu, cpu_count())\n",
    "    if verbose:\n",
    "        print('#############################################')\n",
    "        print('Pooling function: ')\n",
    "        if hasattr(function, '__name__'):\n",
    "            print(function.__name__)\n",
    "        print(f'{n_cpu} of {cpu_count()} cpus used')\n",
    "        print('Number of function calls: ', len(input_list))\n",
    "\n",
    "    start = time.time()\n",
    "    pool = Pool(n_cpu)\n",
    "    res = pool.map(function, input_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if verbose:\n",
    "        print('Time taken:',\n",
    "              round((time.time() - start) / 60, 2),\n",
    "              'minutes')\n",
    "    return res if res else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "Pooling function: \n",
      "f\n",
      "16 of 16 cpus used\n",
      "Number of function calls:  20\n",
      "Time taken: 0.0 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x): return x * 5\n",
    "pool_func(f, list(range(20)), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"Converts numeric columns to smallest datatype that preserves information\"\"\"\n",
    "    \n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                       df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def merge_by_concat(df1, df2, merge_on):\n",
    "    if type(merge_on) == str: merge_on = [merge_on]\n",
    "    merged_df = df1[merge_on]\n",
    "    merged_df = merged_df.merge(df2, on=merge_on, how='left')\n",
    "    new_columns = [col for col in list(merged_df) if col not in merge_on]\n",
    "    df1 = pd.concat([df1, merged_df[new_columns]], axis=1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_memory_usage():\n",
    "    \"\"\"Returns RAM usage in gigabytes\n",
    "    \n",
    "    Explanation of code\n",
    "    -------------------\n",
    "    # getpid: gets the process id number.\n",
    "    # psutil.process gets that process with a certain pid.\n",
    "    # .memory_info() describes notebook memory usage.\n",
    "    # [0] gets the rss resident state size of (process I think) in bytes.\n",
    "    # /2.**30 converts output from bytes to gigabytes\n",
    "    \"\"\"\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    \"\"\"Reformats `num`, which is num bytes\"\"\"\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def time_taken(start_time: float=0, time_elapsed: float=None): \n",
    "    \"\"\"Returns a string with the time elapsed from `start_time` \n",
    "    in a nice format. If `time_elapsed` is provided, we ignore \n",
    "    the start time. \n",
    "    \n",
    "    `start_time` should come from by calling the time module: \n",
    "    start_time = time.time()\n",
    "    \"\"\"\n",
    "    \n",
    "    import time\n",
    "    if not time_elapsed: \n",
    "        time_elapsed = int(time.time() - start_time)\n",
    "    else:\n",
    "        time_elapsed = int(time_elapsed)\n",
    "        \n",
    "    m, s = divmod(time_elapsed, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    if d: return f'Time taken: {d} days {h} hours {m} minutes {s} seconds'\n",
    "    if h: return f'Time taken: {h} hours {m} minutes {s} seconds'\n",
    "    if m: return f'Time taken: {m} minutes {s} seconds'\n",
    "    if s: return f'Time taken: {s} seconds'\n",
    "    return 'Time taken: 0 seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Time taken: 2 seconds'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "time.sleep(2)\n",
    "time_taken(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Time taken: 1 hours 1 minutes 6 seconds'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_taken(time_elapsed=3666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted 01_brief_eda.ipynb.\n",
      "Converted 02_WRMSSE_metric.ipynb.\n",
      "Converted 03_feature_engineering.ipynb.\n",
      "Converted 04_out_of_stock_detection.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted training_day_by_day_models.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
