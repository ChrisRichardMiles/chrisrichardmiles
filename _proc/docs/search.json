[
  {
    "objectID": "projects/optiver/opt-error-analysis.html",
    "href": "projects/optiver/opt-error-analysis.html",
    "title": "Error analysis",
    "section": "",
    "text": "About 20 percent of the rows account for 75 percent of the total error.\nWorst scores due to bad stocks or bad time_ids? When comparing errors aggregated over stocks and errors aggregated over time_ids, the time_ids show a much higher variance than stock_ids. This could be due to fast changing shocks to the market, imposed on all stocks at once. We could possibly detect these shocks if they occur in the last minute or two of the input data window.\nThe worst scoring time_id is 25504 and the worst scoring stock is stock_31.\nThe worst scoring rows are usually due to an extremely low target, since the target is used as a divisor in the competition metric, the rmspe. From the plots I have made, I cannot see any clear signals that could warn me of an extremely low target.\nAction to take: Look for aggregations across time_ids that could possibly help our models detect periods of low targets.\n\n\n#all_no_test\nimport os\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.cluster import KMeans\n\nimport opt_utils as opt\nfrom opt_utils import * \n\nDATA_RAW = 'input/'\nMODEL = 'dart_model'\nTRAIN = 'dart_model/enc_p13_train.pkl'\nsns.set()\n\ndef rdf(train): \n    \"\"\"Adds squared percentage error for each row for our training data.\"\"\"\n    train['spe'] = ((train['target'] - train['pred']) / train['target']) ** 2\n    return np.sqrt((train['spe'].sum()) / train.shape[0])\n\n\ntrain = pd.read_pickle(TRAIN)\noof_preds = np.load(os.path.join(MODEL, 'oof_predictions.npy'))\ntrain['pred'] = oof_preds\ntrain['spe'] = ((train['target'] - train['pred']) / train['target']) ** 2\ntrain['raw_error'] = train['pred'] - train['target']\ntrain['rv'] = train['log_return_realized_volatility']\nprint(rdf(train))\ntrain.head(3)\n\n0.21259060811686517\n\n\n/home/c/miniconda3/envs/opt_nb/lib/python3.7/site-packages/ipykernel_launcher.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n  after removing the cwd from sys.path.\n/home/c/miniconda3/envs/opt_nb/lib/python3.7/site-packages/ipykernel_launcher.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n  \"\"\"\n/home/c/miniconda3/envs/opt_nb/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n  \n\n\n\n\n\n\n  \n    \n      \n      row_id\n      stock_id\n      time_id\n      target\n      fold\n      log_return_max_sub_min\n      log_return_std\n      log_return_realized_volatility\n      log_return_mean_decay\n      log_return_mean_decay_flip\n      ...\n      stock_id_order_size_mean_mean\n      stock_id_order_size_mean_std\n      stock_id_spread_mean_decay_95_mean\n      stock_id_spread_mean_decay_95_std\n      stock_id_spread_pct_momentum_mean\n      stock_id_spread_pct_momentum_std\n      pred\n      spe\n      raw_error\n      rv\n    \n  \n  \n    \n      0\n      0-5\n      0\n      5\n      0.004136\n      1.0\n      0.001945\n      0.000184\n      0.004499\n      0.000002\n      1.640986e-05\n      ...\n      30.978695\n      9.120817\n      0.000964\n      0.000868\n      0.973997\n      0.251807\n      0.003911\n      0.002965\n      -0.000225\n      0.004499\n    \n    \n      1\n      0-11\n      0\n      11\n      0.001445\n      0.0\n      0.000872\n      0.000049\n      0.001204\n      -0.000002\n      1.816128e-08\n      ...\n      30.978695\n      9.120817\n      0.000964\n      0.000868\n      0.973997\n      0.251807\n      0.001534\n      0.003801\n      0.000089\n      0.001204\n    \n    \n      2\n      0-16\n      0\n      16\n      0.002168\n      4.0\n      0.001583\n      0.000097\n      0.002369\n      -0.000006\n      4.263426e-06\n      ...\n      30.978695\n      9.120817\n      0.000964\n      0.000868\n      0.973997\n      0.251807\n      0.002236\n      0.000988\n      0.000068\n      0.002369\n    \n  \n\n3 rows × 372 columns\n\n\n\nAdding the ratio of the volume of shares traded to the average total bid_size and ask_size because I think it could be important\n\ntrain['ratio'] = train.size_sum / train.sum_bid_ask_mean\ntrain[['ratio']].corrwith(train['target'])\n\n/home/c/miniconda3/envs/opt_nb/lib/python3.7/site-packages/ipykernel_launcher.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n  \"\"\"Entry point for launching an IPython kernel.\n\n\nratio    0.022022\ndtype: float64\n\n\n\ntop_err = train.sort_values('spe', ascending=False)\n\n\ntop_err[:100].raw_error.hist()\nplt.title('top error histogram')\nplt.show()\n\n\n\n\n\ntop_err[:100]['target'].mean()\n\n0.0008222269300000001\n\n\n\ntrain.columns.tolist()\n\n['row_id',\n 'stock_id',\n 'time_id',\n 'target',\n 'fold',\n 'log_return_max_sub_min',\n 'log_return_std',\n 'log_return_realized_volatility',\n 'log_return_mean_decay',\n 'log_return_mean_decay_flip',\n 'is_pos_return_std',\n 'is_pos_return_mean_decay',\n 'is_pos_return_mean_decay_flip',\n 'is_neg_return_std',\n 'is_neg_return_mean_decay',\n 'is_neg_return_mean_decay_flip',\n 'abs_log_return_max_sub_min',\n 'abs_log_return_std',\n 'abs_log_return_sum',\n 'abs_log_return_mean_decay',\n 'abs_log_return_mean_decay_flip',\n 'log_return_2_max_sub_min',\n 'log_return_2_std',\n 'log_return_2_realized_volatility',\n 'log_return_2_mean_decay',\n 'log_return_2_mean_decay_flip',\n 'is_pos_return_2_std',\n 'is_pos_return_2_mean_decay',\n 'is_pos_return_2_mean_decay_flip',\n 'is_neg_return_2_std',\n 'is_neg_return_2_mean_decay',\n 'is_neg_return_2_mean_decay_flip',\n 'abs_log_return_2_max_sub_min',\n 'abs_log_return_2_std',\n 'abs_log_return_2_sum',\n 'abs_log_return_2_mean_decay',\n 'abs_log_return_2_mean_decay_flip',\n 'sum_bid_max_sub_min',\n 'sum_bid_std',\n 'sum_bid_sum',\n 'sum_bid_mean_decay',\n 'sum_bid_mean_decay_flip',\n 'sum_ask_max_sub_min',\n 'sum_ask_std',\n 'sum_ask_sum',\n 'sum_ask_mean_decay',\n 'sum_ask_mean_decay_flip',\n 'size_spread_max_sub_min',\n 'size_spread_std',\n 'size_spread_mean',\n 'size_spread_mean_decay',\n 'size_spread_mean_decay_flip',\n 'size_spread_mean_decay_95',\n 'size_spread_mean_decay_flip_95',\n 'sum_bid_ask_max_sub_min',\n 'sum_bid_ask_std',\n 'sum_bid_ask_mean',\n 'sum_bid_ask_mean_decay',\n 'sum_bid_ask_mean_decay_flip',\n 'size_max_sub_min',\n 'size_std',\n 'size_mean',\n 'size_sum',\n 'size_mean_decay',\n 'size_mean_decay_flip',\n 'size_mean_decay_95',\n 'size_mean_decay_flip_95',\n 'size_norm_max_sub_min',\n 'size_norm_std',\n 'size_norm_mean',\n 'size_norm_sum',\n 'size_norm_mean_decay',\n 'size_norm_mean_decay_flip',\n 'size_norm_mean_decay_95',\n 'size_norm_mean_decay_flip_95',\n 'order_norm_max_sub_min',\n 'order_norm_std',\n 'order_norm_mean',\n 'order_norm_sum',\n 'order_norm_mean_decay',\n 'order_norm_mean_decay_flip',\n 'order_norm_mean_decay_95',\n 'order_norm_mean_decay_flip_95',\n 'wap_max_sub_min',\n 'wap_std',\n 'wap_first',\n 'wap_last',\n 'wap_2_max_sub_min',\n 'wap_2_std',\n 'wap_2_first',\n 'wap_2_last',\n 'price_wap_diff_max_sub_min',\n 'price_wap_diff_std',\n 'price_wap_diff_mean',\n 'price_wap_diff_amin',\n 'price_wap_diff_amax',\n 'price_wap_diff_mean_decay',\n 'price_wap_diff_mean_decay_flip',\n 'price_wap_diff_2_max_sub_min',\n 'price_wap_diff_2_std',\n 'price_wap_diff_2_mean',\n 'price_wap_diff_2_amin',\n 'price_wap_diff_2_amax',\n 'price_wap_diff_2_mean_decay',\n 'price_wap_diff_2_mean_decay_flip',\n 'abs_price_wap_diff_max_sub_min',\n 'abs_price_wap_diff_std',\n 'abs_price_wap_diff_mean',\n 'abs_price_wap_diff_amin',\n 'abs_price_wap_diff_amax',\n 'abs_price_wap_diff_mean_decay',\n 'abs_price_wap_diff_mean_decay_flip',\n 'abs_price_wap_diff_2_max_sub_min',\n 'abs_price_wap_diff_2_std',\n 'abs_price_wap_diff_2_mean',\n 'abs_price_wap_diff_2_amin',\n 'abs_price_wap_diff_2_amax',\n 'abs_price_wap_diff_2_mean_decay',\n 'abs_price_wap_diff_2_mean_decay_flip',\n 'spread_max_sub_min',\n 'spread_std',\n 'spread_mean',\n 'spread_sum',\n 'spread_mean_decay',\n 'spread_mean_decay_flip',\n 'spread_mean_decay_95',\n 'spread_mean_decay_flip_95',\n 'spread_2_max_sub_min',\n 'spread_2_std',\n 'spread_2_mean',\n 'spread_2_sum',\n 'spread_2_mean_decay',\n 'spread_2_mean_decay_flip',\n 'spread_2_mean_decay_95',\n 'spread_2_mean_decay_flip_95',\n 'spread_pct_max_sub_min',\n 'spread_pct_std',\n 'spread_pct_mean',\n 'spread_pct_mean_decay',\n 'spread_pct_mean_decay_flip',\n 'spread_2_pct_max_sub_min',\n 'spread_2_pct_std',\n 'spread_2_pct_mean',\n 'spread_2_pct_mean_decay',\n 'spread_2_pct_mean_decay_flip',\n 'order_count_sum',\n 'order_size_sqaure_weighted_sum',\n 'bid_price_diff_count_unique',\n 'ask_price_diff_count_unique',\n 'mean_squares',\n 'order_size_mean',\n 'order_size_var_norm',\n 'ratio_sales_ask_bid_size',\n 'real_vol_min_1',\n 'real_vol_min_2',\n 'real_vol_min_3',\n 'real_vol_min_4',\n 'real_vol_min_5',\n 'real_vol_min_6',\n 'real_vol_min_7',\n 'real_vol_min_8',\n 'real_vol_min_9',\n 'real_vol_min_10',\n 'real_vol_mean_decay_0.99_1',\n 'real_vol_mean_decay_0.99_-1',\n 'real_vol_mean_decay_0.95_1',\n 'real_vol_mean_decay_0.95_-1',\n 'real_vol_mean_decay_0.9_1',\n 'real_vol_mean_decay_0.9_-1',\n 'real_vol_mean_decay_0.85_1',\n 'real_vol_mean_decay_0.85_-1',\n 'real_vol_mean_decay_0.75_1',\n 'real_vol_mean_decay_0.75_-1',\n 'real_vol_mean_decay_0.65_1',\n 'real_vol_mean_decay_0.65_-1',\n 'real_vol_mean_decay_0.55_1',\n 'real_vol_mean_decay_0.55_-1',\n 'real_vol_mean_decay_0.45_1',\n 'real_vol_mean_decay_0.45_-1',\n 'real_vol_min_1_2',\n 'real_vol_min_2_2',\n 'real_vol_min_3_2',\n 'real_vol_min_4_2',\n 'real_vol_min_5_2',\n 'real_vol_min_6_2',\n 'real_vol_min_7_2',\n 'real_vol_min_8_2',\n 'real_vol_min_9_2',\n 'real_vol_min_10_2',\n 'real_vol_mean_decay_0.99_1_2',\n 'real_vol_mean_decay_0.99_-1_2',\n 'real_vol_mean_decay_0.95_1_2',\n 'real_vol_mean_decay_0.95_-1_2',\n 'real_vol_mean_decay_0.9_1_2',\n 'real_vol_mean_decay_0.9_-1_2',\n 'real_vol_mean_decay_0.85_1_2',\n 'real_vol_mean_decay_0.85_-1_2',\n 'real_vol_mean_decay_0.75_1_2',\n 'real_vol_mean_decay_0.75_-1_2',\n 'real_vol_mean_decay_0.65_1_2',\n 'real_vol_mean_decay_0.65_-1_2',\n 'real_vol_mean_decay_0.55_1_2',\n 'real_vol_mean_decay_0.55_-1_2',\n 'real_vol_mean_decay_0.45_1_2',\n 'real_vol_mean_decay_0.45_-1_2',\n 'log_return_momentum',\n 'is_pos_return_momentum',\n 'is_neg_return_momentum',\n 'abs_log_return_momentum',\n 'log_return_2_momentum',\n 'is_pos_return_2_momentum',\n 'is_neg_return_2_momentum',\n 'abs_log_return_2_momentum',\n 'sum_bid_momentum',\n 'sum_ask_momentum',\n 'size_spread_momentum',\n 'size_spread_momentum_95',\n 'sum_bid_ask_momentum',\n 'size_momentum',\n 'size_momentum_95',\n 'size_norm_momentum',\n 'size_norm_momentum_95',\n 'order_norm_momentum',\n 'order_norm_momentum_95',\n 'price_wap_diff_momentum',\n 'price_wap_diff_2_momentum',\n 'abs_price_wap_diff_momentum',\n 'abs_price_wap_diff_2_momentum',\n 'spread_momentum',\n 'spread_momentum_95',\n 'spread_2_momentum',\n 'spread_2_momentum_95',\n 'spread_pct_momentum',\n 'spread_2_pct_momentum',\n 'real_momentum_0.99_-1',\n 'real_momentum_0.95_-1',\n 'real_momentum_0.9_-1',\n 'real_momentum_0.85_-1',\n 'real_momentum_0.75_-1',\n 'real_momentum_0.65_-1',\n 'real_momentum_0.55_-1',\n 'real_momentum_0.45_-1',\n 'real_momentum_0.99_-1_2',\n 'real_momentum_0.95_-1_2',\n 'real_momentum_0.9_-1_2',\n 'real_momentum_0.85_-1_2',\n 'real_momentum_0.75_-1_2',\n 'real_momentum_0.65_-1_2',\n 'real_momentum_0.55_-1_2',\n 'real_momentum_0.45_-1_2',\n 'wap_last-first',\n 'wap_2_last-first',\n 'bid_price1_real_vol',\n 'ask_price1_real_vol',\n 'bid_size1_real_vol',\n 'sum_bid_real_vol',\n 'sum_ask_real_vol',\n 'spread_pct_real_vol',\n 'spread_2_pct_real_vol',\n 'spread_real_vol',\n 'spread_2_real_vol',\n 'size_spread_real_vol',\n 'bid_ask_ratio_real_vol',\n 'total_bid_ask_ratio_real_vol',\n 'sum_bid_ask_real_vol',\n 'size_real_vol',\n 'price_real_vol',\n 'wap_2_real_vol',\n 'dummy1',\n 'dummy2',\n 'dummy3',\n 'real_vol_ratio_5_10',\n 'time_id_real_vol_ratio_5_10_mean',\n 'time_id_real_vol_ratio_5_10_std',\n 'time_id_real_vol_mean_decay_0.9_-1_mean',\n 'time_id_real_vol_mean_decay_0.9_-1_std',\n 'time_id_order_norm_momentum_mean',\n 'time_id_order_norm_momentum_std',\n 'time_id_real_vol_mean_decay_0.85_-1_mean',\n 'time_id_real_vol_mean_decay_0.85_-1_std',\n 'time_id_real_vol_mean_decay_0.99_1_mean',\n 'time_id_real_vol_mean_decay_0.99_1_std',\n 'time_id_real_vol_mean_decay_0.95_1_mean',\n 'time_id_real_vol_mean_decay_0.95_1_std',\n 'time_id_abs_price_wap_diff_mean_decay_flip_mean',\n 'time_id_abs_price_wap_diff_mean_decay_flip_std',\n 'time_id_abs_price_wap_diff_mean_decay_mean',\n 'time_id_abs_price_wap_diff_mean_decay_std',\n 'time_id_order_norm_sum_mean',\n 'time_id_order_norm_sum_std',\n 'time_id_real_vol_mean_decay_0.85_-1_2_mean',\n 'time_id_real_vol_mean_decay_0.85_-1_2_std',\n 'time_id_spread_mean_decay_flip_95_mean',\n 'time_id_spread_mean_decay_flip_95_std',\n 'time_id_real_vol_mean_decay_0.99_-1_mean',\n 'time_id_real_vol_mean_decay_0.99_-1_std',\n 'time_id_real_vol_mean_decay_0.75_-1_mean',\n 'time_id_real_vol_mean_decay_0.75_-1_std',\n 'time_id_spread_mean_mean',\n 'time_id_spread_mean_std',\n 'time_id_order_count_sum_mean',\n 'time_id_order_count_sum_std',\n 'time_id_bid_price_diff_count_unique_mean',\n 'time_id_bid_price_diff_count_unique_std',\n 'time_id_spread_momentum_mean',\n 'time_id_spread_momentum_std',\n 'time_id_size_mean_mean',\n 'time_id_size_mean_std',\n 'time_id_real_vol_mean_decay_0.95_-1_mean',\n 'time_id_real_vol_mean_decay_0.95_-1_std',\n 'time_id_order_norm_mean_decay_mean',\n 'time_id_order_norm_mean_decay_std',\n 'time_id_spread_2_mean_decay_95_mean',\n 'time_id_spread_2_mean_decay_95_std',\n 'time_id_order_size_mean_mean',\n 'time_id_order_size_mean_std',\n 'time_id_spread_mean_decay_95_mean',\n 'time_id_spread_mean_decay_95_std',\n 'time_id_spread_pct_momentum_mean',\n 'time_id_spread_pct_momentum_std',\n 'stock_id_real_vol_ratio_5_10_mean',\n 'stock_id_real_vol_ratio_5_10_std',\n 'stock_id_real_vol_mean_decay_0.9_-1_mean',\n 'stock_id_real_vol_mean_decay_0.9_-1_std',\n 'stock_id_order_norm_momentum_mean',\n 'stock_id_order_norm_momentum_std',\n 'stock_id_real_vol_mean_decay_0.85_-1_mean',\n 'stock_id_real_vol_mean_decay_0.85_-1_std',\n 'stock_id_real_vol_mean_decay_0.99_1_mean',\n 'stock_id_real_vol_mean_decay_0.99_1_std',\n 'stock_id_real_vol_mean_decay_0.95_1_mean',\n 'stock_id_real_vol_mean_decay_0.95_1_std',\n 'stock_id_abs_price_wap_diff_mean_decay_flip_mean',\n 'stock_id_abs_price_wap_diff_mean_decay_flip_std',\n 'stock_id_abs_price_wap_diff_mean_decay_mean',\n 'stock_id_abs_price_wap_diff_mean_decay_std',\n 'stock_id_order_norm_sum_mean',\n 'stock_id_order_norm_sum_std',\n 'stock_id_real_vol_mean_decay_0.85_-1_2_mean',\n 'stock_id_real_vol_mean_decay_0.85_-1_2_std',\n 'stock_id_spread_mean_decay_flip_95_mean',\n 'stock_id_spread_mean_decay_flip_95_std',\n 'stock_id_real_vol_mean_decay_0.99_-1_mean',\n 'stock_id_real_vol_mean_decay_0.99_-1_std',\n 'stock_id_real_vol_mean_decay_0.75_-1_mean',\n 'stock_id_real_vol_mean_decay_0.75_-1_std',\n 'stock_id_spread_mean_mean',\n 'stock_id_spread_mean_std',\n 'stock_id_order_count_sum_mean',\n 'stock_id_order_count_sum_std',\n 'stock_id_bid_price_diff_count_unique_mean',\n 'stock_id_bid_price_diff_count_unique_std',\n 'stock_id_spread_momentum_mean',\n 'stock_id_spread_momentum_std',\n 'stock_id_size_mean_mean',\n 'stock_id_size_mean_std',\n 'stock_id_real_vol_mean_decay_0.95_-1_mean',\n 'stock_id_real_vol_mean_decay_0.95_-1_std',\n 'stock_id_order_norm_mean_decay_mean',\n 'stock_id_order_norm_mean_decay_std',\n 'stock_id_spread_2_mean_decay_95_mean',\n 'stock_id_spread_2_mean_decay_95_std',\n 'stock_id_order_size_mean_mean',\n 'stock_id_order_size_mean_std',\n 'stock_id_spread_mean_decay_95_mean',\n 'stock_id_spread_mean_decay_95_std',\n 'stock_id_spread_pct_momentum_mean',\n 'stock_id_spread_pct_momentum_std',\n 'pred',\n 'spe',\n 'raw_error',\n 'rv',\n 'ratio']\n\n\n\ntrain[['ratio', 'target']].corr()\n\n\n\n\n\n  \n    \n      \n      ratio\n      target\n    \n  \n  \n    \n      ratio\n      1.000000\n      0.022022\n    \n    \n      target\n      0.022022\n      1.000000\n    \n  \n\n\n\n\n\ntop_err[:100]\n\n\n\n\n\n  \n    \n      \n      row_id\n      stock_id\n      time_id\n      target\n      fold\n      log_return_max_sub_min\n      log_return_std\n      log_return_realized_volatility\n      log_return_mean_decay\n      log_return_mean_decay_flip\n      ...\n      stock_id_order_size_mean_std\n      stock_id_spread_mean_decay_95_mean\n      stock_id_spread_mean_decay_95_std\n      stock_id_spread_pct_momentum_mean\n      stock_id_spread_pct_momentum_std\n      pred\n      spe\n      raw_error\n      rv\n      ratio\n    \n  \n  \n    \n      110278\n      31-25504\n      31\n      25504\n      0.000139\n      1.0\n      0.002713\n      0.000144\n      0.003528\n      -1.915218e-06\n      1.643631e-06\n      ...\n      396.636807\n      0.001207\n      0.000324\n      0.998620\n      0.015354\n      0.002351\n      253.353148\n      0.002212\n      0.003528\n      283529.781250\n    \n    \n      108254\n      31-8534\n      31\n      8534\n      0.000105\n      3.0\n      0.002760\n      0.000081\n      0.001986\n      2.102843e-06\n      5.847572e-07\n      ...\n      396.636807\n      0.001207\n      0.000324\n      0.998620\n      0.015354\n      0.000859\n      51.307601\n      0.000754\n      0.001986\n      111114.992188\n    \n    \n      110479\n      31-27174\n      31\n      27174\n      0.000123\n      1.0\n      0.002623\n      0.000109\n      0.002662\n      -2.080473e-06\n      1.383185e-05\n      ...\n      396.636807\n      0.001207\n      0.000324\n      0.998620\n      0.015354\n      0.000958\n      45.948679\n      0.000835\n      0.002662\n      60701.390625\n    \n    \n      275261\n      81-28319\n      81\n      28319\n      0.000389\n      0.0\n      0.002005\n      0.000123\n      0.003025\n      -2.650691e-06\n      -2.003285e-05\n      ...\n      34.043645\n      0.000658\n      0.000316\n      0.974421\n      0.216022\n      0.002968\n      43.877539\n      0.002579\n      0.003025\n      407105.843750\n    \n    \n      107425\n      31-1544\n      31\n      1544\n      0.000289\n      2.0\n      0.001773\n      0.000086\n      0.002103\n      5.815194e-07\n      1.080874e-05\n      ...\n      396.636807\n      0.001207\n      0.000324\n      0.998620\n      0.015354\n      0.001548\n      18.923841\n      0.001259\n      0.002103\n      172874.531250\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      351567\n      103-25687\n      103\n      25687\n      0.001166\n      0.0\n      0.002422\n      0.000152\n      0.003708\n      -1.011342e-06\n      -1.920315e-06\n      ...\n      9.959292\n      0.001149\n      0.000948\n      0.977414\n      0.233322\n      0.002908\n      2.235902\n      0.001743\n      0.003708\n      42375.414062\n    \n    \n      256160\n      75-28745\n      75\n      28745\n      0.002029\n      2.0\n      0.003652\n      0.000250\n      0.006107\n      5.880733e-06\n      -1.244763e-06\n      ...\n      12.042979\n      0.001547\n      0.001127\n      0.983532\n      0.244317\n      0.005063\n      2.235394\n      0.003034\n      0.006107\n      60402.402344\n    \n    \n      106640\n      30-27127\n      30\n      27127\n      0.001587\n      0.0\n      0.002852\n      0.000170\n      0.004155\n      1.102896e-05\n      1.145801e-05\n      ...\n      11.495466\n      0.000872\n      0.000876\n      0.975616\n      0.257962\n      0.003954\n      2.222999\n      0.002366\n      0.004155\n      23441.160156\n    \n    \n      281618\n      83-17058\n      83\n      17058\n      0.001092\n      0.0\n      0.001838\n      0.000102\n      0.002504\n      1.111177e-06\n      -1.198854e-05\n      ...\n      13.773025\n      0.000984\n      0.000752\n      0.980698\n      0.237261\n      0.002710\n      2.192483\n      0.001617\n      0.002504\n      46389.765625\n    \n    \n      132478\n      37-18628\n      37\n      18628\n      0.001349\n      3.0\n      0.002163\n      0.000221\n      0.005413\n      4.068129e-06\n      6.385957e-07\n      ...\n      7.233090\n      0.001578\n      0.000928\n      0.989780\n      0.250437\n      0.003342\n      2.185381\n      0.001994\n      0.005413\n      15415.371094\n    \n  \n\n100 rows × 373 columns\n\n\n\n\ntop_err[:100][['ratio', 'target']].corr()\n\n\n\n\n\n  \n    \n      \n      ratio\n      target\n    \n  \n  \n    \n      ratio\n      1.000000\n      0.218161\n    \n    \n      target\n      0.218161\n      1.000000"
  },
  {
    "objectID": "projects/optiver/opt-error-analysis.html#feature-correlation-with-the-target",
    "href": "projects/optiver/opt-error-analysis.html#feature-correlation-with-the-target",
    "title": "Error analysis",
    "section": "Feature correlation with the target",
    "text": "Feature correlation with the target\nLets see how well all the columns correlate with the target. All columns except ‘target’ and ‘pred’ are features that can be used for training\n\ntrain.corrwith(train['target']).abs().sort_values(ascending=False)[:20]\n\ntarget                            1.000000\npred                              0.922224\nreal_vol_mean_decay_0.85_-1       0.885936\nreal_vol_mean_decay_0.75_-1       0.885581\nreal_vol_mean_decay_0.9_-1        0.884346\nreal_vol_mean_decay_0.95_-1       0.881675\nreal_vol_mean_decay_0.65_-1       0.880945\nreal_vol_mean_decay_0.99_-1       0.878880\nreal_vol_mean_decay_0.99_1        0.877295\nreal_vol_mean_decay_0.85_-1_2     0.876040\nreal_vol_mean_decay_0.75_-1_2     0.875160\nreal_vol_mean_decay_0.9_-1_2      0.874569\nlog_return_realized_volatility    0.873777\nrv                                0.873777\nlog_return_std                    0.873740\nreal_vol_mean_decay_0.95_1        0.873627\nreal_vol_mean_decay_0.55_-1       0.873266\nreal_vol_mean_decay_0.95_-1_2     0.871917\nreal_vol_mean_decay_0.65_-1_2     0.869714\nreal_vol_mean_decay_0.99_-1_2     0.869073\ndtype: float64"
  },
  {
    "objectID": "projects/optiver/opt-error-analysis.html#error-distribution",
    "href": "projects/optiver/opt-error-analysis.html#error-distribution",
    "title": "Error analysis",
    "section": "Error distribution",
    "text": "Error distribution\n\nWhat is the general distribution of errors? Are they low or high variance?\nIf They have high variance, with a few very large errors, we may be able to identify some way of easily reducing these errors, which would have a large impact on our overall score.\n\nsns.kdeplot(train['spe'])\nplt.title('squared percentage error kernel density plot')\nplt.show()\n\n\n\n\nWhat the heck. This looks like I have one or a few large errors and most near zero.\n\ntrain['spe'].hist()\nplt.title('squared percentage error histogram')\nplt.show()\n\n\n\n\nLets see the highest and lowest scoreing rows. They will show that there are a small amount of rows that are greatly increasing the error.\n\ntrain['spe'].sort_values(ascending=False)\n\n110278    2.533531e+02\n108254    5.130760e+01\n110479    4.594868e+01\n275261    4.387754e+01\n107425    1.892384e+01\n              ...     \n15927     1.529692e-12\n335831    1.403667e-12\n346117    1.188800e-12\n277792    4.652826e-14\n259398    8.194316e-16\nName: spe, Length: 428932, dtype: float64\n\n\nLets look at the cumulative sum of errors to see how spread out the errors are.\n\ndf = train['spe'].sort_values().cumsum().reset_index(drop=True)\ndf.index /= df.index.values[-1]\ndf /= df.max()\ndf.plot()\nplt.suptitle('Cumulative sum of sorted errors')\nplt.xlabel('fraction of rows')\nplt.ylabel('fraction of error')\nplt.show()\n\n\n\n\nIt looks like the last 20% of the rows carry about 75% of the error."
  },
  {
    "objectID": "projects/optiver/opt-error-analysis.html#comparing-stock_id-and-time_id-group-error-distribution",
    "href": "projects/optiver/opt-error-analysis.html#comparing-stock_id-and-time_id-group-error-distribution",
    "title": "Error analysis",
    "section": "Comparing stock_id and time_id group error distribution",
    "text": "Comparing stock_id and time_id group error distribution\nLets see if the error is balanced accross stock_ids and time_ids.\n\nStock_id\n\nprint('Errors by stock_id sorted in descending order')\nstock = train.groupby('stock_id')['spe'].sum()\nstock.sort_values(ascending=False)\n\nErrors by stock_id sorted in descending order\n\n\nstock_id\n31     1092.696514\n37      329.793868\n18      311.135581\n33      296.696029\n88      287.739433\n          ...     \n84      104.070718\n96      102.221548\n14      100.687571\n124      98.935379\n56       87.401965\nName: spe, Length: 112, dtype: float64\n\n\nI was expecting the minimum to be much much lower compared to the maximum spe stock_id. The worst offender, stock_id 31 is only about 3 times worse than the second at 380 and gradually goes down to around 100 for the lowest stock. So stock 31 needs a little special attention, but we need to look at all stocks erros. I am guessing that the time_id aggregations won’t be as balanced.\nI am curious to see how the correlation between the target and log_return_realized_volatility (the most standard predictor) compares between the best and worst scoring stock.\n\ntrain[train.stock_id == 31][['log_return_realized_volatility', 'target']].corr()\n\n\n\n\n\n  \n    \n      \n      log_return_realized_volatility\n      target\n    \n  \n  \n    \n      log_return_realized_volatility\n      1.000000\n      0.820801\n    \n    \n      target\n      0.820801\n      1.000000\n    \n  \n\n\n\n\n\ntrain[train.stock_id == 56][['log_return_realized_volatility', 'target']].corr()\n\n\n\n\n\n  \n    \n      \n      log_return_realized_volatility\n      target\n    \n  \n  \n    \n      log_return_realized_volatility\n      1.000000\n      0.901207\n    \n    \n      target\n      0.901207\n      1.000000\n    \n  \n\n\n\n\nIt turns out that the worst performing stock has a lower correlation.\n\n\nTime_id\n\nprint('Errors by time_id sorted in descending order')\ntime = train.groupby('time_id')['spe'].sum()\nworst_times = time.sort_values(ascending=False)\nworst_times\n\nErrors by time_id sorted in descending order\n\n\ntime_id\n25504    258.750772\n24034     69.625326\n8534      58.088269\n20439     53.063871\n27174     49.766181\n            ...    \n11499      1.334917\n17337      1.296191\n22893      1.153656\n32082      1.127673\n4432       1.029422\nName: spe, Length: 3830, dtype: float64\n\n\nI was correct about time_id group score being more spread than stock_id. The worst time id is about 250 times as bad as the best scoring time_id.\nI am curious to see how the correlation between the target and log_return_realized_volatility (the most standard predictor) compares between the best and worst scoring time_id.\n\ntrain[train.time_id == 25504][['log_return_realized_volatility', 'target']].corr()\n\n\n\n\n\n  \n    \n      \n      log_return_realized_volatility\n      target\n    \n  \n  \n    \n      log_return_realized_volatility\n      1.000000\n      0.828771\n    \n    \n      target\n      0.828771\n      1.000000\n    \n  \n\n\n\n\n\ntrain[train.time_id == 4432][['log_return_realized_volatility', 'target']].corr()\n\n\n\n\n\n  \n    \n      \n      log_return_realized_volatility\n      target\n    \n  \n  \n    \n      log_return_realized_volatility\n      1.000000\n      0.896323\n    \n    \n      target\n      0.896323\n      1.000000\n    \n  \n\n\n\n\nSimilar to stock_id, the best time_id group has a higher correlation."
  },
  {
    "objectID": "projects/optiver/opt-error-analysis.html#a-further-look-at-the-worst-time_ids-plotting-realized-volatility-target-and-prediction-for-all-stocks",
    "href": "projects/optiver/opt-error-analysis.html#a-further-look-at-the-worst-time_ids-plotting-realized-volatility-target-and-prediction-for-all-stocks",
    "title": "Error analysis",
    "section": "A further look at the worst time_ids: plotting realized volatility, target, and prediction for all stocks",
    "text": "A further look at the worst time_ids: plotting realized volatility, target, and prediction for all stocks\n\ntop_5_worst_times = worst_times[:5].index\n\nThere is a great imbalance here, with the top time_id accruing about 200 times the error of the bottom. If we can identify the reason for these errors in the hardest hit time ids, we have the best chance to improve our models.\nI am suspecting that either the first 10 minute window is low volatitliy, followed by a second 10 minute window with high volatility, or vica versa. For the top time_id, 25504, lets see how the realized volatility compares to the average of the first 10 minutes, and then how the target compares to the average target.\nLets normalize the target and realized volatility of the the first 10 minutes. This way we put the variables on the same scale that is used when calculating correlation between variables.\n\ntar_mean = train['target'].mean()\nrv_mean = train.log_return_realized_volatility.mean()\ntar_std = train['target'].std()\nrv_std = train.log_return_realized_volatility.std()\ntrain['norm_real_vol'] = (train.log_return_realized_volatility - rv_mean) / rv_std\ntrain['norm_target'] = (train.target - tar_mean) / tar_std\n\nLets look at the top 3 worst scoring time_ids, and then the best scoring time_ids.\n\nfig, axes = plt.subplots(3, 1, figsize=(15, 20))\ntrain[train.time_id == 25504][['norm_real_vol', 'norm_target']].plot(ax=axes[0])\naxes[0].set_title('Worst scoring time_id, 25504 normalized target and realized variance')\n\ntrain[train.time_id == 27174][['norm_real_vol', 'norm_target']].plot(ax=axes[1])\naxes[1].set_title('2nd worst scoring time_id, 27174 normalized target and realized variance')\n\ntrain[train.time_id == 24034][['norm_real_vol', 'norm_target']].plot(ax=axes[2])\naxes[2].set_title('3rd worst scoring time_id, 24034 normalized target and realized variance')\nplt.show()\n\n\n\n\n\nfig, axes = plt.subplots(3, 1, figsize=(15, 20))\ntrain[train.time_id == 29850][['norm_real_vol', 'norm_target']].plot(ax=axes[0])\naxes[0].set_title('Best scoring time_id, 29850 normalized target and realized variance')\n\ntrain[train.time_id == 4432][['norm_real_vol', 'norm_target']].plot(ax=axes[1])\naxes[1].set_title('2nd best scoring time_id, 4432 normalized target and realized variance')\n\ntrain[train.time_id == 21116][['norm_real_vol', 'norm_target']].plot(ax=axes[2])\naxes[2].set_title('3rd best scoring time_id, 21116 normalized target and realized variance')\n\nplt.show()\n\n\n\n\nI am a bit confused. The 3rd worst scoring time_id looks really bad, but the first 2 look almost like best scoring time_ids. Maybe there is something I can’t see yet that is hurting my model. Lets plot the same plots again, along with our predictions. We will have to scale the predictions with the the same mean and std of the target to put them on the same scale.\n\ntrain['norm_pred'] = (train.pred - tar_mean) / tar_std\n\nfig, axes = plt.subplots(3, 1, figsize=(15, 20))\ntrain[train.time_id == 25504][['norm_real_vol', 'norm_target', 'norm_pred']].plot(ax=axes[0])\naxes[0].set_title('Worst scoring time_id, 25504 normalized target and realized variance')\n\ntrain[train.time_id == 27174][['norm_real_vol', 'norm_target', 'norm_pred']].plot(ax=axes[1])\naxes[1].set_title('2nd worst scoring time_id, 27174 normalized target and realized variance')\n\ntrain[train.time_id == 24034][['norm_real_vol', 'norm_target', 'norm_pred']].plot(ax=axes[2])\naxes[2].set_title('3rd worst scoring time_id, 24034 normalized target and realized variance')\nplt.show()\n\n\n\n\n\nfig, axes = plt.subplots(3, 1, figsize=(15, 20))\ntrain[train.time_id == 29850][['norm_real_vol', 'norm_target', 'norm_pred']].plot(ax=axes[0])\naxes[0].set_title('Best scoring time_id, 29850 normalized target and realized variance')\n\ntrain[train.time_id == 4432][['norm_real_vol', 'norm_target', 'norm_pred']].plot(ax=axes[1])\naxes[1].set_title('2nd best scoring time_id, 4432 normalized target and realized variance')\n\ntrain[train.time_id == 21116][['norm_real_vol', 'norm_target', 'norm_pred']].plot(ax=axes[2])\naxes[2].set_title('3rd best scoring time_id, 21116 normalized target and realized variance')\n\nplt.show()\n\n\n\n\nI am still confused about the third worst time_id. It looks like the predictions follow the first 10 minute volatility, and should be far off. Maybe I am missing something by normalizing. Lets just look at the raw values of preds and the target, along with the error plotted underneath for reference.\n\nPlot that finally brings some understanding of the large errors\n\nfig, axes = plt.subplots(6, 1, figsize=(15, 35))\ntrain[train.time_id == 25504][['target', 'pred']].plot(ax=axes[0])\naxes[0].set_title('Worst scoring time_id, 25504 normalized target and realized variance')\ntrain[train.time_id == 25504][['spe']].plot(ax=axes[1])\n\ntrain[train.time_id == 27174][['target', 'pred']].plot(ax=axes[2])\naxes[2].set_title('2nd worst scoring time_id, 27174 normalized target and realized variance')\ntrain[train.time_id == 27174][['spe']].plot(ax=axes[3])\n\ntrain[train.time_id == 24034][['target', 'pred']].plot(ax=axes[4])\naxes[4].set_title('3rd worst scoring time_id, 24034 normalized target and realized variance')\ntrain[train.time_id == 24034][['spe']].plot(ax=axes[5])\n\nplt.show()\n\n\n\n\nkey takeaway: the largest errors are caused when the target is small because the errors are divided by the target in the metric calculation. The top two worst scoring time_ids both have a single prediction with an extremely low target, while the 3rd worst time_id has a generally low target for all stocks."
  },
  {
    "objectID": "projects/optiver/opt-error-analysis.html#looking-at-rows-with-the-highest-error-testing-hypothesis-that-a-small-target-is-the-culprit",
    "href": "projects/optiver/opt-error-analysis.html#looking-at-rows-with-the-highest-error-testing-hypothesis-that-a-small-target-is-the-culprit",
    "title": "Error analysis",
    "section": "Looking at rows with the highest error, testing hypothesis that a small target is the culprit",
    "text": "Looking at rows with the highest error, testing hypothesis that a small target is the culprit\nLets start with the top 50 errors\n\nfig, axes = plt.subplots(2, 1, figsize=(15, 10))\ntop = train.sort_values('spe', ascending=False).head(50).reset_index()\ntop[['target', 'pred', 'log_return_realized_volatility']].plot(ax=axes[0])\naxes[0].set_title('Top 25 squared percentage errors')\ntop[['spe']].plot(ax=axes[1])\naxes[1].set_title('spe')\nplt.show()\n\n\n\n\nIt definitely seems that the largest errors are coming from overpredicting the target, along with an especially small target. I think overprediction could be the only times when we have a large penalty from the metric. Lets look at the largest losses where we underpredict.\n\ndf = train[train.pred < train.target]\ndf.sort_values('spe', ascending=False)[['pred', 'target', 'spe']].head(3)\n\n\n\n\n\n  \n    \n      \n      pred\n      target\n      spe\n    \n  \n  \n    \n      202001\n      0.002458\n      0.069165\n      0.930183\n    \n    \n      378265\n      0.001178\n      0.019343\n      0.881915\n    \n    \n      78772\n      0.001295\n      0.019935\n      0.874268\n    \n  \n\n\n\n\nThe largest spe is less than .92. For reference, if we predicted 0 for all targets our average spe and overall metric would be 1. Given that the underpredicted errors gave spe penalties in the 5,6, and 7 range at the high end (highest about 200) with relatively small absolute error, and these underpredictions give a max penalty less than 1, I am certain that overpredicting especially small targets is the largest source of error."
  },
  {
    "objectID": "projects/optiver/opt-error-analysis.html#looking-for-signals-of-low-volatility",
    "href": "projects/optiver/opt-error-analysis.html#looking-for-signals-of-low-volatility",
    "title": "Error analysis",
    "section": "Looking for signals of low volatility",
    "text": "Looking for signals of low volatility\nLets look at some of the book and trade data for the top losses. Maybe we can find some features that show that we are about to enter a low volatility period, even if the previous 10 minutes was high.\n\ndef add_percentile(df, col): \n    \"\"\"Adds `{col}_percentile` to compare where each row ranks in terms of `col`.\"\"\"\n    if type(col) == list: \n        for c in col: df = add_percentile(df, c)\n    else: \n        df[col + '_percentile'] = (df[col].rank(pct=True) * 100).astype(int)\n    return df\n\n\nadd_percentile(train, ['pred', 'target', 'log_return_realized_volatility'])\ntop_spe = train.sort_values('spe', ascending=False)\ntop_spe.head()\n\n\n\n\n\n  \n    \n      \n      row_id\n      stock_id\n      time_id\n      target\n      fold\n      log_return_max_sub_min\n      log_return_std\n      log_return_realized_volatility\n      log_return_mean_decay\n      log_return_mean_decay_flip\n      ...\n      spe\n      raw_error\n      rv\n      ratio\n      norm_real_vol\n      norm_target\n      norm_pred\n      pred_percentile\n      target_percentile\n      log_return_realized_volatility_percentile\n    \n  \n  \n    \n      110278\n      31-25504\n      31\n      25504\n      0.000139\n      1.0\n      0.002713\n      0.000144\n      0.003528\n      -1.915218e-06\n      1.643631e-06\n      ...\n      253.353148\n      0.002212\n      0.003528\n      283529.781250\n      -0.196735\n      -1.274253\n      -0.520822\n      37\n      0\n      56\n    \n    \n      108254\n      31-8534\n      31\n      8534\n      0.000105\n      3.0\n      0.002760\n      0.000081\n      0.001986\n      2.102843e-06\n      5.847572e-07\n      ...\n      51.307601\n      0.000754\n      0.001986\n      111114.992188\n      -0.626816\n      -1.285737\n      -1.028943\n      1\n      0\n      22\n    \n    \n      110479\n      31-27174\n      31\n      27174\n      0.000123\n      1.0\n      0.002623\n      0.000109\n      0.002662\n      -2.080473e-06\n      1.383185e-05\n      ...\n      45.948679\n      0.000835\n      0.002662\n      60701.390625\n      -0.438237\n      -1.279647\n      -0.995348\n      2\n      0\n      39\n    \n    \n      275261\n      81-28319\n      81\n      28319\n      0.000389\n      0.0\n      0.002005\n      0.000123\n      0.003025\n      -2.650691e-06\n      -2.003285e-05\n      ...\n      43.877539\n      0.002579\n      0.003025\n      407105.843750\n      -0.336934\n      -1.189000\n      -0.310741\n      52\n      0\n      47\n    \n    \n      107425\n      31-1544\n      31\n      1544\n      0.000289\n      2.0\n      0.001773\n      0.000086\n      0.002103\n      5.815194e-07\n      1.080874e-05\n      ...\n      18.923841\n      0.001259\n      0.002103\n      172874.531250\n      -0.594068\n      -1.223036\n      -0.794324\n      13\n      0\n      25\n    \n  \n\n5 rows × 379 columns\n\n\n\n\ndef plot_book(stock_id, time_id, train=train): \n    \"\"\"Plots book and trade data for single stock and time combination. \n    This is to try and tease out indicators for especially large errors.\"\"\"\n    mask = (train.stock_id == stock_id) & (train.time_id == time_id)\n    target, pred, spe, realized_volatitlity, pred_percentile, target_percentile, \\\n    realized_volatitlity_percentile, size_sum, ratio \\\n        = train.loc[mask, ['target', 'pred', 'spe', \n                           'log_return_realized_volatility',\n                           'pred_percentile', \n                           'target_percentile', \n                           'log_return_realized_volatility_percentile', \n                           'size_sum', \n                           'ratio'\n                          ]].values[0].round(5)\n    \n    bt = load_bt(DATA_RAW, stock_id, 'train')\n    bt['wap'] = (bt['bid_price1'] * bt['ask_size1'] + bt['ask_price1'] * bt['bid_size1']) /\\\n                          (bt['bid_size1'] + bt['ask_size1'])\n    bt['total_bid_size'] = bt['bid_size1'] + bt['bid_size2']\n    bt['total_ask_size'] = bt['ask_size1'] + bt['ask_size2']\n    book = bt[bt.time_id == time_id].set_index('seconds_in_bucket')\n    \n    fig, axes = plt.subplots(3, 1, figsize=(15, 15))\n    \n    cmap = {'ask_price1': 'yellow', \n            'ask_price2': 'khaki',\n            'ask_size1': 'yellow', \n            'ask_size2': 'khaki',\n            'bid_price1': 'blue', \n            'bid_price2': 'lightblue', \n            'bid_size1': 'blue', \n            'bid_size2': 'lightblue',\n            'total_ask_size': 'yellow', \n            'total_bid_size': 'blue', \n            'wap': 'green', \n            'size': 'red', \n            'price': 'red', \n           }\n    \n    book[['ask_price2', 'ask_price1', 'bid_price1',  'bid_price2', 'wap', 'price']].plot(ax=axes[0], color=cmap)\n    book[['bid_size1', 'ask_size1', 'bid_size2','ask_size2']].plot(ax=axes[1], color=cmap)\n    book[['total_bid_size', 'total_ask_size']].plot(ax=axes[2], color=cmap)\n    book[['size']].plot(marker='o', ax=axes[1], color=cmap)\n\n    \n    axes[0].set_title('Price info')\n    axes[1].set_title('Size info')\n    axes[2].set_title('Total size info')\n    axes[0].legend(loc='upper left')\n    axes[1].legend(loc='upper left')\n    axes[2].legend(loc='upper left')\n    \n    fig.suptitle(f'\\\n        Stock: {stock_id}         missing seconds: {600 - len(book)}\\n\\\n        Time_id: {time_id}\\n\\\n        spe: {spe} \\n\\\n        target: {target} \\n\\\n        pred: {pred} \\n\\\n        realized_volatitlity: {realized_volatitlity},\\n\\n\\\n        error: {round(pred - target, 5)} \\n\\\n        target_percentile: {target_percentile} \\n\\\n        pred_percentile: {pred_percentile} \\n\\\n        realized_volatitlity_percentile: {realized_volatitlity_percentile}           total sales: {size_sum}         ratio: {ratio}\\n')\n    plt.tight_layout()\n    plt.show()\n\n\ntrain['d'] = train['pred'] - train['target']\n\n\nPlotting rows with a large absolute error\n\nfor stock_id, time_id in train.sort_values('d', ascending=False)[['stock_id', 'time_id']].values[: 10]: \n    plot_book(stock_id, time_id)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef mean_decay(x, decay=.9, step=-1, axis=0): \n    \"\"\"Returns sum with exponential decay, step = -1\n    for the end of the array to matter the most.\"\"\"\n    weights = np.power(decay, np.arange(x.shape[axis])[::step]).astype(np.float32)\n    return np.sum(weights * x, axis=axis) / weights.sum()\n\n\n\nPlotting top 3 instances for each of the top 5 worst scoring time_ids\n\nfor t in top_5_worst_times: \n    tmp = train[train.time_id == t].sort_values('spe', ascending=False)\n    for stock_id, time_id in tmp[['stock_id', 'time_id']].values[: 3]: \n        plot_book(stock_id, time_id)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLets look at the most penalized instances and see if we can see a pattern.\n\nlow = train.sort_values('log_return_realized_volatility')\n\n\n\nPlotting rows with low volatiltiy during the 10 minutes of input data for reference\nLets see what the lowest volatility instances look like before looking at the instances where we went from high volatility to a low target\n\nfor stock_id, time_id in low[['stock_id', 'time_id']].values[: 10]: \n    plot_book(stock_id, time_id)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThey all have a very low ratio of sales to ask and bid size\n\n\nPlotting the worst scoring rows of stock 31, the worst scoring stock\n\nfor stock_id, time_id in top_spe[top_spe.stock_id != 31][['stock_id', 'time_id']].values[: 10]: \n    plot_book(stock_id, time_id)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting the first 10 rows of stock 31 to compare to the worst scoring rows\n\nfor stock_id, time_id in train[train.stock_id == 31][['stock_id', 'time_id']].values[: 10]: \n    plot_book(stock_id, time_id)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting random rows with average measured realized_volatitliy\n\ncomp = train[(train.log_return_realized_volatility_percentile < 60) & (train.log_return_realized_volatility_percentile > 40)]\nfor stock_id, time_id in comp[['stock_id', 'time_id']].values[:10]: \n    plot_book(stock_id, time_id)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI can’t see any obvious patterns in these plots that I could use to create different features than I already have."
  },
  {
    "objectID": "projects/optiver/notebooks/opt-train-tabnet-142.html",
    "href": "projects/optiver/notebooks/opt-train-tabnet-142.html",
    "title": "chrisrichardmiles",
    "section": "",
    "text": "def main(): \n    train = pd.read_pickle(cfg['path_features'])\n    train.replace([np.inf, -np.inf], np.nan,inplace=True)\n    train = train.fillna(train.mean())\n    train = encode_cols(train, cfg[\"encode_time_cols\"], funcs=cfg['encode_funcs'], on='time_id')\n\n    # Saving encoded stock columns != 'stock_id']\n    drop_cols = [c for c in cfg['drop_cols'] if c != 'stock_id']\n    x = train.drop(drop_cols, axis = 1)\n    y = train['target']\n    \n\n    # dict_eval_logs = [] # For experimentation tracking\n    # booster_summaries = [] # For experimentation tracking\n\n    oof_predictions = np.zeros(x.shape[0]) # Create out of folds array\n    scores = [] # Keep track of scores for each fold and all oof at the end\n    best_iterations = []\n    training_best_scores = []\n    valid_best_scores = [] # Same as scores in this script, but would be different with nested cv\n    best_score_diffs = []\n    rmspe_logs = []\n    loss_logs = []\n\n    feature_importances = pd.DataFrame()\n    \n#     stats = pd.DataFrame()\n#     explain_matrices = []\n#     masks_ = []\n\n    for fold in range(5):\n        trn_ind = x.fold != fold\n        val_ind = x.fold == fold\n\n        print(f'Training fold {fold}')\n        x_train, x_val = x[trn_ind].drop('fold', axis=1), x[val_ind].drop('fold', axis=1)\n        y_train, y_val = y[trn_ind].values.reshape(-1, 1), y[val_ind].values.reshape(-1, 1)\n\n        x_train = encode_cols(x_train, \n                              cfg['encode_stock_cols'], \n                              funcs=cfg['encode_funcs'], \n                              shake=cfg['shake'], \n                              shake_std=cfg['shake_std']).drop('stock_id', axis=1)\n        if fold == 0: feature_importances[\"feature\"] = x_train.columns.tolist()\n        x_train = x_train.values\n        n_train_cols = x_train.shape[1]\n        \n\n        x_val = encode_cols(x_val, \n                            cfg['encode_stock_cols'], \n                            funcs=cfg['encode_funcs']).drop('stock_id', axis=1).values\n\n        clf =  TabNetRegressor(**cfg['tabnet_params'])\n        clf.fit(\n          x_train, y_train,\n          eval_set=[(x_val, y_val)],\n          max_epochs = 400,\n          patience = 50,\n          batch_size = 2 ** 12, \n          virtual_batch_size = 2 ** 10,\n          num_workers = 4,\n          drop_last = False,\n          eval_metric=[RMSPE],\n          loss_fn=RMSPELoss\n          )\n\n        clf.save_model(os.path.join(cfg['path_models'], f'{cfg[\"prefix\"]}tab_fold_{fold}'))\n        y_pred = clf.predict(x_val).flatten()\n        oof_predictions[val_ind] = y_pred\n        scores.append(round(rmspe(y_val.flatten(), y_pred), 3))\n        \n#         explain_matrix, masks = clf.explain(x_val)\n#         explain_matrices.append(explain_matrix)\n#         masks_.append(masks[0])\n#         masks_.append(masks[1])\n\n        feature_importances[f\"fold_{fold}\"] = clf.feature_importances_\n\n#         stats[f'fold{fold+1}_train_rmspe']=clf.history['loss']\n#         stats[f'fold{fold+1}_val_rmspe']=clf.history['val_0_rmspe']\n\n        # clf_ =  TabNetRegressor(**tabnet_params)\n        # clf_.load_model('./tab_fold_0.zip')\n\n        best_iterations.append(clf.best_epoch)\n        train_score = clf.history['loss'][clf.best_epoch]\n        valid_score = clf.best_cost\n        training_best_scores.append(round(train_score, 3))\n        valid_best_scores.append(round(valid_score, 3))\n        best_score_diffs.append(round(valid_score - train_score, 3))\n\n        rmspe_logs.append(clf.history['val_0_rmspe'])\n        loss_logs.append(clf.history['loss'])\n\n    rmspe_score = round(rmspe(y, oof_predictions), 3)\n    print(f'Our out of folds RMSPE is {rmspe_score}')\n    print(f'Our cv fold scores are {scores}')\n    np.save('oof_predictions', oof_predictions)\n\n    run = neptune.init(\n            project=cfg['neptune_project'],\n            api_token=NEPTUNE_API_TOKEN,\n            name=cfg['neptune_run_name'],    \n            description=cfg['neptune_description'],\n            tags=[cfg['path_features'], cfg['prefix']],\n            source_files=['cfg.json'],\n    )\n    \n    run['cfg'] = cfg\n    cfg['feat_file'] = 'enc_' + os.path.split(cfg['path_features'])[1]\n    run['RMSPE'] = rmspe_score\n    run['RMSPE_oof_scores'] = scores\n    run['RMSPE_cv_std'] = np.std(scores)\n\n    run['best_iterations'] = best_iterations\n    run['oof_predictions'] = oof_predictions\n    best_iterations_mean = int(np.mean(best_iterations))\n    run['best_iterations_mean'] = best_iterations_mean\n    run['training_best_scores'] = training_best_scores\n    run['valid_best_scores'] = valid_best_scores\n    run['best_score_diffs'] = best_score_diffs\n    run['best_score_diffs_mean'] = round(np.mean(best_score_diffs), 3)\n    \n    # Feature importance\n    cols = [c for c in list(feature_importances) if c.startswith('fold_')]\n    feature_importances['mean_importance'] = feature_importances[cols].mean(axis=1)\n    feature_importances.sort_values(by='mean_importance', ascending=False, inplace=True)\n    fig, ax = plt.subplots()\n    sns.barplot(y=feature_importances['feature'][:25],x=feature_importances['mean_importance'][:25], palette='inferno', ax=ax)\n    plt.title('Mean Feature Importance by Folds')\n    run['feature_importance'].upload(fig)\n\n    # Logs for each folds model\n    for fold in range(5):\n        for val in rmspe_logs[fold]:\n            run[f'eval_logs/{fold}_rmspe'].log(val)\n        for val in loss_logs[fold]:\n            run[f'eval_logs/{fold}_loss'].log(val)\n        run[f'models/fold_{fold}/model_params'].upload('./model_params.json')\n        run[f'models/fold_{fold}/network'].upload('./network.pt')\n\n    run.stop()\n\n    # if cfg['rerun']: \n    #     print(f'retraining model with all data for {best_iterations} iterations')\n    #     params = cfg['lgb_params'].copy()\n    #     params['early_stopping_rounds'] = 0 # No valid set to stop with\n\n    #     x_train = x.drop(['fold'], axis=1)\n    #     x_train = encode_cols(x_train, \n    #                           cfg['encode_stock_cols'], \n    #                           funcs=cfg['encode_funcs'], \n    #                           shake=cfg['shake'], \n    #                           shake_std=cfg['shake_std']).drop('stock_id', axis=1)\n    #     y_train = y\n\n    #     assert(n_train_cols == x_train.shape[1])\n\n    #     train_weights = 1 / np.square(y_train) # Root mean squared percentage error weights\n    #     train_dataset = lgb.Dataset(x_train, y_train, weight=train_weights)\n\n    #     for fold, best_iter in enumerate(best_iterations): \n    #         params['n_estimators'] = int(best_iter) # lgbm needs int here\n    #         model = lgb.train(params = params, \n    #                           train_set = train_dataset)\n    #         model.save_model(os.path.join(cfg['path_models'], f'{cfg[\"prefix\"]}rerun_lgb_{fold}.txt'))\n\n\nif __name__ == '__main__': \n    main()\n\nTraining fold 0\nDevice used : cuda\nepoch 0  | loss: 34.84265| val_0_rmspe: 3.97562 |  0:00:09s\nepoch 10 | loss: 0.25115 | val_0_rmspe: 0.64807 |  0:01:45s\nepoch 20 | loss: 0.24029 | val_0_rmspe: 0.22786 |  0:03:22s\nepoch 30 | loss: 0.22001 | val_0_rmspe: 0.22581 |  0:05:01s\nepoch 40 | loss: 0.22145 | val_0_rmspe: 0.22225 |  0:06:38s\nepoch 50 | loss: 0.2176  | val_0_rmspe: 0.22428 |  0:08:17s\nepoch 60 | loss: 0.21214 | val_0_rmspe: 0.23971 |  0:09:52s\nepoch 70 | loss: 0.2109  | val_0_rmspe: 0.21874 |  0:11:28s\nepoch 80 | loss: 0.21048 | val_0_rmspe: 0.21648 |  0:13:05s\nepoch 90 | loss: 0.2065  | val_0_rmspe: 0.22274 |  0:14:39s\nepoch 100| loss: 0.20502 | val_0_rmspe: 0.22282 |  0:16:12s\nepoch 110| loss: 0.20462 | val_0_rmspe: 0.2217  |  0:17:45s\nepoch 120| loss: 0.20281 | val_0_rmspe: 0.21807 |  0:19:19s\nepoch 130| loss: 0.20293 | val_0_rmspe: 0.21796 |  0:20:53s\n\nEarly stopping occurred at epoch 135 with best_epoch = 85 and best_val_0_rmspe = 0.21598\nBest weights from best epoch are automatically used!\nSuccessfully saved model at tab_fold_0.zip\nTraining fold 1\nDevice used : cuda\nepoch 0  | loss: 28.85411| val_0_rmspe: 2.52175 |  0:00:09s\nepoch 10 | loss: 0.27012 | val_0_rmspe: 1.12129 |  0:01:48s\nepoch 20 | loss: 0.40789 | val_0_rmspe: 0.44142 |  0:03:28s\nepoch 30 | loss: 0.21607 | val_0_rmspe: 0.22727 |  0:05:07s\nepoch 40 | loss: 0.21843 | val_0_rmspe: 0.24677 |  0:06:46s\nepoch 50 | loss: 0.21108 | val_0_rmspe: 0.22993 |  0:08:26s\nepoch 60 | loss: 0.20979 | val_0_rmspe: 0.22135 |  0:10:05s\nepoch 70 | loss: 0.20701 | val_0_rmspe: 0.22407 |  0:11:44s\nepoch 80 | loss: 0.20625 | val_0_rmspe: 0.22319 |  0:13:22s\nepoch 90 | loss: 0.20381 | val_0_rmspe: 0.23268 |  0:15:04s\nepoch 100| loss: 0.2021  | val_0_rmspe: 0.23506 |  0:16:43s\nepoch 110| loss: 0.20113 | val_0_rmspe: 0.22683 |  0:18:22s\nepoch 120| loss: 0.20124 | val_0_rmspe: 0.23338 |  0:20:02s\n\nEarly stopping occurred at epoch 128 with best_epoch = 78 and best_val_0_rmspe = 0.22053\nBest weights from best epoch are automatically used!\nSuccessfully saved model at tab_fold_1.zip\nTraining fold 2\nDevice used : cuda\nepoch 0  | loss: 50.4229 | val_0_rmspe: 5.23441 |  0:00:08s\nepoch 10 | loss: 0.27655 | val_0_rmspe: 0.79095 |  0:01:37s\nepoch 20 | loss: 0.30464 | val_0_rmspe: 0.34668 |  0:03:05s\nepoch 30 | loss: 0.24451 | val_0_rmspe: 0.24319 |  0:04:34s\nepoch 40 | loss: 0.26945 | val_0_rmspe: 0.25431 |  0:06:02s\nepoch 50 | loss: 0.25402 | val_0_rmspe: 0.24095 |  0:07:29s\nepoch 60 | loss: 0.24599 | val_0_rmspe: 0.23744 |  0:08:59s\nepoch 70 | loss: 0.23164 | val_0_rmspe: 0.23012 |  0:10:28s\nepoch 80 | loss: 0.21893 | val_0_rmspe: 0.21354 |  0:11:55s\nepoch 90 | loss: 0.21603 | val_0_rmspe: 0.21312 |  0:13:23s\nepoch 100| loss: 0.21227 | val_0_rmspe: 0.21308 |  0:14:51s\nepoch 110| loss: 0.21155 | val_0_rmspe: 0.2135  |  0:16:19s\nepoch 120| loss: 0.20886 | val_0_rmspe: 0.21186 |  0:17:47s\nepoch 130| loss: 0.20745 | val_0_rmspe: 0.21268 |  0:19:15s\nepoch 140| loss: 0.20618 | val_0_rmspe: 0.21459 |  0:20:43s\nepoch 150| loss: 0.20497 | val_0_rmspe: 0.21554 |  0:22:11s\nepoch 160| loss: 0.20448 | val_0_rmspe: 0.21365 |  0:23:39s\nepoch 170| loss: 0.20284 | val_0_rmspe: 0.21464 |  0:25:06s\n\nEarly stopping occurred at epoch 172 with best_epoch = 122 and best_val_0_rmspe = 0.21161\nBest weights from best epoch are automatically used!\nSuccessfully saved model at tab_fold_2.zip\nTraining fold 3\nDevice used : cuda\nepoch 0  | loss: 56.02314| val_0_rmspe: 10.22007|  0:00:08s\nepoch 10 | loss: 0.43983 | val_0_rmspe: 0.8568  |  0:01:37s\nepoch 20 | loss: 0.22995 | val_0_rmspe: 0.21907 |  0:03:05s\nepoch 30 | loss: 0.21569 | val_0_rmspe: 0.21242 |  0:04:34s\nepoch 40 | loss: 0.21423 | val_0_rmspe: 0.21458 |  0:06:02s\nepoch 50 | loss: 0.21082 | val_0_rmspe: 0.20932 |  0:07:31s\nepoch 60 | loss: 0.20849 | val_0_rmspe: 0.21884 |  0:08:58s\nepoch 70 | loss: 0.20578 | val_0_rmspe: 0.21442 |  0:10:26s\nepoch 80 | loss: 0.20617 | val_0_rmspe: 0.21196 |  0:11:55s\nepoch 90 | loss: 0.20397 | val_0_rmspe: 0.20988 |  0:13:22s\nepoch 100| loss: 0.20236 | val_0_rmspe: 0.21301 |  0:14:50s\nepoch 110| loss: 0.2     | val_0_rmspe: 0.21585 |  0:16:19s\n\nEarly stopping occurred at epoch 115 with best_epoch = 65 and best_val_0_rmspe = 0.20921\nBest weights from best epoch are automatically used!\nSuccessfully saved model at tab_fold_3.zip\nTraining fold 4\nDevice used : cuda\nepoch 0  | loss: 38.22281| val_0_rmspe: 2.98199 |  0:00:09s\nepoch 10 | loss: 0.43127 | val_0_rmspe: 0.84528 |  0:01:39s\nepoch 20 | loss: 0.23322 | val_0_rmspe: 0.22677 |  0:03:08s\nepoch 30 | loss: 0.30976 | val_0_rmspe: 0.23742 |  0:04:39s\nepoch 40 | loss: 0.2227  | val_0_rmspe: 0.22571 |  0:06:10s\nepoch 50 | loss: 0.21846 | val_0_rmspe: 0.21939 |  0:07:38s\nepoch 60 | loss: 0.21502 | val_0_rmspe: 0.21909 |  0:09:07s\nepoch 70 | loss: 0.21122 | val_0_rmspe: 0.21164 |  0:10:36s\nepoch 80 | loss: 0.20849 | val_0_rmspe: 0.20901 |  0:12:06s\nepoch 90 | loss: 0.20691 | val_0_rmspe: 0.20908 |  0:13:34s\nepoch 100| loss: 0.20505 | val_0_rmspe: 0.20844 |  0:15:05s\nepoch 110| loss: 0.20261 | val_0_rmspe: 0.21361 |  0:16:35s\nepoch 120| loss: 0.20074 | val_0_rmspe: 0.21291 |  0:18:03s\nepoch 130| loss: 0.19878 | val_0_rmspe: 0.21502 |  0:19:31s\nepoch 140| loss: 0.19704 | val_0_rmspe: 0.21522 |  0:20:59s\nepoch 150| loss: 0.19538 | val_0_rmspe: 0.21667 |  0:22:27s\n\nEarly stopping occurred at epoch 151 with best_epoch = 101 and best_val_0_rmspe = 0.20763\nBest weights from best epoch are automatically used!\nSuccessfully saved model at tab_fold_4.zip\nOur out of folds RMSPE is 0.213\nOur cv fold scores are [0.216, 0.221, 0.212, 0.209, 0.208]\nhttps://app.neptune.ai/chrisrichardmiles/optiver/e/OP-142\nRemember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\nShutting down background jobs, please wait a moment...\nDone!\n\n\nWaiting for the remaining 1481 operations to synchronize with Neptune. Do not kill this process.\n\n\nAll 1481 operations synced, thanks for waiting!\n\n\n\n\n\n\n# import shutil\n# shutil.copy('../input/tmp3zip/model_params.json', 'model_params.json')\n# shutil.copy('../input/tmp3zip/network.pt', 'network.pt')\n\n# z = zipfile.ZipFile('tmp.zip', 'w')\n# z.write('model_params.json')\n# z.write('network.pt')\n# z.close()\n# tmp.load_model('tmp.zip')"
  },
  {
    "objectID": "projects/optiver/notebooks/opt-train-dart.html",
    "href": "projects/optiver/notebooks/opt-train-dart.html",
    "title": "chrisrichardmiles",
    "section": "",
    "text": "cfg = {\n    \"script_name\": 'opt_train_v2_op_89',\n    \"path_features\": '../input/generate-train-features-script-p13/p13_train.pkl', # Used in train mode\n    \"path_models\": '',\n    \"path_data_raw\": '../input/optiver-realized-volatility-prediction/',\n    \"neptune_project\": 'chrisrichardmiles/optiver',\n    \"neptune_description\": 'p13 encoding top columns with shake .3',\n    \"encode_time_cols\": ['real_vol_ratio_5_10', 'real_vol_mean_decay_0.9_-1', 'order_norm_momentum', 'real_vol_mean_decay_0.85_-1', 'real_vol_mean_decay_0.99_1', 'real_vol_mean_decay_0.95_1', 'abs_price_wap_diff_mean_decay_flip', 'abs_price_wap_diff_mean_decay', 'order_norm_sum', 'real_vol_mean_decay_0.85_-1_2', 'spread_mean_decay_flip_95', 'real_vol_mean_decay_0.99_-1', 'real_vol_mean_decay_0.75_-1', 'spread_mean', 'order_count_sum', 'bid_price_diff_count_unique', 'spread_momentum', 'size_mean', 'real_vol_mean_decay_0.95_-1', 'order_norm_mean_decay', 'spread_2_mean_decay_95', 'order_size_mean', 'spread_mean_decay_95', \n                         'spread_pct_momentum'], \n    \"encode_stock_cols\": ['real_vol_ratio_5_10', 'real_vol_mean_decay_0.9_-1', 'order_norm_momentum', 'real_vol_mean_decay_0.85_-1', 'real_vol_mean_decay_0.99_1', 'real_vol_mean_decay_0.95_1', 'abs_price_wap_diff_mean_decay_flip', 'abs_price_wap_diff_mean_decay', 'order_norm_sum', 'real_vol_mean_decay_0.85_-1_2', 'spread_mean_decay_flip_95', 'real_vol_mean_decay_0.99_-1', 'real_vol_mean_decay_0.75_-1', 'spread_mean', 'order_count_sum', 'bid_price_diff_count_unique', 'spread_momentum', 'size_mean', 'real_vol_mean_decay_0.95_-1', 'order_norm_mean_decay', 'spread_2_mean_decay_95', 'order_size_mean', 'spread_mean_decay_95',\n                          'spread_pct_momentum'], \n    \"drop_cols\": ['row_id', 'time_id', 'stock_id', 'target'] + ['real_momentum_0.55_-1', 'wap_2_last-first', 'sum_bid_ask_momentum', 'abs_log_return_momentum', 'order_size_sqaure_weighted_sum', 'size_mean_decay_95', 'size_norm_momentum_95', 'size_norm_momentum', 'size_spread_mean_decay_flip_95', 'log_return_2_realized_volatility', 'abs_price_wap_diff_2_std', 'sum_bid_ask_mean', 'real_momentum_0.85_-1', 'real_vol_mean_decay_0.55_-1', 'abs_price_wap_diff_amax', 'size_mean_decay', 'real_vol_mean_decay_0.9_-1_2', 'abs_price_wap_diff_2_mean', 'real_momentum_0.65_-1_2', 'price_wap_diff_2_max_sub_min', 'real_vol_mean_decay_0.75_1', 'real_vol_min_5', 'real_vol_mean_decay_0.95_-1_2', 'real_vol_min_6', 'size_spread_mean', 'size_spread_mean_decay_95', 'real_vol_mean_decay_0.75_1_2', 'sum_bid_ask_std', 'price_wap_diff_mean_decay', 'wap_2_real_vol', 'abs_price_wap_diff_2_mean_decay', 'size_momentum_95', 'real_momentum_0.65_-1', 'size_spread_momentum_95', 'real_vol_min_2', 'sum_bid_ask_mean_decay_flip', 'real_vol_mean_decay_0.65_1', 'size_spread_mean_decay_flip', 'real_momentum_0.75_-1_2', 'abs_price_wap_diff_2_max_sub_min', 'price_wap_diff_momentum', 'real_momentum_0.55_-1_2', 'real_momentum_0.45_-1_2', 'spread_pct_std', 'abs_price_wap_diff_max_sub_min', 'real_momentum_0.95_-1', 'real_vol_min_7', 'real_vol_min_4_2', 'real_vol_mean_decay_0.99_1_2', 'spread_2_sum', 'sum_bid_ask_mean_decay', 'real_vol_mean_decay_0.55_1', 'real_vol_mean_decay_0.55_1_2', 'real_vol_mean_decay_0.9_1_2', 'real_vol_mean_decay_0.65_1_2', 'real_vol_mean_decay_0.45_1_2', 'wap_2_std', 'price_wap_diff_max_sub_min', 'real_momentum_0.85_-1_2', 'real_momentum_0.45_-1', 'price_wap_diff_2_mean_decay_flip', 'size_norm_mean_decay_flip_95', 'price_wap_diff_mean_decay_flip', 'real_momentum_0.99_-1', 'sum_bid_ask_max_sub_min', 'real_vol_mean_decay_0.95_1_2', 'real_vol_min_4', 'real_vol_min_8', 'real_vol_min_2_2', 'real_momentum_0.99_-1_2', 'real_momentum_0.95_-1_2', 'log_return_mean_decay_flip', 'real_vol_mean_decay_0.85_1_2', 'price_wap_diff_2_std', 'log_return_realized_volatility', 'abs_log_return_2_momentum', 'log_return_2_mean_decay_flip', 'log_return_std', 'log_return_2_std', 'real_momentum_0.75_-1', 'real_vol_mean_decay_0.45_-1_2', 'abs_price_wap_diff_2_momentum', 'real_momentum_0.9_-1_2', 'real_vol_mean_decay_0.9_1', 'price_wap_diff_2_mean_decay', 'real_vol_min_9_2', 'real_vol_mean_decay_0.99_-1_2', 'wap_2_max_sub_min', 'real_momentum_0.9_-1', 'dummy3', 'abs_price_wap_diff_2_mean_decay_flip', \n                                                               'abs_log_return_2_std'],\n    \"encode_funcs\": ['mean', 'std'], \n    \"shake\": False, \n    \"shake_std\": .3, \n    \"prefix\": '',\n    \"rerun\": True,\n    \"neptune_run_name\": '',\n    \"lgb_params\": {\n        # https://lightgbm.readthedocs.io/en/latest/index.html\n        \"boosting_type\": \"dart\",\n        \"objective\": \"rmse\",\n        \"learning_rate\": .05,\n        \"num_leaves\": 255,\n        \"min_data_in_leaf\": 255,\n        \"feature_fraction\": 0.8,\n        \"bagging_fraction\": .5, # Select bagging_fraction of rows every bagging_freq of iterations.\n        \"bagging_freq\": 1,      # This speeds up training and underfits. Need both set to do anything.\n        \"n_estimators\": 3,\n        \"early_stopping_rounds\": 400,\n        \"n_jobs\": -1,\n        \"seed\": 42,\n        \"verbose\": -1, \n    },\n}\nwith open('cfg.json', 'w') as f: \n    json.dump(cfg, f)\n\n\ndef main(): \n    train = pd.read_pickle(cfg['path_features'])\n    train['real_vol_ratio_5_10'] = train[[f'real_vol_min_{i}' for i in range(1, 6)]].sum(axis=1) / train[[f'real_vol_min_{i}' for i in range(6, 11)]].sum(axis=1)\n    train = encode_cols(train, cfg[\"encode_time_cols\"], funcs=cfg['encode_funcs'], on='time_id')\n\n    # Saving encoded stock columns\n    feat_file = 'enc_' + os.path.split(cfg['path_features'])[1]\n    tmp = encode_cols(train, cfg[\"encode_stock_cols\"], funcs=cfg['encode_funcs'], on='stock_id')\n    tmp.to_pickle(os.path.join(cfg['path_models'], feat_file))\n    del tmp\n\n    drop_cols = [c for c in cfg['drop_cols'] if c in train.columns and c != 'stock_id']\n    x = train.drop(drop_cols, axis = 1)\n    y = train['target']\n\n    oof_predictions = np.zeros(x.shape[0]) # Create out of folds array\n    scores = [] # Keep track of scores for each fold and all oof at the end\n    best_iterations = []\n    training_best_scores = []\n    valid_best_scores = [] # Same as scores in this script, but would be different with nested cv\n    best_score_diffs = []\n    dict_eval_logs = [] # For experimentation tracking\n    booster_summaries = [] # For experimentation tracking\n    dumb_features = []\n    top_features = []\n\n    for fold in range(5):\n        \n        trn_ind = x.fold != fold\n        val_ind = x.fold == fold\n\n        print(f'Training fold {fold}')\n        x_train, x_val = x[trn_ind].drop('fold', axis=1), x[val_ind].drop('fold', axis=1)\n        y_train, y_val = y[trn_ind], y[val_ind]\n\n        x_train = encode_cols(x_train, \n                              cfg['encode_stock_cols'], \n                              funcs=cfg['encode_funcs'], \n                              shake=cfg['shake'], \n                              shake_std=cfg['shake_std']).drop('stock_id', axis=1)\n        n_train_cols = x_train.shape[1]\n\n        x_val = encode_cols(x_val, \n                            cfg['encode_stock_cols'], \n                            funcs=cfg['encode_funcs']).drop('stock_id', axis=1)\n\n        train_weights = 1 / np.square(y_train) # Root mean squared percentage error weights\n        val_weights = 1 / np.square(y_val)\n        train_dataset = lgb.Dataset(x_train, y_train, weight=train_weights, free_raw_data=False)\n        val_dataset = lgb.Dataset(x_val, y_val, weight=val_weights, reference=train_dataset, free_raw_data=False)\n\n        # Variables for callback functions\n        \n        model_file = os.path.join(cfg['path_models'], f'{cfg[\"prefix\"]}lgb_fold_{fold}.txt')\n        dart_dict = {'stopping_rounds': cfg['lgb_params']['early_stopping_rounds'],\n                     'model_file': model_file}\n        dict_eval_log = {}\n        \n\n        model = lgb.train(params = cfg['lgb_params'], \n                          train_set = train_dataset, \n                          valid_sets = [val_dataset, train_dataset], \n                          valid_names = ['valid', 'train'], \n                          feval = feval_rmspe,\n                          callbacks=[record_evaluation(dict_eval_log), \n                                     early_stopping_dart(dart_dict)],\n                          verbose_eval = 1)\n\n        model = lgb.Booster(model_file=model_file)\n        y_pred = model.predict(x_val)\n        oof_predictions[val_ind] = y_pred\n        scores.append(round(rmspe(y_val, y_pred), 3))\n\n        dumb_features.append(get_dumb_features(model))\n        top_features.append(get_top_features(model))\n\n        booster_summary = create_booster_summary(\n            booster=model,\n            log_importances=True,\n            max_num_features=25,\n            log_trees_as_dataframe=False, \n            log_pickled_booster=True, \n            y_true=y_val, \n            y_pred=y_pred, \n        )\n        \n        train_score = dart_dict['train_score']\n        valid_score = dart_dict['valid_score']\n        print(dart_dict['best_iteration'])\n        best_iterations.append(dart_dict['best_iteration'])\n        training_best_scores.append(round(train_score, 3))\n        valid_best_scores.append(round(valid_score, 3))\n        best_score_diffs.append(round(valid_score - train_score, 3))\n\n        booster_summaries.append(booster_summary)\n        dict_eval_logs.append(dict_eval_log)\n        del booster_summary, dict_eval_log\n\n    rmspe_score = round(rmspe(y, oof_predictions), 4)\n    print(f'Our out of folds RMSPE is {rmspe_score}')\n    print(f'Our cv fold scores are {scores}')\n    np.save('oof_predictions', oof_predictions)\n\n    run = neptune.init(\n            project=cfg['neptune_project'],\n            api_token=NEPTUNE_API_TOKEN,\n            name=cfg['neptune_run_name'],    \n            description=cfg['neptune_description'],\n            tags=[cfg['path_features'], cfg['prefix']],\n            source_files=['cfg.json'],\n    )\n    run['feat_id'] = feat_file\n    run['cfg'] = cfg\n    run['RMSPE'] = rmspe_score\n    run['RMSPE_oof_scores'] = scores\n    run['RMSPE_cv_std'] = np.std(scores)\n\n    run['best_iterations'] = best_iterations\n    best_iterations_mean = int(np.mean(best_iterations))\n    run['best_iterations_mean'] = best_iterations_mean\n    run['training_best_scores'] = training_best_scores\n    run['valid_best_scores'] = valid_best_scores\n    run['best_score_diffs'] = best_score_diffs\n    run['best_score_diffs_mean'] = round(np.mean(best_score_diffs), 3)\n    run['dumb_features'] = list(reduce(lambda a, b: set(a).intersection(set(b)), dumb_features))\n    run['top_features'] = list(reduce(lambda a, b: set(a).intersection(set(b)), top_features))\n\n    # Logs for each folds model\n    for fold in range(5):\n        run[f'lgbm_summaries/fold_{fold}'] = booster_summaries[fold]\n        run[f'lgbm_summaries/dumb_features_{fold}'] = list(dumb_features[fold])\n        run[f'lgbm_summaries/top_features_{fold}'] = list(top_features[fold])\n        dict_eval_log = dict_eval_logs[fold]\n        for valid_set, odict in dict_eval_log.items():\n            for metric, log in odict.items():\n                for val in log:\n                    run[f'eval_logs/{fold}_{valid_set}_{metric}'].log(val)\n    run.stop()\n\n    if cfg['rerun']: \n        print(f'retraining model with all data for {best_iterations} iterations')\n        params = cfg['lgb_params'].copy()\n        params['early_stopping_rounds'] = 0 # No valid set to stop with\n\n        x_train = x.drop(['fold'], axis=1)\n        x_train = encode_cols(x_train, \n                              cfg['encode_stock_cols'], \n                              funcs=cfg['encode_funcs'], \n                              shake=cfg['shake'], \n                              shake_std=cfg['shake_std']).drop('stock_id', axis=1)\n        y_train = y\n\n        assert(n_train_cols == x_train.shape[1])\n\n        train_weights = 1 / np.square(y_train) # Root mean squared percentage error weights\n        train_dataset = lgb.Dataset(x_train, y_train, weight=train_weights)\n\n        for fold, best_iter in enumerate(best_iterations): \n            params['n_estimators'] = int(best_iter) # lgbm needs int here\n            model = lgb.train(params = params, \n                              train_set = train_dataset)\n            model.save_model(os.path.join(cfg['path_models'], f'{cfg[\"prefix\"]}rerun_lgb_{fold}.txt'))\n    \nif __name__ == '__main__': \n    main()\n\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[1] train's rmse: 0.00114413    train's RMSPE: 0.52998  valid's rmse: 0.00115188    valid's RMSPE: 0.53124\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:183: UserWarning: Early stopping is not available in dart mode\n  _log_warning('Early stopping is not available in dart mode')\n\n\n[2] train's rmse: 0.00109769    train's RMSPE: 0.508467 valid's rmse: 0.00110573    valid's RMSPE: 0.509958\n[3] train's rmse: 0.00105382    train's RMSPE: 0.488149 valid's rmse: 0.00106222    valid's RMSPE: 0.48989\n2\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[1] train's rmse: 0.0011456 train's RMSPE: 0.52913  valid's rmse: 0.00114536    valid's RMSPE: 0.534346\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:183: UserWarning: Early stopping is not available in dart mode\n  _log_warning('Early stopping is not available in dart mode')\n\n\n[2] train's rmse: 0.00109882    train's RMSPE: 0.507522 valid's rmse: 0.00109936    valid's RMSPE: 0.512882\n[3] train's rmse: 0.00105481    train's RMSPE: 0.487196 valid's rmse: 0.00105636    valid's RMSPE: 0.492825\n2\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[1] train's rmse: 0.00114983    train's RMSPE: 0.531413 valid's rmse: 0.00112919    valid's RMSPE: 0.52551\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:183: UserWarning: Early stopping is not available in dart mode\n  _log_warning('Early stopping is not available in dart mode')\n\n\n[2] train's rmse: 0.00110306    train's RMSPE: 0.509799 valid's rmse: 0.0010835 valid's RMSPE: 0.504245\n[3] train's rmse: 0.00105898    train's RMSPE: 0.489427 valid's rmse: 0.00104054    valid's RMSPE: 0.484253\n2\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[1] train's rmse: 0.001147  train's RMSPE: 0.530741 valid's rmse: 0.00114036    valid's RMSPE: 0.528187\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:183: UserWarning: Early stopping is not available in dart mode\n  _log_warning('Early stopping is not available in dart mode')\n\n\n[2] train's rmse: 0.00110018    train's RMSPE: 0.509077 valid's rmse: 0.00109398    valid's RMSPE: 0.506709\n[3] train's rmse: 0.00105622    train's RMSPE: 0.488736 valid's rmse: 0.00105007    valid's RMSPE: 0.48637\n2\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[1] train's rmse: 0.0011412 train's RMSPE: 0.529605 valid's rmse: 0.00116322    valid's RMSPE: 0.532431\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:183: UserWarning: Early stopping is not available in dart mode\n  _log_warning('Early stopping is not available in dart mode')\n\n\n[2] train's rmse: 0.00109532    train's RMSPE: 0.508314 valid's rmse: 0.00111604    valid's RMSPE: 0.510835\n[3] train's rmse: 0.00105181    train's RMSPE: 0.488118 valid's rmse: 0.00107131    valid's RMSPE: 0.490362\n2\nOur out of folds RMSPE is 0.4887\nOur cv fold scores are [0.49, 0.493, 0.484, 0.486, 0.49]\nhttps://app.neptune.ai/chrisrichardmiles/optiver/e/OP-125\nRemember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\nShutting down background jobs, please wait a moment...\nDone!\n\n\nWaiting for the remaining 142 operations to synchronize with Neptune. Do not kill this process.\n\n\nAll 142 operations synced, thanks for waiting!\nretraining model with all data for [2, 2, 2, 2, 2] iterations\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nm = lgb.Booster(model_file='./lgb_fold_0.txt')"
  },
  {
    "objectID": "projects/optiver/notebooks/opt-train-dart-op-129a-stock-31-only.html",
    "href": "projects/optiver/notebooks/opt-train-dart-op-129a-stock-31-only.html",
    "title": "chrisrichardmiles",
    "section": "",
    "text": "cfg = {\n    \"script_name\": 'opt_train_dart_op_129a_not_stock_31',\n    \"path_features\": '../input/generate-train-features-script-p13/p13_train.pkl', # Used in train mode\n    \"path_models\": '',\n    \"path_data_raw\": '../input/optiver-realized-volatility-prediction/',\n    \"neptune_project\": 'chrisrichardmiles/optiver',\n    \"neptune_description\": 'p13 encoding top columns with shake .3 using dart with custom early stopping',\n    \"encode_time_cols\": ['real_vol_ratio_5_10', 'real_vol_std', 'real_vol_mean', 'real_vol_mean_decay_0.9_-1', 'order_norm_momentum', 'real_vol_mean_decay_0.85_-1', 'real_vol_mean_decay_0.99_1', 'real_vol_mean_decay_0.95_1', 'abs_price_wap_diff_mean_decay_flip', 'abs_price_wap_diff_mean_decay', 'order_norm_sum', 'real_vol_mean_decay_0.85_-1_2', 'spread_mean_decay_flip_95', 'real_vol_mean_decay_0.99_-1', 'real_vol_mean_decay_0.75_-1', 'spread_mean', 'order_count_sum', 'bid_price_diff_count_unique', 'spread_momentum', 'size_mean', 'real_vol_mean_decay_0.95_-1', 'order_norm_mean_decay', 'spread_2_mean_decay_95', 'order_size_mean', 'spread_mean_decay_95', \n                         'spread_pct_momentum'], \n    \"encode_stock_cols\": ['real_vol_ratio_5_10', 'real_vol_std', 'real_vol_mean', 'real_vol_mean_decay_0.9_-1', 'order_norm_momentum', 'real_vol_mean_decay_0.85_-1', 'real_vol_mean_decay_0.99_1', 'real_vol_mean_decay_0.95_1', 'abs_price_wap_diff_mean_decay_flip', 'abs_price_wap_diff_mean_decay', 'order_norm_sum', 'real_vol_mean_decay_0.85_-1_2', 'spread_mean_decay_flip_95', 'real_vol_mean_decay_0.99_-1', 'real_vol_mean_decay_0.75_-1', 'spread_mean', 'order_count_sum', 'bid_price_diff_count_unique', 'spread_momentum', 'size_mean', 'real_vol_mean_decay_0.95_-1', 'order_norm_mean_decay', 'spread_2_mean_decay_95', 'order_size_mean', 'spread_mean_decay_95',\n                          'spread_pct_momentum'], \n    \"drop_cols\": ['row_id', 'time_id', 'stock_id', 'target'] + ['real_momentum_0.55_-1', 'wap_2_last-first', 'sum_bid_ask_momentum', 'abs_log_return_momentum', 'order_size_sqaure_weighted_sum', 'size_mean_decay_95', 'size_norm_momentum_95', 'size_norm_momentum', 'size_spread_mean_decay_flip_95', 'log_return_2_realized_volatility', 'abs_price_wap_diff_2_std', 'sum_bid_ask_mean', 'real_momentum_0.85_-1', 'real_vol_mean_decay_0.55_-1', 'abs_price_wap_diff_amax', 'size_mean_decay', 'real_vol_mean_decay_0.9_-1_2', 'abs_price_wap_diff_2_mean', 'real_momentum_0.65_-1_2', 'price_wap_diff_2_max_sub_min', 'real_vol_mean_decay_0.75_1', 'real_vol_min_5', 'real_vol_mean_decay_0.95_-1_2', 'real_vol_min_6', 'size_spread_mean', 'size_spread_mean_decay_95', 'real_vol_mean_decay_0.75_1_2', 'sum_bid_ask_std', 'price_wap_diff_mean_decay', 'wap_2_real_vol', 'abs_price_wap_diff_2_mean_decay', 'size_momentum_95', 'real_momentum_0.65_-1', 'size_spread_momentum_95', 'real_vol_min_2', 'sum_bid_ask_mean_decay_flip', 'real_vol_mean_decay_0.65_1', 'size_spread_mean_decay_flip', 'real_momentum_0.75_-1_2', 'abs_price_wap_diff_2_max_sub_min', 'price_wap_diff_momentum', 'real_momentum_0.55_-1_2', 'real_momentum_0.45_-1_2', 'spread_pct_std', 'abs_price_wap_diff_max_sub_min', 'real_momentum_0.95_-1', 'real_vol_min_7', 'real_vol_min_4_2', 'real_vol_mean_decay_0.99_1_2', 'spread_2_sum', 'sum_bid_ask_mean_decay', 'real_vol_mean_decay_0.55_1', 'real_vol_mean_decay_0.55_1_2', 'real_vol_mean_decay_0.9_1_2', 'real_vol_mean_decay_0.65_1_2', 'real_vol_mean_decay_0.45_1_2', 'wap_2_std', 'price_wap_diff_max_sub_min', 'real_momentum_0.85_-1_2', 'real_momentum_0.45_-1', 'price_wap_diff_2_mean_decay_flip', 'size_norm_mean_decay_flip_95', 'price_wap_diff_mean_decay_flip', 'real_momentum_0.99_-1', 'sum_bid_ask_max_sub_min', 'real_vol_mean_decay_0.95_1_2', 'real_vol_min_4', 'real_vol_min_8', 'real_vol_min_2_2', 'real_momentum_0.99_-1_2', 'real_momentum_0.95_-1_2', 'log_return_mean_decay_flip', 'real_vol_mean_decay_0.85_1_2', 'price_wap_diff_2_std', 'log_return_realized_volatility', 'abs_log_return_2_momentum', 'log_return_2_mean_decay_flip', 'log_return_std', 'log_return_2_std', 'real_momentum_0.75_-1', 'real_vol_mean_decay_0.45_-1_2', 'abs_price_wap_diff_2_momentum', 'real_momentum_0.9_-1_2', 'real_vol_mean_decay_0.9_1', 'price_wap_diff_2_mean_decay', 'real_vol_min_9_2', 'real_vol_mean_decay_0.99_-1_2', 'wap_2_max_sub_min', 'real_momentum_0.9_-1', 'dummy3', 'abs_price_wap_diff_2_mean_decay_flip', \n                                                               'abs_log_return_2_std'],\n    \"encode_funcs\": ['mean', 'std'], \n    \"shake\": False, \n    \"shake_std\": .3, \n    \"prefix\": '',\n    \"rerun\": True,\n    \"neptune_run_name\": '',\n    \"lgb_params\": {\n        # https://lightgbm.readthedocs.io/en/latest/index.html\n        \"boosting_type\": \"dart\",\n        \"objective\": \"rmse\",\n        \"learning_rate\": .05,\n        \"num_leaves\": 255,\n        \"min_data_in_leaf\": 255,\n        \"feature_fraction\": 0.8,\n        \"bagging_fraction\": .5, # Select bagging_fraction of rows every bagging_freq of iterations.\n        \"bagging_freq\": 1,      # This speeds up training and underfits. Need both set to do anything.\n        \"n_estimators\": 10_000,\n        \"early_stopping_rounds\": 400,\n        \"n_jobs\": -1,\n        \"seed\": 42,\n        \"verbose\": -1, \n    },\n}\nwith open('cfg.json', 'w') as f: \n    json.dump(cfg, f)\n\n\ndef main(): \n    train = pd.read_pickle(cfg['path_features'])\n    train['real_vol_ratio_5_10'] = train[[f'real_vol_min_{i}' for i in range(1, 6)]].sum(axis=1) / train[[f'real_vol_min_{i}' for i in range(6, 11)]].sum(axis=1)\n    train['real_vol_std'] = train[[f'real_vol_min_{i}' for i in range(1, 11)]].std(axis=1)\n    train['real_vol_mean'] = train[[f'real_vol_min_{i}' for i in range(1, 11)]].mean(axis=1)\n    train = encode_cols(train, cfg[\"encode_time_cols\"], funcs=cfg['encode_funcs'], on='time_id')\n\n    # Saving encoded stock columns\n    feat_file = 'enc_' + os.path.split(cfg['path_features'])[1]\n    tmp = encode_cols(train, cfg[\"encode_stock_cols\"], funcs=cfg['encode_funcs'], on='stock_id')\n    tmp.to_pickle(os.path.join(cfg['path_models'], feat_file))\n    del tmp\n\n    drop_cols = [c for c in cfg['drop_cols'] if c in train.columns and c != 'stock_id']\n    x = train.drop(drop_cols, axis = 1)\n    y = train['target']\n\n    oof_predictions = np.zeros(x.shape[0]) # Create out of folds array\n    scores = [] # Keep track of scores for each fold and all oof at the end\n    best_iterations = []\n    training_best_scores = []\n    valid_best_scores = [] # Same as scores in this script, but would be different with nested cv\n    best_score_diffs = []\n    dict_eval_logs = [] # For experimentation tracking\n    booster_summaries = [] # For experimentation tracking\n    dumb_features = []\n    top_features = []\n\n    for fold in range(5):\n        \n        trn_ind = x.fold != fold\n        val_ind = x.fold == fold\n\n        print(f'Training fold {fold}')\n        x_train, x_val = x[trn_ind].drop('fold', axis=1), x[val_ind].drop('fold', axis=1)\n        y_train, y_val = y[trn_ind], y[val_ind]\n        tmp = np.zeros(x_val.shape[0])\n        \n        train_mask = x_train.stock_id == 31\n        val_mask = x_val.stock_id == 31\n\n        x_train = encode_cols(x_train, \n                              cfg['encode_stock_cols'], \n                              funcs=cfg['encode_funcs'], \n                              shake=cfg['shake'], \n                              shake_std=cfg['shake_std']).drop('stock_id', axis=1)\n        n_train_cols = x_train.shape[1]\n\n        x_val = encode_cols(x_val, \n                            cfg['encode_stock_cols'], \n                            funcs=cfg['encode_funcs']).drop('stock_id', axis=1)\n        \n        x_train, y_train = x_train[train_mask], y_train[train_mask]\n        x_val, y_val = x_val[val_mask], y_val[val_mask]\n\n        train_weights = 1 / np.square(y_train) # Root mean squared percentage error weights\n        val_weights = 1 / np.square(y_val)\n        train_dataset = lgb.Dataset(x_train, y_train, weight=train_weights, free_raw_data=False)\n        val_dataset = lgb.Dataset(x_val, y_val, weight=val_weights, reference=train_dataset, free_raw_data=False)\n\n        # Variables for callback functions\n        \n        model_file = os.path.join(cfg['path_models'], f'{cfg[\"prefix\"]}lgb_fold_{fold}.txt')\n        dart_dict = {'stopping_rounds': cfg['lgb_params']['early_stopping_rounds'],\n                     'model_file': model_file}\n        dict_eval_log = {}\n        \n\n        model = lgb.train(params = cfg['lgb_params'], \n                          train_set = train_dataset, \n                          valid_sets = [val_dataset, train_dataset], \n                          valid_names = ['valid', 'train'], \n                          feval = feval_rmspe,\n                          callbacks=[record_evaluation(dict_eval_log), \n                                     early_stopping_dart(dart_dict)],\n                          verbose_eval = 1)\n\n        model = lgb.Booster(model_file=model_file)\n        y_pred = model.predict(x_val)\n        tmp[val_mask] = y_pred\n        oof_predictions[val_ind] = tmp\n        scores.append(round(rmspe(y_val, y_pred), 3))\n\n        dumb_features.append(get_dumb_features(model))\n        top_features.append(get_top_features(model))\n\n        booster_summary = create_booster_summary(\n            booster=model,\n            log_importances=True,\n            max_num_features=25,\n            log_trees_as_dataframe=False, \n            log_pickled_booster=True, \n            y_true=y_val, \n            y_pred=y_pred, \n        )\n        \n        train_score = dart_dict['train_score']\n        valid_score = dart_dict['valid_score']\n        print(dart_dict['best_iteration'])\n        best_iterations.append(dart_dict['best_iteration'])\n        training_best_scores.append(round(train_score, 3))\n        valid_best_scores.append(round(valid_score, 3))\n        best_score_diffs.append(round(valid_score - train_score, 3))\n\n        booster_summaries.append(booster_summary)\n        dict_eval_logs.append(dict_eval_log)\n        del booster_summary, dict_eval_log\n\n    rmspe_score = round(rmspe(y, oof_predictions), 4)\n    print(f'Our out of folds RMSPE is {rmspe_score}')\n    print(f'Our cv fold scores are {scores}')\n    np.save('oof_predictions', oof_predictions)\n\n    run = neptune.init(\n            project=cfg['neptune_project'],\n            api_token=NEPTUNE_API_TOKEN,\n            name=cfg['neptune_run_name'],    \n            description=cfg['neptune_description'],\n            tags=[cfg['path_features'], cfg['prefix']],\n            source_files=['cfg.json'],\n    )\n    run['feat_id'] = feat_file\n    run['cfg'] = cfg\n    run['RMSPE'] = rmspe_score\n    run['RMSPE_oof_scores'] = scores\n    run['RMSPE_cv_std'] = np.std(scores)\n\n    run['best_iterations'] = best_iterations\n    best_iterations_mean = int(np.mean(best_iterations))\n    run['best_iterations_mean'] = best_iterations_mean\n    run['training_best_scores'] = training_best_scores\n    run['valid_best_scores'] = valid_best_scores\n    run['best_score_diffs'] = best_score_diffs\n    run['best_score_diffs_mean'] = round(np.mean(best_score_diffs), 3)\n    run['dumb_features'] = list(reduce(lambda a, b: set(a).intersection(set(b)), dumb_features))\n    run['top_features'] = list(reduce(lambda a, b: set(a).intersection(set(b)), top_features))\n\n    # Logs for each folds model\n    for fold in range(5):\n        run[f'lgbm_summaries/fold_{fold}'] = booster_summaries[fold]\n        run[f'lgbm_summaries/dumb_features_{fold}'] = list(dumb_features[fold])\n        run[f'lgbm_summaries/top_features_{fold}'] = list(top_features[fold])\n        dict_eval_log = dict_eval_logs[fold]\n        for valid_set, odict in dict_eval_log.items():\n            for metric, log in odict.items():\n                for val in log:\n                    run[f'eval_logs/{fold}_{valid_set}_{metric}'].log(val)\n    run.stop()\n\n    if cfg['rerun']: \n        print(f'retraining model with all data for {best_iterations} iterations')\n        params = cfg['lgb_params'].copy()\n        params['early_stopping_rounds'] = 0 # No valid set to stop with\n\n        x_train = x.drop(['fold'], axis=1)\n        x_train = encode_cols(x_train, \n                              cfg['encode_stock_cols'], \n                              funcs=cfg['encode_funcs'], \n                              shake=cfg['shake'], \n                              shake_std=cfg['shake_std']).drop('stock_id', axis=1)\n        y_train = y\n\n        assert(n_train_cols == x_train.shape[1])\n\n        train_weights = 1 / np.square(y_train) # Root mean squared percentage error weights\n        train_dataset = lgb.Dataset(x_train, y_train, weight=train_weights)\n\n        for fold, best_iter in enumerate(best_iterations): \n            params['n_estimators'] = int(best_iter) # lgbm needs int here\n            model = lgb.train(params = params, \n                              train_set = train_dataset)\n            model.save_model(os.path.join(cfg['path_models'], f'{cfg[\"prefix\"]}rerun_lgb_{fold}.txt'))\n    \nif __name__ == '__main__': \n    main()\n\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[1] train's rmse: 0.00106867    train's RMSPE: 0.767499 valid's rmse: 0.00122727    valid's RMSPE: 0.708038\n[2] train's rmse: 0.001042  train's RMSPE: 0.748345 valid's rmse: 0.00119375    valid's RMSPE: 0.6887\n[3] train's rmse: 0.00101946    train's RMSPE: 0.732156 valid's rmse: 0.00116574    valid's RMSPE: 0.672537\n[4] train's rmse: 0.000995148   train's RMSPE: 0.714695 valid's rmse: 0.00113797    valid's RMSPE: 0.656516\n[5] train's rmse: 0.000973506   train's RMSPE: 0.699153 valid's rmse: 0.00111283    valid's RMSPE: 0.642014\n[6] train's rmse: 0.000949377   train's RMSPE: 0.681824 valid's rmse: 0.00108566    valid's RMSPE: 0.626337\n[7] train's rmse: 0.000948331   train's RMSPE: 0.681072 valid's rmse: 0.00108585    valid's RMSPE: 0.626448\n[8] train's rmse: 0.000927308   train's RMSPE: 0.665974 valid's rmse: 0.0010636 valid's RMSPE: 0.613614\n[9] train's rmse: 0.000907417   train's RMSPE: 0.651689 valid's rmse: 0.00104234    valid's RMSPE: 0.601345\n[10]    train's rmse: 0.000908382   train's RMSPE: 0.652382 valid's rmse: 0.00104545    valid's RMSPE: 0.603142\n[11]    train's rmse: 0.000886237   train's RMSPE: 0.636478 valid's rmse: 0.00102186    valid's RMSPE: 0.589535\n[12]    train's rmse: 0.000891033   train's RMSPE: 0.639922 valid's rmse: 0.00102665    valid's RMSPE: 0.592296\n[13]    train's rmse: 0.000871068   train's RMSPE: 0.625584 valid's rmse: 0.00100649    valid's RMSPE: 0.580667\n[14]    train's rmse: 0.000859981   train's RMSPE: 0.617621 valid's rmse: 0.000989759   valid's RMSPE: 0.571013\n[15]    train's rmse: 0.000849121   train's RMSPE: 0.609822 valid's rmse: 0.000973886   valid's RMSPE: 0.561855\n[16]    train's rmse: 0.00083352    train's RMSPE: 0.598618 valid's rmse: 0.000959015   valid's RMSPE: 0.553276\n[17]    train's rmse: 0.000839672   train's RMSPE: 0.603036 valid's rmse: 0.000964272   valid's RMSPE: 0.556309\n[18]    train's rmse: 0.000828681   train's RMSPE: 0.595142 valid's rmse: 0.000946612   valid's RMSPE: 0.54612\n[19]    train's rmse: 0.00082501    train's RMSPE: 0.592506 valid's rmse: 0.000947348   valid's RMSPE: 0.546545\n[20]    train's rmse: 0.000825573   train's RMSPE: 0.59291  valid's rmse: 0.00094836    valid's RMSPE: 0.547129\n[21]    train's rmse: 0.00083271    train's RMSPE: 0.598036 valid's rmse: 0.000955271   valid's RMSPE: 0.551116\n[22]    train's rmse: 0.000851336   train's RMSPE: 0.611413 valid's rmse: 0.00102261    valid's RMSPE: 0.589968\n[23]    train's rmse: 0.000834639   train's RMSPE: 0.599421 valid's rmse: 0.00100348    valid's RMSPE: 0.578928\n[24]    train's rmse: 0.000871333   train's RMSPE: 0.625774 valid's rmse: 0.00107203    valid's RMSPE: 0.618474\n[25]    train's rmse: 0.000866251   train's RMSPE: 0.622124 valid's rmse: 0.00106389    valid's RMSPE: 0.613778\n[26]    train's rmse: 0.000848347   train's RMSPE: 0.609266 valid's rmse: 0.00104062    valid's RMSPE: 0.600356\n[27]    train's rmse: 0.000829409   train's RMSPE: 0.595665 valid's rmse: 0.00101704    valid's RMSPE: 0.586751\n[28]    train's rmse: 0.000833406   train's RMSPE: 0.598536 valid's rmse: 0.00102131    valid's RMSPE: 0.589215\n[29]    train's rmse: 0.000840003   train's RMSPE: 0.603273 valid's rmse: 0.00102844    valid's RMSPE: 0.59333\n[30]    train's rmse: 0.000824358   train's RMSPE: 0.592038 valid's rmse: 0.00100794    valid's RMSPE: 0.581501\n[31]    train's rmse: 0.000809802   train's RMSPE: 0.581583 valid's rmse: 0.000991967   valid's RMSPE: 0.572287\n[32]    train's rmse: 0.000816707   train's RMSPE: 0.586542 valid's rmse: 0.00100078    valid's RMSPE: 0.57737\n[33]    train's rmse: 0.000802064   train's RMSPE: 0.576026 valid's rmse: 0.000981735   valid's RMSPE: 0.566383\n[34]    train's rmse: 0.000789655   train's RMSPE: 0.567114 valid's rmse: 0.0009655 valid's RMSPE: 0.557017\n[35]    train's rmse: 0.00077858    train's RMSPE: 0.559161 valid's rmse: 0.000951306   valid's RMSPE: 0.548828\n[36]    train's rmse: 0.000767113   train's RMSPE: 0.550925 valid's rmse: 0.000934836   valid's RMSPE: 0.539326\n[37]    train's rmse: 0.000769686   train's RMSPE: 0.552773 valid's rmse: 0.000938198   valid's RMSPE: 0.541266\n[38]    train's rmse: 0.000795299   train's RMSPE: 0.571168 valid's rmse: 0.000983672   valid's RMSPE: 0.567501\n[39]    train's rmse: 0.00077998    train's RMSPE: 0.560166 valid's rmse: 0.000963977   valid's RMSPE: 0.556138\n[40]    train's rmse: 0.000766369   train's RMSPE: 0.550391 valid's rmse: 0.000945856   valid's RMSPE: 0.545684\n[41]    train's rmse: 0.000770796   train's RMSPE: 0.55357  valid's rmse: 0.000951052   valid's RMSPE: 0.548682\n[42]    train's rmse: 0.000776215   train's RMSPE: 0.557462 valid's rmse: 0.000957698   valid's RMSPE: 0.552516\n[43]    train's rmse: 0.0007622 train's RMSPE: 0.547397 valid's rmse: 0.000941449   valid's RMSPE: 0.543141\n[44]    train's rmse: 0.000750164   train's RMSPE: 0.538753 valid's rmse: 0.000925796   valid's RMSPE: 0.534111\n[45]    train's rmse: 0.000739687   train's RMSPE: 0.531229 valid's rmse: 0.000911756   valid's RMSPE: 0.526011\n[46]    train's rmse: 0.000745714   train's RMSPE: 0.535557 valid's rmse: 0.000919691   valid's RMSPE: 0.530589\n[47]    train's rmse: 0.000734649   train's RMSPE: 0.52761  valid's rmse: 0.000904165   valid's RMSPE: 0.521632\n[48]    train's rmse: 0.000739857   train's RMSPE: 0.53135  valid's rmse: 0.000910779   valid's RMSPE: 0.525448\n[49]    train's rmse: 0.000745251   train's RMSPE: 0.535225 valid's rmse: 0.000916823   valid's RMSPE: 0.528935\n[50]    train's rmse: 0.000734425   train's RMSPE: 0.527449 valid's rmse: 0.000904457   valid's RMSPE: 0.5218\n[51]    train's rmse: 0.000738497   train's RMSPE: 0.530373 valid's rmse: 0.000909029   valid's RMSPE: 0.524438\n[52]    train's rmse: 0.000740706   train's RMSPE: 0.53196  valid's rmse: 0.000912051   valid's RMSPE: 0.526181\n[53]    train's rmse: 0.00074488    train's RMSPE: 0.534958 valid's rmse: 0.000916664   valid's RMSPE: 0.528843\n[54]    train's rmse: 0.000734004   train's RMSPE: 0.527147 valid's rmse: 0.000904429   valid's RMSPE: 0.521784\n[55]    train's rmse: 0.000737999   train's RMSPE: 0.530016 valid's rmse: 0.000909868   valid's RMSPE: 0.524922\n[56]    train's rmse: 0.000728848   train's RMSPE: 0.523444 valid's rmse: 0.000897811   valid's RMSPE: 0.517966\n[57]    train's rmse: 0.000720937   train's RMSPE: 0.517763 valid's rmse: 0.000885932   valid's RMSPE: 0.511113\n[58]    train's rmse: 0.000714298   train's RMSPE: 0.512995 valid's rmse: 0.000875901   valid's RMSPE: 0.505326\n[59]    train's rmse: 0.000718439   train's RMSPE: 0.515968 valid's rmse: 0.000881649   valid's RMSPE: 0.508642\n[60]    train's rmse: 0.000708969   train's RMSPE: 0.509167 valid's rmse: 0.000870505   valid's RMSPE: 0.502212\n[61]    train's rmse: 0.000715741   train's RMSPE: 0.514031 valid's rmse: 0.000879099   valid's RMSPE: 0.507171\n[62]    train's rmse: 0.000708445   train's RMSPE: 0.508791 valid's rmse: 0.000868078   valid's RMSPE: 0.500812\n[63]    train's rmse: 0.000723033   train's RMSPE: 0.519268 valid's rmse: 0.000894915   valid's RMSPE: 0.516295\n[64]    train's rmse: 0.000738603   train's RMSPE: 0.53045  valid's rmse: 0.00092066    valid's RMSPE: 0.531148\n[65]    train's rmse: 0.000745101   train's RMSPE: 0.535116 valid's rmse: 0.000928227   valid's RMSPE: 0.535514\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:183: UserWarning: Early stopping is not available in dart mode\n  _log_warning('Early stopping is not available in dart mode')\n\n\n[66]    train's rmse: 0.000733834   train's RMSPE: 0.527025 valid's rmse: 0.000909756   valid's RMSPE: 0.524857\n[67]    train's rmse: 0.000736107   train's RMSPE: 0.528657 valid's rmse: 0.000913679   valid's RMSPE: 0.527121\n[68]    train's rmse: 0.000726519   train's RMSPE: 0.521771 valid's rmse: 0.000899999   valid's RMSPE: 0.519228\n[69]    train's rmse: 0.000717202   train's RMSPE: 0.51508  valid's rmse: 0.000890045   valid's RMSPE: 0.513485\n[70]    train's rmse: 0.000721566   train's RMSPE: 0.518214 valid's rmse: 0.000894665   valid's RMSPE: 0.516151\n[71]    train's rmse: 0.000724795   train's RMSPE: 0.520533 valid's rmse: 0.000898705   valid's RMSPE: 0.518481\n[72]    train's rmse: 0.00071496    train's RMSPE: 0.51347  valid's rmse: 0.000887779   valid's RMSPE: 0.512178\n[73]    train's rmse: 0.000706178   train's RMSPE: 0.507163 valid's rmse: 0.000876401   valid's RMSPE: 0.505614\n[74]    train's rmse: 0.000710555   train's RMSPE: 0.510306 valid's rmse: 0.000882314   valid's RMSPE: 0.509025\n[75]    train's rmse: 0.000701982   train's RMSPE: 0.504149 valid's rmse: 0.000869734   valid's RMSPE: 0.501768\n[76]    train's rmse: 0.000706629   train's RMSPE: 0.507487 valid's rmse: 0.000875249   valid's RMSPE: 0.504949\n[77]    train's rmse: 0.00069902    train's RMSPE: 0.502022 valid's rmse: 0.000864215   valid's RMSPE: 0.498584\n[78]    train's rmse: 0.000698679   train's RMSPE: 0.501777 valid's rmse: 0.000864072   valid's RMSPE: 0.498501\n[79]    train's rmse: 0.000702681   train's RMSPE: 0.504652 valid's rmse: 0.000868702   valid's RMSPE: 0.501172\n[80]    train's rmse: 0.000705923   train's RMSPE: 0.50698  valid's rmse: 0.000872905   valid's RMSPE: 0.503597\n[81]    train's rmse: 0.000697684   train's RMSPE: 0.501063 valid's rmse: 0.000862714   valid's RMSPE: 0.497718\n[82]    train's rmse: 0.000691211   train's RMSPE: 0.496414 valid's rmse: 0.000853568   valid's RMSPE: 0.492441\n[83]    train's rmse: 0.000695175   train's RMSPE: 0.499261 valid's rmse: 0.000859349   valid's RMSPE: 0.495776\n[84]    train's rmse: 0.000687328   train's RMSPE: 0.493625 valid's rmse: 0.000849384   valid's RMSPE: 0.490027\n[85]    train's rmse: 0.000690435   train's RMSPE: 0.495856 valid's rmse: 0.000853598   valid's RMSPE: 0.492458\n[86]    train's rmse: 0.000694205   train's RMSPE: 0.498564 valid's rmse: 0.000858298   valid's RMSPE: 0.49517\n[87]    train's rmse: 0.000687312   train's RMSPE: 0.493614 valid's rmse: 0.000849632   valid's RMSPE: 0.49017\n[88]    train's rmse: 0.000689668   train's RMSPE: 0.495306 valid's rmse: 0.000852658   valid's RMSPE: 0.491916\n[89]    train's rmse: 0.000693378   train's RMSPE: 0.497971 valid's rmse: 0.000857112   valid's RMSPE: 0.494486\n[90]    train's rmse: 0.000697989   train's RMSPE: 0.501281 valid's rmse: 0.000862996   valid's RMSPE: 0.497881\n[91]    train's rmse: 0.000702023   train's RMSPE: 0.504179 valid's rmse: 0.000868071   valid's RMSPE: 0.500808\n[92]    train's rmse: 0.000696968   train's RMSPE: 0.500549 valid's rmse: 0.000857844   valid's RMSPE: 0.494908\n[93]    train's rmse: 0.000688708   train's RMSPE: 0.494616 valid's rmse: 0.000847622   valid's RMSPE: 0.489011\n[94]    train's rmse: 0.000679024   train's RMSPE: 0.487662 valid's rmse: 0.000836406   valid's RMSPE: 0.48254\n[95]    train's rmse: 0.000672076   train's RMSPE: 0.482671 valid's rmse: 0.000827842   valid's RMSPE: 0.477599\n[96]    train's rmse: 0.000668494   train's RMSPE: 0.480099 valid's rmse: 0.000821475   valid's RMSPE: 0.473926\n[97]    train's rmse: 0.000663797   train's RMSPE: 0.476726 valid's rmse: 0.000813206   valid's RMSPE: 0.469155\n[98]    train's rmse: 0.000666955   train's RMSPE: 0.478993 valid's rmse: 0.000817319   valid's RMSPE: 0.471528\n[99]    train's rmse: 0.000669655   train's RMSPE: 0.480932 valid's rmse: 0.000820732   valid's RMSPE: 0.473497\n[100]   train's rmse: 0.000672264   train's RMSPE: 0.482807 valid's rmse: 0.000824683   valid's RMSPE: 0.475777\n[101]   train's rmse: 0.000665829   train's RMSPE: 0.478185 valid's rmse: 0.000817764   valid's RMSPE: 0.471785\n[102]   train's rmse: 0.000660724   train's RMSPE: 0.474519 valid's rmse: 0.000810551   valid's RMSPE: 0.467624\n[103]   train's rmse: 0.000663419   train's RMSPE: 0.476454 valid's rmse: 0.000813972   valid's RMSPE: 0.469597\n[104]   train's rmse: 0.000665568   train's RMSPE: 0.477998 valid's rmse: 0.000817227   valid's RMSPE: 0.471476\n[105]   train's rmse: 0.000668884   train's RMSPE: 0.480379 valid's rmse: 0.000821531   valid's RMSPE: 0.473958\n[106]   train's rmse: 0.000679121   train's RMSPE: 0.487731 valid's rmse: 0.000837538   valid's RMSPE: 0.483193\n[107]   train's rmse: 0.000682608   train's RMSPE: 0.490236 valid's rmse: 0.000841696   valid's RMSPE: 0.485592\n[108]   train's rmse: 0.000686209   train's RMSPE: 0.492821 valid's rmse: 0.000846521   valid's RMSPE: 0.488376\n[109]   train's rmse: 0.000689783   train's RMSPE: 0.495388 valid's rmse: 0.000850672   valid's RMSPE: 0.49077\n[110]   train's rmse: 0.000680605   train's RMSPE: 0.488797 valid's rmse: 0.000840467   valid's RMSPE: 0.484883\n[111]   train's rmse: 0.000684274   train's RMSPE: 0.491432 valid's rmse: 0.000845008   valid's RMSPE: 0.487503\n[112]   train's rmse: 0.000687929   train's RMSPE: 0.494057 valid's rmse: 0.000849893   valid's RMSPE: 0.490321\n[113]   train's rmse: 0.000680967   train's RMSPE: 0.489057 valid's rmse: 0.000842237   valid's RMSPE: 0.485904\n[114]   train's rmse: 0.000684974   train's RMSPE: 0.491935 valid's rmse: 0.000847023   valid's RMSPE: 0.488665\n[115]   train's rmse: 0.00068811    train's RMSPE: 0.494187 valid's rmse: 0.000851023   valid's RMSPE: 0.490973\n[116]   train's rmse: 0.000681715   train's RMSPE: 0.489594 valid's rmse: 0.000841468   valid's RMSPE: 0.485461\n[117]   train's rmse: 0.000684302   train's RMSPE: 0.491452 valid's rmse: 0.000844741   valid's RMSPE: 0.487349\n[118]   train's rmse: 0.000686934   train's RMSPE: 0.493343 valid's rmse: 0.000848432   valid's RMSPE: 0.489478\n[119]   train's rmse: 0.000689344   train's RMSPE: 0.495073 valid's rmse: 0.000851435   valid's RMSPE: 0.491211\n[120]   train's rmse: 0.000682935   train's RMSPE: 0.49047  valid's rmse: 0.000843516   valid's RMSPE: 0.486642\n[121]   train's rmse: 0.000685725   train's RMSPE: 0.492474 valid's rmse: 0.000846778   valid's RMSPE: 0.488524\n[122]   train's rmse: 0.000689342   train's RMSPE: 0.495072 valid's rmse: 0.000851365   valid's RMSPE: 0.49117\n[123]   train's rmse: 0.000697772   train's RMSPE: 0.501126 valid's rmse: 0.000863492   valid's RMSPE: 0.498167\n[124]   train's rmse: 0.000699702   train's RMSPE: 0.502512 valid's rmse: 0.00086606    valid's RMSPE: 0.499648\n[125]   train's rmse: 0.000690555   train's RMSPE: 0.495943 valid's rmse: 0.000855639   valid's RMSPE: 0.493636\n[126]   train's rmse: 0.000693507   train's RMSPE: 0.498063 valid's rmse: 0.000859221   valid's RMSPE: 0.495703\n[127]   train's rmse: 0.00069578    train's RMSPE: 0.499695 valid's rmse: 0.00086233    valid's RMSPE: 0.497496\n[128]   train's rmse: 0.000689707   train's RMSPE: 0.495334 valid's rmse: 0.000854133   valid's RMSPE: 0.492767\n[129]   train's rmse: 0.000681762   train's RMSPE: 0.489628 valid's rmse: 0.000847061   valid's RMSPE: 0.488687\n[130]   train's rmse: 0.000688552   train's RMSPE: 0.494505 valid's rmse: 0.000857005   valid's RMSPE: 0.494424\n[131]   train's rmse: 0.000681276   train's RMSPE: 0.489279 valid's rmse: 0.000849256   valid's RMSPE: 0.489954\n[132]   train's rmse: 0.000683924   train's RMSPE: 0.491181 valid's rmse: 0.000852629   valid's RMSPE: 0.4919\n[133]   train's rmse: 0.000677955   train's RMSPE: 0.486894 valid's rmse: 0.000844751   valid's RMSPE: 0.487354\n[134]   train's rmse: 0.000681189   train's RMSPE: 0.489217 valid's rmse: 0.000848656   valid's RMSPE: 0.489608\n[135]   train's rmse: 0.000673352   train's RMSPE: 0.483588 valid's rmse: 0.000839815   valid's RMSPE: 0.484507\n[136]   train's rmse: 0.000676588   train's RMSPE: 0.485912 valid's rmse: 0.000843313   valid's RMSPE: 0.486525\n[137]   train's rmse: 0.000679821   train's RMSPE: 0.488234 valid's rmse: 0.000847274   valid's RMSPE: 0.48881\n[138]   train's rmse: 0.00068315    train's RMSPE: 0.490624 valid's rmse: 0.000850813   valid's RMSPE: 0.490852\n[139]   train's rmse: 0.000685334   train's RMSPE: 0.492193 valid's rmse: 0.000853542   valid's RMSPE: 0.492426\n[140]   train's rmse: 0.000677982   train's RMSPE: 0.486913 valid's rmse: 0.00084427    valid's RMSPE: 0.487077\n[141]   train's rmse: 0.000669413   train's RMSPE: 0.480759 valid's rmse: 0.000836283   valid's RMSPE: 0.482469\n[142]   train's rmse: 0.000662101   train's RMSPE: 0.475508 valid's rmse: 0.000826969   valid's RMSPE: 0.477096\n[143]   train's rmse: 0.000658071   train's RMSPE: 0.472613 valid's rmse: 0.000819341   valid's RMSPE: 0.472695\n[144]   train's rmse: 0.000652693   train's RMSPE: 0.468751 valid's rmse: 0.000813534   valid's RMSPE: 0.469345\n[145]   train's rmse: 0.000655707   train's RMSPE: 0.470915 valid's rmse: 0.000817145   valid's RMSPE: 0.471428\n[146]   train's rmse: 0.000654375   train's RMSPE: 0.469959 valid's rmse: 0.000811918   valid's RMSPE: 0.468412\n[147]   train's rmse: 0.000656633   train's RMSPE: 0.471581 valid's rmse: 0.000814623   valid's RMSPE: 0.469973\n[148]   train's rmse: 0.000659198   train's RMSPE: 0.473423 valid's rmse: 0.000817463   valid's RMSPE: 0.471612\n[149]   train's rmse: 0.0006571 train's RMSPE: 0.471916 valid's rmse: 0.000812387   valid's RMSPE: 0.468683\n[150]   train's rmse: 0.000654368   train's RMSPE: 0.469954 valid's rmse: 0.000810857   valid's RMSPE: 0.4678\n[151]   train's rmse: 0.000657054   train's RMSPE: 0.471883 valid's rmse: 0.000814301   valid's RMSPE: 0.469787\n[152]   train's rmse: 0.000659825   train's RMSPE: 0.473873 valid's rmse: 0.000817785   valid's RMSPE: 0.471797\n[153]   train's rmse: 0.000661856   train's RMSPE: 0.475332 valid's rmse: 0.000820392   valid's RMSPE: 0.473301\n[154]   train's rmse: 0.000664632   train's RMSPE: 0.477326 valid's rmse: 0.000824246   valid's RMSPE: 0.475525\n[155]   train's rmse: 0.000666683   train's RMSPE: 0.478799 valid's rmse: 0.000827094   valid's RMSPE: 0.477168\n[156]   train's rmse: 0.000668389   train's RMSPE: 0.480023 valid's rmse: 0.000829213   valid's RMSPE: 0.47839\n[157]   train's rmse: 0.000671205   train's RMSPE: 0.482046 valid's rmse: 0.000832669   valid's RMSPE: 0.480384\n[158]   train's rmse: 0.000673914   train's RMSPE: 0.483992 valid's rmse: 0.000835986   valid's RMSPE: 0.482297\n[159]   train's rmse: 0.000676085   train's RMSPE: 0.485551 valid's rmse: 0.000838976   valid's RMSPE: 0.484023\n[160]   train's rmse: 0.000669415   train's RMSPE: 0.480761 valid's rmse: 0.00083196    valid's RMSPE: 0.479975\n[161]   train's rmse: 0.000671711   train's RMSPE: 0.48241  valid's rmse: 0.00083467    valid's RMSPE: 0.481539\n[162]   train's rmse: 0.000666145   train's RMSPE: 0.478412 valid's rmse: 0.000825236   valid's RMSPE: 0.476096\n[163]   train's rmse: 0.000671356   train's RMSPE: 0.482155 valid's rmse: 0.000833126   valid's RMSPE: 0.480648\n[164]   train's rmse: 0.000666369   train's RMSPE: 0.478572 valid's rmse: 0.000825186   valid's RMSPE: 0.476067\n[165]   train's rmse: 0.000671232   train's RMSPE: 0.482065 valid's rmse: 0.000833054   valid's RMSPE: 0.480606\n[166]   train's rmse: 0.000673513   train's RMSPE: 0.483703 valid's rmse: 0.000836085   valid's RMSPE: 0.482355\n[167]   train's rmse: 0.000666888   train's RMSPE: 0.478946 valid's rmse: 0.000828683   valid's RMSPE: 0.478084\n[168]   train's rmse: 0.000661757   train's RMSPE: 0.47526  valid's rmse: 0.000824354   valid's RMSPE: 0.475587\n[169]   train's rmse: 0.000655948   train's RMSPE: 0.471089 valid's rmse: 0.000820103   valid's RMSPE: 0.473135\n[170]   train's rmse: 0.000658426   train's RMSPE: 0.472868 valid's rmse: 0.000822965   valid's RMSPE: 0.474786\n[171]   train's rmse: 0.000661072   train's RMSPE: 0.474769 valid's rmse: 0.000825946   valid's RMSPE: 0.476506\n[172]   train's rmse: 0.00065711    train's RMSPE: 0.471923 valid's rmse: 0.000819864   valid's RMSPE: 0.472996\n[173]   train's rmse: 0.000654695   train's RMSPE: 0.470189 valid's rmse: 0.00081447    valid's RMSPE: 0.469885\n[174]   train's rmse: 0.000656893   train's RMSPE: 0.471767 valid's rmse: 0.000817284   valid's RMSPE: 0.471508\n[175]   train's rmse: 0.000651864   train's RMSPE: 0.468156 valid's rmse: 0.00081287    valid's RMSPE: 0.468961\n[176]   train's rmse: 0.000648132   train's RMSPE: 0.465475 valid's rmse: 0.000805973   valid's RMSPE: 0.464983\n[177]   train's rmse: 0.00065029    train's RMSPE: 0.467025 valid's rmse: 0.000808475   valid's RMSPE: 0.466426\n[178]   train's rmse: 0.000645788   train's RMSPE: 0.463792 valid's rmse: 0.000804718   valid's RMSPE: 0.464259\n[179]   train's rmse: 0.000643379   train's RMSPE: 0.462062 valid's rmse: 0.000800465   valid's RMSPE: 0.461805\n[180]   train's rmse: 0.000645381   train's RMSPE: 0.463499 valid's rmse: 0.000803064   valid's RMSPE: 0.463304\n[181]   train's rmse: 0.000647613   train's RMSPE: 0.465102 valid's rmse: 0.000805968   valid's RMSPE: 0.46498\n[182]   train's rmse: 0.000652506   train's RMSPE: 0.468617 valid's rmse: 0.000813701   valid's RMSPE: 0.469441\n[183]   train's rmse: 0.000647192   train's RMSPE: 0.4648   valid's rmse: 0.000808012   valid's RMSPE: 0.466159\n[184]   train's rmse: 0.000649422   train's RMSPE: 0.466402 valid's rmse: 0.00081073    valid's RMSPE: 0.467727\n[185]   train's rmse: 0.000643224   train's RMSPE: 0.461951 valid's rmse: 0.000807332   valid's RMSPE: 0.465767\n[186]   train's rmse: 0.000645152   train's RMSPE: 0.463335 valid's rmse: 0.000809659   valid's RMSPE: 0.467109\n[187]   train's rmse: 0.000647364   train's RMSPE: 0.464924 valid's rmse: 0.000812106   valid's RMSPE: 0.468521\n[188]   train's rmse: 0.000646296   train's RMSPE: 0.464156 valid's rmse: 0.000807553   valid's RMSPE: 0.465894\n[189]   train's rmse: 0.000648217   train's RMSPE: 0.465536 valid's rmse: 0.000809974   valid's RMSPE: 0.467291\n[190]   train's rmse: 0.000645179   train's RMSPE: 0.463355 valid's rmse: 0.000806297   valid's RMSPE: 0.46517\n[191]   train's rmse: 0.000646905   train's RMSPE: 0.464594 valid's rmse: 0.000808497   valid's RMSPE: 0.466439\n[192]   train's rmse: 0.00064179    train's RMSPE: 0.460921 valid's rmse: 0.000801977   valid's RMSPE: 0.462677\n[193]   train's rmse: 0.000644164   train's RMSPE: 0.462626 valid's rmse: 0.000804729   valid's RMSPE: 0.464265\n[194]   train's rmse: 0.000641679   train's RMSPE: 0.460841 valid's rmse: 0.000800346   valid's RMSPE: 0.461736\n[195]   train's rmse: 0.000643811   train's RMSPE: 0.462372 valid's rmse: 0.000802924   valid's RMSPE: 0.463224\n[196]   train's rmse: 0.000638606   train's RMSPE: 0.458634 valid's rmse: 0.000798373   valid's RMSPE: 0.460598\n[197]   train's rmse: 0.000640536   train's RMSPE: 0.46002  valid's rmse: 0.000800451   valid's RMSPE: 0.461797\n[198]   train's rmse: 0.000642456   train's RMSPE: 0.461399 valid's rmse: 0.000802776   valid's RMSPE: 0.463138\n[199]   train's rmse: 0.000644534   train's RMSPE: 0.462891 valid's rmse: 0.000805399   valid's RMSPE: 0.464652\n[200]   train's rmse: 0.000646003   train's RMSPE: 0.463946 valid's rmse: 0.000807466   valid's RMSPE: 0.465844\n[201]   train's rmse: 0.000647947   train's RMSPE: 0.465343 valid's rmse: 0.000809843   valid's RMSPE: 0.467216\n[202]   train's rmse: 0.000649575   train's RMSPE: 0.466512 valid's rmse: 0.000811922   valid's RMSPE: 0.468415\n[203]   train's rmse: 0.000651772   train's RMSPE: 0.46809  valid's rmse: 0.000814504   valid's RMSPE: 0.469905\n[204]   train's rmse: 0.000653499   train's RMSPE: 0.46933  valid's rmse: 0.000816514   valid's RMSPE: 0.471064\n[205]   train's rmse: 0.000647767   train's RMSPE: 0.465213 valid's rmse: 0.000812786   valid's RMSPE: 0.468913\n[206]   train's rmse: 0.000650339   train's RMSPE: 0.46706  valid's rmse: 0.000815235   valid's RMSPE: 0.470326\n[207]   train's rmse: 0.000652441   train's RMSPE: 0.46857  valid's rmse: 0.000817695   valid's RMSPE: 0.471745\n[208]   train's rmse: 0.000654354   train's RMSPE: 0.469944 valid's rmse: 0.00082005    valid's RMSPE: 0.473104\n[209]   train's rmse: 0.00064998    train's RMSPE: 0.466802 valid's rmse: 0.000811443   valid's RMSPE: 0.468138\n[210]   train's rmse: 0.000643062   train's RMSPE: 0.461834 valid's rmse: 0.000807325   valid's RMSPE: 0.465763\n[211]   train's rmse: 0.000640145   train's RMSPE: 0.45974  valid's rmse: 0.000801562   valid's RMSPE: 0.462438\n[212]   train's rmse: 0.000635551   train's RMSPE: 0.45644  valid's rmse: 0.000798216   valid's RMSPE: 0.460508\n[213]   train's rmse: 0.000631564   train's RMSPE: 0.453576 valid's rmse: 0.000794651   valid's RMSPE: 0.45845\n[214]   train's rmse: 0.000634257   train's RMSPE: 0.45551  valid's rmse: 0.000798571   valid's RMSPE: 0.460712\n[215]   train's rmse: 0.000631259   train's RMSPE: 0.453358 valid's rmse: 0.000793606   valid's RMSPE: 0.457848\n[216]   train's rmse: 0.000624993   train's RMSPE: 0.448858 valid's rmse: 0.000789067   valid's RMSPE: 0.455229\n[217]   train's rmse: 0.000626454   train's RMSPE: 0.449907 valid's rmse: 0.000790751   valid's RMSPE: 0.456201\n[218]   train's rmse: 0.000628126   train's RMSPE: 0.451107 valid's rmse: 0.000792686   valid's RMSPE: 0.457317\n[219]   train's rmse: 0.00062406    train's RMSPE: 0.448187 valid's rmse: 0.000790074   valid's RMSPE: 0.45581\n[220]   train's rmse: 0.000625889   train's RMSPE: 0.449501 valid's rmse: 0.000791986   valid's RMSPE: 0.456913\n[221]   train's rmse: 0.000627639   train's RMSPE: 0.450758 valid's rmse: 0.000794188   valid's RMSPE: 0.458184\n[222]   train's rmse: 0.000623891   train's RMSPE: 0.448066 valid's rmse: 0.000789053   valid's RMSPE: 0.455221\n[223]   train's rmse: 0.000619514   train's RMSPE: 0.444923 valid's rmse: 0.000783983   valid's RMSPE: 0.452296\n[224]   train's rmse: 0.000616856   train's RMSPE: 0.443014 valid's rmse: 0.000780742   valid's RMSPE: 0.450427\n[225]   train's rmse: 0.000614923   train's RMSPE: 0.441625 valid's rmse: 0.000777795   valid's RMSPE: 0.448726\n[226]   train's rmse: 0.000611549   train's RMSPE: 0.439202 valid's rmse: 0.00077578    valid's RMSPE: 0.447564\n[227]   train's rmse: 0.000613422   train's RMSPE: 0.440547 valid's rmse: 0.000777481   valid's RMSPE: 0.448545\n[228]   train's rmse: 0.000607773   train's RMSPE: 0.43649  valid's rmse: 0.000774461   valid's RMSPE: 0.446803\n[229]   train's rmse: 0.000606038   train's RMSPE: 0.435244 valid's rmse: 0.000772749   valid's RMSPE: 0.445815\n[230]   train's rmse: 0.000603378   train's RMSPE: 0.433334 valid's rmse: 0.000769606   valid's RMSPE: 0.444002\n[231]   train's rmse: 0.000604707   train's RMSPE: 0.434288 valid's rmse: 0.000771135   valid's RMSPE: 0.444884\n[232]   train's rmse: 0.000604205   train's RMSPE: 0.433928 valid's rmse: 0.000770242   valid's RMSPE: 0.444369\n[233]   train's rmse: 0.000601125   train's RMSPE: 0.431716 valid's rmse: 0.000769419   valid's RMSPE: 0.443894\n[234]   train's rmse: 0.000602383   train's RMSPE: 0.432619 valid's rmse: 0.000770418   valid's RMSPE: 0.44447\n[235]   train's rmse: 0.000603716   train's RMSPE: 0.433577 valid's rmse: 0.000771417   valid's RMSPE: 0.445046\n[236]   train's rmse: 0.000605165   train's RMSPE: 0.434617 valid's rmse: 0.000772438   valid's RMSPE: 0.445636\n[237]   train's rmse: 0.000606478   train's RMSPE: 0.43556  valid's rmse: 0.000773566   valid's RMSPE: 0.446286\n[238]   train's rmse: 0.000607831   train's RMSPE: 0.436532 valid's rmse: 0.000774745   valid's RMSPE: 0.446967\n[239]   train's rmse: 0.000609553   train's RMSPE: 0.437769 valid's rmse: 0.00077618    valid's RMSPE: 0.447795\n[240]   train's rmse: 0.000605093   train's RMSPE: 0.434565 valid's rmse: 0.000772431   valid's RMSPE: 0.445632\n[241]   train's rmse: 0.000606942   train's RMSPE: 0.435893 valid's rmse: 0.000773986   valid's RMSPE: 0.446528\n[242]   train's rmse: 0.000608533   train's RMSPE: 0.437036 valid's rmse: 0.000775102   valid's RMSPE: 0.447172\n[243]   train's rmse: 0.00061065    train's RMSPE: 0.438557 valid's rmse: 0.000776675   valid's RMSPE: 0.44808\n[244]   train's rmse: 0.000607667   train's RMSPE: 0.436414 valid's rmse: 0.000773891   valid's RMSPE: 0.446474\n[245]   train's rmse: 0.000605487   train's RMSPE: 0.434849 valid's rmse: 0.000771617   valid's RMSPE: 0.445162\n[246]   train's rmse: 0.00060189    train's RMSPE: 0.432265 valid's rmse: 0.00076994    valid's RMSPE: 0.444194\n[247]   train's rmse: 0.000601092   train's RMSPE: 0.431692 valid's rmse: 0.000767544   valid's RMSPE: 0.442812\n[248]   train's rmse: 0.000602371   train's RMSPE: 0.432611 valid's rmse: 0.000768601   valid's RMSPE: 0.443422\n[249]   train's rmse: 0.000599076   train's RMSPE: 0.430244 valid's rmse: 0.000766677   valid's RMSPE: 0.442312\n[250]   train's rmse: 0.000600807   train's RMSPE: 0.431488 valid's rmse: 0.000767779   valid's RMSPE: 0.442948\n[251]   train's rmse: 0.000599248   train's RMSPE: 0.430368 valid's rmse: 0.000766448   valid's RMSPE: 0.44218\n[252]   train's rmse: 0.000597659   train's RMSPE: 0.429227 valid's rmse: 0.000766047   valid's RMSPE: 0.441948\n[253]   train's rmse: 0.000599329   train's RMSPE: 0.430426 valid's rmse: 0.000767251   valid's RMSPE: 0.442643\n[254]   train's rmse: 0.000598855   train's RMSPE: 0.430086 valid's rmse: 0.000767215   valid's RMSPE: 0.442622\n[255]   train's rmse: 0.00059995    train's RMSPE: 0.430872 valid's rmse: 0.000768193   valid's RMSPE: 0.443186\n[256]   train's rmse: 0.000601099   train's RMSPE: 0.431698 valid's rmse: 0.00076922    valid's RMSPE: 0.443779\n[257]   train's rmse: 0.000598683   train's RMSPE: 0.429962 valid's rmse: 0.000767196   valid's RMSPE: 0.442612\n[258]   train's rmse: 0.000599691   train's RMSPE: 0.430686 valid's rmse: 0.000768281   valid's RMSPE: 0.443237\n[259]   train's rmse: 0.000600633   train's RMSPE: 0.431362 valid's rmse: 0.000769243   valid's RMSPE: 0.443792\n[260]   train's rmse: 0.00059948    train's RMSPE: 0.430535 valid's rmse: 0.000768093   valid's RMSPE: 0.443129\n[261]   train's rmse: 0.000600932   train's RMSPE: 0.431577 valid's rmse: 0.000768965   valid's RMSPE: 0.443632\n[262]   train's rmse: 0.000601896   train's RMSPE: 0.43227  valid's rmse: 0.000769818   valid's RMSPE: 0.444124\n[263]   train's rmse: 0.000603041   train's RMSPE: 0.433092 valid's rmse: 0.0007707 valid's RMSPE: 0.444633\n[264]   train's rmse: 0.000604614   train's RMSPE: 0.434221 valid's rmse: 0.000772415   valid's RMSPE: 0.445622\n[265]   train's rmse: 0.000601409   train's RMSPE: 0.43192  valid's rmse: 0.0007706 valid's RMSPE: 0.444575\n[266]   train's rmse: 0.000602878   train's RMSPE: 0.432975 valid's rmse: 0.00077165    valid's RMSPE: 0.445181\n[267]   train's rmse: 0.00059782    train's RMSPE: 0.429342 valid's rmse: 0.000771646   valid's RMSPE: 0.445179\n[268]   train's rmse: 0.000593841   train's RMSPE: 0.426484 valid's rmse: 0.000768318   valid's RMSPE: 0.443258\n[269]   train's rmse: 0.000593386   train's RMSPE: 0.426158 valid's rmse: 0.000767162   valid's RMSPE: 0.442592\n[270]   train's rmse: 0.00059197    train's RMSPE: 0.425141 valid's rmse: 0.000765884   valid's RMSPE: 0.441854\n[271]   train's rmse: 0.000593152   train's RMSPE: 0.42599  valid's rmse: 0.000766716   valid's RMSPE: 0.442335\n[272]   train's rmse: 0.000594528   train's RMSPE: 0.426978 valid's rmse: 0.000767677   valid's RMSPE: 0.442889\n[273]   train's rmse: 0.000595785   train's RMSPE: 0.427881 valid's rmse: 0.000768689   valid's RMSPE: 0.443473\n[274]   train's rmse: 0.000591827   train's RMSPE: 0.425039 valid's rmse: 0.000766971   valid's RMSPE: 0.442481\n[275]   train's rmse: 0.000589819   train's RMSPE: 0.423596 valid's rmse: 0.000766875   valid's RMSPE: 0.442426\n[276]   train's rmse: 0.000591413   train's RMSPE: 0.424741 valid's rmse: 0.000767605   valid's RMSPE: 0.442847\n[277]   train's rmse: 0.000590388   train's RMSPE: 0.424004 valid's rmse: 0.0007655 valid's RMSPE: 0.441633\n[278]   train's rmse: 0.000588177   train's RMSPE: 0.422417 valid's rmse: 0.000764788   valid's RMSPE: 0.441222\n[279]   train's rmse: 0.000589541   train's RMSPE: 0.423396 valid's rmse: 0.000765521   valid's RMSPE: 0.441645\n[280]   train's rmse: 0.000587639   train's RMSPE: 0.422031 valid's rmse: 0.000765338   valid's RMSPE: 0.441539\n[281]   train's rmse: 0.000588498   train's RMSPE: 0.422648 valid's rmse: 0.000765886   valid's RMSPE: 0.441856\n[282]   train's rmse: 0.000589777   train's RMSPE: 0.423566 valid's rmse: 0.000766411   valid's RMSPE: 0.442158\n[283]   train's rmse: 0.000586571   train's RMSPE: 0.421263 valid's rmse: 0.000764576   valid's RMSPE: 0.4411\n[284]   train's rmse: 0.000587544   train's RMSPE: 0.421962 valid's rmse: 0.000765313   valid's RMSPE: 0.441525\n[285]   train's rmse: 0.000585926   train's RMSPE: 0.4208   valid's rmse: 0.000762822   valid's RMSPE: 0.440088\n[286]   train's rmse: 0.000586982   train's RMSPE: 0.421559 valid's rmse: 0.000763452   valid's RMSPE: 0.440451\n[287]   train's rmse: 0.000584614   train's RMSPE: 0.419858 valid's rmse: 0.000762324   valid's RMSPE: 0.439801\n[288]   train's rmse: 0.00058568    train's RMSPE: 0.420624 valid's rmse: 0.00076281    valid's RMSPE: 0.440081\n[289]   train's rmse: 0.000586845   train's RMSPE: 0.42146  valid's rmse: 0.000763445   valid's RMSPE: 0.440447\n[290]   train's rmse: 0.000585333   train's RMSPE: 0.420374 valid's rmse: 0.000762047   valid's RMSPE: 0.439641\n[291]   train's rmse: 0.000581538   train's RMSPE: 0.417649 valid's rmse: 0.000762351   valid's RMSPE: 0.439816\n[292]   train's rmse: 0.000582809   train's RMSPE: 0.418562 valid's rmse: 0.000763008   valid's RMSPE: 0.440195\n[293]   train's rmse: 0.000583251   train's RMSPE: 0.418879 valid's rmse: 0.000763117   valid's RMSPE: 0.440258\n[294]   train's rmse: 0.000584287   train's RMSPE: 0.419623 valid's rmse: 0.000763307   valid's RMSPE: 0.440368\n[295]   train's rmse: 0.000585282   train's RMSPE: 0.420338 valid's rmse: 0.000763917   valid's RMSPE: 0.44072\n[296]   train's rmse: 0.000586321   train's RMSPE: 0.421084 valid's rmse: 0.000764453   valid's RMSPE: 0.441029\n[297]   train's rmse: 0.000582118   train's RMSPE: 0.418066 valid's rmse: 0.000762343   valid's RMSPE: 0.439811\n[298]   train's rmse: 0.000583188   train's RMSPE: 0.418834 valid's rmse: 0.000762874   valid's RMSPE: 0.440118\n[299]   train's rmse: 0.000582593   train's RMSPE: 0.418406 valid's rmse: 0.000760839   valid's RMSPE: 0.438944\n[300]   train's rmse: 0.000582278   train's RMSPE: 0.41818  valid's rmse: 0.000761501   valid's RMSPE: 0.439326\n[301]   train's rmse: 0.000579614   train's RMSPE: 0.416267 valid's rmse: 0.000762663   valid's RMSPE: 0.439996\n[302]   train's rmse: 0.000577449   train's RMSPE: 0.414712 valid's rmse: 0.000760895   valid's RMSPE: 0.438976\n[303]   train's rmse: 0.000578686   train's RMSPE: 0.415601 valid's rmse: 0.000761135   valid's RMSPE: 0.439115\n[304]   train's rmse: 0.000576417   train's RMSPE: 0.413971 valid's rmse: 0.000762082   valid's RMSPE: 0.439661\n[305]   train's rmse: 0.000574249   train's RMSPE: 0.412414 valid's rmse: 0.000760519   valid's RMSPE: 0.43876\n[306]   train's rmse: 0.000575481   train's RMSPE: 0.413299 valid's rmse: 0.000760872   valid's RMSPE: 0.438963\n[307]   train's rmse: 0.000573843   train's RMSPE: 0.412122 valid's rmse: 0.00076093    valid's RMSPE: 0.438997\n[308]   train's rmse: 0.000574845   train's RMSPE: 0.412842 valid's rmse: 0.000761132   valid's RMSPE: 0.439113\n[309]   train's rmse: 0.000573311   train's RMSPE: 0.41174  valid's rmse: 0.000761081   valid's RMSPE: 0.439084\n[310]   train's rmse: 0.000570836   train's RMSPE: 0.409963 valid's rmse: 0.000762286   valid's RMSPE: 0.439779\n[311]   train's rmse: 0.00057095    train's RMSPE: 0.410045 valid's rmse: 0.000762419   valid's RMSPE: 0.439855\n[312]   train's rmse: 0.000571881   train's RMSPE: 0.410713 valid's rmse: 0.000762856   valid's RMSPE: 0.440107\n[313]   train's rmse: 0.000572831   train's RMSPE: 0.411396 valid's rmse: 0.00076305    valid's RMSPE: 0.44022\n[314]   train's rmse: 0.000570518   train's RMSPE: 0.409735 valid's rmse: 0.000763133   valid's RMSPE: 0.440267\n[315]   train's rmse: 0.000570868   train's RMSPE: 0.409986 valid's rmse: 0.000765485   valid's RMSPE: 0.441624\n[316]   train's rmse: 0.000569241   train's RMSPE: 0.408817 valid's rmse: 0.000764455   valid's RMSPE: 0.44103\n[317]   train's rmse: 0.000569945   train's RMSPE: 0.409323 valid's rmse: 0.00076447    valid's RMSPE: 0.441039\n[318]   train's rmse: 0.000567087   train's RMSPE: 0.40727  valid's rmse: 0.000765708   valid's RMSPE: 0.441753\n[319]   train's rmse: 0.000568044   train's RMSPE: 0.407958 valid's rmse: 0.000765546   valid's RMSPE: 0.441659\n[320]   train's rmse: 0.000568771   train's RMSPE: 0.40848  valid's rmse: 0.00076562    valid's RMSPE: 0.441702\n[321]   train's rmse: 0.00056987    train's RMSPE: 0.409269 valid's rmse: 0.00076558    valid's RMSPE: 0.441679\n[322]   train's rmse: 0.00057079    train's RMSPE: 0.40993  valid's rmse: 0.000765748   valid's RMSPE: 0.441776\n[323]   train's rmse: 0.000571641   train's RMSPE: 0.410541 valid's rmse: 0.000765946   valid's RMSPE: 0.44189\n[324]   train's rmse: 0.00057268    train's RMSPE: 0.411287 valid's rmse: 0.000766244   valid's RMSPE: 0.442062\n[325]   train's rmse: 0.000570382   train's RMSPE: 0.409637 valid's rmse: 0.000766326   valid's RMSPE: 0.44211\n[326]   train's rmse: 0.000567449   train's RMSPE: 0.407531 valid's rmse: 0.000765362   valid's RMSPE: 0.441554\n[327]   train's rmse: 0.00056826    train's RMSPE: 0.408113 valid's rmse: 0.000765533   valid's RMSPE: 0.441652\n[328]   train's rmse: 0.000568746   train's RMSPE: 0.408462 valid's rmse: 0.000764333   valid's RMSPE: 0.440959\n[329]   train's rmse: 0.000569629   train's RMSPE: 0.409096 valid's rmse: 0.00076437    valid's RMSPE: 0.440981\n[330]   train's rmse: 0.000570391   train's RMSPE: 0.409643 valid's rmse: 0.000764412   valid's RMSPE: 0.441005\n[331]   train's rmse: 0.000571163   train's RMSPE: 0.410198 valid's rmse: 0.000764646   valid's RMSPE: 0.44114\n[332]   train's rmse: 0.000569321   train's RMSPE: 0.408875 valid's rmse: 0.000764418   valid's RMSPE: 0.441009\n[333]   train's rmse: 0.000570289   train's RMSPE: 0.40957  valid's rmse: 0.00076451    valid's RMSPE: 0.441062\n[334]   train's rmse: 0.000571339   train's RMSPE: 0.410325 valid's rmse: 0.000764606   valid's RMSPE: 0.441117\n[335]   train's rmse: 0.000569086   train's RMSPE: 0.408706 valid's rmse: 0.000762395   valid's RMSPE: 0.439842\n[336]   train's rmse: 0.000570204   train's RMSPE: 0.409509 valid's rmse: 0.000762695   valid's RMSPE: 0.440015\n[337]   train's rmse: 0.000571147   train's RMSPE: 0.410186 valid's rmse: 0.000762869   valid's RMSPE: 0.440115\n[338]   train's rmse: 0.000570184   train's RMSPE: 0.409494 valid's rmse: 0.000763726   valid's RMSPE: 0.440609\n[339]   train's rmse: 0.000571211   train's RMSPE: 0.410233 valid's rmse: 0.000764098   valid's RMSPE: 0.440824\n[340]   train's rmse: 0.000569284   train's RMSPE: 0.408848 valid's rmse: 0.000762342   valid's RMSPE: 0.439811\n[341]   train's rmse: 0.000570387   train's RMSPE: 0.409641 valid's rmse: 0.000762715   valid's RMSPE: 0.440026\n[342]   train's rmse: 0.000570148   train's RMSPE: 0.409469 valid's rmse: 0.000762684   valid's RMSPE: 0.440008\n[343]   train's rmse: 0.000571028   train's RMSPE: 0.410101 valid's rmse: 0.000762972   valid's RMSPE: 0.440175\n[344]   train's rmse: 0.000568403   train's RMSPE: 0.408216 valid's rmse: 0.000762771   valid's RMSPE: 0.440059\n[345]   train's rmse: 0.000565909   train's RMSPE: 0.406424 valid's rmse: 0.000763301   valid's RMSPE: 0.440364\n[346]   train's rmse: 0.000567153   train's RMSPE: 0.407318 valid's rmse: 0.000763439   valid's RMSPE: 0.440444\n[347]   train's rmse: 0.00056504    train's RMSPE: 0.4058   valid's rmse: 0.000762028   valid's RMSPE: 0.43963\n[348]   train's rmse: 0.000565064   train's RMSPE: 0.405818 valid's rmse: 0.000761604   valid's RMSPE: 0.439385\n[349]   train's rmse: 0.000565814   train's RMSPE: 0.406356 valid's rmse: 0.000761767   valid's RMSPE: 0.439479\n[350]   train's rmse: 0.000566848   train's RMSPE: 0.407099 valid's rmse: 0.000761848   valid's RMSPE: 0.439526\n[351]   train's rmse: 0.000567857   train's RMSPE: 0.407824 valid's rmse: 0.000761938   valid's RMSPE: 0.439578\n[352]   train's rmse: 0.000568888   train's RMSPE: 0.408564 valid's rmse: 0.000762124   valid's RMSPE: 0.439685\n[353]   train's rmse: 0.000569905   train's RMSPE: 0.409294 valid's rmse: 0.000762438   valid's RMSPE: 0.439866\n[354]   train's rmse: 0.00056785    train's RMSPE: 0.407819 valid's rmse: 0.000764941   valid's RMSPE: 0.441311\n[355]   train's rmse: 0.000568945   train's RMSPE: 0.408605 valid's rmse: 0.000765274   valid's RMSPE: 0.441502\n[356]   train's rmse: 0.00057   train's RMSPE: 0.409363 valid's rmse: 0.000765501   valid's RMSPE: 0.441633\n[357]   train's rmse: 0.000571032   train's RMSPE: 0.410104 valid's rmse: 0.00076578    valid's RMSPE: 0.441794\n[358]   train's rmse: 0.000571976   train's RMSPE: 0.410782 valid's rmse: 0.000765979   valid's RMSPE: 0.441909\n[359]   train's rmse: 0.000572896   train's RMSPE: 0.411443 valid's rmse: 0.000766371   valid's RMSPE: 0.442135\n[360]   train's rmse: 0.000569541   train's RMSPE: 0.409033 valid's rmse: 0.000766594   valid's RMSPE: 0.442264\n[361]   train's rmse: 0.000570534   train's RMSPE: 0.409746 valid's rmse: 0.000766865   valid's RMSPE: 0.44242\n[362]   train's rmse: 0.000568068   train's RMSPE: 0.407975 valid's rmse: 0.00076514    valid's RMSPE: 0.441425\n[363]   train's rmse: 0.000569324   train's RMSPE: 0.408877 valid's rmse: 0.000765516   valid's RMSPE: 0.441642\n[364]   train's rmse: 0.000567764   train's RMSPE: 0.407757 valid's rmse: 0.000765903   valid's RMSPE: 0.441865\n[365]   train's rmse: 0.000568917   train's RMSPE: 0.408584 valid's rmse: 0.000766208   valid's RMSPE: 0.442042\n[366]   train's rmse: 0.000566383   train's RMSPE: 0.406765 valid's rmse: 0.000762769   valid's RMSPE: 0.440057\n[367]   train's rmse: 0.000567484   train's RMSPE: 0.407555 valid's rmse: 0.000762936   valid's RMSPE: 0.440154\n[368]   train's rmse: 0.0005687 train's RMSPE: 0.408429 valid's rmse: 0.000763572   valid's RMSPE: 0.440521\n[369]   train's rmse: 0.00056676    train's RMSPE: 0.407035 valid's rmse: 0.000761787   valid's RMSPE: 0.439491\n[370]   train's rmse: 0.000567735   train's RMSPE: 0.407736 valid's rmse: 0.0007622 valid's RMSPE: 0.439729\n[371]   train's rmse: 0.000565667   train's RMSPE: 0.40625  valid's rmse: 0.000760001   valid's RMSPE: 0.43846\n[372]   train's rmse: 0.000566573   train's RMSPE: 0.406902 valid's rmse: 0.000760082   valid's RMSPE: 0.438507\n[373]   train's rmse: 0.00056519    train's RMSPE: 0.405908 valid's rmse: 0.000759263   valid's RMSPE: 0.438035\n[374]   train's rmse: 0.000563539   train's RMSPE: 0.404722 valid's rmse: 0.000759314   valid's RMSPE: 0.438064\n[375]   train's rmse: 0.000564603   train's RMSPE: 0.405487 valid's rmse: 0.000759494   valid's RMSPE: 0.438168\n[376]   train's rmse: 0.000565416   train's RMSPE: 0.406071 valid's rmse: 0.00075961    valid's RMSPE: 0.438235\n[377]   train's rmse: 0.000564366   train's RMSPE: 0.405316 valid's rmse: 0.000760706   valid's RMSPE: 0.438867\n[378]   train's rmse: 0.000564085   train's RMSPE: 0.405115 valid's rmse: 0.000759183   valid's RMSPE: 0.437988\n[379]   train's rmse: 0.00056322    train's RMSPE: 0.404494 valid's rmse: 0.000758796   valid's RMSPE: 0.437765\n[380]   train's rmse: 0.00056215    train's RMSPE: 0.403725 valid's rmse: 0.000759318   valid's RMSPE: 0.438066\n[381]   train's rmse: 0.00056289    train's RMSPE: 0.404256 valid's rmse: 0.000759578   valid's RMSPE: 0.438217\n[382]   train's rmse: 0.000563604   train's RMSPE: 0.404769 valid's rmse: 0.000759692   valid's RMSPE: 0.438282\n[383]   train's rmse: 0.000564418   train's RMSPE: 0.405354 valid's rmse: 0.000759683   valid's RMSPE: 0.438277\n[384]   train's rmse: 0.000562676   train's RMSPE: 0.404103 valid's rmse: 0.000758574   valid's RMSPE: 0.437637\n[385]   train's rmse: 0.000562312   train's RMSPE: 0.403841 valid's rmse: 0.000760255   valid's RMSPE: 0.438607\n[386]   train's rmse: 0.000563183   train's RMSPE: 0.404467 valid's rmse: 0.000760223   valid's RMSPE: 0.438588\n[387]   train's rmse: 0.000564234   train's RMSPE: 0.405221 valid's rmse: 0.000760119   valid's RMSPE: 0.438528\n[388]   train's rmse: 0.00056211    train's RMSPE: 0.403696 valid's rmse: 0.000760195   valid's RMSPE: 0.438572\n[389]   train's rmse: 0.000561308   train's RMSPE: 0.40312  valid's rmse: 0.000760238   valid's RMSPE: 0.438597\n[390]   train's rmse: 0.000562057   train's RMSPE: 0.403658 valid's rmse: 0.000760426   valid's RMSPE: 0.438706\n[391]   train's rmse: 0.000562946   train's RMSPE: 0.404297 valid's rmse: 0.000760406   valid's RMSPE: 0.438694\n[392]   train's rmse: 0.000563885   train's RMSPE: 0.404971 valid's rmse: 0.000760354   valid's RMSPE: 0.438664\n[393]   train's rmse: 0.000564742   train's RMSPE: 0.405586 valid's rmse: 0.000760547   valid's RMSPE: 0.438776\n[394]   train's rmse: 0.00056556    train's RMSPE: 0.406174 valid's rmse: 0.000760592   valid's RMSPE: 0.438801\n[395]   train's rmse: 0.000566475   train's RMSPE: 0.406831 valid's rmse: 0.000760997   valid's RMSPE: 0.439035\n[396]   train's rmse: 0.000563495   train's RMSPE: 0.404691 valid's rmse: 0.000760449   valid's RMSPE: 0.438719\n[397]   train's rmse: 0.000564308   train's RMSPE: 0.405275 valid's rmse: 0.00076042    valid's RMSPE: 0.438702\n[398]   train's rmse: 0.000562676   train's RMSPE: 0.404103 valid's rmse: 0.000759217   valid's RMSPE: 0.438008\n[399]   train's rmse: 0.000563606   train's RMSPE: 0.404771 valid's rmse: 0.000759474   valid's RMSPE: 0.438156\n[400]   train's rmse: 0.000563296   train's RMSPE: 0.404548 valid's rmse: 0.000759211   valid's RMSPE: 0.438005\n[401]   train's rmse: 0.000564118   train's RMSPE: 0.405138 valid's rmse: 0.000759485   valid's RMSPE: 0.438163\n[402]   train's rmse: 0.000562336   train's RMSPE: 0.403858 valid's rmse: 0.000757802   valid's RMSPE: 0.437192\n[403]   train's rmse: 0.000561201   train's RMSPE: 0.403043 valid's rmse: 0.000756012   valid's RMSPE: 0.436159\n[404]   train's rmse: 0.000562046   train's RMSPE: 0.40365  valid's rmse: 0.000756187   valid's RMSPE: 0.43626\n[405]   train's rmse: 0.000562308   train's RMSPE: 0.403839 valid's rmse: 0.000756327   valid's RMSPE: 0.436341\n[406]   train's rmse: 0.000563088   train's RMSPE: 0.404398 valid's rmse: 0.00075636    valid's RMSPE: 0.43636\n[407]   train's rmse: 0.000561724   train's RMSPE: 0.403419 valid's rmse: 0.000756553   valid's RMSPE: 0.436471\n[408]   train's rmse: 0.000561268   train's RMSPE: 0.403091 valid's rmse: 0.00075691    valid's RMSPE: 0.436677\n[409]   train's rmse: 0.00055962    train's RMSPE: 0.401908 valid's rmse: 0.000756398   valid's RMSPE: 0.436382\n[410]   train's rmse: 0.000560444   train's RMSPE: 0.402499 valid's rmse: 0.000756378   valid's RMSPE: 0.43637\n[411]   train's rmse: 0.000561076   train's RMSPE: 0.402954 valid's rmse: 0.000756576   valid's RMSPE: 0.436485\n[412]   train's rmse: 0.000561802   train's RMSPE: 0.403475 valid's rmse: 0.000756536   valid's RMSPE: 0.436461\n[413]   train's rmse: 0.00056251    train's RMSPE: 0.403983 valid's rmse: 0.000756664   valid's RMSPE: 0.436535\n[414]   train's rmse: 0.000563294   train's RMSPE: 0.404546 valid's rmse: 0.000756799   valid's RMSPE: 0.436613\n[415]   train's rmse: 0.000564091   train's RMSPE: 0.405119 valid's rmse: 0.000756946   valid's RMSPE: 0.436698\n[416]   train's rmse: 0.00056235    train's RMSPE: 0.403868 valid's rmse: 0.000757302   valid's RMSPE: 0.436903\n[417]   train's rmse: 0.000559709   train's RMSPE: 0.401971 valid's rmse: 0.000760965   valid's RMSPE: 0.439017\n[418]   train's rmse: 0.000557412   train's RMSPE: 0.400322 valid's rmse: 0.000761213   valid's RMSPE: 0.43916\n[419]   train's rmse: 0.000556348   train's RMSPE: 0.399558 valid's rmse: 0.000763096   valid's RMSPE: 0.440246\n[420]   train's rmse: 0.000557048   train's RMSPE: 0.400061 valid's rmse: 0.000762858   valid's RMSPE: 0.440109\n[421]   train's rmse: 0.000557927   train's RMSPE: 0.400692 valid's rmse: 0.00076298    valid's RMSPE: 0.440179\n[422]   train's rmse: 0.000555357   train's RMSPE: 0.398846 valid's rmse: 0.000763954   valid's RMSPE: 0.440741\n[423]   train's rmse: 0.000556221   train's RMSPE: 0.399467 valid's rmse: 0.000763774   valid's RMSPE: 0.440637\n[424]   train's rmse: 0.000557151   train's RMSPE: 0.400134 valid's rmse: 0.0007636 valid's RMSPE: 0.440537\n[425]   train's rmse: 0.00055798    train's RMSPE: 0.40073  valid's rmse: 0.000763385   valid's RMSPE: 0.440413\n[426]   train's rmse: 0.00055876    train's RMSPE: 0.401291 valid's rmse: 0.000763264   valid's RMSPE: 0.440343\n[427]   train's rmse: 0.000557367   train's RMSPE: 0.40029  valid's rmse: 0.000763964   valid's RMSPE: 0.440747\n[428]   train's rmse: 0.000558216   train's RMSPE: 0.4009   valid's rmse: 0.000763613   valid's RMSPE: 0.440544\n[429]   train's rmse: 0.00055904    train's RMSPE: 0.401491 valid's rmse: 0.000763603   valid's RMSPE: 0.440538\n[430]   train's rmse: 0.000559852   train's RMSPE: 0.402074 valid's rmse: 0.000763408   valid's RMSPE: 0.440426\n[431]   train's rmse: 0.000558375   train's RMSPE: 0.401014 valid's rmse: 0.00076194    valid's RMSPE: 0.439579\n[432]   train's rmse: 0.00055929    train's RMSPE: 0.401671 valid's rmse: 0.000761958   valid's RMSPE: 0.439589\n[433]   train's rmse: 0.00055759    train's RMSPE: 0.40045  valid's rmse: 0.000761865   valid's RMSPE: 0.439536\n[434]   train's rmse: 0.000558396   train's RMSPE: 0.401029 valid's rmse: 0.000762003   valid's RMSPE: 0.439616\n[435]   train's rmse: 0.000557575   train's RMSPE: 0.400439 valid's rmse: 0.000762935   valid's RMSPE: 0.440153\n[436]   train's rmse: 0.000558027   train's RMSPE: 0.400764 valid's rmse: 0.000763367   valid's RMSPE: 0.440402\n[437]   train's rmse: 0.000558789   train's RMSPE: 0.401311 valid's rmse: 0.000763219   valid's RMSPE: 0.440317\n[438]   train's rmse: 0.000557529   train's RMSPE: 0.400406 valid's rmse: 0.000762926   valid's RMSPE: 0.440148\n[439]   train's rmse: 0.000558192   train's RMSPE: 0.400883 valid's rmse: 0.000762813   valid's RMSPE: 0.440083\n[440]   train's rmse: 0.000558982   train's RMSPE: 0.40145  valid's rmse: 0.000762539   valid's RMSPE: 0.439925\n[441]   train's rmse: 0.000559902   train's RMSPE: 0.40211  valid's rmse: 0.000762339   valid's RMSPE: 0.439809\n[442]   train's rmse: 0.000560558   train's RMSPE: 0.402581 valid's rmse: 0.000762436   valid's RMSPE: 0.439865\n[443]   train's rmse: 0.000561348   train's RMSPE: 0.403149 valid's rmse: 0.000762487   valid's RMSPE: 0.439895\n[444]   train's rmse: 0.000561985   train's RMSPE: 0.403606 valid's rmse: 0.00076257    valid's RMSPE: 0.439943\n[445]   train's rmse: 0.000561492   train's RMSPE: 0.403252 valid's rmse: 0.000763259   valid's RMSPE: 0.44034\n[446]   train's rmse: 0.000562223   train's RMSPE: 0.403777 valid's rmse: 0.000763041   valid's RMSPE: 0.440214\n[447]   train's rmse: 0.000563089   train's RMSPE: 0.404399 valid's rmse: 0.000762988   valid's RMSPE: 0.440184\n[448]   train's rmse: 0.000561611   train's RMSPE: 0.403338 valid's rmse: 0.000762261   valid's RMSPE: 0.439764\n[449]   train's rmse: 0.000562448   train's RMSPE: 0.403939 valid's rmse: 0.000762306   valid's RMSPE: 0.43979\n[450]   train's rmse: 0.000563172   train's RMSPE: 0.404459 valid's rmse: 0.000762341   valid's RMSPE: 0.43981\n[451]   train's rmse: 0.000563994   train's RMSPE: 0.405049 valid's rmse: 0.000762435   valid's RMSPE: 0.439865\n[452]   train's rmse: 0.000562406   train's RMSPE: 0.403909 valid's rmse: 0.000763347   valid's RMSPE: 0.440391\n[453]   train's rmse: 0.000560909   train's RMSPE: 0.402834 valid's rmse: 0.000763224   valid's RMSPE: 0.44032\n[454]   train's rmse: 0.000559005   train's RMSPE: 0.401466 valid's rmse: 0.000763905   valid's RMSPE: 0.440713\n[455]   train's rmse: 0.000559728   train's RMSPE: 0.401985 valid's rmse: 0.000763825   valid's RMSPE: 0.440666\n[456]   train's rmse: 0.000559118   train's RMSPE: 0.401548 valid's rmse: 0.00076355    valid's RMSPE: 0.440508\n[457]   train's rmse: 0.000559821   train's RMSPE: 0.402052 valid's rmse: 0.000763384   valid's RMSPE: 0.440412\n[458]   train's rmse: 0.000557174   train's RMSPE: 0.400151 valid's rmse: 0.000763269   valid's RMSPE: 0.440346\n[459]   train's rmse: 0.000555722   train's RMSPE: 0.399108 valid's rmse: 0.000764017   valid's RMSPE: 0.440777\n[460]   train's rmse: 0.000556449   train's RMSPE: 0.399631 valid's rmse: 0.000763593   valid's RMSPE: 0.440533\n[461]   train's rmse: 0.000557186   train's RMSPE: 0.40016  valid's rmse: 0.00076329    valid's RMSPE: 0.440358\n[462]   train's rmse: 0.000555551   train's RMSPE: 0.398986 valid's rmse: 0.000763591   valid's RMSPE: 0.440531\n[463]   train's rmse: 0.000552854   train's RMSPE: 0.397049 valid's rmse: 0.000762877   valid's RMSPE: 0.440119\n[464]   train's rmse: 0.000553528   train's RMSPE: 0.397533 valid's rmse: 0.000762266   valid's RMSPE: 0.439767\n[465]   train's rmse: 0.000552805   train's RMSPE: 0.397013 valid's rmse: 0.000763391   valid's RMSPE: 0.440416\n[466]   train's rmse: 0.000552177   train's RMSPE: 0.396562 valid's rmse: 0.000764244   valid's RMSPE: 0.440909\n[467]   train's rmse: 0.000550139   train's RMSPE: 0.395099 valid's rmse: 0.000762757   valid's RMSPE: 0.44005\n[468]   train's rmse: 0.000550086   train's RMSPE: 0.395061 valid's rmse: 0.000764242   valid's RMSPE: 0.440907\n[469]   train's rmse: 0.000549744   train's RMSPE: 0.394815 valid's rmse: 0.000766815   valid's RMSPE: 0.442391\n[470]   train's rmse: 0.000548037   train's RMSPE: 0.393589 valid's rmse: 0.000767058   valid's RMSPE: 0.442532\n[471]   train's rmse: 0.000548625   train's RMSPE: 0.394011 valid's rmse: 0.000766322   valid's RMSPE: 0.442107\n[472]   train's rmse: 0.000547278   train's RMSPE: 0.393044 valid's rmse: 0.000765974   valid's RMSPE: 0.441906\n[473]   train's rmse: 0.000545068   train's RMSPE: 0.391457 valid's rmse: 0.000764508   valid's RMSPE: 0.441061\n[474]   train's rmse: 0.000545698   train's RMSPE: 0.39191  valid's rmse: 0.000763968   valid's RMSPE: 0.440749\n[475]   train's rmse: 0.000543546   train's RMSPE: 0.390364 valid's rmse: 0.000765518   valid's RMSPE: 0.441643\n[476]   train's rmse: 0.000541559   train's RMSPE: 0.388937 valid's rmse: 0.00076618    valid's RMSPE: 0.442025\n[477]   train's rmse: 0.000542213   train's RMSPE: 0.389406 valid's rmse: 0.000765756   valid's RMSPE: 0.441781\n[478]   train's rmse: 0.000542927   train's RMSPE: 0.38992  valid's rmse: 0.00076557    valid's RMSPE: 0.441674\n[479]   train's rmse: 0.000541889   train's RMSPE: 0.389174 valid's rmse: 0.000764754   valid's RMSPE: 0.441203\n[480]   train's rmse: 0.00053977    train's RMSPE: 0.387652 valid's rmse: 0.000764618   valid's RMSPE: 0.441124\n[481]   train's rmse: 0.000540563   train's RMSPE: 0.388222 valid's rmse: 0.000764198   valid's RMSPE: 0.440882\n[482]   train's rmse: 0.000541405   train's RMSPE: 0.388826 valid's rmse: 0.000766227   valid's RMSPE: 0.442052\n[483]   train's rmse: 0.000541931   train's RMSPE: 0.389204 valid's rmse: 0.000765331   valid's RMSPE: 0.441536\n[484]   train's rmse: 0.000540255   train's RMSPE: 0.388    valid's rmse: 0.000765733   valid's RMSPE: 0.441767\n[485]   train's rmse: 0.000540816   train's RMSPE: 0.388403 valid's rmse: 0.000765168   valid's RMSPE: 0.441441\n[486]   train's rmse: 0.000539738   train's RMSPE: 0.387629 valid's rmse: 0.000766437   valid's RMSPE: 0.442173\n[487]   train's rmse: 0.000538364   train's RMSPE: 0.386642 valid's rmse: 0.000768104   valid's RMSPE: 0.443135\n[488]   train's rmse: 0.00053676    train's RMSPE: 0.38549  valid's rmse: 0.000767556   valid's RMSPE: 0.442819\n[489]   train's rmse: 0.00053625    train's RMSPE: 0.385124 valid's rmse: 0.000768674   valid's RMSPE: 0.443464\n[490]   train's rmse: 0.000535161   train's RMSPE: 0.384342 valid's rmse: 0.000767847   valid's RMSPE: 0.442987\n[491]   train's rmse: 0.000535854   train's RMSPE: 0.38484  valid's rmse: 0.00076708    valid's RMSPE: 0.442545\n[492]   train's rmse: 0.000534218   train's RMSPE: 0.383664 valid's rmse: 0.000765479   valid's RMSPE: 0.441621\n[493]   train's rmse: 0.000534757   train's RMSPE: 0.384052 valid's rmse: 0.000764995   valid's RMSPE: 0.441342\n[494]   train's rmse: 0.000535409   train's RMSPE: 0.38452  valid's rmse: 0.000764391   valid's RMSPE: 0.440993\n[495]   train's rmse: 0.000536161   train's RMSPE: 0.38506  valid's rmse: 0.000763587   valid's RMSPE: 0.440529\n[496]   train's rmse: 0.000536919   train's RMSPE: 0.385604 valid's rmse: 0.000763072   valid's RMSPE: 0.440232\n[497]   train's rmse: 0.000535618   train's RMSPE: 0.38467  valid's rmse: 0.000763885   valid's RMSPE: 0.440701\n[498]   train's rmse: 0.000534082   train's RMSPE: 0.383567 valid's rmse: 0.000764432   valid's RMSPE: 0.441017\n[499]   train's rmse: 0.000534655   train's RMSPE: 0.383979 valid's rmse: 0.000763939   valid's RMSPE: 0.440732\n[500]   train's rmse: 0.000535267   train's RMSPE: 0.384418 valid's rmse: 0.000763512   valid's RMSPE: 0.440486\n[501]   train's rmse: 0.000534941   train's RMSPE: 0.384184 valid's rmse: 0.000763059   valid's RMSPE: 0.440224\n[502]   train's rmse: 0.000535628   train's RMSPE: 0.384678 valid's rmse: 0.000762685   valid's RMSPE: 0.440009\n[503]   train's rmse: 0.000534521   train's RMSPE: 0.383882 valid's rmse: 0.000765808   valid's RMSPE: 0.441811\n[504]   train's rmse: 0.000535078   train's RMSPE: 0.384282 valid's rmse: 0.000765258   valid's RMSPE: 0.441493\n[505]   train's rmse: 0.000535664   train's RMSPE: 0.384703 valid's rmse: 0.000764906   valid's RMSPE: 0.44129\n[506]   train's rmse: 0.000534336   train's RMSPE: 0.383749 valid's rmse: 0.000764691   valid's RMSPE: 0.441166\n[507]   train's rmse: 0.000533021   train's RMSPE: 0.382805 valid's rmse: 0.0007671 valid's RMSPE: 0.442556\n[508]   train's rmse: 0.000531745   train's RMSPE: 0.381889 valid's rmse: 0.000765788   valid's RMSPE: 0.441799\n[509]   train's rmse: 0.000530876   train's RMSPE: 0.381264 valid's rmse: 0.000768217   valid's RMSPE: 0.443201\n[510]   train's rmse: 0.000531518   train's RMSPE: 0.381726 valid's rmse: 0.000767602   valid's RMSPE: 0.442846\n[511]   train's rmse: 0.000530593   train's RMSPE: 0.381061 valid's rmse: 0.000768088   valid's RMSPE: 0.443126\n[512]   train's rmse: 0.0005311 train's RMSPE: 0.381425 valid's rmse: 0.000766753   valid's RMSPE: 0.442356\n[513]   train's rmse: 0.000531745   train's RMSPE: 0.381889 valid's rmse: 0.000766238   valid's RMSPE: 0.442058\n[514]   train's rmse: 0.00053243    train's RMSPE: 0.382381 valid's rmse: 0.000765653   valid's RMSPE: 0.441721\n[515]   train's rmse: 0.000533097   train's RMSPE: 0.382859 valid's rmse: 0.000765114   valid's RMSPE: 0.44141\n[516]   train's rmse: 0.00053364    train's RMSPE: 0.38325  valid's rmse: 0.000764639   valid's RMSPE: 0.441136\n[517]   train's rmse: 0.000534356   train's RMSPE: 0.383764 valid's rmse: 0.00076411    valid's RMSPE: 0.440831\n[518]   train's rmse: 0.00053498    train's RMSPE: 0.384212 valid's rmse: 0.000763833   valid's RMSPE: 0.440671\n[519]   train's rmse: 0.00053569    train's RMSPE: 0.384722 valid's rmse: 0.00076286    valid's RMSPE: 0.44011\n[520]   train's rmse: 0.00053647    train's RMSPE: 0.385282 valid's rmse: 0.000761989   valid's RMSPE: 0.439607\n[521]   train's rmse: 0.000537257   train's RMSPE: 0.385847 valid's rmse: 0.000761514   valid's RMSPE: 0.439333\n[522]   train's rmse: 0.00053599    train's RMSPE: 0.384938 valid's rmse: 0.000761621   valid's RMSPE: 0.439395\n[523]   train's rmse: 0.000536695   train's RMSPE: 0.385443 valid's rmse: 0.000761288   valid's RMSPE: 0.439203\n[524]   train's rmse: 0.000537329   train's RMSPE: 0.385899 valid's rmse: 0.00076093    valid's RMSPE: 0.438996\n[525]   train's rmse: 0.000538056   train's RMSPE: 0.386421 valid's rmse: 0.000760585   valid's RMSPE: 0.438798\n[526]   train's rmse: 0.0005388 train's RMSPE: 0.386955 valid's rmse: 0.00076037    valid's RMSPE: 0.438673\n[527]   train's rmse: 0.000537913   train's RMSPE: 0.386319 valid's rmse: 0.000762005   valid's RMSPE: 0.439617\n[528]   train's rmse: 0.000535592   train's RMSPE: 0.384652 valid's rmse: 0.000762942   valid's RMSPE: 0.440157\n[529]   train's rmse: 0.00053386    train's RMSPE: 0.383407 valid's rmse: 0.000765044   valid's RMSPE: 0.44137\n[530]   train's rmse: 0.000534613   train's RMSPE: 0.383948 valid's rmse: 0.000764657   valid's RMSPE: 0.441146\n[531]   train's rmse: 0.000535217   train's RMSPE: 0.384382 valid's rmse: 0.00076429    valid's RMSPE: 0.440935\n[532]   train's rmse: 0.000533418   train's RMSPE: 0.38309  valid's rmse: 0.000763899   valid's RMSPE: 0.44071\n[533]   train's rmse: 0.000534108   train's RMSPE: 0.383586 valid's rmse: 0.000763454   valid's RMSPE: 0.440452\n[534]   train's rmse: 0.000532636   train's RMSPE: 0.382528 valid's rmse: 0.000762829   valid's RMSPE: 0.440092\n[535]   train's rmse: 0.000531857   train's RMSPE: 0.381969 valid's rmse: 0.000762571   valid's RMSPE: 0.439943\n[536]   train's rmse: 0.000531847   train's RMSPE: 0.381962 valid's rmse: 0.000763161   valid's RMSPE: 0.440283\n[537]   train's rmse: 0.000530633   train's RMSPE: 0.38109  valid's rmse: 0.000762397   valid's RMSPE: 0.439843\n[538]   train's rmse: 0.000531281   train's RMSPE: 0.381556 valid's rmse: 0.000762078   valid's RMSPE: 0.439658\n[539]   train's rmse: 0.00052949    train's RMSPE: 0.380269 valid's rmse: 0.000762943   valid's RMSPE: 0.440158\n[540]   train's rmse: 0.000530102   train's RMSPE: 0.380709 valid's rmse: 0.000762508   valid's RMSPE: 0.439907\n[541]   train's rmse: 0.000530756   train's RMSPE: 0.381178 valid's rmse: 0.000761974   valid's RMSPE: 0.439599\n[542]   train's rmse: 0.000530165   train's RMSPE: 0.380754 valid's rmse: 0.000763202   valid's RMSPE: 0.440307\n[543]   train's rmse: 0.000528335   train's RMSPE: 0.379439 valid's rmse: 0.000764299   valid's RMSPE: 0.44094\n[544]   train's rmse: 0.000527709   train's RMSPE: 0.37899  valid's rmse: 0.00076406    valid's RMSPE: 0.440802\n[545]   train's rmse: 0.000526759   train's RMSPE: 0.378308 valid's rmse: 0.000764695   valid's RMSPE: 0.441168\n[546]   train's rmse: 0.000527085   train's RMSPE: 0.378542 valid's rmse: 0.000765931   valid's RMSPE: 0.441882\n[547]   train's rmse: 0.000527743   train's RMSPE: 0.379015 valid's rmse: 0.000765392   valid's RMSPE: 0.441571\n[548]   train's rmse: 0.000526108   train's RMSPE: 0.37784  valid's rmse: 0.000764579   valid's RMSPE: 0.441102\n[549]   train's rmse: 0.000526576   train's RMSPE: 0.378177 valid's rmse: 0.000764024   valid's RMSPE: 0.440782\n[550]   train's rmse: 0.000527151   train's RMSPE: 0.37859  valid's rmse: 0.000763516   valid's RMSPE: 0.440488\n[551]   train's rmse: 0.000526217   train's RMSPE: 0.377919 valid's rmse: 0.000763006   valid's RMSPE: 0.440194\n[552]   train's rmse: 0.000526809   train's RMSPE: 0.378344 valid's rmse: 0.000762405   valid's RMSPE: 0.439848\n[553]   train's rmse: 0.000527487   train's RMSPE: 0.378831 valid's rmse: 0.000761778   valid's RMSPE: 0.439486\n[554]   train's rmse: 0.000528095   train's RMSPE: 0.379267 valid's rmse: 0.000761501   valid's RMSPE: 0.439326\n[555]   train's rmse: 0.000528669   train's RMSPE: 0.37968  valid's rmse: 0.000761073   valid's RMSPE: 0.439079\n[556]   train's rmse: 0.000526719   train's RMSPE: 0.378279 valid's rmse: 0.000761095   valid's RMSPE: 0.439092\n[557]   train's rmse: 0.000525404   train's RMSPE: 0.377335 valid's rmse: 0.000761696   valid's RMSPE: 0.439438\n[558]   train's rmse: 0.00052527    train's RMSPE: 0.377238 valid's rmse: 0.00076316    valid's RMSPE: 0.440283\n[559]   train's rmse: 0.00052586    train's RMSPE: 0.377662 valid's rmse: 0.000762775   valid's RMSPE: 0.440061\n[560]   train's rmse: 0.000524233   train's RMSPE: 0.376493 valid's rmse: 0.000761696   valid's RMSPE: 0.439438\n[561]   train's rmse: 0.000524913   train's RMSPE: 0.376982 valid's rmse: 0.000761292   valid's RMSPE: 0.439205\n[562]   train's rmse: 0.000525476   train's RMSPE: 0.377386 valid's rmse: 0.000760707   valid's RMSPE: 0.438868\n[563]   train's rmse: 0.000523916   train's RMSPE: 0.376266 valid's rmse: 0.000758736   valid's RMSPE: 0.437731\n[564]   train's rmse: 0.000524546   train's RMSPE: 0.376718 valid's rmse: 0.000757791   valid's RMSPE: 0.437186\n[565]   train's rmse: 0.000523738   train's RMSPE: 0.376138 valid's rmse: 0.000758042   valid's RMSPE: 0.43733\n[566]   train's rmse: 0.000524361   train's RMSPE: 0.376585 valid's rmse: 0.000757712   valid's RMSPE: 0.43714\n[567]   train's rmse: 0.000524894   train's RMSPE: 0.376968 valid's rmse: 0.000757264   valid's RMSPE: 0.436881\n[568]   train's rmse: 0.000524204   train's RMSPE: 0.376472 valid's rmse: 0.000756831   valid's RMSPE: 0.436632\n[569]   train's rmse: 0.000524772   train's RMSPE: 0.37688  valid's rmse: 0.000756341   valid's RMSPE: 0.436349\n[570]   train's rmse: 0.000525232   train's RMSPE: 0.377211 valid's rmse: 0.000756014   valid's RMSPE: 0.43616\n[571]   train's rmse: 0.000525896   train's RMSPE: 0.377688 valid's rmse: 0.00075547    valid's RMSPE: 0.435846\n[572]   train's rmse: 0.000526551   train's RMSPE: 0.378159 valid's rmse: 0.000755171   valid's RMSPE: 0.435674\n[573]   train's rmse: 0.000527211   train's RMSPE: 0.378633 valid's rmse: 0.000754843   valid's RMSPE: 0.435485\n[574]   train's rmse: 0.000526301   train's RMSPE: 0.377979 valid's rmse: 0.000755742   valid's RMSPE: 0.436003\n[575]   train's rmse: 0.000526928   train's RMSPE: 0.378429 valid's rmse: 0.000755313   valid's RMSPE: 0.435756\n[576]   train's rmse: 0.000527586   train's RMSPE: 0.378901 valid's rmse: 0.000755036   valid's RMSPE: 0.435596\n[577]   train's rmse: 0.000528294   train's RMSPE: 0.37941  valid's rmse: 0.000754837   valid's RMSPE: 0.435481\n[578]   train's rmse: 0.000526708   train's RMSPE: 0.378271 valid's rmse: 0.000754901   valid's RMSPE: 0.435518\n[579]   train's rmse: 0.000525121   train's RMSPE: 0.377131 valid's rmse: 0.000756947   valid's RMSPE: 0.436699\n[580]   train's rmse: 0.000525793   train's RMSPE: 0.377614 valid's rmse: 0.000756649   valid's RMSPE: 0.436527\n[581]   train's rmse: 0.000525548   train's RMSPE: 0.377438 valid's rmse: 0.000758862   valid's RMSPE: 0.437803\n[582]   train's rmse: 0.000526091   train's RMSPE: 0.377828 valid's rmse: 0.000758472   valid's RMSPE: 0.437578\n[583]   train's rmse: 0.000526595   train's RMSPE: 0.37819  valid's rmse: 0.000757978   valid's RMSPE: 0.437293\n[584]   train's rmse: 0.000525731   train's RMSPE: 0.377569 valid's rmse: 0.000758306   valid's RMSPE: 0.437482\n[585]   train's rmse: 0.000526355   train's RMSPE: 0.378017 valid's rmse: 0.000758008   valid's RMSPE: 0.437311\n[586]   train's rmse: 0.000525179   train's RMSPE: 0.377173 valid's rmse: 0.000757126   valid's RMSPE: 0.436802\n[587]   train's rmse: 0.000524016   train's RMSPE: 0.376338 valid's rmse: 0.000759856   valid's RMSPE: 0.438377\n[588]   train's rmse: 0.000522917   train's RMSPE: 0.375549 valid's rmse: 0.000760414   valid's RMSPE: 0.438699\n[589]   train's rmse: 0.000523564   train's RMSPE: 0.376013 valid's rmse: 0.000759915   valid's RMSPE: 0.438411\n[590]   train's rmse: 0.000523308   train's RMSPE: 0.375829 valid's rmse: 0.000760047   valid's RMSPE: 0.438487\n[591]   train's rmse: 0.000523903   train's RMSPE: 0.376256 valid's rmse: 0.000759153   valid's RMSPE: 0.437971\n[592]   train's rmse: 0.000522395   train's RMSPE: 0.375174 valid's rmse: 0.000759954   valid's RMSPE: 0.438433\n[593]   train's rmse: 0.000522938   train's RMSPE: 0.375563 valid's rmse: 0.000759382   valid's RMSPE: 0.438103\n[594]   train's rmse: 0.000523536   train's RMSPE: 0.375993 valid's rmse: 0.000758794   valid's RMSPE: 0.437764\n[595]   train's rmse: 0.000524319   train's RMSPE: 0.376556 valid's rmse: 0.000758267   valid's RMSPE: 0.43746\n[596]   train's rmse: 0.000524898   train's RMSPE: 0.376971 valid's rmse: 0.000757871   valid's RMSPE: 0.437231\n[597]   train's rmse: 0.000525556   train's RMSPE: 0.377443 valid's rmse: 0.000757456   valid's RMSPE: 0.436992\n[598]   train's rmse: 0.00052453    train's RMSPE: 0.376707 valid's rmse: 0.000759029   valid's RMSPE: 0.4379\n[599]   train's rmse: 0.000523154   train's RMSPE: 0.375719 valid's rmse: 0.00075972    valid's RMSPE: 0.438298\n[600]   train's rmse: 0.000522103   train's RMSPE: 0.374964 valid's rmse: 0.000760063   valid's RMSPE: 0.438496\n[601]   train's rmse: 0.000520941   train's RMSPE: 0.374129 valid's rmse: 0.000760167   valid's RMSPE: 0.438556\n[602]   train's rmse: 0.000519905   train's RMSPE: 0.373385 valid's rmse: 0.000759167   valid's RMSPE: 0.437979\n[603]   train's rmse: 0.000520311   train's RMSPE: 0.373677 valid's rmse: 0.000758569   valid's RMSPE: 0.437634\n[604]   train's rmse: 0.000518495   train's RMSPE: 0.372373 valid's rmse: 0.000759287   valid's RMSPE: 0.438049\n[605]   train's rmse: 0.00051708    train's RMSPE: 0.371356 valid's rmse: 0.000761538   valid's RMSPE: 0.439347\n[606]   train's rmse: 0.000515827   train's RMSPE: 0.370456 valid's rmse: 0.000761071   valid's RMSPE: 0.439078\n[607]   train's rmse: 0.000516497   train's RMSPE: 0.370938 valid's rmse: 0.000760035   valid's RMSPE: 0.43848\n[608]   train's rmse: 0.000515394   train's RMSPE: 0.370146 valid's rmse: 0.000762222   valid's RMSPE: 0.439742\n[609]   train's rmse: 0.000515765   train's RMSPE: 0.370412 valid's rmse: 0.000761601   valid's RMSPE: 0.439383\n[610]   train's rmse: 0.00051461    train's RMSPE: 0.369582 valid's rmse: 0.000762311   valid's RMSPE: 0.439793\n[611]   train's rmse: 0.000513593   train's RMSPE: 0.368852 valid's rmse: 0.000761463   valid's RMSPE: 0.439304\n[612]   train's rmse: 0.000513281   train's RMSPE: 0.368628 valid's rmse: 0.000764856   valid's RMSPE: 0.441261\n[613]   train's rmse: 0.000512745   train's RMSPE: 0.368243 valid's rmse: 0.000766879   valid's RMSPE: 0.442428\n[614]   train's rmse: 0.000513163   train's RMSPE: 0.368543 valid's rmse: 0.000766209   valid's RMSPE: 0.442042\n[615]   train's rmse: 0.000511851   train's RMSPE: 0.367601 valid's rmse: 0.000765972   valid's RMSPE: 0.441905\n[616]   train's rmse: 0.000512232   train's RMSPE: 0.367875 valid's rmse: 0.000765017   valid's RMSPE: 0.441355\n[617]   train's rmse: 0.00051296    train's RMSPE: 0.368397 valid's rmse: 0.000765102   valid's RMSPE: 0.441403\n[618]   train's rmse: 0.000512772   train's RMSPE: 0.368263 valid's rmse: 0.000767114   valid's RMSPE: 0.442564\n[619]   train's rmse: 0.000513139   train's RMSPE: 0.368526 valid's rmse: 0.000766231   valid's RMSPE: 0.442055\n[620]   train's rmse: 0.00051346    train's RMSPE: 0.368757 valid's rmse: 0.000765577   valid's RMSPE: 0.441677\n[621]   train's rmse: 0.000513888   train's RMSPE: 0.369064 valid's rmse: 0.000764956   valid's RMSPE: 0.441319\n[622]   train's rmse: 0.000514184   train's RMSPE: 0.369277 valid's rmse: 0.00076356    valid's RMSPE: 0.440514\n[623]   train's rmse: 0.000514646   train's RMSPE: 0.369608 valid's rmse: 0.000762913   valid's RMSPE: 0.44014\n[624]   train's rmse: 0.000514516   train's RMSPE: 0.369515 valid's rmse: 0.000763077   valid's RMSPE: 0.440235\n[625]   train's rmse: 0.000513516   train's RMSPE: 0.368797 valid's rmse: 0.000763408   valid's RMSPE: 0.440426\n[626]   train's rmse: 0.000512245   train's RMSPE: 0.367884 valid's rmse: 0.000763991   valid's RMSPE: 0.440763\n[627]   train's rmse: 0.000512555   train's RMSPE: 0.368107 valid's rmse: 0.000763275   valid's RMSPE: 0.440349\n[628]   train's rmse: 0.000513009   train's RMSPE: 0.368433 valid's rmse: 0.000762918   valid's RMSPE: 0.440143\n[629]   train's rmse: 0.000513352   train's RMSPE: 0.368679 valid's rmse: 0.000761766   valid's RMSPE: 0.439479\n[630]   train's rmse: 0.000511726   train's RMSPE: 0.367512 valid's rmse: 0.0007635 valid's RMSPE: 0.440479\n[631]   train's rmse: 0.000512168   train's RMSPE: 0.367829 valid's rmse: 0.000762887   valid's RMSPE: 0.440125\n[632]   train's rmse: 0.000510732   train's RMSPE: 0.366797 valid's rmse: 0.000761925   valid's RMSPE: 0.43957\n[633]   train's rmse: 0.000511135   train's RMSPE: 0.367087 valid's rmse: 0.000761282   valid's RMSPE: 0.439199\n[634]   train's rmse: 0.000510107   train's RMSPE: 0.366349 valid's rmse: 0.000761065   valid's RMSPE: 0.439074\n[635]   train's rmse: 0.000510498   train's RMSPE: 0.366629 valid's rmse: 0.000760013   valid's RMSPE: 0.438468\n[636]   train's rmse: 0.000510159   train's RMSPE: 0.366386 valid's rmse: 0.00076034    valid's RMSPE: 0.438656\n[637]   train's rmse: 0.000510431   train's RMSPE: 0.366581 valid's rmse: 0.00076069    valid's RMSPE: 0.438858\n[638]   train's rmse: 0.000508537   train's RMSPE: 0.365221 valid's rmse: 0.00076187    valid's RMSPE: 0.439539\n[639]   train's rmse: 0.000507952   train's RMSPE: 0.364801 valid's rmse: 0.00076237    valid's RMSPE: 0.439827\n[640]   train's rmse: 0.000508165   train's RMSPE: 0.364954 valid's rmse: 0.000763158   valid's RMSPE: 0.440282\n[641]   train's rmse: 0.000508549   train's RMSPE: 0.36523  valid's rmse: 0.000762393   valid's RMSPE: 0.43984\n[642]   train's rmse: 0.000508815   train's RMSPE: 0.365421 valid's rmse: 0.00076123    valid's RMSPE: 0.439169\n[643]   train's rmse: 0.000506989   train's RMSPE: 0.364109 valid's rmse: 0.000760528   valid's RMSPE: 0.438764\n[644]   train's rmse: 0.000506225   train's RMSPE: 0.36356  valid's rmse: 0.000760129   valid's RMSPE: 0.438534\n[645]   train's rmse: 0.000506562   train's RMSPE: 0.363802 valid's rmse: 0.000759494   valid's RMSPE: 0.438168\n[646]   train's rmse: 0.000504982   train's RMSPE: 0.362668 valid's rmse: 0.000759927   valid's RMSPE: 0.438418\n[647]   train's rmse: 0.00050362    train's RMSPE: 0.36169  valid's rmse: 0.000760017   valid's RMSPE: 0.43847\n[648]   train's rmse: 0.000503384   train's RMSPE: 0.36152  valid's rmse: 0.000762189   valid's RMSPE: 0.439723\n[649]   train's rmse: 0.000503922   train's RMSPE: 0.361906 valid's rmse: 0.000761338   valid's RMSPE: 0.439232\n[650]   train's rmse: 0.00050426    train's RMSPE: 0.362149 valid's rmse: 0.000760633   valid's RMSPE: 0.438825\n[651]   train's rmse: 0.000504522   train's RMSPE: 0.362337 valid's rmse: 0.000760131   valid's RMSPE: 0.438535\n[652]   train's rmse: 0.00050396    train's RMSPE: 0.361934 valid's rmse: 0.000759383   valid's RMSPE: 0.438104\n[653]   train's rmse: 0.000504359   train's RMSPE: 0.362221 valid's rmse: 0.00075886    valid's RMSPE: 0.437802\n[654]   train's rmse: 0.00050335    train's RMSPE: 0.361496 valid's rmse: 0.000759729   valid's RMSPE: 0.438303\n[655]   train's rmse: 0.000503763   train's RMSPE: 0.361793 valid's rmse: 0.00075927    valid's RMSPE: 0.438039\n[656]   train's rmse: 0.000504241   train's RMSPE: 0.362136 valid's rmse: 0.000761173   valid's RMSPE: 0.439137\n[657]   train's rmse: 0.000502816   train's RMSPE: 0.361112 valid's rmse: 0.000761085   valid's RMSPE: 0.439086\n[658]   train's rmse: 0.000502655   train's RMSPE: 0.360997 valid's rmse: 0.000761225   valid's RMSPE: 0.439167\n[659]   train's rmse: 0.000501842   train's RMSPE: 0.360413 valid's rmse: 0.000763265   valid's RMSPE: 0.440344\n[660]   train's rmse: 0.000502116   train's RMSPE: 0.360609 valid's rmse: 0.000762538   valid's RMSPE: 0.439924\n[661]   train's rmse: 0.000500914   train's RMSPE: 0.359746 valid's rmse: 0.000764807   valid's RMSPE: 0.441233\n[662]   train's rmse: 0.000499682   train's RMSPE: 0.358861 valid's rmse: 0.000766037   valid's RMSPE: 0.441943\n[663]   train's rmse: 0.0005    train's RMSPE: 0.35909  valid's rmse: 0.000765424   valid's RMSPE: 0.441589\n[664]   train's rmse: 0.000500316   train's RMSPE: 0.359317 valid's rmse: 0.000764728   valid's RMSPE: 0.441187\n[665]   train's rmse: 0.000500631   train's RMSPE: 0.359543 valid's rmse: 0.000764085   valid's RMSPE: 0.440817\n[666]   train's rmse: 0.000500358   train's RMSPE: 0.359347 valid's rmse: 0.000764885   valid's RMSPE: 0.441278\n[667]   train's rmse: 0.000500666   train's RMSPE: 0.359569 valid's rmse: 0.000764244   valid's RMSPE: 0.440908\n[668]   train's rmse: 0.00050035    train's RMSPE: 0.359341 valid's rmse: 0.000766505   valid's RMSPE: 0.442213\n[669]   train's rmse: 0.000500715   train's RMSPE: 0.359603 valid's rmse: 0.000765762   valid's RMSPE: 0.441784\n[670]   train's rmse: 0.000500516   train's RMSPE: 0.35946  valid's rmse: 0.000765211   valid's RMSPE: 0.441466\n[671]   train's rmse: 0.000499997   train's RMSPE: 0.359088 valid's rmse: 0.000764918   valid's RMSPE: 0.441297\n[672]   train's rmse: 0.000500349   train's RMSPE: 0.359341 valid's rmse: 0.000764236   valid's RMSPE: 0.440904\n[673]   train's rmse: 0.000500722   train's RMSPE: 0.359609 valid's rmse: 0.000763453   valid's RMSPE: 0.440452\n[674]   train's rmse: 0.000501142   train's RMSPE: 0.35991  valid's rmse: 0.000762924   valid's RMSPE: 0.440147\n[675]   train's rmse: 0.000501128   train's RMSPE: 0.3599   valid's rmse: 0.000763703   valid's RMSPE: 0.440596\n[676]   train's rmse: 0.000501565   train's RMSPE: 0.360214 valid's rmse: 0.000763263   valid's RMSPE: 0.440342\n[677]   train's rmse: 0.000500669   train's RMSPE: 0.359571 valid's rmse: 0.000763325   valid's RMSPE: 0.440378\n[678]   train's rmse: 0.000499562   train's RMSPE: 0.358775 valid's rmse: 0.00076472    valid's RMSPE: 0.441183\n[679]   train's rmse: 0.000499156   train's RMSPE: 0.358484 valid's rmse: 0.000764283   valid's RMSPE: 0.440931\n[680]   train's rmse: 0.000499428   train's RMSPE: 0.358679 valid's rmse: 0.00076365    valid's RMSPE: 0.440566\n[681]   train's rmse: 0.00049987    train's RMSPE: 0.358996 valid's rmse: 0.000763161   valid's RMSPE: 0.440283\n[682]   train's rmse: 0.000500209   train's RMSPE: 0.35924  valid's rmse: 0.000762608   valid's RMSPE: 0.439965\n[683]   train's rmse: 0.000500588   train's RMSPE: 0.359512 valid's rmse: 0.000762179   valid's RMSPE: 0.439717\n[684]   train's rmse: 0.000500224   train's RMSPE: 0.359251 valid's rmse: 0.000763917   valid's RMSPE: 0.440719\n[685]   train's rmse: 0.000499089   train's RMSPE: 0.358435 valid's rmse: 0.000765401   valid's RMSPE: 0.441576\n[686]   train's rmse: 0.00049941    train's RMSPE: 0.358666 valid's rmse: 0.000764803   valid's RMSPE: 0.441231\n[687]   train's rmse: 0.000497988   train's RMSPE: 0.357645 valid's rmse: 0.000766201   valid's RMSPE: 0.442038\n[688]   train's rmse: 0.000498297   train's RMSPE: 0.357867 valid's rmse: 0.00076512    valid's RMSPE: 0.441413\n[689]   train's rmse: 0.000497597   train's RMSPE: 0.357364 valid's rmse: 0.000764918   valid's RMSPE: 0.441297\n[690]   train's rmse: 0.000497123   train's RMSPE: 0.357024 valid's rmse: 0.000766685   valid's RMSPE: 0.442317\n[691]   train's rmse: 0.000496819   train's RMSPE: 0.356805 valid's rmse: 0.000768638   valid's RMSPE: 0.443443\n[692]   train's rmse: 0.000496072   train's RMSPE: 0.356269 valid's rmse: 0.000769637   valid's RMSPE: 0.44402\n[693]   train's rmse: 0.000494863   train's RMSPE: 0.355401 valid's rmse: 0.000770562   valid's RMSPE: 0.444553\n[694]   train's rmse: 0.000495205   train's RMSPE: 0.355646 valid's rmse: 0.000769988   valid's RMSPE: 0.444222\n[695]   train's rmse: 0.000494509   train's RMSPE: 0.355146 valid's rmse: 0.00077072    valid's RMSPE: 0.444644\n[696]   train's rmse: 0.000494921   train's RMSPE: 0.355442 valid's rmse: 0.000770023   valid's RMSPE: 0.444242\n[697]   train's rmse: 0.000493977   train's RMSPE: 0.354764 valid's rmse: 0.000772189   valid's RMSPE: 0.445492\n[698]   train's rmse: 0.000494315   train's RMSPE: 0.355007 valid's rmse: 0.000771333   valid's RMSPE: 0.444998\n[699]   train's rmse: 0.000493722   train's RMSPE: 0.354581 valid's rmse: 0.000775488   valid's RMSPE: 0.447395\n[700]   train's rmse: 0.000494076   train's RMSPE: 0.354835 valid's rmse: 0.000774782   valid's RMSPE: 0.446988\n[701]   train's rmse: 0.000494414   train's RMSPE: 0.355078 valid's rmse: 0.000774075   valid's RMSPE: 0.44658\n[702]   train's rmse: 0.000493632   train's RMSPE: 0.354517 valid's rmse: 0.00077724    valid's RMSPE: 0.448406\n[703]   train's rmse: 0.000493998   train's RMSPE: 0.354779 valid's rmse: 0.000775807   valid's RMSPE: 0.447579\n[704]   train's rmse: 0.00049439    train's RMSPE: 0.355061 valid's rmse: 0.00077494    valid's RMSPE: 0.447079\n[705]   train's rmse: 0.000493863   train's RMSPE: 0.354682 valid's rmse: 0.000777125   valid's RMSPE: 0.44834\n[706]   train's rmse: 0.000492657   train's RMSPE: 0.353816 valid's rmse: 0.000779359   valid's RMSPE: 0.449628\n[707]   train's rmse: 0.000492936   train's RMSPE: 0.354017 valid's rmse: 0.000778656   valid's RMSPE: 0.449223\n[708]   train's rmse: 0.000492478   train's RMSPE: 0.353687 valid's rmse: 0.000778625   valid's RMSPE: 0.449205\n[709]   train's rmse: 0.000491704   train's RMSPE: 0.353132 valid's rmse: 0.000781837   valid's RMSPE: 0.451058\n[710]   train's rmse: 0.00049091    train's RMSPE: 0.352562 valid's rmse: 0.00078466    valid's RMSPE: 0.452686\n[711]   train's rmse: 0.000491263   train's RMSPE: 0.352815 valid's rmse: 0.000783734   valid's RMSPE: 0.452153\n[712]   train's rmse: 0.000490325   train's RMSPE: 0.352141 valid's rmse: 0.000782565   valid's RMSPE: 0.451478\n[713]   train's rmse: 0.000489578   train's RMSPE: 0.351605 valid's rmse: 0.000787725   valid's RMSPE: 0.454455\n[714]   train's rmse: 0.000489185   train's RMSPE: 0.351323 valid's rmse: 0.000790162   valid's RMSPE: 0.455861\n[715]   train's rmse: 0.000489464   train's RMSPE: 0.351523 valid's rmse: 0.000789269   valid's RMSPE: 0.455346\n[716]   train's rmse: 0.000488652   train's RMSPE: 0.35094  valid's rmse: 0.000791891   valid's RMSPE: 0.456859\n[717]   train's rmse: 0.000488067   train's RMSPE: 0.35052  valid's rmse: 0.000792612   valid's RMSPE: 0.457275\n[718]   train's rmse: 0.000487137   train's RMSPE: 0.349852 valid's rmse: 0.000793011   valid's RMSPE: 0.457504\n[719]   train's rmse: 0.000486386   train's RMSPE: 0.349312 valid's rmse: 0.000794006   valid's RMSPE: 0.458079\n[720]   train's rmse: 0.000485715   train's RMSPE: 0.348831 valid's rmse: 0.000794286   valid's RMSPE: 0.45824\n[721]   train's rmse: 0.000485701   train's RMSPE: 0.348821 valid's rmse: 0.000794168   valid's RMSPE: 0.458172\n[722]   train's rmse: 0.000486108   train's RMSPE: 0.349113 valid's rmse: 0.000793169   valid's RMSPE: 0.457596\n[723]   train's rmse: 0.000485919   train's RMSPE: 0.348977 valid's rmse: 0.000794917   valid's RMSPE: 0.458604\n[724]   train's rmse: 0.000485397   train's RMSPE: 0.348603 valid's rmse: 0.000796197   valid's RMSPE: 0.459343\n[725]   train's rmse: 0.000485738   train's RMSPE: 0.348847 valid's rmse: 0.000795323   valid's RMSPE: 0.458838\n[726]   train's rmse: 0.000485033   train's RMSPE: 0.348341 valid's rmse: 0.000799133   valid's RMSPE: 0.461036\n[727]   train's rmse: 0.000484337   train's RMSPE: 0.347841 valid's rmse: 0.000798801   valid's RMSPE: 0.460845\n[728]   train's rmse: 0.000484259   train's RMSPE: 0.347785 valid's rmse: 0.000797839   valid's RMSPE: 0.46029\n[729]   train's rmse: 0.000484033   train's RMSPE: 0.347623 valid's rmse: 0.000796537   valid's RMSPE: 0.459539\n[730]   train's rmse: 0.000484309   train's RMSPE: 0.347821 valid's rmse: 0.000795587   valid's RMSPE: 0.45899\n[731]   train's rmse: 0.000484606   train's RMSPE: 0.348034 valid's rmse: 0.000794715   valid's RMSPE: 0.458487\n[732]   train's rmse: 0.000484915   train's RMSPE: 0.348256 valid's rmse: 0.000793752   valid's RMSPE: 0.457932\n[733]   train's rmse: 0.000485218   train's RMSPE: 0.348474 valid's rmse: 0.000792792   valid's RMSPE: 0.457378\n[734]   train's rmse: 0.000485533   train's RMSPE: 0.3487   valid's rmse: 0.000792096   valid's RMSPE: 0.456977\n[735]   train's rmse: 0.000485807   train's RMSPE: 0.348897 valid's rmse: 0.000791385   valid's RMSPE: 0.456567\n[736]   train's rmse: 0.000486108   train's RMSPE: 0.349113 valid's rmse: 0.000790712   valid's RMSPE: 0.456178\n[737]   train's rmse: 0.000485347   train's RMSPE: 0.348566 valid's rmse: 0.0007918 valid's RMSPE: 0.456806\n[738]   train's rmse: 0.000485717   train's RMSPE: 0.348833 valid's rmse: 0.000790755   valid's RMSPE: 0.456203\n[739]   train's rmse: 0.000484723   train's RMSPE: 0.348119 valid's rmse: 0.000793666   valid's RMSPE: 0.457882\n[740]   train's rmse: 0.000483855   train's RMSPE: 0.347495 valid's rmse: 0.000794336   valid's RMSPE: 0.458269\n[741]   train's rmse: 0.000484136   train's RMSPE: 0.347697 valid's rmse: 0.000793557   valid's RMSPE: 0.457819\n[742]   train's rmse: 0.000483322   train's RMSPE: 0.347112 valid's rmse: 0.000792975   valid's RMSPE: 0.457484\n[743]   train's rmse: 0.000482951   train's RMSPE: 0.346846 valid's rmse: 0.000792749   valid's RMSPE: 0.457353\n[744]   train's rmse: 0.000483388   train's RMSPE: 0.34716  valid's rmse: 0.000791781   valid's RMSPE: 0.456795\n[745]   train's rmse: 0.000483804   train's RMSPE: 0.347459 valid's rmse: 0.000791097   valid's RMSPE: 0.456401\n[746]   train's rmse: 0.000483224   train's RMSPE: 0.347042 valid's rmse: 0.000790346   valid's RMSPE: 0.455967\n[747]   train's rmse: 0.000483441   train's RMSPE: 0.347198 valid's rmse: 0.000789527   valid's RMSPE: 0.455494\n[748]   train's rmse: 0.000482843   train's RMSPE: 0.346768 valid's rmse: 0.000790069   valid's RMSPE: 0.455807\n[749]   train's rmse: 0.000482537   train's RMSPE: 0.346549 valid's rmse: 0.000792351   valid's RMSPE: 0.457124\n[750]   train's rmse: 0.000482069   train's RMSPE: 0.346212 valid's rmse: 0.000792381   valid's RMSPE: 0.457141\n[751]   train's rmse: 0.000482407   train's RMSPE: 0.346455 valid's rmse: 0.000791384   valid's RMSPE: 0.456566\n[752]   train's rmse: 0.000481909   train's RMSPE: 0.346097 valid's rmse: 0.000792495   valid's RMSPE: 0.457207\n[753]   train's rmse: 0.000482215   train's RMSPE: 0.346317 valid's rmse: 0.000791683   valid's RMSPE: 0.456739\n[754]   train's rmse: 0.00048253    train's RMSPE: 0.346543 valid's rmse: 0.000790791   valid's RMSPE: 0.456224\n[755]   train's rmse: 0.00048152    train's RMSPE: 0.345818 valid's rmse: 0.000793781   valid's RMSPE: 0.457949\n[756]   train's rmse: 0.000480763   train's RMSPE: 0.345274 valid's rmse: 0.000792982   valid's RMSPE: 0.457488\n[757]   train's rmse: 0.000479804   train's RMSPE: 0.344586 valid's rmse: 0.000792671   valid's RMSPE: 0.457308\n[758]   train's rmse: 0.000479118   train's RMSPE: 0.344093 valid's rmse: 0.000789831   valid's RMSPE: 0.45567\n[759]   train's rmse: 0.000479421   train's RMSPE: 0.344311 valid's rmse: 0.000789001   valid's RMSPE: 0.455191\n[760]   train's rmse: 0.000479752   train's RMSPE: 0.344549 valid's rmse: 0.000788328   valid's RMSPE: 0.454803\n[761]   train's rmse: 0.000480041   train's RMSPE: 0.344756 valid's rmse: 0.000787702   valid's RMSPE: 0.454442\n[762]   train's rmse: 0.000480401   train's RMSPE: 0.345015 valid's rmse: 0.000787008   valid's RMSPE: 0.454041\n[763]   train's rmse: 0.000480324   train's RMSPE: 0.344959 valid's rmse: 0.000787813   valid's RMSPE: 0.454506\n[764]   train's rmse: 0.00047981    train's RMSPE: 0.34459  valid's rmse: 0.000788978   valid's RMSPE: 0.455178\n[765]   train's rmse: 0.000479216   train's RMSPE: 0.344163 valid's rmse: 0.000788616   valid's RMSPE: 0.454969\n[766]   train's rmse: 0.000478598   train's RMSPE: 0.34372  valid's rmse: 0.00078959    valid's RMSPE: 0.455531\n[767]   train's rmse: 0.000477889   train's RMSPE: 0.34321  valid's rmse: 0.000787798   valid's RMSPE: 0.454497\n[768]   train's rmse: 0.000477108   train's RMSPE: 0.342649 valid's rmse: 0.000788055   valid's RMSPE: 0.454645\n[769]   train's rmse: 0.000477474   train's RMSPE: 0.342912 valid's rmse: 0.000787291   valid's RMSPE: 0.454205\n[770]   train's rmse: 0.000477781   train's RMSPE: 0.343133 valid's rmse: 0.000786612   valid's RMSPE: 0.453813\n[771]   train's rmse: 0.00047741    train's RMSPE: 0.342866 valid's rmse: 0.000788146   valid's RMSPE: 0.454698\n[772]   train's rmse: 0.000477765   train's RMSPE: 0.343121 valid's rmse: 0.000786702   valid's RMSPE: 0.453865\n[773]   train's rmse: 0.000476548   train's RMSPE: 0.342247 valid's rmse: 0.000786189   valid's RMSPE: 0.453569\n[774]   train's rmse: 0.000476962   train's RMSPE: 0.342545 valid's rmse: 0.00078504    valid's RMSPE: 0.452906\n[775]   train's rmse: 0.000476438   train's RMSPE: 0.342168 valid's rmse: 0.000784291   valid's RMSPE: 0.452474\n[776]   train's rmse: 0.000476753   train's RMSPE: 0.342394 valid's rmse: 0.000783463   valid's RMSPE: 0.451996\n[777]   train's rmse: 0.000477127   train's RMSPE: 0.342663 valid's rmse: 0.000782505   valid's RMSPE: 0.451444\n[778]   train's rmse: 0.000477146   train's RMSPE: 0.342677 valid's rmse: 0.00078409    valid's RMSPE: 0.452358\n[779]   train's rmse: 0.000476555   train's RMSPE: 0.342252 valid's rmse: 0.000785794   valid's RMSPE: 0.453341\n[780]   train's rmse: 0.000476823   train's RMSPE: 0.342445 valid's rmse: 0.000785045   valid's RMSPE: 0.452909\n[781]   train's rmse: 0.000477149   train's RMSPE: 0.342679 valid's rmse: 0.000784356   valid's RMSPE: 0.452511\n[782]   train's rmse: 0.000477584   train's RMSPE: 0.342991 valid's rmse: 0.00078361    valid's RMSPE: 0.452081\n[783]   train's rmse: 0.000478036   train's RMSPE: 0.343316 valid's rmse: 0.000782681   valid's RMSPE: 0.451545\n[784]   train's rmse: 0.000477428   train's RMSPE: 0.342879 valid's rmse: 0.000782687   valid's RMSPE: 0.451548\n[785]   train's rmse: 0.000476852   train's RMSPE: 0.342466 valid's rmse: 0.000784838   valid's RMSPE: 0.45279\n[786]   train's rmse: 0.000477171   train's RMSPE: 0.342694 valid's rmse: 0.000783372   valid's RMSPE: 0.451944\n[787]   train's rmse: 0.000477023   train's RMSPE: 0.342589 valid's rmse: 0.000784078   valid's RMSPE: 0.452351\n[788]   train's rmse: 0.000477326   train's RMSPE: 0.342806 valid's rmse: 0.00078348    valid's RMSPE: 0.452006\n[789]   train's rmse: 0.000477063   train's RMSPE: 0.342617 valid's rmse: 0.000784171   valid's RMSPE: 0.452405\n[790]   train's rmse: 0.000477402   train's RMSPE: 0.342861 valid's rmse: 0.000783471   valid's RMSPE: 0.452001\n[791]   train's rmse: 0.000476584   train's RMSPE: 0.342273 valid's rmse: 0.000782173   valid's RMSPE: 0.451252\n[792]   train's rmse: 0.000475941   train's RMSPE: 0.341812 valid's rmse: 0.000781735   valid's RMSPE: 0.450999\n[793]   train's rmse: 0.000474917   train's RMSPE: 0.341076 valid's rmse: 0.000782964   valid's RMSPE: 0.451708\n[794]   train's rmse: 0.000475427   train's RMSPE: 0.341442 valid's rmse: 0.000782787   valid's RMSPE: 0.451606\n[795]   train's rmse: 0.000474402   train's RMSPE: 0.340706 valid's rmse: 0.000786927   valid's RMSPE: 0.453994\n[796]   train's rmse: 0.000474763   train's RMSPE: 0.340965 valid's rmse: 0.000786037   valid's RMSPE: 0.453481\n[797]   train's rmse: 0.000475008   train's RMSPE: 0.341141 valid's rmse: 0.000785221   valid's RMSPE: 0.45301\n[798]   train's rmse: 0.000474632   train's RMSPE: 0.340871 valid's rmse: 0.000784217   valid's RMSPE: 0.452431\n[799]   train's rmse: 0.000474934   train's RMSPE: 0.341088 valid's rmse: 0.000783459   valid's RMSPE: 0.451994\n[800]   train's rmse: 0.000474635   train's RMSPE: 0.340873 valid's rmse: 0.000784503   valid's RMSPE: 0.452596\n[801]   train's rmse: 0.000474885   train's RMSPE: 0.341053 valid's rmse: 0.000783648   valid's RMSPE: 0.452103\n[802]   train's rmse: 0.000474874   train's RMSPE: 0.341045 valid's rmse: 0.000784821   valid's RMSPE: 0.452779\n[803]   train's rmse: 0.000474394   train's RMSPE: 0.3407   valid's rmse: 0.000786104   valid's RMSPE: 0.45352\n[804]   train's rmse: 0.000474059   train's RMSPE: 0.34046  valid's rmse: 0.000785929   valid's RMSPE: 0.453419\n[805]   train's rmse: 0.000472877   train's RMSPE: 0.339611 valid's rmse: 0.000787564   valid's RMSPE: 0.454362\n[806]   train's rmse: 0.000472237   train's RMSPE: 0.339151 valid's rmse: 0.000787562   valid's RMSPE: 0.454361\n[807]   train's rmse: 0.000471592   train's RMSPE: 0.338688 valid's rmse: 0.000787279   valid's RMSPE: 0.454197\n[808]   train's rmse: 0.000471245   train's RMSPE: 0.338439 valid's rmse: 0.000788714   valid's RMSPE: 0.455025\n[809]   train's rmse: 0.00047058    train's RMSPE: 0.337961 valid's rmse: 0.000787857   valid's RMSPE: 0.454531\n[810]   train's rmse: 0.000470798   train's RMSPE: 0.338117 valid's rmse: 0.000786782   valid's RMSPE: 0.453911\n[811]   train's rmse: 0.000470478   train's RMSPE: 0.337888 valid's rmse: 0.000791513   valid's RMSPE: 0.456641\n[812]   train's rmse: 0.00046992    train's RMSPE: 0.337487 valid's rmse: 0.000792747   valid's RMSPE: 0.457353\n[813]   train's rmse: 0.000469179   train's RMSPE: 0.336955 valid's rmse: 0.000792683   valid's RMSPE: 0.457316\n[814]   train's rmse: 0.000469419   train's RMSPE: 0.337128 valid's rmse: 0.000791817   valid's RMSPE: 0.456816\n[815]   train's rmse: 0.000469635   train's RMSPE: 0.337282 valid's rmse: 0.000790917   valid's RMSPE: 0.456296\n[816]   train's rmse: 0.000469333   train's RMSPE: 0.337065 valid's rmse: 0.000790238   valid's RMSPE: 0.455905\n[817]   train's rmse: 0.000469599   train's RMSPE: 0.337257 valid's rmse: 0.00078943    valid's RMSPE: 0.455439\n[818]   train's rmse: 0.000469653   train's RMSPE: 0.337295 valid's rmse: 0.000794212   valid's RMSPE: 0.458197\n[819]   train's rmse: 0.000468967   train's RMSPE: 0.336803 valid's rmse: 0.000793336   valid's RMSPE: 0.457692\n[820]   train's rmse: 0.000469321   train's RMSPE: 0.337057 valid's rmse: 0.000792432   valid's RMSPE: 0.45717\n[821]   train's rmse: 0.000468628   train's RMSPE: 0.33656  valid's rmse: 0.000793743   valid's RMSPE: 0.457927\n[822]   train's rmse: 0.000468009   train's RMSPE: 0.336115 valid's rmse: 0.000793416   valid's RMSPE: 0.457738\n[823]   train's rmse: 0.000467467   train's RMSPE: 0.335726 valid's rmse: 0.000793831   valid's RMSPE: 0.457978\n[824]   train's rmse: 0.000467074   train's RMSPE: 0.335443 valid's rmse: 0.000792622   valid's RMSPE: 0.45728\n[825]   train's rmse: 0.000467  train's RMSPE: 0.33539  valid's rmse: 0.000792921   valid's RMSPE: 0.457453\n[826]   train's rmse: 0.000467307   train's RMSPE: 0.335611 valid's rmse: 0.000792116   valid's RMSPE: 0.456988\n[827]   train's rmse: 0.000466837   train's RMSPE: 0.335273 valid's rmse: 0.000792287   valid's RMSPE: 0.457087\n[828]   train's rmse: 0.000467091   train's RMSPE: 0.335455 valid's rmse: 0.000791601   valid's RMSPE: 0.456691\n[829]   train's rmse: 0.000466483   train's RMSPE: 0.335019 valid's rmse: 0.000789211   valid's RMSPE: 0.455313\n[830]   train's rmse: 0.00046674    train's RMSPE: 0.335203 valid's rmse: 0.000788333   valid's RMSPE: 0.454806\n[831]   train's rmse: 0.000466629   train's RMSPE: 0.335123 valid's rmse: 0.00078925    valid's RMSPE: 0.455335\n[832]   train's rmse: 0.000466879   train's RMSPE: 0.335303 valid's rmse: 0.000788339   valid's RMSPE: 0.454809\n[833]   train's rmse: 0.000466399   train's RMSPE: 0.334958 valid's rmse: 0.00078877    valid's RMSPE: 0.455058\n[834]   train's rmse: 0.000466198   train's RMSPE: 0.334814 valid's rmse: 0.000789292   valid's RMSPE: 0.455359\n[835]   train's rmse: 0.000466513   train's RMSPE: 0.33504  valid's rmse: 0.000788271   valid's RMSPE: 0.45477\n[836]   train's rmse: 0.000466753   train's RMSPE: 0.335213 valid's rmse: 0.000787334   valid's RMSPE: 0.45423\n[837]   train's rmse: 0.00046614    train's RMSPE: 0.334772 valid's rmse: 0.000786891   valid's RMSPE: 0.453974\n[838]   train's rmse: 0.000466355   train's RMSPE: 0.334927 valid's rmse: 0.000785162   valid's RMSPE: 0.452976\n[839]   train's rmse: 0.000466102   train's RMSPE: 0.334745 valid's rmse: 0.000787024   valid's RMSPE: 0.454051\n[840]   train's rmse: 0.000465515   train's RMSPE: 0.334323 valid's rmse: 0.000786762   valid's RMSPE: 0.4539\n[841]   train's rmse: 0.000465227   train's RMSPE: 0.334116 valid's rmse: 0.000786897   valid's RMSPE: 0.453978\n[842]   train's rmse: 0.000464702   train's RMSPE: 0.33374  valid's rmse: 0.000787855   valid's RMSPE: 0.45453\n[843]   train's rmse: 0.000464913   train's RMSPE: 0.333891 valid's rmse: 0.00078676    valid's RMSPE: 0.453898\n[844]   train's rmse: 0.000464389   train's RMSPE: 0.333515 valid's rmse: 0.000787796   valid's RMSPE: 0.454496\n[845]   train's rmse: 0.000463869   train's RMSPE: 0.333141 valid's rmse: 0.000790237   valid's RMSPE: 0.455904\n[846]   train's rmse: 0.000464155   train's RMSPE: 0.333347 valid's rmse: 0.000789492   valid's RMSPE: 0.455474\n[847]   train's rmse: 0.0004644 train's RMSPE: 0.333523 valid's rmse: 0.000788544   valid's RMSPE: 0.454927\n[848]   train's rmse: 0.000463779   train's RMSPE: 0.333077 valid's rmse: 0.000788862   valid's RMSPE: 0.455111\n[849]   train's rmse: 0.0004641 train's RMSPE: 0.333308 valid's rmse: 0.000788067   valid's RMSPE: 0.454652\n[850]   train's rmse: 0.000464403   train's RMSPE: 0.333525 valid's rmse: 0.000787353   valid's RMSPE: 0.45424\n[851]   train's rmse: 0.000463874   train's RMSPE: 0.333145 valid's rmse: 0.000789102   valid's RMSPE: 0.455249\n[852]   train's rmse: 0.000464127   train's RMSPE: 0.333327 valid's rmse: 0.00078848    valid's RMSPE: 0.454891\n[853]   train's rmse: 0.000463758   train's RMSPE: 0.333062 valid's rmse: 0.00078951    valid's RMSPE: 0.455485\n[854]   train's rmse: 0.000464056   train's RMSPE: 0.333276 valid's rmse: 0.000788449   valid's RMSPE: 0.454873\n[855]   train's rmse: 0.000464295   train's RMSPE: 0.333448 valid's rmse: 0.000786787   valid's RMSPE: 0.453914\n[856]   train's rmse: 0.00046371    train's RMSPE: 0.333027 valid's rmse: 0.000787464   valid's RMSPE: 0.454305\n[857]   train's rmse: 0.000463275   train's RMSPE: 0.332715 valid's rmse: 0.000786711   valid's RMSPE: 0.45387\n[858]   train's rmse: 0.000463576   train's RMSPE: 0.332931 valid's rmse: 0.000785812   valid's RMSPE: 0.453351\n[859]   train's rmse: 0.000463869   train's RMSPE: 0.333141 valid's rmse: 0.000784775   valid's RMSPE: 0.452753\n[860]   train's rmse: 0.000463154   train's RMSPE: 0.332628 valid's rmse: 0.000784928   valid's RMSPE: 0.452841\n[861]   train's rmse: 0.000463441   train's RMSPE: 0.332834 valid's rmse: 0.000784031   valid's RMSPE: 0.452324\n[862]   train's rmse: 0.000463093   train's RMSPE: 0.332584 valid's rmse: 0.000785663   valid's RMSPE: 0.453265\n[863]   train's rmse: 0.000463374   train's RMSPE: 0.332786 valid's rmse: 0.000784882   valid's RMSPE: 0.452815\n[864]   train's rmse: 0.000463617   train's RMSPE: 0.33296  valid's rmse: 0.000784171   valid's RMSPE: 0.452405\n[865]   train's rmse: 0.000463267   train's RMSPE: 0.332709 valid's rmse: 0.00078341    valid's RMSPE: 0.451966\n[866]   train's rmse: 0.000463504   train's RMSPE: 0.332879 valid's rmse: 0.000782659   valid's RMSPE: 0.451532\n[867]   train's rmse: 0.000463035   train's RMSPE: 0.332542 valid's rmse: 0.000782911   valid's RMSPE: 0.451678\n[868]   train's rmse: 0.000462938   train's RMSPE: 0.332473 valid's rmse: 0.00078445    valid's RMSPE: 0.452565\n[869]   train's rmse: 0.000462654   train's RMSPE: 0.332269 valid's rmse: 0.000785921   valid's RMSPE: 0.453414\n[870]   train's rmse: 0.000462923   train's RMSPE: 0.332462 valid's rmse: 0.000784787   valid's RMSPE: 0.45276\n[871]   train's rmse: 0.000462285   train's RMSPE: 0.332004 valid's rmse: 0.000785486   valid's RMSPE: 0.453163\n[872]   train's rmse: 0.000462632   train's RMSPE: 0.332253 valid's rmse: 0.000784257   valid's RMSPE: 0.452454\n[873]   train's rmse: 0.000462331   train's RMSPE: 0.332037 valid's rmse: 0.000785036   valid's RMSPE: 0.452904\n[874]   train's rmse: 0.000462612   train's RMSPE: 0.332239 valid's rmse: 0.000784193   valid's RMSPE: 0.452417\n[875]   train's rmse: 0.000462412   train's RMSPE: 0.332095 valid's rmse: 0.000784799   valid's RMSPE: 0.452767\n[876]   train's rmse: 0.000462145   train's RMSPE: 0.331904 valid's rmse: 0.000785404   valid's RMSPE: 0.453116\n[877]   train's rmse: 0.000461629   train's RMSPE: 0.331533 valid's rmse: 0.000788141   valid's RMSPE: 0.454695\n[878]   train's rmse: 0.000461443   train's RMSPE: 0.331399 valid's rmse: 0.000789662   valid's RMSPE: 0.455572\n[879]   train's rmse: 0.000461657   train's RMSPE: 0.331552 valid's rmse: 0.000788731   valid's RMSPE: 0.455035\n[880]   train's rmse: 0.000461159   train's RMSPE: 0.331195 valid's rmse: 0.000787462   valid's RMSPE: 0.454304\n[881]   train's rmse: 0.000460653   train's RMSPE: 0.330831 valid's rmse: 0.000787948   valid's RMSPE: 0.454584\n[882]   train's rmse: 0.000460909   train's RMSPE: 0.331016 valid's rmse: 0.000787012   valid's RMSPE: 0.454044\n[883]   train's rmse: 0.000461212   train's RMSPE: 0.331233 valid's rmse: 0.000786025   valid's RMSPE: 0.453474\n[884]   train's rmse: 0.000461481   train's RMSPE: 0.331426 valid's rmse: 0.000785164   valid's RMSPE: 0.452978\n[885]   train's rmse: 0.000461814   train's RMSPE: 0.331665 valid's rmse: 0.000784492   valid's RMSPE: 0.45259\n[886]   train's rmse: 0.000462152   train's RMSPE: 0.331908 valid's rmse: 0.000783328   valid's RMSPE: 0.451918\n[887]   train's rmse: 0.000462379   train's RMSPE: 0.332072 valid's rmse: 0.00078275    valid's RMSPE: 0.451585\n[888]   train's rmse: 0.000461795   train's RMSPE: 0.331652 valid's rmse: 0.000784778   valid's RMSPE: 0.452755\n[889]   train's rmse: 0.000461344   train's RMSPE: 0.331328 valid's rmse: 0.000785857   valid's RMSPE: 0.453377\n[890]   train's rmse: 0.000460694   train's RMSPE: 0.330861 valid's rmse: 0.000786737   valid's RMSPE: 0.453885\n[891]   train's rmse: 0.000461003   train's RMSPE: 0.331083 valid's rmse: 0.000786002   valid's RMSPE: 0.453461\n[892]   train's rmse: 0.000460481   train's RMSPE: 0.330708 valid's rmse: 0.00079013    valid's RMSPE: 0.455842\n[893]   train's rmse: 0.000460058   train's RMSPE: 0.330404 valid's rmse: 0.000792792   valid's RMSPE: 0.457378\n[894]   train's rmse: 0.000460324   train's RMSPE: 0.330595 valid's rmse: 0.000791989   valid's RMSPE: 0.456915\n[895]   train's rmse: 0.000460629   train's RMSPE: 0.330815 valid's rmse: 0.0007913 valid's RMSPE: 0.456518\n[896]   train's rmse: 0.000460107   train's RMSPE: 0.330439 valid's rmse: 0.000794106   valid's RMSPE: 0.458136\n[897]   train's rmse: 0.00045955    train's RMSPE: 0.330039 valid's rmse: 0.000798178   valid's RMSPE: 0.460485\n[898]   train's rmse: 0.000459768   train's RMSPE: 0.330196 valid's rmse: 0.000797321   valid's RMSPE: 0.459991\n[899]   train's rmse: 0.000459348   train's RMSPE: 0.329894 valid's rmse: 0.00079931    valid's RMSPE: 0.461138\n[900]   train's rmse: 0.000459669   train's RMSPE: 0.330125 valid's rmse: 0.00079827    valid's RMSPE: 0.460538\n[901]   train's rmse: 0.000459138   train's RMSPE: 0.329743 valid's rmse: 0.000799293   valid's RMSPE: 0.461129\n[902]   train's rmse: 0.000458624   train's RMSPE: 0.329375 valid's rmse: 0.000798471   valid's RMSPE: 0.460655\n[903]   train's rmse: 0.000458907   train's RMSPE: 0.329578 valid's rmse: 0.000797616   valid's RMSPE: 0.460161\n[904]   train's rmse: 0.000459185   train's RMSPE: 0.329778 valid's rmse: 0.000796772   valid's RMSPE: 0.459674\n[905]   train's rmse: 0.000459458   train's RMSPE: 0.329973 valid's rmse: 0.000795861   valid's RMSPE: 0.459149\n[906]   train's rmse: 0.000458518   train's RMSPE: 0.329299 valid's rmse: 0.00079595    valid's RMSPE: 0.4592\n[907]   train's rmse: 0.000458774   train's RMSPE: 0.329482 valid's rmse: 0.000795065   valid's RMSPE: 0.45869\n[908]   train's rmse: 0.000459036   train's RMSPE: 0.32967  valid's rmse: 0.00079342    valid's RMSPE: 0.457741\n[909]   train's rmse: 0.000459369   train's RMSPE: 0.329909 valid's rmse: 0.000792525   valid's RMSPE: 0.457224\n[910]   train's rmse: 0.000459601   train's RMSPE: 0.330076 valid's rmse: 0.000791784   valid's RMSPE: 0.456796\n[911]   train's rmse: 0.000459938   train's RMSPE: 0.330318 valid's rmse: 0.000790607   valid's RMSPE: 0.456118\n[912]   train's rmse: 0.000459437   train's RMSPE: 0.329958 valid's rmse: 0.000791036   valid's RMSPE: 0.456365\n[913]   train's rmse: 0.000459794   train's RMSPE: 0.330215 valid's rmse: 0.000790218   valid's RMSPE: 0.455893\n[914]   train's rmse: 0.000460074   train's RMSPE: 0.330416 valid's rmse: 0.000789265   valid's RMSPE: 0.455343\n[915]   train's rmse: 0.000460414   train's RMSPE: 0.33066  valid's rmse: 0.000788216   valid's RMSPE: 0.454739\n[916]   train's rmse: 0.000459719   train's RMSPE: 0.330161 valid's rmse: 0.000788873   valid's RMSPE: 0.455117\n[917]   train's rmse: 0.00045909    train's RMSPE: 0.329709 valid's rmse: 0.000792346   valid's RMSPE: 0.457121\n[918]   train's rmse: 0.000459377   train's RMSPE: 0.329915 valid's rmse: 0.000791442   valid's RMSPE: 0.456599\n[919]   train's rmse: 0.000459694   train's RMSPE: 0.330143 valid's rmse: 0.000790596   valid's RMSPE: 0.456112\n[920]   train's rmse: 0.000460048   train's RMSPE: 0.330397 valid's rmse: 0.000789683   valid's RMSPE: 0.455584\n[921]   train's rmse: 0.000460302   train's RMSPE: 0.33058  valid's rmse: 0.00078905    valid's RMSPE: 0.455219\n[922]   train's rmse: 0.000460569   train's RMSPE: 0.330772 valid's rmse: 0.000788209   valid's RMSPE: 0.454734\n[923]   train's rmse: 0.000460887   train's RMSPE: 0.331    valid's rmse: 0.0007875 valid's RMSPE: 0.454325\n[924]   train's rmse: 0.000460031   train's RMSPE: 0.330385 valid's rmse: 0.000789919   valid's RMSPE: 0.455721\n[925]   train's rmse: 0.000459308   train's RMSPE: 0.329866 valid's rmse: 0.000790453   valid's RMSPE: 0.456029\n[926]   train's rmse: 0.000459632   train's RMSPE: 0.330099 valid's rmse: 0.000789715   valid's RMSPE: 0.455603\n[927]   train's rmse: 0.000459973   train's RMSPE: 0.330343 valid's rmse: 0.000788978   valid's RMSPE: 0.455178\n[928]   train's rmse: 0.000460313   train's RMSPE: 0.330587 valid's rmse: 0.000788108   valid's RMSPE: 0.454676\n[929]   train's rmse: 0.000460687   train's RMSPE: 0.330856 valid's rmse: 0.000787163   valid's RMSPE: 0.454131\n[930]   train's rmse: 0.000461022   train's RMSPE: 0.331097 valid's rmse: 0.00078644    valid's RMSPE: 0.453714\n[931]   train's rmse: 0.000461323   train's RMSPE: 0.331313 valid's rmse: 0.000785826   valid's RMSPE: 0.45336\n[932]   train's rmse: 0.00046056    train's RMSPE: 0.330765 valid's rmse: 0.00078678    valid's RMSPE: 0.45391\n[933]   train's rmse: 0.000460877   train's RMSPE: 0.330992 valid's rmse: 0.000785981   valid's RMSPE: 0.453449\n[934]   train's rmse: 0.000460231   train's RMSPE: 0.330529 valid's rmse: 0.000788808   valid's RMSPE: 0.45508\n[935]   train's rmse: 0.000459817   train's RMSPE: 0.330231 valid's rmse: 0.000789958   valid's RMSPE: 0.455743\n[936]   train's rmse: 0.000459265   train's RMSPE: 0.329835 valid's rmse: 0.000795195   valid's RMSPE: 0.458765\n[937]   train's rmse: 0.000458672   train's RMSPE: 0.329409 valid's rmse: 0.000799426   valid's RMSPE: 0.461206\n[938]   train's rmse: 0.000457729   train's RMSPE: 0.328731 valid's rmse: 0.000799559   valid's RMSPE: 0.461282\n[939]   train's rmse: 0.000457095   train's RMSPE: 0.328276 valid's rmse: 0.000799457   valid's RMSPE: 0.461223\n[940]   train's rmse: 0.000457375   train's RMSPE: 0.328477 valid's rmse: 0.000798588   valid's RMSPE: 0.460722\n[941]   train's rmse: 0.00045714    train's RMSPE: 0.328309 valid's rmse: 0.00079905    valid's RMSPE: 0.460988\n[942]   train's rmse: 0.000456308   train's RMSPE: 0.327712 valid's rmse: 0.000799122   valid's RMSPE: 0.46103\n[943]   train's rmse: 0.000456607   train's RMSPE: 0.327926 valid's rmse: 0.00079832    valid's RMSPE: 0.460568\n[944]   train's rmse: 0.000456899   train's RMSPE: 0.328136 valid's rmse: 0.000797495   valid's RMSPE: 0.460092\n[945]   train's rmse: 0.000457172   train's RMSPE: 0.328332 valid's rmse: 0.000795709   valid's RMSPE: 0.459061\n[946]   train's rmse: 0.000456748   train's RMSPE: 0.328027 valid's rmse: 0.000797073   valid's RMSPE: 0.459848\n[947]   train's rmse: 0.000457097   train's RMSPE: 0.328278 valid's rmse: 0.000795289   valid's RMSPE: 0.458819\n[948]   train's rmse: 0.000457407   train's RMSPE: 0.328501 valid's rmse: 0.000794744   valid's RMSPE: 0.458504\n[949]   train's rmse: 0.000457139   train's RMSPE: 0.328308 valid's rmse: 0.000794012   valid's RMSPE: 0.458082\n[950]   train's rmse: 0.000457466   train's RMSPE: 0.328543 valid's rmse: 0.000793059   valid's RMSPE: 0.457532\n[951]   train's rmse: 0.00045681    train's RMSPE: 0.328072 valid's rmse: 0.0007942 valid's RMSPE: 0.458191\n[952]   train's rmse: 0.000456529   train's RMSPE: 0.32787  valid's rmse: 0.000795964   valid's RMSPE: 0.459209\n[953]   train's rmse: 0.000455765   train's RMSPE: 0.327322 valid's rmse: 0.000798158   valid's RMSPE: 0.460474\n[954]   train's rmse: 0.000456039   train's RMSPE: 0.327518 valid's rmse: 0.000797497   valid's RMSPE: 0.460093\n[955]   train's rmse: 0.00045629    train's RMSPE: 0.327698 valid's rmse: 0.000796888   valid's RMSPE: 0.459742\n[956]   train's rmse: 0.000455805   train's RMSPE: 0.32735  valid's rmse: 0.000800086   valid's RMSPE: 0.461586\n[957]   train's rmse: 0.00045608    train's RMSPE: 0.327548 valid's rmse: 0.000798999   valid's RMSPE: 0.460959\n[958]   train's rmse: 0.000456337   train's RMSPE: 0.327732 valid's rmse: 0.000798338   valid's RMSPE: 0.460578\n[959]   train's rmse: 0.000456628   train's RMSPE: 0.327941 valid's rmse: 0.000797524   valid's RMSPE: 0.460108\n[960]   train's rmse: 0.000456935   train's RMSPE: 0.328161 valid's rmse: 0.000796827   valid's RMSPE: 0.459706\n[961]   train's rmse: 0.000456326   train's RMSPE: 0.327724 valid's rmse: 0.000798207   valid's RMSPE: 0.460503\n[962]   train's rmse: 0.000455838   train's RMSPE: 0.327373 valid's rmse: 0.000797536   valid's RMSPE: 0.460115\n[963]   train's rmse: 0.00045571    train's RMSPE: 0.327282 valid's rmse: 0.000795892   valid's RMSPE: 0.459167\n[964]   train's rmse: 0.000456014   train's RMSPE: 0.3275   valid's rmse: 0.000795072   valid's RMSPE: 0.458693\n[965]   train's rmse: 0.00045553    train's RMSPE: 0.327153 valid's rmse: 0.00079559    valid's RMSPE: 0.458992\n[966]   train's rmse: 0.00045498    train's RMSPE: 0.326758 valid's rmse: 0.000797625   valid's RMSPE: 0.460167\n[967]   train's rmse: 0.000454117   train's RMSPE: 0.326137 valid's rmse: 0.000796813   valid's RMSPE: 0.459698\n[968]   train's rmse: 0.000453903   train's RMSPE: 0.325984 valid's rmse: 0.000798189   valid's RMSPE: 0.460492\n[969]   train's rmse: 0.000454148   train's RMSPE: 0.32616  valid's rmse: 0.00079719    valid's RMSPE: 0.459916\n[970]   train's rmse: 0.000454386   train's RMSPE: 0.326331 valid's rmse: 0.000795998   valid's RMSPE: 0.459228\n[971]   train's rmse: 0.000454626   train's RMSPE: 0.326503 valid's rmse: 0.000795185   valid's RMSPE: 0.458759\n[972]   train's rmse: 0.000454067   train's RMSPE: 0.326102 valid's rmse: 0.000798873   valid's RMSPE: 0.460887\n[973]   train's rmse: 0.000453748   train's RMSPE: 0.325873 valid's rmse: 0.000798526   valid's RMSPE: 0.460686\n[974]   train's rmse: 0.000453563   train's RMSPE: 0.32574  valid's rmse: 0.000801814   valid's RMSPE: 0.462583\n[975]   train's rmse: 0.000453737   train's RMSPE: 0.325865 valid's rmse: 0.000800204   valid's RMSPE: 0.461654\n[976]   train's rmse: 0.000453219   train's RMSPE: 0.325493 valid's rmse: 0.000800931   valid's RMSPE: 0.462074\nEarly stopping, best iteration is:\n[577]   0.4354814419454263\n576\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:183: UserWarning: Early stopping is not available in dart mode\n  _log_warning('Early stopping is not available in dart mode')\n\n\n[1] train's rmse: 0.00108749    train's RMSPE: 0.758174 valid's rmse: 0.00111254    valid's RMSPE: 0.747748\n[2] train's rmse: 0.00105834    train's RMSPE: 0.73785  valid's rmse: 0.00109043    valid's RMSPE: 0.732886\n[3] train's rmse: 0.00103296    train's RMSPE: 0.720161 valid's rmse: 0.00107393    valid's RMSPE: 0.7218\n[4] train's rmse: 0.00100695    train's RMSPE: 0.702026 valid's rmse: 0.00105584    valid's RMSPE: 0.709642\n[5] train's rmse: 0.000979996   train's RMSPE: 0.683234 valid's rmse: 0.00104258    valid's RMSPE: 0.700729\n[6] train's rmse: 0.000955547   train's RMSPE: 0.666188 valid's rmse: 0.00103366    valid's RMSPE: 0.694734\n[7] train's rmse: 0.000956649   train's RMSPE: 0.666957 valid's rmse: 0.00103457    valid's RMSPE: 0.695343\n[8] train's rmse: 0.000933196   train's RMSPE: 0.650605 valid's rmse: 0.00103942    valid's RMSPE: 0.698601\n[9] train's rmse: 0.000914023   train's RMSPE: 0.637238 valid's rmse: 0.00102669    valid's RMSPE: 0.690049\n[10]    train's rmse: 0.000914776   train's RMSPE: 0.637764 valid's rmse: 0.00102852    valid's RMSPE: 0.691278\n[11]    train's rmse: 0.000894851   train's RMSPE: 0.623872 valid's rmse: 0.00102336    valid's RMSPE: 0.687811\n[12]    train's rmse: 0.000898151   train's RMSPE: 0.626173 valid's rmse: 0.0010255 valid's RMSPE: 0.689246\n[13]    train's rmse: 0.000877033   train's RMSPE: 0.61145  valid's rmse: 0.00103504    valid's RMSPE: 0.695659\n[14]    train's rmse: 0.000857918   train's RMSPE: 0.598123 valid's rmse: 0.00104605    valid's RMSPE: 0.703056\n[15]    train's rmse: 0.000839185   train's RMSPE: 0.585063 valid's rmse: 0.00104056    valid's RMSPE: 0.699368\n[16]    train's rmse: 0.000822023   train's RMSPE: 0.573098 valid's rmse: 0.00104568    valid's RMSPE: 0.702809\n[17]    train's rmse: 0.000828462   train's RMSPE: 0.577587 valid's rmse: 0.00103727    valid's RMSPE: 0.697158\n[18]    train's rmse: 0.000813074   train's RMSPE: 0.566859 valid's rmse: 0.00104912    valid's RMSPE: 0.705121\n[19]    train's rmse: 0.000815061   train's RMSPE: 0.568244 valid's rmse: 0.00104031    valid's RMSPE: 0.6992\n[20]    train's rmse: 0.000817201   train's RMSPE: 0.569736 valid's rmse: 0.00103519    valid's RMSPE: 0.695758\n[21]    train's rmse: 0.000824845   train's RMSPE: 0.575065 valid's rmse: 0.0010304 valid's RMSPE: 0.69254\n[22]    train's rmse: 0.000847323   train's RMSPE: 0.590736 valid's rmse: 0.0010184 valid's RMSPE: 0.684476\n[23]    train's rmse: 0.000830787   train's RMSPE: 0.579208 valid's rmse: 0.00100204    valid's RMSPE: 0.67348\n[24]    train's rmse: 0.000871064   train's RMSPE: 0.607288 valid's rmse: 0.00101938    valid's RMSPE: 0.685135\n[25]    train's rmse: 0.000866313   train's RMSPE: 0.603976 valid's rmse: 0.00102515    valid's RMSPE: 0.689012\n[26]    train's rmse: 0.000846248   train's RMSPE: 0.589987 valid's rmse: 0.00101865    valid's RMSPE: 0.684641\n[27]    train's rmse: 0.000829419   train's RMSPE: 0.578254 valid's rmse: 0.00101399    valid's RMSPE: 0.681513\n[28]    train's rmse: 0.000833643   train's RMSPE: 0.581199 valid's rmse: 0.00101573    valid's RMSPE: 0.682677\n[29]    train's rmse: 0.000839836   train's RMSPE: 0.585517 valid's rmse: 0.00101852    valid's RMSPE: 0.684555\n[30]    train's rmse: 0.000823078   train's RMSPE: 0.573833 valid's rmse: 0.00101002    valid's RMSPE: 0.678841\n[31]    train's rmse: 0.00080874    train's RMSPE: 0.563837 valid's rmse: 0.00100658    valid's RMSPE: 0.676529\n[32]    train's rmse: 0.000816157   train's RMSPE: 0.569008 valid's rmse: 0.00101337    valid's RMSPE: 0.681095\n[33]    train's rmse: 0.000797787   train's RMSPE: 0.556201 valid's rmse: 0.00101468    valid's RMSPE: 0.681975\n[34]    train's rmse: 0.000782332   train's RMSPE: 0.545426 valid's rmse: 0.00101108    valid's RMSPE: 0.679558\n[35]    train's rmse: 0.000768646   train's RMSPE: 0.535885 valid's rmse: 0.0010227 valid's RMSPE: 0.687366\n[36]    train's rmse: 0.000756209   train's RMSPE: 0.527213 valid's rmse: 0.00102988    valid's RMSPE: 0.692193\n[37]    train's rmse: 0.000761608   train's RMSPE: 0.530978 valid's rmse: 0.0010281 valid's RMSPE: 0.690996\n[38]    train's rmse: 0.000792936   train's RMSPE: 0.552819 valid's rmse: 0.00102549    valid's RMSPE: 0.689239\n[39]    train's rmse: 0.000777902   train's RMSPE: 0.542337 valid's rmse: 0.00103325    valid's RMSPE: 0.694454\n[40]    train's rmse: 0.000763903   train's RMSPE: 0.532577 valid's rmse: 0.0010376 valid's RMSPE: 0.697382\n[41]    train's rmse: 0.000769494   train's RMSPE: 0.536476 valid's rmse: 0.00103548    valid's RMSPE: 0.695956\n[42]    train's rmse: 0.000775344   train's RMSPE: 0.540554 valid's rmse: 0.00103246    valid's RMSPE: 0.693925\n[43]    train's rmse: 0.000762693   train's RMSPE: 0.531734 valid's rmse: 0.00104666    valid's RMSPE: 0.703472\n[44]    train's rmse: 0.000749266   train's RMSPE: 0.522373 valid's rmse: 0.00106171    valid's RMSPE: 0.713586\n[45]    train's rmse: 0.000737056   train's RMSPE: 0.51386  valid's rmse: 0.0010694 valid's RMSPE: 0.718752\n[46]    train's rmse: 0.000743775   train's RMSPE: 0.518545 valid's rmse: 0.00106565    valid's RMSPE: 0.716234\n[47]    train's rmse: 0.000731667   train's RMSPE: 0.510103 valid's rmse: 0.00106779    valid's RMSPE: 0.717672\n[48]    train's rmse: 0.000738313   train's RMSPE: 0.514737 valid's rmse: 0.00106779    valid's RMSPE: 0.71767\n[49]    train's rmse: 0.000743282   train's RMSPE: 0.518201 valid's rmse: 0.00106358    valid's RMSPE: 0.714839\n[50]    train's rmse: 0.000730073   train's RMSPE: 0.508992 valid's rmse: 0.0010737 valid's RMSPE: 0.72164\n[51]    train's rmse: 0.000734695   train's RMSPE: 0.512214 valid's rmse: 0.00106769    valid's RMSPE: 0.717606\n[52]    train's rmse: 0.00073655    train's RMSPE: 0.513508 valid's rmse: 0.00105883    valid's RMSPE: 0.711647\n[53]    train's rmse: 0.000741006   train's RMSPE: 0.516614 valid's rmse: 0.00105502    valid's RMSPE: 0.709088\n[54]    train's rmse: 0.000729639   train's RMSPE: 0.50869  valid's rmse: 0.00106957    valid's RMSPE: 0.718866\n[55]    train's rmse: 0.000732936   train's RMSPE: 0.510988 valid's rmse: 0.00106648    valid's RMSPE: 0.71679\n[56]    train's rmse: 0.000721779   train's RMSPE: 0.503209 valid's rmse: 0.00106658    valid's RMSPE: 0.716856\n[57]    train's rmse: 0.000709871   train's RMSPE: 0.494908 valid's rmse: 0.0010572 valid's RMSPE: 0.710551\n[58]    train's rmse: 0.000699826   train's RMSPE: 0.487905 valid's rmse: 0.00106229    valid's RMSPE: 0.713971\n[59]    train's rmse: 0.000704748   train's RMSPE: 0.491336 valid's rmse: 0.00106217    valid's RMSPE: 0.713891\n[60]    train's rmse: 0.000696339   train's RMSPE: 0.485474 valid's rmse: 0.00106766    valid's RMSPE: 0.717583\n[61]    train's rmse: 0.000703394   train's RMSPE: 0.490392 valid's rmse: 0.00106088    valid's RMSPE: 0.713026\n[62]    train's rmse: 0.000693831   train's RMSPE: 0.483725 valid's rmse: 0.00106432    valid's RMSPE: 0.715338\n[63]    train's rmse: 0.00071213    train's RMSPE: 0.496482 valid's rmse: 0.00105515    valid's RMSPE: 0.709177\n[64]    train's rmse: 0.00073198    train's RMSPE: 0.510322 valid's rmse: 0.0010499 valid's RMSPE: 0.705649\n[65]    train's rmse: 0.000738515   train's RMSPE: 0.514877 valid's rmse: 0.0010468 valid's RMSPE: 0.703566\n[66]    train's rmse: 0.000726545   train's RMSPE: 0.506533 valid's rmse: 0.00105056    valid's RMSPE: 0.706087\n[67]    train's rmse: 0.000728908   train's RMSPE: 0.50818  valid's rmse: 0.00104771    valid's RMSPE: 0.704177\n[68]    train's rmse: 0.000717261   train's RMSPE: 0.500059 valid's rmse: 0.00105256    valid's RMSPE: 0.707436\n[69]    train's rmse: 0.000706782   train's RMSPE: 0.492754 valid's rmse: 0.00105592    valid's RMSPE: 0.709689\n[70]    train's rmse: 0.000712043   train's RMSPE: 0.496422 valid's rmse: 0.00105288    valid's RMSPE: 0.707651\n[71]    train's rmse: 0.000715475   train's RMSPE: 0.498815 valid's rmse: 0.00104892    valid's RMSPE: 0.704991\n[72]    train's rmse: 0.000704251   train's RMSPE: 0.49099  valid's rmse: 0.00103984    valid's RMSPE: 0.698882\n[73]    train's rmse: 0.000693968   train's RMSPE: 0.48382  valid's rmse: 0.00104431    valid's RMSPE: 0.701887\n[74]    train's rmse: 0.000699305   train's RMSPE: 0.487541 valid's rmse: 0.00104142    valid's RMSPE: 0.69995\n[75]    train's rmse: 0.000688891   train's RMSPE: 0.480281 valid's rmse: 0.00105161    valid's RMSPE: 0.706798\n[76]    train's rmse: 0.000693904   train's RMSPE: 0.483776 valid's rmse: 0.001048  valid's RMSPE: 0.70437\n[77]    train's rmse: 0.000683996   train's RMSPE: 0.476868 valid's rmse: 0.00103996    valid's RMSPE: 0.698967\n[78]    train's rmse: 0.000683562   train's RMSPE: 0.476566 valid's rmse: 0.00104114    valid's RMSPE: 0.699759\n[79]    train's rmse: 0.000688415   train's RMSPE: 0.479949 valid's rmse: 0.00103866    valid's RMSPE: 0.698095\n[80]    train's rmse: 0.000691624   train's RMSPE: 0.482186 valid's rmse: 0.00103715    valid's RMSPE: 0.697077\n[81]    train's rmse: 0.000682255   train's RMSPE: 0.475655 valid's rmse: 0.0010408 valid's RMSPE: 0.699529\n[82]    train's rmse: 0.000674053   train's RMSPE: 0.469936 valid's rmse: 0.00104617    valid's RMSPE: 0.703139\n[83]    train's rmse: 0.000679055   train's RMSPE: 0.473423 valid's rmse: 0.00104051    valid's RMSPE: 0.699333\n[84]    train's rmse: 0.000670182   train's RMSPE: 0.467237 valid's rmse: 0.00104564    valid's RMSPE: 0.702782\n[85]    train's rmse: 0.00067432    train's RMSPE: 0.470122 valid's rmse: 0.00104512    valid's RMSPE: 0.702433\n[86]    train's rmse: 0.000679044   train's RMSPE: 0.473415 valid's rmse: 0.00104363    valid's RMSPE: 0.701433\n[87]    train's rmse: 0.000671185   train's RMSPE: 0.467937 valid's rmse: 0.00104947    valid's RMSPE: 0.705358\n[88]    train's rmse: 0.000674287   train's RMSPE: 0.470099 valid's rmse: 0.00104907    valid's RMSPE: 0.705089\n[89]    train's rmse: 0.00067885    train's RMSPE: 0.473281 valid's rmse: 0.00104739    valid's RMSPE: 0.703959\n[90]    train's rmse: 0.000684012   train's RMSPE: 0.476879 valid's rmse: 0.00104385    valid's RMSPE: 0.70158\n[91]    train's rmse: 0.000688515   train's RMSPE: 0.480019 valid's rmse: 0.00104189    valid's RMSPE: 0.700263\n[92]    train's rmse: 0.000679523   train's RMSPE: 0.47375  valid's rmse: 0.00103724    valid's RMSPE: 0.69714\n[93]    train's rmse: 0.000671913   train's RMSPE: 0.468444 valid's rmse: 0.00104955    valid's RMSPE: 0.70541\n[94]    train's rmse: 0.000664156   train's RMSPE: 0.463036 valid's rmse: 0.00105741    valid's RMSPE: 0.710693\n[95]    train's rmse: 0.000657876   train's RMSPE: 0.458658 valid's rmse: 0.00105856    valid's RMSPE: 0.711467\n[96]    train's rmse: 0.000650974   train's RMSPE: 0.453846 valid's rmse: 0.00107028    valid's RMSPE: 0.719347\n[97]    train's rmse: 0.000646187   train's RMSPE: 0.450508 valid's rmse: 0.00107674    valid's RMSPE: 0.723686\n[98]    train's rmse: 0.000649985   train's RMSPE: 0.453156 valid's rmse: 0.00107069    valid's RMSPE: 0.719617\n[99]    train's rmse: 0.000653159   train's RMSPE: 0.455369 valid's rmse: 0.00106825    valid's RMSPE: 0.717979\n[100]   train's rmse: 0.000656818   train's RMSPE: 0.45792  valid's rmse: 0.00106517    valid's RMSPE: 0.715911\n[101]   train's rmse: 0.000650276   train's RMSPE: 0.453359 valid's rmse: 0.00107162    valid's RMSPE: 0.720241\n[102]   train's rmse: 0.000645102   train's RMSPE: 0.449752 valid's rmse: 0.00107983    valid's RMSPE: 0.725762\n[103]   train's rmse: 0.000648036   train's RMSPE: 0.451797 valid's rmse: 0.00107442    valid's RMSPE: 0.722126\n[104]   train's rmse: 0.000651128   train's RMSPE: 0.453953 valid's rmse: 0.00107157    valid's RMSPE: 0.720213\n[105]   train's rmse: 0.000654616   train's RMSPE: 0.456385 valid's rmse: 0.00106619    valid's RMSPE: 0.716592\n[106]   train's rmse: 0.000666122   train's RMSPE: 0.464407 valid's rmse: 0.00105681    valid's RMSPE: 0.710289\n[107]   train's rmse: 0.000669873   train's RMSPE: 0.467022 valid's rmse: 0.00105408    valid's RMSPE: 0.708455\n[108]   train's rmse: 0.000674112   train's RMSPE: 0.469977 valid's rmse: 0.00105145    valid's RMSPE: 0.706687\n[109]   train's rmse: 0.000677964   train's RMSPE: 0.472663 valid's rmse: 0.00104899    valid's RMSPE: 0.705033\n[110]   train's rmse: 0.000669043   train's RMSPE: 0.466443 valid's rmse: 0.00104328    valid's RMSPE: 0.701196\n[111]   train's rmse: 0.000673273   train's RMSPE: 0.469392 valid's rmse: 0.00104048    valid's RMSPE: 0.699313\n[112]   train's rmse: 0.000677779   train's RMSPE: 0.472534 valid's rmse: 0.0010386 valid's RMSPE: 0.69805\n[113]   train's rmse: 0.000669003   train's RMSPE: 0.466415 valid's rmse: 0.00103088    valid's RMSPE: 0.692864\n[114]   train's rmse: 0.000673677   train's RMSPE: 0.469674 valid's rmse: 0.00102975    valid's RMSPE: 0.6921\n[115]   train's rmse: 0.000677317   train's RMSPE: 0.472212 valid's rmse: 0.00102773    valid's RMSPE: 0.690746\n[116]   train's rmse: 0.000669293   train's RMSPE: 0.466617 valid's rmse: 0.00104243    valid's RMSPE: 0.700627\n[117]   train's rmse: 0.000671896   train's RMSPE: 0.468432 valid's rmse: 0.0010419 valid's RMSPE: 0.700273\n[118]   train's rmse: 0.000675341   train's RMSPE: 0.470834 valid's rmse: 0.00104071    valid's RMSPE: 0.699471\n[119]   train's rmse: 0.000677829   train's RMSPE: 0.472568 valid's rmse: 0.00103791    valid's RMSPE: 0.69759\n[120]   train's rmse: 0.000668459   train's RMSPE: 0.466036 valid's rmse: 0.00104797    valid's RMSPE: 0.704346\n[121]   train's rmse: 0.000671435   train's RMSPE: 0.468111 valid's rmse: 0.00104548    valid's RMSPE: 0.702679\n[122]   train's rmse: 0.000675641   train's RMSPE: 0.471043 valid's rmse: 0.00104286    valid's RMSPE: 0.700913\n[123]   train's rmse: 0.000685268   train's RMSPE: 0.477755 valid's rmse: 0.00103717    valid's RMSPE: 0.697091\n[124]   train's rmse: 0.000687621   train's RMSPE: 0.479395 valid's rmse: 0.00103599    valid's RMSPE: 0.6963\n[125]   train's rmse: 0.00067892    train's RMSPE: 0.473329 valid's rmse: 0.00103656    valid's RMSPE: 0.696678\n[126]   train's rmse: 0.000682434   train's RMSPE: 0.475779 valid's rmse: 0.00103421    valid's RMSPE: 0.695102\n[127]   train's rmse: 0.000685315   train's RMSPE: 0.477788 valid's rmse: 0.00103317    valid's RMSPE: 0.694404\n[128]   train's rmse: 0.000676198   train's RMSPE: 0.471432 valid's rmse: 0.00103103    valid's RMSPE: 0.692966\n[129]   train's rmse: 0.000666841   train's RMSPE: 0.464908 valid's rmse: 0.00103877    valid's RMSPE: 0.698163\n[130]   train's rmse: 0.000674838   train's RMSPE: 0.470483 valid's rmse: 0.00103412    valid's RMSPE: 0.695043\n[131]   train's rmse: 0.000667591   train's RMSPE: 0.465431 valid's rmse: 0.00103428    valid's RMSPE: 0.695146\n[132]   train's rmse: 0.000670985   train's RMSPE: 0.467797 valid's rmse: 0.00103522    valid's RMSPE: 0.695782\n[133]   train's rmse: 0.000663077   train's RMSPE: 0.462284 valid's rmse: 0.00103524    valid's RMSPE: 0.695794\n[134]   train's rmse: 0.000666712   train's RMSPE: 0.464818 valid's rmse: 0.00103301    valid's RMSPE: 0.694295\n[135]   train's rmse: 0.000658953   train's RMSPE: 0.459409 valid's rmse: 0.00104384    valid's RMSPE: 0.701574\n[136]   train's rmse: 0.000662094   train's RMSPE: 0.461598 valid's rmse: 0.00104047    valid's RMSPE: 0.699305\n[137]   train's rmse: 0.000665796   train's RMSPE: 0.464179 valid's rmse: 0.00103825    valid's RMSPE: 0.697814\n[138]   train's rmse: 0.000669489   train's RMSPE: 0.466754 valid's rmse: 0.00103492    valid's RMSPE: 0.695576\n[139]   train's rmse: 0.000672257   train's RMSPE: 0.468684 valid's rmse: 0.00103378    valid's RMSPE: 0.69481\n[140]   train's rmse: 0.0006646 train's RMSPE: 0.463346 valid's rmse: 0.00103891    valid's RMSPE: 0.698257\n[141]   train's rmse: 0.000658038   train's RMSPE: 0.458771 valid's rmse: 0.00104225    valid's RMSPE: 0.700506\n[142]   train's rmse: 0.000650101   train's RMSPE: 0.453237 valid's rmse: 0.00103838    valid's RMSPE: 0.6979\n[143]   train's rmse: 0.000642801   train's RMSPE: 0.448148 valid's rmse: 0.00103905    valid's RMSPE: 0.698356\n[144]   train's rmse: 0.000635887   train's RMSPE: 0.443327 valid's rmse: 0.00104171    valid's RMSPE: 0.70014\n[145]   train's rmse: 0.000639148   train's RMSPE: 0.445601 valid's rmse: 0.00103921    valid's RMSPE: 0.69846\n[146]   train's rmse: 0.000631674   train's RMSPE: 0.440391 valid's rmse: 0.00103771    valid's RMSPE: 0.697456\n[147]   train's rmse: 0.000634372   train's RMSPE: 0.442271 valid's rmse: 0.00103477    valid's RMSPE: 0.695479\n[148]   train's rmse: 0.000637368   train's RMSPE: 0.44436  valid's rmse: 0.00103354    valid's RMSPE: 0.694654\n[149]   train's rmse: 0.000631455   train's RMSPE: 0.440237 valid's rmse: 0.00104539    valid's RMSPE: 0.702617\n[150]   train's rmse: 0.000625893   train's RMSPE: 0.43636  valid's rmse: 0.00105014    valid's RMSPE: 0.70581\n[151]   train's rmse: 0.000629501   train's RMSPE: 0.438876 valid's rmse: 0.00104687    valid's RMSPE: 0.703612\n[152]   train's rmse: 0.000633006   train's RMSPE: 0.441319 valid's rmse: 0.00104533    valid's RMSPE: 0.702572\n[153]   train's rmse: 0.000635721   train's RMSPE: 0.443212 valid's rmse: 0.00104273    valid's RMSPE: 0.700825\n[154]   train's rmse: 0.000639391   train's RMSPE: 0.44577  valid's rmse: 0.00103865    valid's RMSPE: 0.698086\n[155]   train's rmse: 0.000642814   train's RMSPE: 0.448157 valid's rmse: 0.00103722    valid's RMSPE: 0.697127\n[156]   train's rmse: 0.000645199   train's RMSPE: 0.44982  valid's rmse: 0.00103656    valid's RMSPE: 0.696682\n[157]   train's rmse: 0.000648654   train's RMSPE: 0.452229 valid's rmse: 0.00103439    valid's RMSPE: 0.695225\n[158]   train's rmse: 0.000652004   train's RMSPE: 0.454564 valid's rmse: 0.00103331    valid's RMSPE: 0.694495\n[159]   train's rmse: 0.000654801   train's RMSPE: 0.456514 valid's rmse: 0.00103125    valid's RMSPE: 0.693111\n[160]   train's rmse: 0.000646525   train's RMSPE: 0.450744 valid's rmse: 0.00103549    valid's RMSPE: 0.695963\n[161]   train's rmse: 0.00064914    train's RMSPE: 0.452568 valid's rmse: 0.00103363    valid's RMSPE: 0.694708\n[162]   train's rmse: 0.000642486   train's RMSPE: 0.447928 valid's rmse: 0.00103568    valid's RMSPE: 0.696086\n[163]   train's rmse: 0.00064912    train's RMSPE: 0.452553 valid's rmse: 0.00103022    valid's RMSPE: 0.692419\n[164]   train's rmse: 0.000642297   train's RMSPE: 0.447797 valid's rmse: 0.00103716    valid's RMSPE: 0.697082\n[165]   train's rmse: 0.000649106   train's RMSPE: 0.452544 valid's rmse: 0.00103264    valid's RMSPE: 0.694043\n[166]   train's rmse: 0.000652238   train's RMSPE: 0.454727 valid's rmse: 0.00103149    valid's RMSPE: 0.693275\n[167]   train's rmse: 0.00064555    train's RMSPE: 0.450065 valid's rmse: 0.00103716    valid's RMSPE: 0.697086\n[168]   train's rmse: 0.000639051   train's RMSPE: 0.445534 valid's rmse: 0.00104953    valid's RMSPE: 0.7054\n[169]   train's rmse: 0.000633259   train's RMSPE: 0.441495 valid's rmse: 0.001046  valid's RMSPE: 0.703025\n[170]   train's rmse: 0.000636272   train's RMSPE: 0.443596 valid's rmse: 0.00104339    valid's RMSPE: 0.701272\n[171]   train's rmse: 0.000639424   train's RMSPE: 0.445794 valid's rmse: 0.00104199    valid's RMSPE: 0.700328\n[172]   train's rmse: 0.000632183   train's RMSPE: 0.440745 valid's rmse: 0.00105135    valid's RMSPE: 0.706622\n[173]   train's rmse: 0.000626366   train's RMSPE: 0.43669  valid's rmse: 0.00104999    valid's RMSPE: 0.705706\n[174]   train's rmse: 0.000629277   train's RMSPE: 0.438719 valid's rmse: 0.00104721    valid's RMSPE: 0.703836\n[175]   train's rmse: 0.000624324   train's RMSPE: 0.435266 valid's rmse: 0.0010443 valid's RMSPE: 0.70188\n[176]   train's rmse: 0.000619442   train's RMSPE: 0.431862 valid's rmse: 0.00104975    valid's RMSPE: 0.705547\n[177]   train's rmse: 0.000622525   train's RMSPE: 0.434012 valid's rmse: 0.00104715    valid's RMSPE: 0.703798\n[178]   train's rmse: 0.000619562   train's RMSPE: 0.431946 valid's rmse: 0.00105554    valid's RMSPE: 0.709436\n[179]   train's rmse: 0.000615495   train's RMSPE: 0.42911  valid's rmse: 0.00106502    valid's RMSPE: 0.71581\n[180]   train's rmse: 0.0006183 train's RMSPE: 0.431066 valid's rmse: 0.00106253    valid's RMSPE: 0.714134\n[181]   train's rmse: 0.000621119   train's RMSPE: 0.433032 valid's rmse: 0.00105953    valid's RMSPE: 0.712119\n[182]   train's rmse: 0.000627753   train's RMSPE: 0.437657 valid's rmse: 0.00105153    valid's RMSPE: 0.706742\n[183]   train's rmse: 0.000622135   train's RMSPE: 0.43374  valid's rmse: 0.00105292    valid's RMSPE: 0.707676\n[184]   train's rmse: 0.000624922   train's RMSPE: 0.435683 valid's rmse: 0.00105047    valid's RMSPE: 0.706026\n[185]   train's rmse: 0.00061985    train's RMSPE: 0.432147 valid's rmse: 0.00106598    valid's RMSPE: 0.716451\n[186]   train's rmse: 0.000622739   train's RMSPE: 0.434161 valid's rmse: 0.00106213    valid's RMSPE: 0.713863\n[187]   train's rmse: 0.000625331   train's RMSPE: 0.435968 valid's rmse: 0.00105896    valid's RMSPE: 0.711739\n[188]   train's rmse: 0.000620245   train's RMSPE: 0.432422 valid's rmse: 0.00106025    valid's RMSPE: 0.7126\n[189]   train's rmse: 0.000622788   train's RMSPE: 0.434195 valid's rmse: 0.00105777    valid's RMSPE: 0.710937\n[190]   train's rmse: 0.000617257   train's RMSPE: 0.430339 valid's rmse: 0.00106183    valid's RMSPE: 0.713666\n[191]   train's rmse: 0.000619969   train's RMSPE: 0.43223  valid's rmse: 0.00105942    valid's RMSPE: 0.712044\n[192]   train's rmse: 0.000614494   train's RMSPE: 0.428413 valid's rmse: 0.00105649    valid's RMSPE: 0.710076\n[193]   train's rmse: 0.000617526   train's RMSPE: 0.430526 valid's rmse: 0.00105314    valid's RMSPE: 0.707822\n[194]   train's rmse: 0.00061268    train's RMSPE: 0.427148 valid's rmse: 0.00106778    valid's RMSPE: 0.717661\n[195]   train's rmse: 0.000615789   train's RMSPE: 0.429315 valid's rmse: 0.00106417    valid's RMSPE: 0.715237\n[196]   train's rmse: 0.000610754   train's RMSPE: 0.425805 valid's rmse: 0.00106151    valid's RMSPE: 0.713452\n[197]   train's rmse: 0.000613292   train's RMSPE: 0.427575 valid's rmse: 0.00105874    valid's RMSPE: 0.71159\n[198]   train's rmse: 0.000615821   train's RMSPE: 0.429338 valid's rmse: 0.00105681    valid's RMSPE: 0.710292\n[199]   train's rmse: 0.000618545   train's RMSPE: 0.431237 valid's rmse: 0.00105428    valid's RMSPE: 0.708588\n[200]   train's rmse: 0.000620861   train's RMSPE: 0.432852 valid's rmse: 0.00105239    valid's RMSPE: 0.707323\n[201]   train's rmse: 0.000623549   train's RMSPE: 0.434726 valid's rmse: 0.00105026    valid's RMSPE: 0.705891\n[202]   train's rmse: 0.00062573    train's RMSPE: 0.436246 valid's rmse: 0.0010487 valid's RMSPE: 0.704842\n[203]   train's rmse: 0.000628374   train's RMSPE: 0.438089 valid's rmse: 0.00104731    valid's RMSPE: 0.703907\n[204]   train's rmse: 0.000630931   train's RMSPE: 0.439872 valid's rmse: 0.00104575    valid's RMSPE: 0.702854\n[205]   train's rmse: 0.000626236   train's RMSPE: 0.436599 valid's rmse: 0.00105024    valid's RMSPE: 0.705874\n[206]   train's rmse: 0.000628947   train's RMSPE: 0.438489 valid's rmse: 0.00104783    valid's RMSPE: 0.704252\n[207]   train's rmse: 0.00063163    train's RMSPE: 0.440359 valid's rmse: 0.00104482    valid's RMSPE: 0.702234\n[208]   train's rmse: 0.000634231   train's RMSPE: 0.442173 valid's rmse: 0.00104191    valid's RMSPE: 0.700278\n[209]   train's rmse: 0.000628157   train's RMSPE: 0.437938 valid's rmse: 0.00103745    valid's RMSPE: 0.697279\n[210]   train's rmse: 0.000622278   train's RMSPE: 0.43384  valid's rmse: 0.0010533 valid's RMSPE: 0.707933\n[211]   train's rmse: 0.000618066   train's RMSPE: 0.430903 valid's rmse: 0.00105367    valid's RMSPE: 0.708181\n[212]   train's rmse: 0.000614365   train's RMSPE: 0.428323 valid's rmse: 0.0010518 valid's RMSPE: 0.706925\n[213]   train's rmse: 0.000609559   train's RMSPE: 0.424972 valid's rmse: 0.00106803    valid's RMSPE: 0.717829\n[214]   train's rmse: 0.000613552   train's RMSPE: 0.427756 valid's rmse: 0.0010636 valid's RMSPE: 0.714854\n[215]   train's rmse: 0.000609097   train's RMSPE: 0.42465  valid's rmse: 0.0010697 valid's RMSPE: 0.718955\n[216]   train's rmse: 0.000603861   train's RMSPE: 0.420999 valid's rmse: 0.00106627    valid's RMSPE: 0.716646\n[217]   train's rmse: 0.000605779   train's RMSPE: 0.422337 valid's rmse: 0.00106315    valid's RMSPE: 0.714553\n[218]   train's rmse: 0.000607881   train's RMSPE: 0.423802 valid's rmse: 0.00106033    valid's RMSPE: 0.712659\n[219]   train's rmse: 0.000602891   train's RMSPE: 0.420324 valid's rmse: 0.00106527    valid's RMSPE: 0.715977\n[220]   train's rmse: 0.000605119   train's RMSPE: 0.421877 valid's rmse: 0.00106251    valid's RMSPE: 0.71412\n[221]   train's rmse: 0.000607437   train's RMSPE: 0.423493 valid's rmse: 0.00106075    valid's RMSPE: 0.712939\n[222]   train's rmse: 0.000604184   train's RMSPE: 0.421225 valid's rmse: 0.00106219    valid's RMSPE: 0.713904\n[223]   train's rmse: 0.000599298   train's RMSPE: 0.417818 valid's rmse: 0.00106315    valid's RMSPE: 0.714553\n[224]   train's rmse: 0.00059553    train's RMSPE: 0.415192 valid's rmse: 0.00106094    valid's RMSPE: 0.713066\n[225]   train's rmse: 0.000592319   train's RMSPE: 0.412953 valid's rmse: 0.0010714 valid's RMSPE: 0.720099\n[226]   train's rmse: 0.000589447   train's RMSPE: 0.410951 valid's rmse: 0.00107183    valid's RMSPE: 0.720386\n[227]   train's rmse: 0.000591648   train's RMSPE: 0.412485 valid's rmse: 0.0010673 valid's RMSPE: 0.71734\n[228]   train's rmse: 0.000588365   train's RMSPE: 0.410196 valid's rmse: 0.00107095    valid's RMSPE: 0.719793\n[229]   train's rmse: 0.00058537    train's RMSPE: 0.408108 valid's rmse: 0.00108403    valid's RMSPE: 0.728588\n[230]   train's rmse: 0.0005826 train's RMSPE: 0.406177 valid's rmse: 0.00108319    valid's RMSPE: 0.728023\n[231]   train's rmse: 0.000584607   train's RMSPE: 0.407576 valid's rmse: 0.00108043    valid's RMSPE: 0.726168\n[232]   train's rmse: 0.000582358   train's RMSPE: 0.406008 valid's rmse: 0.0010893 valid's RMSPE: 0.732129\n[233]   train's rmse: 0.000580045   train's RMSPE: 0.404396 valid's rmse: 0.00110076    valid's RMSPE: 0.739831\n[234]   train's rmse: 0.000581596   train's RMSPE: 0.405477 valid's rmse: 0.00109647    valid's RMSPE: 0.736943\n[235]   train's rmse: 0.000583524   train's RMSPE: 0.406821 valid's rmse: 0.00109331    valid's RMSPE: 0.73482\n[236]   train's rmse: 0.000585251   train's RMSPE: 0.408025 valid's rmse: 0.00109063    valid's RMSPE: 0.733023\n[237]   train's rmse: 0.00058691    train's RMSPE: 0.409182 valid's rmse: 0.00108824    valid's RMSPE: 0.731418\n[238]   train's rmse: 0.000588528   train's RMSPE: 0.41031  valid's rmse: 0.00108516    valid's RMSPE: 0.729348\n[239]   train's rmse: 0.000590503   train's RMSPE: 0.411687 valid's rmse: 0.00108285    valid's RMSPE: 0.727789\n[240]   train's rmse: 0.000587338   train's RMSPE: 0.40948  valid's rmse: 0.00108976    valid's RMSPE: 0.732437\n[241]   train's rmse: 0.000589398   train's RMSPE: 0.410916 valid's rmse: 0.00108643    valid's RMSPE: 0.730199\n[242]   train's rmse: 0.00059122    train's RMSPE: 0.412186 valid's rmse: 0.00108241    valid's RMSPE: 0.727496\n[243]   train's rmse: 0.000593371   train's RMSPE: 0.413686 valid's rmse: 0.00107812    valid's RMSPE: 0.724613\n[244]   train's rmse: 0.000589433   train's RMSPE: 0.410941 valid's rmse: 0.00108354    valid's RMSPE: 0.728259\n[245]   train's rmse: 0.000586836   train's RMSPE: 0.40913  valid's rmse: 0.00108206    valid's RMSPE: 0.727263\n[246]   train's rmse: 0.000584111   train's RMSPE: 0.40723  valid's rmse: 0.00109086    valid's RMSPE: 0.733179\n[247]   train's rmse: 0.000581645   train's RMSPE: 0.405511 valid's rmse: 0.00109561    valid's RMSPE: 0.736371\n[248]   train's rmse: 0.000583192   train's RMSPE: 0.406589 valid's rmse: 0.00109267    valid's RMSPE: 0.734394\n[249]   train's rmse: 0.000581234   train's RMSPE: 0.405225 valid's rmse: 0.00109734    valid's RMSPE: 0.737528\n[250]   train's rmse: 0.000583016   train's RMSPE: 0.406467 valid's rmse: 0.00109404    valid's RMSPE: 0.735312\n[251]   train's rmse: 0.000579082   train's RMSPE: 0.403724 valid's rmse: 0.00109328    valid's RMSPE: 0.734802\n[252]   train's rmse: 0.00057741    train's RMSPE: 0.402559 valid's rmse: 0.00110237    valid's RMSPE: 0.74091\n[253]   train's rmse: 0.000579262   train's RMSPE: 0.40385  valid's rmse: 0.00109959    valid's RMSPE: 0.739046\n[254]   train's rmse: 0.00057666    train's RMSPE: 0.402036 valid's rmse: 0.00110756    valid's RMSPE: 0.744398\n[255]   train's rmse: 0.000578291   train's RMSPE: 0.403173 valid's rmse: 0.00110299    valid's RMSPE: 0.74133\n[256]   train's rmse: 0.00057995    train's RMSPE: 0.404329 valid's rmse: 0.00109922    valid's RMSPE: 0.738796\n[257]   train's rmse: 0.000577541   train's RMSPE: 0.40265  valid's rmse: 0.00110048    valid's RMSPE: 0.739642\n[258]   train's rmse: 0.000579399   train's RMSPE: 0.403945 valid's rmse: 0.00109796    valid's RMSPE: 0.737945\n[259]   train's rmse: 0.000581038   train's RMSPE: 0.405088 valid's rmse: 0.00109315    valid's RMSPE: 0.734716\n[260]   train's rmse: 0.000578379   train's RMSPE: 0.403234 valid's rmse: 0.00109328    valid's RMSPE: 0.734803\n[261]   train's rmse: 0.000579872   train's RMSPE: 0.404275 valid's rmse: 0.00109072    valid's RMSPE: 0.73308\n[262]   train's rmse: 0.000581217   train's RMSPE: 0.405213 valid's rmse: 0.00108841    valid's RMSPE: 0.731526\n[263]   train's rmse: 0.000582913   train's RMSPE: 0.406395 valid's rmse: 0.00108507    valid's RMSPE: 0.729283\n[264]   train's rmse: 0.000585325   train's RMSPE: 0.408076 valid's rmse: 0.00107915    valid's RMSPE: 0.725307\n[265]   train's rmse: 0.000581822   train's RMSPE: 0.405635 valid's rmse: 0.00108239    valid's RMSPE: 0.727486\n[266]   train's rmse: 0.000583633   train's RMSPE: 0.406897 valid's rmse: 0.00107947    valid's RMSPE: 0.725522\n[267]   train's rmse: 0.00057982    train's RMSPE: 0.404239 valid's rmse: 0.00109106    valid's RMSPE: 0.733311\n[268]   train's rmse: 0.000576833   train's RMSPE: 0.402156 valid's rmse: 0.00109537    valid's RMSPE: 0.736208\n[269]   train's rmse: 0.00057382    train's RMSPE: 0.400056 valid's rmse: 0.00109326    valid's RMSPE: 0.734786\n[270]   train's rmse: 0.000571639   train's RMSPE: 0.398535 valid's rmse: 0.00109484    valid's RMSPE: 0.735848\n[271]   train's rmse: 0.000573222   train's RMSPE: 0.399639 valid's rmse: 0.00109235    valid's RMSPE: 0.734176\n[272]   train's rmse: 0.000574725   train's RMSPE: 0.400687 valid's rmse: 0.00109009    valid's RMSPE: 0.732658\n[273]   train's rmse: 0.000576489   train's RMSPE: 0.401916 valid's rmse: 0.00108778    valid's RMSPE: 0.731104\n[274]   train's rmse: 0.000573697   train's RMSPE: 0.39997  valid's rmse: 0.00109571    valid's RMSPE: 0.736438\n[275]   train's rmse: 0.000571089   train's RMSPE: 0.398152 valid's rmse: 0.00109303    valid's RMSPE: 0.734633\n[276]   train's rmse: 0.000572765   train's RMSPE: 0.39932  valid's rmse: 0.00108929    valid's RMSPE: 0.732122\n[277]   train's rmse: 0.000570589   train's RMSPE: 0.397803 valid's rmse: 0.00109448    valid's RMSPE: 0.735609\n[278]   train's rmse: 0.000568998   train's RMSPE: 0.396694 valid's rmse: 0.0011039 valid's RMSPE: 0.741943\n[279]   train's rmse: 0.000570622   train's RMSPE: 0.397826 valid's rmse: 0.0011002 valid's RMSPE: 0.739455\n[280]   train's rmse: 0.000567643   train's RMSPE: 0.395749 valid's rmse: 0.00109904    valid's RMSPE: 0.738676\n[281]   train's rmse: 0.000569226   train's RMSPE: 0.396853 valid's rmse: 0.00109509    valid's RMSPE: 0.736019\n[282]   train's rmse: 0.000570855   train's RMSPE: 0.397989 valid's rmse: 0.00109221    valid's RMSPE: 0.734086\n[283]   train's rmse: 0.000568937   train's RMSPE: 0.396651 valid's rmse: 0.00109642    valid's RMSPE: 0.736911\n[284]   train's rmse: 0.000570375   train's RMSPE: 0.397654 valid's rmse: 0.00109407    valid's RMSPE: 0.735335\n[285]   train's rmse: 0.000568473   train's RMSPE: 0.396328 valid's rmse: 0.00109564    valid's RMSPE: 0.736386\n[286]   train's rmse: 0.000569944   train's RMSPE: 0.397353 valid's rmse: 0.00109297    valid's RMSPE: 0.734593\n[287]   train's rmse: 0.000567783   train's RMSPE: 0.395847 valid's rmse: 0.00109078    valid's RMSPE: 0.733124\n[288]   train's rmse: 0.000569215   train's RMSPE: 0.396845 valid's rmse: 0.00108719    valid's RMSPE: 0.730706\n[289]   train's rmse: 0.000570507   train's RMSPE: 0.397746 valid's rmse: 0.00108445    valid's RMSPE: 0.728868\n[290]   train's rmse: 0.000567977   train's RMSPE: 0.395982 valid's rmse: 0.00108295    valid's RMSPE: 0.727861\n[291]   train's rmse: 0.000565901   train's RMSPE: 0.394535 valid's rmse: 0.00108222    valid's RMSPE: 0.727369\n[292]   train's rmse: 0.000567517   train's RMSPE: 0.395661 valid's rmse: 0.00108017    valid's RMSPE: 0.725991\n[293]   train's rmse: 0.000565486   train's RMSPE: 0.394245 valid's rmse: 0.00107897    valid's RMSPE: 0.725186\n[294]   train's rmse: 0.000566958   train's RMSPE: 0.395272 valid's rmse: 0.00107698    valid's RMSPE: 0.723849\n[295]   train's rmse: 0.000568393   train's RMSPE: 0.396272 valid's rmse: 0.00107484    valid's RMSPE: 0.722411\n[296]   train's rmse: 0.000569807   train's RMSPE: 0.397258 valid's rmse: 0.00107218    valid's RMSPE: 0.72062\n[297]   train's rmse: 0.000566822   train's RMSPE: 0.395176 valid's rmse: 0.0010827 valid's RMSPE: 0.727694\n[298]   train's rmse: 0.000568301   train's RMSPE: 0.396208 valid's rmse: 0.00108004    valid's RMSPE: 0.725903\n[299]   train's rmse: 0.00056576    train's RMSPE: 0.394437 valid's rmse: 0.00108066    valid's RMSPE: 0.726318\n[300]   train's rmse: 0.000564221   train's RMSPE: 0.393363 valid's rmse: 0.00107969    valid's RMSPE: 0.725672\n[301]   train's rmse: 0.000562216   train's RMSPE: 0.391966 valid's rmse: 0.00108432    valid's RMSPE: 0.728779\n[302]   train's rmse: 0.000560683   train's RMSPE: 0.390897 valid's rmse: 0.0010893 valid's RMSPE: 0.732128\n[303]   train's rmse: 0.000561997   train's RMSPE: 0.391813 valid's rmse: 0.00108652    valid's RMSPE: 0.730257\n[304]   train's rmse: 0.000559659   train's RMSPE: 0.390183 valid's rmse: 0.00108835    valid's RMSPE: 0.731487\n[305]   train's rmse: 0.000556903   train's RMSPE: 0.388262 valid's rmse: 0.00108615    valid's RMSPE: 0.730011\n[306]   train's rmse: 0.000558336   train's RMSPE: 0.38926  valid's rmse: 0.00108339    valid's RMSPE: 0.728158\n[307]   train's rmse: 0.000556453   train's RMSPE: 0.387948 valid's rmse: 0.00108308    valid's RMSPE: 0.72795\n[308]   train's rmse: 0.000557549   train's RMSPE: 0.388712 valid's rmse: 0.00108129    valid's RMSPE: 0.726742\n[309]   train's rmse: 0.000555908   train's RMSPE: 0.387568 valid's rmse: 0.00107784    valid's RMSPE: 0.724427\n[310]   train's rmse: 0.000554408   train's RMSPE: 0.386522 valid's rmse: 0.00107601    valid's RMSPE: 0.723196\n[311]   train's rmse: 0.000552594   train's RMSPE: 0.385257 valid's rmse: 0.00108337    valid's RMSPE: 0.728145\n[312]   train's rmse: 0.000553842   train's RMSPE: 0.386128 valid's rmse: 0.00108129    valid's RMSPE: 0.726747\n[313]   train's rmse: 0.000555042   train's RMSPE: 0.386964 valid's rmse: 0.00107883    valid's RMSPE: 0.725094\n[314]   train's rmse: 0.000553538   train's RMSPE: 0.385915 valid's rmse: 0.00108215    valid's RMSPE: 0.72732\n[315]   train's rmse: 0.000552199   train's RMSPE: 0.384982 valid's rmse: 0.00108342    valid's RMSPE: 0.728174\n[316]   train's rmse: 0.000550855   train's RMSPE: 0.384045 valid's rmse: 0.00108448    valid's RMSPE: 0.728889\n[317]   train's rmse: 0.00055186    train's RMSPE: 0.384745 valid's rmse: 0.00108269    valid's RMSPE: 0.727685\n[318]   train's rmse: 0.000550019   train's RMSPE: 0.383462 valid's rmse: 0.00108434    valid's RMSPE: 0.728793\n[319]   train's rmse: 0.000551174   train's RMSPE: 0.384267 valid's rmse: 0.00108193    valid's RMSPE: 0.727176\n[320]   train's rmse: 0.000552239   train's RMSPE: 0.38501  valid's rmse: 0.00107995    valid's RMSPE: 0.725845\n[321]   train's rmse: 0.000553511   train's RMSPE: 0.385896 valid's rmse: 0.00107611    valid's RMSPE: 0.723262\n[322]   train's rmse: 0.000554671   train's RMSPE: 0.386705 valid's rmse: 0.00107471    valid's RMSPE: 0.722324\n[323]   train's rmse: 0.000555816   train's RMSPE: 0.387504 valid's rmse: 0.00107199    valid's RMSPE: 0.720492\n[324]   train's rmse: 0.000557152   train's RMSPE: 0.388435 valid's rmse: 0.00106931    valid's RMSPE: 0.718691\n[325]   train's rmse: 0.000555377   train's RMSPE: 0.387197 valid's rmse: 0.00107043    valid's RMSPE: 0.719446\n[326]   train's rmse: 0.000553188   train's RMSPE: 0.385672 valid's rmse: 0.0010705 valid's RMSPE: 0.719493\n[327]   train's rmse: 0.000554279   train's RMSPE: 0.386432 valid's rmse: 0.00106887    valid's RMSPE: 0.718397\n[328]   train's rmse: 0.000552416   train's RMSPE: 0.385134 valid's rmse: 0.00106738    valid's RMSPE: 0.717392\n[329]   train's rmse: 0.000553585   train's RMSPE: 0.385948 valid's rmse: 0.00106487    valid's RMSPE: 0.715709\n[330]   train's rmse: 0.000554646   train's RMSPE: 0.386688 valid's rmse: 0.00106247    valid's RMSPE: 0.714097\n[331]   train's rmse: 0.000555689   train's RMSPE: 0.387415 valid's rmse: 0.00105985    valid's RMSPE: 0.712335\n[332]   train's rmse: 0.000554689   train's RMSPE: 0.386718 valid's rmse: 0.00106873    valid's RMSPE: 0.718305\n[333]   train's rmse: 0.000555785   train's RMSPE: 0.387482 valid's rmse: 0.00106644    valid's RMSPE: 0.716761\n[334]   train's rmse: 0.0005573 train's RMSPE: 0.388538 valid's rmse: 0.00106146    valid's RMSPE: 0.713417\n[335]   train's rmse: 0.000555829   train's RMSPE: 0.387513 valid's rmse: 0.00106532    valid's RMSPE: 0.716013\n[336]   train's rmse: 0.000557183   train's RMSPE: 0.388457 valid's rmse: 0.00106322    valid's RMSPE: 0.714599\n[337]   train's rmse: 0.000558317   train's RMSPE: 0.389247 valid's rmse: 0.00106135    valid's RMSPE: 0.713342\n[338]   train's rmse: 0.000556614   train's RMSPE: 0.38806  valid's rmse: 0.00105964    valid's RMSPE: 0.712195\n[339]   train's rmse: 0.000557858   train's RMSPE: 0.388928 valid's rmse: 0.00105772    valid's RMSPE: 0.710899\n[340]   train's rmse: 0.000555452   train's RMSPE: 0.38725  valid's rmse: 0.00106152    valid's RMSPE: 0.713458\n[341]   train's rmse: 0.000556661   train's RMSPE: 0.388093 valid's rmse: 0.00105943    valid's RMSPE: 0.712052\n[342]   train's rmse: 0.000554457   train's RMSPE: 0.386556 valid's rmse: 0.00106296    valid's RMSPE: 0.714424\n[343]   train's rmse: 0.000555586   train's RMSPE: 0.387343 valid's rmse: 0.00106016    valid's RMSPE: 0.712545\n[344]   train's rmse: 0.000553657   train's RMSPE: 0.385998 valid's rmse: 0.0010595 valid's RMSPE: 0.712102\n[345]   train's rmse: 0.000551372   train's RMSPE: 0.384405 valid's rmse: 0.00106599    valid's RMSPE: 0.716459\n[346]   train's rmse: 0.00055259    train's RMSPE: 0.385255 valid's rmse: 0.00106323    valid's RMSPE: 0.714603\n[347]   train's rmse: 0.000550797   train's RMSPE: 0.384005 valid's rmse: 0.00106497    valid's RMSPE: 0.715775\n[348]   train's rmse: 0.000549095   train's RMSPE: 0.382818 valid's rmse: 0.00106811    valid's RMSPE: 0.717884\n[349]   train's rmse: 0.000550183   train's RMSPE: 0.383577 valid's rmse: 0.00106627    valid's RMSPE: 0.716646\n[350]   train's rmse: 0.000551261   train's RMSPE: 0.384328 valid's rmse: 0.00106422    valid's RMSPE: 0.715273\n[351]   train's rmse: 0.000552767   train's RMSPE: 0.385378 valid's rmse: 0.00106043    valid's RMSPE: 0.712727\n[352]   train's rmse: 0.000553922   train's RMSPE: 0.386183 valid's rmse: 0.00105809    valid's RMSPE: 0.711154\n[353]   train's rmse: 0.000555136   train's RMSPE: 0.38703  valid's rmse: 0.00105645    valid's RMSPE: 0.710052\n[354]   train's rmse: 0.000553487   train's RMSPE: 0.38588  valid's rmse: 0.00106461    valid's RMSPE: 0.715533\n[355]   train's rmse: 0.000554504   train's RMSPE: 0.386589 valid's rmse: 0.00106249    valid's RMSPE: 0.714107\n[356]   train's rmse: 0.000556091   train's RMSPE: 0.387696 valid's rmse: 0.00105878    valid's RMSPE: 0.711612\n[357]   train's rmse: 0.000557258   train's RMSPE: 0.388509 valid's rmse: 0.00105692    valid's RMSPE: 0.710362\n[358]   train's rmse: 0.000558413   train's RMSPE: 0.389314 valid's rmse: 0.00105535    valid's RMSPE: 0.709307\n[359]   train's rmse: 0.000559642   train's RMSPE: 0.390171 valid's rmse: 0.00105335    valid's RMSPE: 0.707967\n[360]   train's rmse: 0.000557449   train's RMSPE: 0.388642 valid's rmse: 0.0010647 valid's RMSPE: 0.715596\n[361]   train's rmse: 0.000558505   train's RMSPE: 0.389378 valid's rmse: 0.00106267    valid's RMSPE: 0.714228\n[362]   train's rmse: 0.00055592    train's RMSPE: 0.387576 valid's rmse: 0.00106401    valid's RMSPE: 0.715129\n[363]   train's rmse: 0.000557301   train's RMSPE: 0.388539 valid's rmse: 0.00106169    valid's RMSPE: 0.713573\n[364]   train's rmse: 0.0005558 train's RMSPE: 0.387493 valid's rmse: 0.00107059    valid's RMSPE: 0.719555\n[365]   train's rmse: 0.000557036   train's RMSPE: 0.388354 valid's rmse: 0.0010678 valid's RMSPE: 0.717676\n[366]   train's rmse: 0.000555722   train's RMSPE: 0.387438 valid's rmse: 0.00107702    valid's RMSPE: 0.723876\n[367]   train's rmse: 0.000557215   train's RMSPE: 0.388479 valid's rmse: 0.00107345    valid's RMSPE: 0.721476\n[368]   train's rmse: 0.000558463   train's RMSPE: 0.389349 valid's rmse: 0.00107116    valid's RMSPE: 0.719938\n[369]   train's rmse: 0.000555675   train's RMSPE: 0.387405 valid's rmse: 0.00107842    valid's RMSPE: 0.724812\n[370]   train's rmse: 0.000556752   train's RMSPE: 0.388156 valid's rmse: 0.0010768 valid's RMSPE: 0.723724\n[371]   train's rmse: 0.000554328   train's RMSPE: 0.386466 valid's rmse: 0.00108946    valid's RMSPE: 0.732236\n[372]   train's rmse: 0.000555273   train's RMSPE: 0.387125 valid's rmse: 0.00108737    valid's RMSPE: 0.73083\n[373]   train's rmse: 0.000553647   train's RMSPE: 0.385992 valid's rmse: 0.0010861 valid's RMSPE: 0.729977\n[374]   train's rmse: 0.000552912   train's RMSPE: 0.385479 valid's rmse: 0.00108587    valid's RMSPE: 0.729821\n[375]   train's rmse: 0.00055386    train's RMSPE: 0.38614  valid's rmse: 0.00108365    valid's RMSPE: 0.72833\n[376]   train's rmse: 0.000554869   train's RMSPE: 0.386843 valid's rmse: 0.00108197    valid's RMSPE: 0.727202\n[377]   train's rmse: 0.000553205   train's RMSPE: 0.385683 valid's rmse: 0.00108629    valid's RMSPE: 0.730106\n[378]   train's rmse: 0.000551518   train's RMSPE: 0.384507 valid's rmse: 0.00108725    valid's RMSPE: 0.730747\n[379]   train's rmse: 0.000549802   train's RMSPE: 0.383311 valid's rmse: 0.00108553    valid's RMSPE: 0.729591\n[380]   train's rmse: 0.000548529   train's RMSPE: 0.382423 valid's rmse: 0.00108359    valid's RMSPE: 0.728292\n[381]   train's rmse: 0.000549474   train's RMSPE: 0.383082 valid's rmse: 0.00108183    valid's RMSPE: 0.727105\n[382]   train's rmse: 0.000550361   train's RMSPE: 0.383701 valid's rmse: 0.00107993    valid's RMSPE: 0.725832\n[383]   train's rmse: 0.000551327   train's RMSPE: 0.384374 valid's rmse: 0.00107709    valid's RMSPE: 0.72392\n[384]   train's rmse: 0.000549487   train's RMSPE: 0.383091 valid's rmse: 0.00108215    valid's RMSPE: 0.72732\n[385]   train's rmse: 0.00054824    train's RMSPE: 0.382221 valid's rmse: 0.00108091    valid's RMSPE: 0.726491\n[386]   train's rmse: 0.000549217   train's RMSPE: 0.382903 valid's rmse: 0.00107883    valid's RMSPE: 0.725091\n[387]   train's rmse: 0.000550219   train's RMSPE: 0.383601 valid's rmse: 0.00107628    valid's RMSPE: 0.723379\n[388]   train's rmse: 0.000549052   train's RMSPE: 0.382788 valid's rmse: 0.00107573    valid's RMSPE: 0.723009\n[389]   train's rmse: 0.000547209   train's RMSPE: 0.381503 valid's rmse: 0.00107411    valid's RMSPE: 0.721919\n[390]   train's rmse: 0.000548082   train's RMSPE: 0.382112 valid's rmse: 0.00107208    valid's RMSPE: 0.720553\n[391]   train's rmse: 0.000548987   train's RMSPE: 0.382743 valid's rmse: 0.00107017    valid's RMSPE: 0.719268\n[392]   train's rmse: 0.000549911   train's RMSPE: 0.383387 valid's rmse: 0.00106793    valid's RMSPE: 0.717766\n[393]   train's rmse: 0.000550912   train's RMSPE: 0.384085 valid's rmse: 0.00106607    valid's RMSPE: 0.716514\n[394]   train's rmse: 0.000552078   train's RMSPE: 0.384898 valid's rmse: 0.0010621 valid's RMSPE: 0.713843\n[395]   train's rmse: 0.000553061   train's RMSPE: 0.385583 valid's rmse: 0.00106005    valid's RMSPE: 0.712465\n[396]   train's rmse: 0.000551376   train's RMSPE: 0.384408 valid's rmse: 0.00106562    valid's RMSPE: 0.71621\n[397]   train's rmse: 0.000552406   train's RMSPE: 0.385126 valid's rmse: 0.00106394    valid's RMSPE: 0.715085\n[398]   train's rmse: 0.000550951   train's RMSPE: 0.384112 valid's rmse: 0.00107612    valid's RMSPE: 0.723269\n[399]   train's rmse: 0.000552001   train's RMSPE: 0.384844 valid's rmse: 0.00107372    valid's RMSPE: 0.721659\n[400]   train's rmse: 0.000551157   train's RMSPE: 0.384256 valid's rmse: 0.00107222    valid's RMSPE: 0.720648\n[401]   train's rmse: 0.000552099   train's RMSPE: 0.384912 valid's rmse: 0.00107002    valid's RMSPE: 0.719167\n[402]   train's rmse: 0.000550423   train's RMSPE: 0.383744 valid's rmse: 0.00107286    valid's RMSPE: 0.721076\n[403]   train's rmse: 0.000548837   train's RMSPE: 0.382638 valid's rmse: 0.00107714    valid's RMSPE: 0.723957\n[404]   train's rmse: 0.000549832   train's RMSPE: 0.383331 valid's rmse: 0.00107502    valid's RMSPE: 0.722531\n[405]   train's rmse: 0.000547417   train's RMSPE: 0.381648 valid's rmse: 0.001077  valid's RMSPE: 0.723863\n[406]   train's rmse: 0.000548351   train's RMSPE: 0.382299 valid's rmse: 0.00107467    valid's RMSPE: 0.722294\n[407]   train's rmse: 0.000546485   train's RMSPE: 0.380998 valid's rmse: 0.0010806 valid's RMSPE: 0.726278\n[408]   train's rmse: 0.000544892   train's RMSPE: 0.379888 valid's rmse: 0.00108191    valid's RMSPE: 0.727158\n[409]   train's rmse: 0.000543525   train's RMSPE: 0.378935 valid's rmse: 0.00108092    valid's RMSPE: 0.726492\n[410]   train's rmse: 0.000544375   train's RMSPE: 0.379527 valid's rmse: 0.00107885    valid's RMSPE: 0.725104\n[411]   train's rmse: 0.00054533    train's RMSPE: 0.380193 valid's rmse: 0.00107665    valid's RMSPE: 0.723625\n[412]   train's rmse: 0.000546348   train's RMSPE: 0.380902 valid's rmse: 0.00107442    valid's RMSPE: 0.722128\n[413]   train's rmse: 0.00054734    train's RMSPE: 0.381594 valid's rmse: 0.00107223    valid's RMSPE: 0.720654\n[414]   train's rmse: 0.000548349   train's RMSPE: 0.382298 valid's rmse: 0.00107077    valid's RMSPE: 0.719673\n[415]   train's rmse: 0.000549346   train's RMSPE: 0.382993 valid's rmse: 0.00106896    valid's RMSPE: 0.718459\n[416]   train's rmse: 0.000547598   train's RMSPE: 0.381774 valid's rmse: 0.00106728    valid's RMSPE: 0.717327\n[417]   train's rmse: 0.000545695   train's RMSPE: 0.380448 valid's rmse: 0.00107505    valid's RMSPE: 0.72255\n[418]   train's rmse: 0.000544196   train's RMSPE: 0.379402 valid's rmse: 0.00107804    valid's RMSPE: 0.72456\n[419]   train's rmse: 0.000543094   train's RMSPE: 0.378634 valid's rmse: 0.00108059    valid's RMSPE: 0.726271\n[420]   train's rmse: 0.000544031   train's RMSPE: 0.379287 valid's rmse: 0.00107807    valid's RMSPE: 0.72458\n[421]   train's rmse: 0.000544877   train's RMSPE: 0.379877 valid's rmse: 0.00107569    valid's RMSPE: 0.722978\n[422]   train's rmse: 0.000543404   train's RMSPE: 0.378851 valid's rmse: 0.00107602    valid's RMSPE: 0.723204\nEarly stopping, best iteration is:\n[23]    0.6734802645700604\n22\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:183: UserWarning: Early stopping is not available in dart mode\n  _log_warning('Early stopping is not available in dart mode')\n\n\n[1] train's rmse: 0.00108958    train's RMSPE: 0.753235 valid's rmse: 0.00108864    valid's RMSPE: 0.757637\n[2] train's rmse: 0.00105938    train's RMSPE: 0.732359 valid's rmse: 0.00106573    valid's RMSPE: 0.741697\n[3] train's rmse: 0.00103442    train's RMSPE: 0.715102 valid's rmse: 0.00104278    valid's RMSPE: 0.725726\n[4] train's rmse: 0.00101025    train's RMSPE: 0.698392 valid's rmse: 0.00101601    valid's RMSPE: 0.707094\n[5] train's rmse: 0.000986894   train's RMSPE: 0.682247 valid's rmse: 0.000989767   valid's RMSPE: 0.688829\n[6] train's rmse: 0.000964  train's RMSPE: 0.66642  valid's rmse: 0.000968162   valid's RMSPE: 0.673793\n[7] train's rmse: 0.000965729   train's RMSPE: 0.667615 valid's rmse: 0.000968446   valid's RMSPE: 0.673991\n[8] train's rmse: 0.000940925   train's RMSPE: 0.650468 valid's rmse: 0.000945554   valid's RMSPE: 0.658059\n[9] train's rmse: 0.000923274   train's RMSPE: 0.638265 valid's rmse: 0.000926334   valid's RMSPE: 0.644683\n[10]    train's rmse: 0.000928943   train's RMSPE: 0.642185 valid's rmse: 0.000926594   valid's RMSPE: 0.644863\n[11]    train's rmse: 0.000911857   train's RMSPE: 0.630373 valid's rmse: 0.000906248   valid's RMSPE: 0.630703\n[12]    train's rmse: 0.000916341   train's RMSPE: 0.633473 valid's rmse: 0.000911764   valid's RMSPE: 0.634543\n[13]    train's rmse: 0.000897027   train's RMSPE: 0.620121 valid's rmse: 0.000892253   valid's RMSPE: 0.620964\n[14]    train's rmse: 0.000882249   train's RMSPE: 0.609905 valid's rmse: 0.000875527   valid's RMSPE: 0.609324\n[15]    train's rmse: 0.000866878   train's RMSPE: 0.599279 valid's rmse: 0.000856294   valid's RMSPE: 0.595939\n[16]    train's rmse: 0.000852079   train's RMSPE: 0.589048 valid's rmse: 0.000842471   valid's RMSPE: 0.586318\n[17]    train's rmse: 0.00085924    train's RMSPE: 0.593998 valid's rmse: 0.000848837   valid's RMSPE: 0.590748\n[18]    train's rmse: 0.000843948   train's RMSPE: 0.583427 valid's rmse: 0.000840981   valid's RMSPE: 0.585281\n[19]    train's rmse: 0.00084357    train's RMSPE: 0.583166 valid's rmse: 0.000841975   valid's RMSPE: 0.585973\n[20]    train's rmse: 0.000844653   train's RMSPE: 0.583914 valid's rmse: 0.000842677   valid's RMSPE: 0.586461\n[21]    train's rmse: 0.000851823   train's RMSPE: 0.588871 valid's rmse: 0.000851356   valid's RMSPE: 0.592502\n[22]    train's rmse: 0.000872534   train's RMSPE: 0.603189 valid's rmse: 0.000869431   valid's RMSPE: 0.605081\n[23]    train's rmse: 0.000857511   train's RMSPE: 0.592803 valid's rmse: 0.000852328   valid's RMSPE: 0.593178\n[24]    train's rmse: 0.000895401   train's RMSPE: 0.618997 valid's rmse: 0.00089056    valid's RMSPE: 0.619786\n[25]    train's rmse: 0.000891599   train's RMSPE: 0.616368 valid's rmse: 0.000887421   valid's RMSPE: 0.617601\n[26]    train's rmse: 0.000872693   train's RMSPE: 0.603298 valid's rmse: 0.000870078   valid's RMSPE: 0.605531\n[27]    train's rmse: 0.000856084   train's RMSPE: 0.591816 valid's rmse: 0.000864961   valid's RMSPE: 0.60197\n[28]    train's rmse: 0.000859491   train's RMSPE: 0.594172 valid's rmse: 0.000869047   valid's RMSPE: 0.604814\n[29]    train's rmse: 0.000865825   train's RMSPE: 0.598551 valid's rmse: 0.000874863   valid's RMSPE: 0.608862\n[30]    train's rmse: 0.000850513   train's RMSPE: 0.587965 valid's rmse: 0.000860668   valid's RMSPE: 0.598982\n[31]    train's rmse: 0.000836395   train's RMSPE: 0.578206 valid's rmse: 0.000846365   valid's RMSPE: 0.589028\n[32]    train's rmse: 0.000843109   train's RMSPE: 0.582847 valid's rmse: 0.000852873   valid's RMSPE: 0.593558\n[33]    train's rmse: 0.000828533   train's RMSPE: 0.572771 valid's rmse: 0.000836441   valid's RMSPE: 0.582121\n[34]    train's rmse: 0.000816172   train's RMSPE: 0.564225 valid's rmse: 0.00082253    valid's RMSPE: 0.57244\n[35]    train's rmse: 0.000802005   train's RMSPE: 0.554432 valid's rmse: 0.000810163   valid's RMSPE: 0.563833\n[36]    train's rmse: 0.000790223   train's RMSPE: 0.546286 valid's rmse: 0.000798158   valid's RMSPE: 0.555478\n[37]    train's rmse: 0.000794748   train's RMSPE: 0.549415 valid's rmse: 0.000801687   valid's RMSPE: 0.557934\n[38]    train's rmse: 0.000823221   train's RMSPE: 0.569098 valid's rmse: 0.000825743   valid's RMSPE: 0.574676\n[39]    train's rmse: 0.000807839   train's RMSPE: 0.558464 valid's rmse: 0.000811437   valid's RMSPE: 0.56472\n[40]    train's rmse: 0.000795507   train's RMSPE: 0.54994  valid's rmse: 0.000800359   valid's RMSPE: 0.55701\n[41]    train's rmse: 0.00080089    train's RMSPE: 0.553661 valid's rmse: 0.000806364   valid's RMSPE: 0.56119\n[42]    train's rmse: 0.000805765   train's RMSPE: 0.557031 valid's rmse: 0.000809748   valid's RMSPE: 0.563544\n[43]    train's rmse: 0.00079292    train's RMSPE: 0.548151 valid's rmse: 0.000796534   valid's RMSPE: 0.554348\n[44]    train's rmse: 0.000782697   train's RMSPE: 0.541084 valid's rmse: 0.000786632   valid's RMSPE: 0.547457\n[45]    train's rmse: 0.000772973   train's RMSPE: 0.534362 valid's rmse: 0.000774994   valid's RMSPE: 0.539357\n[46]    train's rmse: 0.000778438   train's RMSPE: 0.538139 valid's rmse: 0.000779103   valid's RMSPE: 0.542217\n[47]    train's rmse: 0.000766186   train's RMSPE: 0.52967  valid's rmse: 0.000767542   valid's RMSPE: 0.534171\n[48]    train's rmse: 0.000771825   train's RMSPE: 0.533568 valid's rmse: 0.000773719   valid's RMSPE: 0.53847\n[49]    train's rmse: 0.000776631   train's RMSPE: 0.53689  valid's rmse: 0.000778611   valid's RMSPE: 0.541875\n[50]    train's rmse: 0.000763693   train's RMSPE: 0.527946 valid's rmse: 0.000767256   valid's RMSPE: 0.533972\n[51]    train's rmse: 0.000768032   train's RMSPE: 0.530946 valid's rmse: 0.000771542   valid's RMSPE: 0.536955\n[52]    train's rmse: 0.000769344   train's RMSPE: 0.531853 valid's rmse: 0.000773386   valid's RMSPE: 0.538238\n[53]    train's rmse: 0.000773681   train's RMSPE: 0.534851 valid's rmse: 0.000777841   valid's RMSPE: 0.541338\n[54]    train's rmse: 0.00076215    train's RMSPE: 0.52688  valid's rmse: 0.000768832   valid's RMSPE: 0.535069\n[55]    train's rmse: 0.000765256   train's RMSPE: 0.529027 valid's rmse: 0.00077214    valid's RMSPE: 0.537371\n[56]    train's rmse: 0.00075375    train's RMSPE: 0.521073 valid's rmse: 0.00075903    valid's RMSPE: 0.528248\n[57]    train's rmse: 0.000743976   train's RMSPE: 0.514316 valid's rmse: 0.000749724   valid's RMSPE: 0.521771\n[58]    train's rmse: 0.00073708    train's RMSPE: 0.509548 valid's rmse: 0.000742453   valid's RMSPE: 0.51671\n[59]    train's rmse: 0.000741374   train's RMSPE: 0.512517 valid's rmse: 0.000746435   valid's RMSPE: 0.519482\n[60]    train's rmse: 0.000731747   train's RMSPE: 0.505861 valid's rmse: 0.000738117   valid's RMSPE: 0.513693\n[61]    train's rmse: 0.00073827    train's RMSPE: 0.510371 valid's rmse: 0.00074407    valid's RMSPE: 0.517836\n[62]    train's rmse: 0.000729183   train's RMSPE: 0.504089 valid's rmse: 0.000736357   valid's RMSPE: 0.512468\n[63]    train's rmse: 0.00074625    train's RMSPE: 0.515888 valid's rmse: 0.000751042   valid's RMSPE: 0.522688\n[64]    train's rmse: 0.000764079   train's RMSPE: 0.528213 valid's rmse: 0.000766404   valid's RMSPE: 0.533379\n[65]    train's rmse: 0.000770238   train's RMSPE: 0.532471 valid's rmse: 0.00077204    valid's RMSPE: 0.537302\n[66]    train's rmse: 0.000757765   train's RMSPE: 0.523848 valid's rmse: 0.000760735   valid's RMSPE: 0.529434\n[67]    train's rmse: 0.000760518   train's RMSPE: 0.525751 valid's rmse: 0.000763033   valid's RMSPE: 0.531033\n[68]    train's rmse: 0.000748778   train's RMSPE: 0.517636 valid's rmse: 0.000753193   valid's RMSPE: 0.524185\n[69]    train's rmse: 0.00073755    train's RMSPE: 0.509873 valid's rmse: 0.00074219    valid's RMSPE: 0.516527\n[70]    train's rmse: 0.00074235    train's RMSPE: 0.513191 valid's rmse: 0.000747107   valid's RMSPE: 0.51995\n[71]    train's rmse: 0.000745621   train's RMSPE: 0.515453 valid's rmse: 0.000750767   valid's RMSPE: 0.522497\n[72]    train's rmse: 0.00073683    train's RMSPE: 0.509375 valid's rmse: 0.000739812   valid's RMSPE: 0.514872\n[73]    train's rmse: 0.000728902   train's RMSPE: 0.503895 valid's rmse: 0.000730054   valid's RMSPE: 0.508081\n[74]    train's rmse: 0.000733933   train's RMSPE: 0.507373 valid's rmse: 0.000734656   valid's RMSPE: 0.511284\n[75]    train's rmse: 0.000726476   train's RMSPE: 0.502218 valid's rmse: 0.000726438   valid's RMSPE: 0.505565\n[76]    train's rmse: 0.000731154   train's RMSPE: 0.505452 valid's rmse: 0.000730406   valid's RMSPE: 0.508326\n[77]    train's rmse: 0.000721575   train's RMSPE: 0.49883  valid's rmse: 0.000722419   valid's RMSPE: 0.502768\n[78]    train's rmse: 0.000723535   train's RMSPE: 0.500185 valid's rmse: 0.000724602   valid's RMSPE: 0.504287\n[79]    train's rmse: 0.000727263   train's RMSPE: 0.502762 valid's rmse: 0.000729011   valid's RMSPE: 0.507355\n[80]    train's rmse: 0.000730039   train's RMSPE: 0.504681 valid's rmse: 0.00073186    valid's RMSPE: 0.509338\n[81]    train's rmse: 0.000721826   train's RMSPE: 0.499003 valid's rmse: 0.000725656   valid's RMSPE: 0.505021\n[82]    train's rmse: 0.00071162    train's RMSPE: 0.491948 valid's rmse: 0.000716148   valid's RMSPE: 0.498404\n[83]    train's rmse: 0.00071584    train's RMSPE: 0.494865 valid's rmse: 0.000720053   valid's RMSPE: 0.501121\n[84]    train's rmse: 0.000707454   train's RMSPE: 0.489068 valid's rmse: 0.000713553   valid's RMSPE: 0.496597\n[85]    train's rmse: 0.000710925   train's RMSPE: 0.491467 valid's rmse: 0.000716928   valid's RMSPE: 0.498947\n[86]    train's rmse: 0.000714929   train's RMSPE: 0.494235 valid's rmse: 0.000720456   valid's RMSPE: 0.501402\n[87]    train's rmse: 0.000706525   train's RMSPE: 0.488426 valid's rmse: 0.000714197   valid's RMSPE: 0.497045\n[88]    train's rmse: 0.000709941   train's RMSPE: 0.490787 valid's rmse: 0.000718106   valid's RMSPE: 0.499766\n[89]    train's rmse: 0.0007136 train's RMSPE: 0.493317 valid's rmse: 0.000721592   valid's RMSPE: 0.502192\n[90]    train's rmse: 0.000718239   train's RMSPE: 0.496523 valid's rmse: 0.000725707   valid's RMSPE: 0.505056\n[91]    train's rmse: 0.000722675   train's RMSPE: 0.49959  valid's rmse: 0.000729707   valid's RMSPE: 0.50784\n[92]    train's rmse: 0.000713674   train's RMSPE: 0.493368 valid's rmse: 0.000721118   valid's RMSPE: 0.501862\n[93]    train's rmse: 0.000705784   train's RMSPE: 0.487914 valid's rmse: 0.000712684   valid's RMSPE: 0.495993\n[94]    train's rmse: 0.000700295   train's RMSPE: 0.484119 valid's rmse: 0.000706617   valid's RMSPE: 0.49177\n[95]    train's rmse: 0.000693238   train's RMSPE: 0.47924  valid's rmse: 0.000701015   valid's RMSPE: 0.487872\n[96]    train's rmse: 0.000688357   train's RMSPE: 0.475866 valid's rmse: 0.000695079   valid's RMSPE: 0.48374\n[97]    train's rmse: 0.000681946   train's RMSPE: 0.471434 valid's rmse: 0.00069043    valid's RMSPE: 0.480505\n[98]    train's rmse: 0.000685303   train's RMSPE: 0.473755 valid's rmse: 0.000693828   valid's RMSPE: 0.48287\n[99]    train's rmse: 0.000687716   train's RMSPE: 0.475423 valid's rmse: 0.000696203   valid's RMSPE: 0.484522\n[100]   train's rmse: 0.000691006   train's RMSPE: 0.477697 valid's rmse: 0.000699261   valid's RMSPE: 0.486651\n[101]   train's rmse: 0.000686192   train's RMSPE: 0.474369 valid's rmse: 0.000694525   valid's RMSPE: 0.483355\n[102]   train's rmse: 0.000679403   train's RMSPE: 0.469676 valid's rmse: 0.000689104   valid's RMSPE: 0.479582\n[103]   train's rmse: 0.000682243   train's RMSPE: 0.471639 valid's rmse: 0.000691709   valid's RMSPE: 0.481396\n[104]   train's rmse: 0.000684616   train's RMSPE: 0.47328  valid's rmse: 0.000694279   valid's RMSPE: 0.483184\n[105]   train's rmse: 0.000687486   train's RMSPE: 0.475264 valid's rmse: 0.000696804   valid's RMSPE: 0.484941\n[106]   train's rmse: 0.000697765   train's RMSPE: 0.48237  valid's rmse: 0.000705562   valid's RMSPE: 0.491036\n[107]   train's rmse: 0.000701165   train's RMSPE: 0.48472  valid's rmse: 0.000708901   valid's RMSPE: 0.49336\n[108]   train's rmse: 0.000705241   train's RMSPE: 0.487538 valid's rmse: 0.000712694   valid's RMSPE: 0.496\n[109]   train's rmse: 0.000708813   train's RMSPE: 0.490007 valid's rmse: 0.000715991   valid's RMSPE: 0.498295\n[110]   train's rmse: 0.000702647   train's RMSPE: 0.485744 valid's rmse: 0.000709498   valid's RMSPE: 0.493775\n[111]   train's rmse: 0.000706559   train's RMSPE: 0.488449 valid's rmse: 0.000712774   valid's RMSPE: 0.496055\n[112]   train's rmse: 0.000710583   train's RMSPE: 0.491231 valid's rmse: 0.000716503   valid's RMSPE: 0.498651\n[113]   train's rmse: 0.000702921   train's RMSPE: 0.485934 valid's rmse: 0.000709286   valid's RMSPE: 0.493628\n[114]   train's rmse: 0.000707105   train's RMSPE: 0.488826 valid's rmse: 0.000713084   valid's RMSPE: 0.496271\n[115]   train's rmse: 0.000710307   train's RMSPE: 0.49104  valid's rmse: 0.000716169   valid's RMSPE: 0.498418\n[116]   train's rmse: 0.000700794   train's RMSPE: 0.484463 valid's rmse: 0.000708181   valid's RMSPE: 0.492859\n[117]   train's rmse: 0.000702848   train's RMSPE: 0.485883 valid's rmse: 0.000710484   valid's RMSPE: 0.494461\n[118]   train's rmse: 0.000705969   train's RMSPE: 0.488041 valid's rmse: 0.000713317   valid's RMSPE: 0.496433\n[119]   train's rmse: 0.000708712   train's RMSPE: 0.489937 valid's rmse: 0.000715466   valid's RMSPE: 0.497929\n[120]   train's rmse: 0.000702201   train's RMSPE: 0.485436 valid's rmse: 0.000707084   valid's RMSPE: 0.492096\n[121]   train's rmse: 0.000704905   train's RMSPE: 0.487306 valid's rmse: 0.000709468   valid's RMSPE: 0.493754\n[122]   train's rmse: 0.000708936   train's RMSPE: 0.490092 valid's rmse: 0.00071298    valid's RMSPE: 0.496199\n[123]   train's rmse: 0.000717141   train's RMSPE: 0.495764 valid's rmse: 0.000720661   valid's RMSPE: 0.501544\n[124]   train's rmse: 0.000719359   train's RMSPE: 0.497298 valid's rmse: 0.000722777   valid's RMSPE: 0.503017\n[125]   train's rmse: 0.000710711   train's RMSPE: 0.491319 valid's rmse: 0.000715506   valid's RMSPE: 0.497957\n[126]   train's rmse: 0.000713409   train's RMSPE: 0.493185 valid's rmse: 0.000718492   valid's RMSPE: 0.500035\n[127]   train's rmse: 0.000715766   train's RMSPE: 0.494814 valid's rmse: 0.000720683   valid's RMSPE: 0.501559\n[128]   train's rmse: 0.00070685    train's RMSPE: 0.48865  valid's rmse: 0.000712773   valid's RMSPE: 0.496055\n[129]   train's rmse: 0.000697845   train's RMSPE: 0.482425 valid's rmse: 0.000706072   valid's RMSPE: 0.491391\n[130]   train's rmse: 0.000705207   train's RMSPE: 0.487514 valid's rmse: 0.000712555   valid's RMSPE: 0.495903\n[131]   train's rmse: 0.00069761    train's RMSPE: 0.482262 valid's rmse: 0.000703846   valid's RMSPE: 0.489842\n[132]   train's rmse: 0.00070086    train's RMSPE: 0.48451  valid's rmse: 0.000706637   valid's RMSPE: 0.491784\n[133]   train's rmse: 0.000694222   train's RMSPE: 0.47992  valid's rmse: 0.000698689   valid's RMSPE: 0.486253\n[134]   train's rmse: 0.000697412   train's RMSPE: 0.482126 valid's rmse: 0.000701842   valid's RMSPE: 0.488447\n[135]   train's rmse: 0.000690575   train's RMSPE: 0.477399 valid's rmse: 0.000694903   valid's RMSPE: 0.483618\n[136]   train's rmse: 0.000693297   train's RMSPE: 0.479281 valid's rmse: 0.000697578   valid's RMSPE: 0.485479\n[137]   train's rmse: 0.000696357   train's RMSPE: 0.481396 valid's rmse: 0.000700706   valid's RMSPE: 0.487656\n[138]   train's rmse: 0.000699749   train's RMSPE: 0.483741 valid's rmse: 0.000703926   valid's RMSPE: 0.489898\n[139]   train's rmse: 0.000702308   train's RMSPE: 0.48551  valid's rmse: 0.000706164   valid's RMSPE: 0.491455\n[140]   train's rmse: 0.000696884   train's RMSPE: 0.48176  valid's rmse: 0.000698107   valid's RMSPE: 0.485848\n[141]   train's rmse: 0.00068867    train's RMSPE: 0.476082 valid's rmse: 0.000691572   valid's RMSPE: 0.4813\n[142]   train's rmse: 0.000683187   train's RMSPE: 0.472291 valid's rmse: 0.000685022   valid's RMSPE: 0.476742\n[143]   train's rmse: 0.000679214   train's RMSPE: 0.469545 valid's rmse: 0.000680033   valid's RMSPE: 0.473269\n[144]   train's rmse: 0.000672184   train's RMSPE: 0.464685 valid's rmse: 0.000676151   valid's RMSPE: 0.470568\n[145]   train's rmse: 0.000675075   train's RMSPE: 0.466684 valid's rmse: 0.000678855   valid's RMSPE: 0.472449\n[146]   train's rmse: 0.000669886   train's RMSPE: 0.463097 valid's rmse: 0.00067599    valid's RMSPE: 0.470456\n[147]   train's rmse: 0.000671952   train's RMSPE: 0.464525 valid's rmse: 0.000678347   valid's RMSPE: 0.472096\n[148]   train's rmse: 0.000674322   train's RMSPE: 0.466163 valid's rmse: 0.000680537   valid's RMSPE: 0.47362\n[149]   train's rmse: 0.000668745   train's RMSPE: 0.462308 valid's rmse: 0.000675237   valid's RMSPE: 0.469932\n[150]   train's rmse: 0.00066245    train's RMSPE: 0.457957 valid's rmse: 0.000671481   valid's RMSPE: 0.467318\n[151]   train's rmse: 0.00066576    train's RMSPE: 0.460244 valid's rmse: 0.000674455   valid's RMSPE: 0.469387\n[152]   train's rmse: 0.000668513   train's RMSPE: 0.462148 valid's rmse: 0.000677262   valid's RMSPE: 0.471341\n[153]   train's rmse: 0.000670888   train's RMSPE: 0.46379  valid's rmse: 0.000679535   valid's RMSPE: 0.472923\n[154]   train's rmse: 0.000674224   train's RMSPE: 0.466096 valid's rmse: 0.000682572   valid's RMSPE: 0.475036\n[155]   train's rmse: 0.000677038   train's RMSPE: 0.468041 valid's rmse: 0.000685018   valid's RMSPE: 0.476739\n[156]   train's rmse: 0.000678862   train's RMSPE: 0.469302 valid's rmse: 0.000686927   valid's RMSPE: 0.478067\n[157]   train's rmse: 0.000681943   train's RMSPE: 0.471432 valid's rmse: 0.000689756   valid's RMSPE: 0.480036\n[158]   train's rmse: 0.000684837   train's RMSPE: 0.473432 valid's rmse: 0.000692324   valid's RMSPE: 0.481823\n[159]   train's rmse: 0.000687408   train's RMSPE: 0.47521  valid's rmse: 0.00069444    valid's RMSPE: 0.483296\n[160]   train's rmse: 0.000682194   train's RMSPE: 0.471606 valid's rmse: 0.000689403   valid's RMSPE: 0.47979\n[161]   train's rmse: 0.000684786   train's RMSPE: 0.473397 valid's rmse: 0.00069154    valid's RMSPE: 0.481277\n[162]   train's rmse: 0.000680651   train's RMSPE: 0.470539 valid's rmse: 0.000685972   valid's RMSPE: 0.477402\n[163]   train's rmse: 0.000686067   train's RMSPE: 0.474283 valid's rmse: 0.000691164   valid's RMSPE: 0.481016\n[164]   train's rmse: 0.00067902    train's RMSPE: 0.469411 valid's rmse: 0.000687043   valid's RMSPE: 0.478148\n[165]   train's rmse: 0.000684661   train's RMSPE: 0.473311 valid's rmse: 0.000691952   valid's RMSPE: 0.481564\n[166]   train's rmse: 0.000687359   train's RMSPE: 0.475176 valid's rmse: 0.000694605   valid's RMSPE: 0.483411\n[167]   train's rmse: 0.000682021   train's RMSPE: 0.471485 valid's rmse: 0.000690991   valid's RMSPE: 0.480896\n[168]   train's rmse: 0.000677349   train's RMSPE: 0.468256 valid's rmse: 0.000686308   valid's RMSPE: 0.477637\n[169]   train's rmse: 0.000672717   train's RMSPE: 0.465054 valid's rmse: 0.000681354   valid's RMSPE: 0.474188\n[170]   train's rmse: 0.0006756 train's RMSPE: 0.467047 valid's rmse: 0.000683871   valid's RMSPE: 0.47594\n[171]   train's rmse: 0.000678133   train's RMSPE: 0.468798 valid's rmse: 0.00068643    valid's RMSPE: 0.477721\n[172]   train's rmse: 0.000671345   train's RMSPE: 0.464106 valid's rmse: 0.000683243   valid's RMSPE: 0.475503\n[173]   train's rmse: 0.000665858   train's RMSPE: 0.460312 valid's rmse: 0.000678395   valid's RMSPE: 0.47213\n[174]   train's rmse: 0.000668413   train's RMSPE: 0.462078 valid's rmse: 0.000680588   valid's RMSPE: 0.473655\n[175]   train's rmse: 0.000663166   train's RMSPE: 0.458451 valid's rmse: 0.000676077   valid's RMSPE: 0.470516\n[176]   train's rmse: 0.000659778   train's RMSPE: 0.456109 valid's rmse: 0.000672097   valid's RMSPE: 0.467746\n[177]   train's rmse: 0.000662256   train's RMSPE: 0.457822 valid's rmse: 0.00067433    valid's RMSPE: 0.4693\n[178]   train's rmse: 0.000659181   train's RMSPE: 0.455697 valid's rmse: 0.000670247   valid's RMSPE: 0.466458\n[179]   train's rmse: 0.000654198   train's RMSPE: 0.452251 valid's rmse: 0.000667256   valid's RMSPE: 0.464377\n[180]   train's rmse: 0.000656821   train's RMSPE: 0.454065 valid's rmse: 0.000669519   valid's RMSPE: 0.465952\n[181]   train's rmse: 0.000659017   train's RMSPE: 0.455583 valid's rmse: 0.000671506   valid's RMSPE: 0.467335\n[182]   train's rmse: 0.000664181   train's RMSPE: 0.459153 valid's rmse: 0.000675817   valid's RMSPE: 0.470335\n[183]   train's rmse: 0.000658985   train's RMSPE: 0.455561 valid's rmse: 0.000670619   valid's RMSPE: 0.466718\n[184]   train's rmse: 0.000661493   train's RMSPE: 0.457295 valid's rmse: 0.000672775   valid's RMSPE: 0.468218\n[185]   train's rmse: 0.00065778    train's RMSPE: 0.454728 valid's rmse: 0.000669913   valid's RMSPE: 0.466226\n[186]   train's rmse: 0.000660122   train's RMSPE: 0.456347 valid's rmse: 0.000672089   valid's RMSPE: 0.46774\n[187]   train's rmse: 0.000662304   train's RMSPE: 0.457856 valid's rmse: 0.000674088   valid's RMSPE: 0.469132\n[188]   train's rmse: 0.000656131   train's RMSPE: 0.453588 valid's rmse: 0.000668885   valid's RMSPE: 0.465511\n[189]   train's rmse: 0.000658391   train's RMSPE: 0.45515  valid's rmse: 0.000670759   valid's RMSPE: 0.466815\n[190]   train's rmse: 0.000653224   train's RMSPE: 0.451579 valid's rmse: 0.000666705   valid's RMSPE: 0.463994\n[191]   train's rmse: 0.000655594   train's RMSPE: 0.453217 valid's rmse: 0.000668731   valid's RMSPE: 0.465404\n[192]   train's rmse: 0.000650593   train's RMSPE: 0.44976  valid's rmse: 0.000664627   valid's RMSPE: 0.462547\n[193]   train's rmse: 0.00065304    train's RMSPE: 0.451451 valid's rmse: 0.00066713    valid's RMSPE: 0.46429\n[194]   train's rmse: 0.000647151   train's RMSPE: 0.44738  valid's rmse: 0.000665784   valid's RMSPE: 0.463353\n[195]   train's rmse: 0.000650308   train's RMSPE: 0.449562 valid's rmse: 0.000668081   valid's RMSPE: 0.464951\n[196]   train's rmse: 0.00064639    train's RMSPE: 0.446854 valid's rmse: 0.000667223   valid's RMSPE: 0.464354\n[197]   train's rmse: 0.000648526   train's RMSPE: 0.448331 valid's rmse: 0.000669064   valid's RMSPE: 0.465636\n[198]   train's rmse: 0.000650674   train's RMSPE: 0.449815 valid's rmse: 0.000670858   valid's RMSPE: 0.466884\n[199]   train's rmse: 0.000653033   train's RMSPE: 0.451446 valid's rmse: 0.000672909   valid's RMSPE: 0.468311\n[200]   train's rmse: 0.000655352   train's RMSPE: 0.453049 valid's rmse: 0.000674483   valid's RMSPE: 0.469407\n[201]   train's rmse: 0.000657715   train's RMSPE: 0.454683 valid's rmse: 0.000676414   valid's RMSPE: 0.47075\n[202]   train's rmse: 0.000659525   train's RMSPE: 0.455934 valid's rmse: 0.000678255   valid's RMSPE: 0.472032\n[203]   train's rmse: 0.000661955   train's RMSPE: 0.457614 valid's rmse: 0.000680138   valid's RMSPE: 0.473342\n[204]   train's rmse: 0.000664118   train's RMSPE: 0.459109 valid's rmse: 0.000682022   valid's RMSPE: 0.474653\n[205]   train's rmse: 0.000658062   train's RMSPE: 0.454923 valid's rmse: 0.000676319   valid's RMSPE: 0.470684\n[206]   train's rmse: 0.000660513   train's RMSPE: 0.456617 valid's rmse: 0.000678312   valid's RMSPE: 0.472071\n[207]   train's rmse: 0.000662714   train's RMSPE: 0.458139 valid's rmse: 0.000680413   valid's RMSPE: 0.473534\n[208]   train's rmse: 0.000665057   train's RMSPE: 0.459758 valid's rmse: 0.000682517   valid's RMSPE: 0.474998\n[209]   train's rmse: 0.0006597 train's RMSPE: 0.456055 valid's rmse: 0.000676352   valid's RMSPE: 0.470707\n[210]   train's rmse: 0.000654301   train's RMSPE: 0.452322 valid's rmse: 0.000671894   valid's RMSPE: 0.467605\n[211]   train's rmse: 0.000647548   train's RMSPE: 0.447655 valid's rmse: 0.000667214   valid's RMSPE: 0.464348\n[212]   train's rmse: 0.000644772   train's RMSPE: 0.445735 valid's rmse: 0.000663681   valid's RMSPE: 0.461889\n[213]   train's rmse: 0.000642179   train's RMSPE: 0.443943 valid's rmse: 0.000661089   valid's RMSPE: 0.460085\n[214]   train's rmse: 0.000645193   train's RMSPE: 0.446027 valid's rmse: 0.000663274   valid's RMSPE: 0.461606\n[215]   train's rmse: 0.000640712   train's RMSPE: 0.442928 valid's rmse: 0.000661999   valid's RMSPE: 0.460718\n[216]   train's rmse: 0.000634509   train's RMSPE: 0.43864  valid's rmse: 0.000662761   valid's RMSPE: 0.461249\n[217]   train's rmse: 0.000636381   train's RMSPE: 0.439935 valid's rmse: 0.000664065   valid's RMSPE: 0.462157\n[218]   train's rmse: 0.000638475   train's RMSPE: 0.441382 valid's rmse: 0.000665354   valid's RMSPE: 0.463053\n[219]   train's rmse: 0.000634837   train's RMSPE: 0.438867 valid's rmse: 0.000662891   valid's RMSPE: 0.461339\n[220]   train's rmse: 0.000636781   train's RMSPE: 0.440211 valid's rmse: 0.000664243   valid's RMSPE: 0.46228\n[221]   train's rmse: 0.000639148   train's RMSPE: 0.441847 valid's rmse: 0.000665823   valid's RMSPE: 0.46338\n[222]   train's rmse: 0.000635065   train's RMSPE: 0.439024 valid's rmse: 0.000663795   valid's RMSPE: 0.461968\n[223]   train's rmse: 0.000629515   train's RMSPE: 0.435188 valid's rmse: 0.000662527   valid's RMSPE: 0.461086\n[224]   train's rmse: 0.000626436   train's RMSPE: 0.433059 valid's rmse: 0.00066078    valid's RMSPE: 0.45987\n[225]   train's rmse: 0.000625068   train's RMSPE: 0.432113 valid's rmse: 0.000658379   valid's RMSPE: 0.458199\n[226]   train's rmse: 0.000622596   train's RMSPE: 0.430405 valid's rmse: 0.000658073   valid's RMSPE: 0.457986\n[227]   train's rmse: 0.000624576   train's RMSPE: 0.431774 valid's rmse: 0.000659188   valid's RMSPE: 0.458762\n[228]   train's rmse: 0.000622757   train's RMSPE: 0.430516 valid's rmse: 0.00065743    valid's RMSPE: 0.457539\n[229]   train's rmse: 0.000618816   train's RMSPE: 0.427792 valid's rmse: 0.000657642   valid's RMSPE: 0.457686\n[230]   train's rmse: 0.000616035   train's RMSPE: 0.425869 valid's rmse: 0.000654945   valid's RMSPE: 0.455809\n[231]   train's rmse: 0.00061765    train's RMSPE: 0.426986 valid's rmse: 0.000656067   valid's RMSPE: 0.45659\n[232]   train's rmse: 0.000614867   train's RMSPE: 0.425062 valid's rmse: 0.000652039   valid's RMSPE: 0.453787\n[233]   train's rmse: 0.000613507   train's RMSPE: 0.424122 valid's rmse: 0.000651831   valid's RMSPE: 0.453642\n[234]   train's rmse: 0.000614863   train's RMSPE: 0.425059 valid's rmse: 0.000652484   valid's RMSPE: 0.454097\n[235]   train's rmse: 0.000616342   train's RMSPE: 0.426081 valid's rmse: 0.000653551   valid's RMSPE: 0.454839\n[236]   train's rmse: 0.000617944   train's RMSPE: 0.427189 valid's rmse: 0.000654693   valid's RMSPE: 0.455634\n[237]   train's rmse: 0.000619171   train's RMSPE: 0.428037 valid's rmse: 0.000655587   valid's RMSPE: 0.456256\n[238]   train's rmse: 0.000620724   train's RMSPE: 0.42911  valid's rmse: 0.000656333   valid's RMSPE: 0.456775\n[239]   train's rmse: 0.000622323   train's RMSPE: 0.430216 valid's rmse: 0.000657632   valid's RMSPE: 0.457679\n[240]   train's rmse: 0.000619237   train's RMSPE: 0.428082 valid's rmse: 0.00065504    valid's RMSPE: 0.455876\n[241]   train's rmse: 0.000621152   train's RMSPE: 0.429407 valid's rmse: 0.000655841   valid's RMSPE: 0.456433\n[242]   train's rmse: 0.000622682   train's RMSPE: 0.430465 valid's rmse: 0.000657154   valid's RMSPE: 0.457347\n[243]   train's rmse: 0.000624622   train's RMSPE: 0.431805 valid's rmse: 0.000658445   valid's RMSPE: 0.458245\n[244]   train's rmse: 0.00062156    train's RMSPE: 0.429688 valid's rmse: 0.000655588   valid's RMSPE: 0.456257\n[245]   train's rmse: 0.000619468   train's RMSPE: 0.428242 valid's rmse: 0.000653151   valid's RMSPE: 0.454561\n[246]   train's rmse: 0.00061894    train's RMSPE: 0.427878 valid's rmse: 0.000650329   valid's RMSPE: 0.452597\n[247]   train's rmse: 0.00061729    train's RMSPE: 0.426737 valid's rmse: 0.000647977   valid's RMSPE: 0.45096\n[248]   train's rmse: 0.000618721   train's RMSPE: 0.427726 valid's rmse: 0.000649028   valid's RMSPE: 0.451691\n[249]   train's rmse: 0.000615385   train's RMSPE: 0.42542  valid's rmse: 0.000645661   valid's RMSPE: 0.449348\n[250]   train's rmse: 0.000617082   train's RMSPE: 0.426593 valid's rmse: 0.000646505   valid's RMSPE: 0.449935\n[251]   train's rmse: 0.000615209   train's RMSPE: 0.425298 valid's rmse: 0.000645664   valid's RMSPE: 0.44935\n[252]   train's rmse: 0.000612417   train's RMSPE: 0.423368 valid's rmse: 0.000646087   valid's RMSPE: 0.449645\n[253]   train's rmse: 0.000614051   train's RMSPE: 0.424498 valid's rmse: 0.000646959   valid's RMSPE: 0.450252\n[254]   train's rmse: 0.000611738   train's RMSPE: 0.422899 valid's rmse: 0.000646809   valid's RMSPE: 0.450147\n[255]   train's rmse: 0.000613255   train's RMSPE: 0.423948 valid's rmse: 0.000647734   valid's RMSPE: 0.450791\n[256]   train's rmse: 0.000614627   train's RMSPE: 0.424896 valid's rmse: 0.000648915   valid's RMSPE: 0.451612\n[257]   train's rmse: 0.00061432    train's RMSPE: 0.424684 valid's rmse: 0.000647009   valid's RMSPE: 0.450286\n[258]   train's rmse: 0.000615986   train's RMSPE: 0.425835 valid's rmse: 0.000648009   valid's RMSPE: 0.450982\n[259]   train's rmse: 0.000617247   train's RMSPE: 0.426707 valid's rmse: 0.000649207   valid's RMSPE: 0.451816\n[260]   train's rmse: 0.00061471    train's RMSPE: 0.424953 valid's rmse: 0.000647063   valid's RMSPE: 0.450324\n[261]   train's rmse: 0.000615989   train's RMSPE: 0.425837 valid's rmse: 0.000647866   valid's RMSPE: 0.450883\n[262]   train's rmse: 0.000617131   train's RMSPE: 0.426627 valid's rmse: 0.00064874    valid's RMSPE: 0.451491\n[263]   train's rmse: 0.000618635   train's RMSPE: 0.427666 valid's rmse: 0.000649507   valid's RMSPE: 0.452025\n[264]   train's rmse: 0.000620509   train's RMSPE: 0.428962 valid's rmse: 0.000650626   valid's RMSPE: 0.452803\n[265]   train's rmse: 0.000616625   train's RMSPE: 0.426277 valid's rmse: 0.000647356   valid's RMSPE: 0.450527\n[266]   train's rmse: 0.000618262   train's RMSPE: 0.427408 valid's rmse: 0.000648501   valid's RMSPE: 0.451325\n[267]   train's rmse: 0.00061472    train's RMSPE: 0.42496  valid's rmse: 0.000644692   valid's RMSPE: 0.448674\n[268]   train's rmse: 0.000611611   train's RMSPE: 0.422811 valid's rmse: 0.000643119   valid's RMSPE: 0.447579\n[269]   train's rmse: 0.000608984   train's RMSPE: 0.420995 valid's rmse: 0.000643115   valid's RMSPE: 0.447576\n[270]   train's rmse: 0.000607326   train's RMSPE: 0.419848 valid's rmse: 0.000641478   valid's RMSPE: 0.446437\n[271]   train's rmse: 0.000608771   train's RMSPE: 0.420848 valid's rmse: 0.000642619   valid's RMSPE: 0.447231\n[272]   train's rmse: 0.000610139   train's RMSPE: 0.421794 valid's rmse: 0.000643612   valid's RMSPE: 0.447922\n[273]   train's rmse: 0.000611813   train's RMSPE: 0.42295  valid's rmse: 0.000644546   valid's RMSPE: 0.448572\n[274]   train's rmse: 0.000608491   train's RMSPE: 0.420654 valid's rmse: 0.000643514   valid's RMSPE: 0.447854\n[275]   train's rmse: 0.000607352   train's RMSPE: 0.419866 valid's rmse: 0.000643594   valid's RMSPE: 0.447909\n[276]   train's rmse: 0.000608938   train's RMSPE: 0.420963 valid's rmse: 0.000644509   valid's RMSPE: 0.448546\n[277]   train's rmse: 0.000605678   train's RMSPE: 0.418709 valid's rmse: 0.000643684   valid's RMSPE: 0.447972\n[278]   train's rmse: 0.000603324   train's RMSPE: 0.417082 valid's rmse: 0.000645454   valid's RMSPE: 0.449204\n[279]   train's rmse: 0.000604705   train's RMSPE: 0.418037 valid's rmse: 0.000646352   valid's RMSPE: 0.449829\n[280]   train's rmse: 0.000602071   train's RMSPE: 0.416216 valid's rmse: 0.000644565   valid's RMSPE: 0.448585\n[281]   train's rmse: 0.000603493   train's RMSPE: 0.417199 valid's rmse: 0.000645302   valid's RMSPE: 0.449098\n[282]   train's rmse: 0.000604908   train's RMSPE: 0.418177 valid's rmse: 0.000646399   valid's RMSPE: 0.449862\n[283]   train's rmse: 0.000605163   train's RMSPE: 0.418354 valid's rmse: 0.000643887   valid's RMSPE: 0.448114\n[284]   train's rmse: 0.000606302   train's RMSPE: 0.41914  valid's rmse: 0.000644673   valid's RMSPE: 0.448661\n[285]   train's rmse: 0.00060275    train's RMSPE: 0.416685 valid's rmse: 0.000644804   valid's RMSPE: 0.448752\n[286]   train's rmse: 0.000604045   train's RMSPE: 0.41758  valid's rmse: 0.000645391   valid's RMSPE: 0.44916\n[287]   train's rmse: 0.00060068    train's RMSPE: 0.415254 valid's rmse: 0.000644928   valid's RMSPE: 0.448838\n[288]   train's rmse: 0.000602048   train's RMSPE: 0.4162   valid's rmse: 0.000645589   valid's RMSPE: 0.449298\n[289]   train's rmse: 0.000603001   train's RMSPE: 0.416859 valid's rmse: 0.000646327   valid's RMSPE: 0.449812\n[290]   train's rmse: 0.000601685   train's RMSPE: 0.415949 valid's rmse: 0.000645972   valid's RMSPE: 0.449564\n[291]   train's rmse: 0.000599953   train's RMSPE: 0.414752 valid's rmse: 0.000645769   valid's RMSPE: 0.449423\n[292]   train's rmse: 0.00060141    train's RMSPE: 0.415759 valid's rmse: 0.000646805   valid's RMSPE: 0.450144\n[293]   train's rmse: 0.00059891    train's RMSPE: 0.414031 valid's rmse: 0.000648026   valid's RMSPE: 0.450994\n[294]   train's rmse: 0.000600273   train's RMSPE: 0.414973 valid's rmse: 0.000648499   valid's RMSPE: 0.451323\n[295]   train's rmse: 0.000601366   train's RMSPE: 0.415729 valid's rmse: 0.000649295   valid's RMSPE: 0.451877\n[296]   train's rmse: 0.000602769   train's RMSPE: 0.416698 valid's rmse: 0.000650205   valid's RMSPE: 0.45251\n[297]   train's rmse: 0.000599522   train's RMSPE: 0.414453 valid's rmse: 0.000648087   valid's RMSPE: 0.451037\n[298]   train's rmse: 0.000600924   train's RMSPE: 0.415423 valid's rmse: 0.000649037   valid's RMSPE: 0.451698\n[299]   train's rmse: 0.000598294   train's RMSPE: 0.413605 valid's rmse: 0.00064857    valid's RMSPE: 0.451373\n[300]   train's rmse: 0.000597638   train's RMSPE: 0.413151 valid's rmse: 0.000648385   valid's RMSPE: 0.451244\n[301]   train's rmse: 0.000594844   train's RMSPE: 0.41122  valid's rmse: 0.000648239   valid's RMSPE: 0.451142\n[302]   train's rmse: 0.000594065   train's RMSPE: 0.410682 valid's rmse: 0.000648489   valid's RMSPE: 0.451317\n[303]   train's rmse: 0.000595292   train's RMSPE: 0.411529 valid's rmse: 0.000648928   valid's RMSPE: 0.451622\n[304]   train's rmse: 0.000593447   train's RMSPE: 0.410254 valid's rmse: 0.000647132   valid's RMSPE: 0.450372\n[305]   train's rmse: 0.00059334    train's RMSPE: 0.41018  valid's rmse: 0.000645562   valid's RMSPE: 0.449279\n[306]   train's rmse: 0.000594591   train's RMSPE: 0.411045 valid's rmse: 0.000645837   valid's RMSPE: 0.449471\n[307]   train's rmse: 0.000592206   train's RMSPE: 0.409396 valid's rmse: 0.000642525   valid's RMSPE: 0.447165\n[308]   train's rmse: 0.000593196   train's RMSPE: 0.41008  valid's rmse: 0.000642884   valid's RMSPE: 0.447416\n[309]   train's rmse: 0.000591023   train's RMSPE: 0.408578 valid's rmse: 0.000645319   valid's RMSPE: 0.44911\n[310]   train's rmse: 0.000589371   train's RMSPE: 0.407436 valid's rmse: 0.000644344   valid's RMSPE: 0.448432\n[311]   train's rmse: 0.000589131   train's RMSPE: 0.40727  valid's rmse: 0.00064286    valid's RMSPE: 0.447399\n[312]   train's rmse: 0.000590333   train's RMSPE: 0.408102 valid's rmse: 0.000642866   valid's RMSPE: 0.447403\n[313]   train's rmse: 0.000591379   train's RMSPE: 0.408825 valid's rmse: 0.000643293   valid's RMSPE: 0.4477\n[314]   train's rmse: 0.000589307   train's RMSPE: 0.407392 valid's rmse: 0.000645371   valid's RMSPE: 0.449146\n[315]   train's rmse: 0.000588313   train's RMSPE: 0.406705 valid's rmse: 0.000644154   valid's RMSPE: 0.448299\n[316]   train's rmse: 0.000584868   train's RMSPE: 0.404323 valid's rmse: 0.00064429    valid's RMSPE: 0.448394\n[317]   train's rmse: 0.000585837   train's RMSPE: 0.404993 valid's rmse: 0.000644547   valid's RMSPE: 0.448573\n[318]   train's rmse: 0.000584321   train's RMSPE: 0.403945 valid's rmse: 0.000647697   valid's RMSPE: 0.450765\n[319]   train's rmse: 0.000585393   train's RMSPE: 0.404686 valid's rmse: 0.000647737   valid's RMSPE: 0.450793\n[320]   train's rmse: 0.000586567   train's RMSPE: 0.405498 valid's rmse: 0.000648042   valid's RMSPE: 0.451005\n[321]   train's rmse: 0.000587804   train's RMSPE: 0.406353 valid's rmse: 0.000648332   valid's RMSPE: 0.451207\n[322]   train's rmse: 0.000588932   train's RMSPE: 0.407133 valid's rmse: 0.000648422   valid's RMSPE: 0.45127\n[323]   train's rmse: 0.000590059   train's RMSPE: 0.407912 valid's rmse: 0.000648852   valid's RMSPE: 0.451569\n[324]   train's rmse: 0.000591105   train's RMSPE: 0.408635 valid's rmse: 0.000649327   valid's RMSPE: 0.4519\n[325]   train's rmse: 0.000587976   train's RMSPE: 0.406472 valid's rmse: 0.000647627   valid's RMSPE: 0.450716\n[326]   train's rmse: 0.000585724   train's RMSPE: 0.404915 valid's rmse: 0.000645781   valid's RMSPE: 0.449431\n[327]   train's rmse: 0.000586728   train's RMSPE: 0.405609 valid's rmse: 0.0006462 valid's RMSPE: 0.449723\n[328]   train's rmse: 0.000583071   train's RMSPE: 0.403081 valid's rmse: 0.000645951   valid's RMSPE: 0.44955\n[329]   train's rmse: 0.000584196   train's RMSPE: 0.403859 valid's rmse: 0.000646436   valid's RMSPE: 0.449888\n[330]   train's rmse: 0.000585143   train's RMSPE: 0.404513 valid's rmse: 0.000646948   valid's RMSPE: 0.450243\n[331]   train's rmse: 0.000586149   train's RMSPE: 0.405209 valid's rmse: 0.000647205   valid's RMSPE: 0.450423\n[332]   train's rmse: 0.000584579   train's RMSPE: 0.404123 valid's rmse: 0.00064829    valid's RMSPE: 0.451178\n[333]   train's rmse: 0.000585777   train's RMSPE: 0.404952 valid's rmse: 0.000648439   valid's RMSPE: 0.451281\n[334]   train's rmse: 0.000586779   train's RMSPE: 0.405644 valid's rmse: 0.000648198   valid's RMSPE: 0.451113\n[335]   train's rmse: 0.000584052   train's RMSPE: 0.403759 valid's rmse: 0.000646262   valid's RMSPE: 0.449766\n[336]   train's rmse: 0.000585387   train's RMSPE: 0.404682 valid's rmse: 0.0006469 valid's RMSPE: 0.45021\n[337]   train's rmse: 0.000586257   train's RMSPE: 0.405283 valid's rmse: 0.000647056   valid's RMSPE: 0.450319\n[338]   train's rmse: 0.000583203   train's RMSPE: 0.403172 valid's rmse: 0.000648606   valid's RMSPE: 0.451397\n[339]   train's rmse: 0.000584258   train's RMSPE: 0.403901 valid's rmse: 0.000649098   valid's RMSPE: 0.45174\n[340]   train's rmse: 0.000582116   train's RMSPE: 0.40242  valid's rmse: 0.000649598   valid's RMSPE: 0.452088\n[341]   train's rmse: 0.000583381   train's RMSPE: 0.403295 valid's rmse: 0.000649811   valid's RMSPE: 0.452236\n[342]   train's rmse: 0.000580883   train's RMSPE: 0.401568 valid's rmse: 0.000649265   valid's RMSPE: 0.451856\n[343]   train's rmse: 0.000581941   train's RMSPE: 0.4023   valid's rmse: 0.000649492   valid's RMSPE: 0.452014\n[344]   train's rmse: 0.000578518   train's RMSPE: 0.399934 valid's rmse: 0.000647962   valid's RMSPE: 0.45095\n[345]   train's rmse: 0.000578014   train's RMSPE: 0.399585 valid's rmse: 0.000647571   valid's RMSPE: 0.450677\n[346]   train's rmse: 0.000579147   train's RMSPE: 0.400368 valid's rmse: 0.000647984   valid's RMSPE: 0.450965\n[347]   train's rmse: 0.000577582   train's RMSPE: 0.399286 valid's rmse: 0.000647517   valid's RMSPE: 0.45064\n[348]   train's rmse: 0.000574426   train's RMSPE: 0.397105 valid's rmse: 0.000649389   valid's RMSPE: 0.451942\n[349]   train's rmse: 0.000575473   train's RMSPE: 0.397829 valid's rmse: 0.00064964    valid's RMSPE: 0.452117\n[350]   train's rmse: 0.000576505   train's RMSPE: 0.398542 valid's rmse: 0.00064954    valid's RMSPE: 0.452048\n[351]   train's rmse: 0.000577648   train's RMSPE: 0.399332 valid's rmse: 0.000648984   valid's RMSPE: 0.451661\n[352]   train's rmse: 0.000578721   train's RMSPE: 0.400074 valid's rmse: 0.000649082   valid's RMSPE: 0.451729\n[353]   train's rmse: 0.00057988    train's RMSPE: 0.400875 valid's rmse: 0.000649507   valid's RMSPE: 0.452025\n[354]   train's rmse: 0.000577257   train's RMSPE: 0.399062 valid's rmse: 0.000647661   valid's RMSPE: 0.45074\n[355]   train's rmse: 0.000578353   train's RMSPE: 0.399819 valid's rmse: 0.000647958   valid's RMSPE: 0.450947\n[356]   train's rmse: 0.000579638   train's RMSPE: 0.400708 valid's rmse: 0.000647714   valid's RMSPE: 0.450777\n[357]   train's rmse: 0.000580878   train's RMSPE: 0.401565 valid's rmse: 0.000648144   valid's RMSPE: 0.451076\n[358]   train's rmse: 0.000582105   train's RMSPE: 0.402413 valid's rmse: 0.000648395   valid's RMSPE: 0.451251\n[359]   train's rmse: 0.00058331    train's RMSPE: 0.403246 valid's rmse: 0.000648932   valid's RMSPE: 0.451624\n[360]   train's rmse: 0.00058029    train's RMSPE: 0.401159 valid's rmse: 0.000650442   valid's RMSPE: 0.452675\n[361]   train's rmse: 0.000581316   train's RMSPE: 0.401868 valid's rmse: 0.000650827   valid's RMSPE: 0.452943\n[362]   train's rmse: 0.000578266   train's RMSPE: 0.399759 valid's rmse: 0.00064976    valid's RMSPE: 0.452201\n[363]   train's rmse: 0.000579715   train's RMSPE: 0.400761 valid's rmse: 0.000650123   valid's RMSPE: 0.452454\n[364]   train's rmse: 0.000577673   train's RMSPE: 0.39935  valid's rmse: 0.000648818   valid's RMSPE: 0.451545\n[365]   train's rmse: 0.000578878   train's RMSPE: 0.400182 valid's rmse: 0.000649114   valid's RMSPE: 0.451751\n[366]   train's rmse: 0.000576394   train's RMSPE: 0.398465 valid's rmse: 0.000649519   valid's RMSPE: 0.452033\n[367]   train's rmse: 0.000577701   train's RMSPE: 0.399369 valid's rmse: 0.000649418   valid's RMSPE: 0.451962\n[368]   train's rmse: 0.000578997   train's RMSPE: 0.400264 valid's rmse: 0.000649888   valid's RMSPE: 0.45229\n[369]   train's rmse: 0.000576608   train's RMSPE: 0.398613 valid's rmse: 0.000648416   valid's RMSPE: 0.451265\n[370]   train's rmse: 0.000577712   train's RMSPE: 0.399376 valid's rmse: 0.000648797   valid's RMSPE: 0.451531\n[371]   train's rmse: 0.000575681   train's RMSPE: 0.397972 valid's rmse: 0.000650502   valid's RMSPE: 0.452717\n[372]   train's rmse: 0.000576536   train's RMSPE: 0.398563 valid's rmse: 0.000650524   valid's RMSPE: 0.452733\n[373]   train's rmse: 0.000573696   train's RMSPE: 0.3966   valid's rmse: 0.000650721   valid's RMSPE: 0.45287\n[374]   train's rmse: 0.000572038   train's RMSPE: 0.395454 valid's rmse: 0.000649388   valid's RMSPE: 0.451942\n[375]   train's rmse: 0.00057312    train's RMSPE: 0.396202 valid's rmse: 0.000649727   valid's RMSPE: 0.452178\n[376]   train's rmse: 0.000574325   train's RMSPE: 0.397035 valid's rmse: 0.000649868   valid's RMSPE: 0.452276\n[377]   train's rmse: 0.000572353   train's RMSPE: 0.395672 valid's rmse: 0.00065007    valid's RMSPE: 0.452417\n[378]   train's rmse: 0.000570119   train's RMSPE: 0.394127 valid's rmse: 0.000648765   valid's RMSPE: 0.451509\n[379]   train's rmse: 0.000570881   train's RMSPE: 0.394654 valid's rmse: 0.000653399   valid's RMSPE: 0.454733\n[380]   train's rmse: 0.000568799   train's RMSPE: 0.393214 valid's rmse: 0.000654901   valid's RMSPE: 0.455779\n[381]   train's rmse: 0.000569819   train's RMSPE: 0.39392  valid's rmse: 0.000655023   valid's RMSPE: 0.455864\n[382]   train's rmse: 0.000570899   train's RMSPE: 0.394666 valid's rmse: 0.000654988   valid's RMSPE: 0.455839\n[383]   train's rmse: 0.000571939   train's RMSPE: 0.395386 valid's rmse: 0.000655188   valid's RMSPE: 0.455979\n[384]   train's rmse: 0.000571575   train's RMSPE: 0.395134 valid's rmse: 0.000656597   valid's RMSPE: 0.456959\n[385]   train's rmse: 0.000569493   train's RMSPE: 0.393695 valid's rmse: 0.000655851   valid's RMSPE: 0.45644\n[386]   train's rmse: 0.000570416   train's RMSPE: 0.394332 valid's rmse: 0.000655847   valid's RMSPE: 0.456437\n[387]   train's rmse: 0.000571512   train's RMSPE: 0.39509  valid's rmse: 0.00065611    valid's RMSPE: 0.45662\n[388]   train's rmse: 0.000569022   train's RMSPE: 0.393369 valid's rmse: 0.000658018   valid's RMSPE: 0.457948\n[389]   train's rmse: 0.000567252   train's RMSPE: 0.392145 valid's rmse: 0.000657362   valid's RMSPE: 0.457491\n[390]   train's rmse: 0.000568097   train's RMSPE: 0.392729 valid's rmse: 0.000657399   valid's RMSPE: 0.457517\n[391]   train's rmse: 0.000568991   train's RMSPE: 0.393347 valid's rmse: 0.000657043   valid's RMSPE: 0.457269\n[392]   train's rmse: 0.000570088   train's RMSPE: 0.394106 valid's rmse: 0.000657172   valid's RMSPE: 0.457359\n[393]   train's rmse: 0.000571228   train's RMSPE: 0.394894 valid's rmse: 0.00065732    valid's RMSPE: 0.457462\n[394]   train's rmse: 0.000572392   train's RMSPE: 0.395698 valid's rmse: 0.000656867   valid's RMSPE: 0.457147\n[395]   train's rmse: 0.000573485   train's RMSPE: 0.396454 valid's rmse: 0.000656794   valid's RMSPE: 0.457096\n[396]   train's rmse: 0.000571957   train's RMSPE: 0.395398 valid's rmse: 0.000654852   valid's RMSPE: 0.455744\n[397]   train's rmse: 0.000572889   train's RMSPE: 0.396042 valid's rmse: 0.00065484    valid's RMSPE: 0.455736\n[398]   train's rmse: 0.00057072    train's RMSPE: 0.394543 valid's rmse: 0.000654483   valid's RMSPE: 0.455488\n[399]   train's rmse: 0.000571668   train's RMSPE: 0.395198 valid's rmse: 0.000654691   valid's RMSPE: 0.455633\n[400]   train's rmse: 0.000570242   train's RMSPE: 0.394212 valid's rmse: 0.000653982   valid's RMSPE: 0.455139\n[401]   train's rmse: 0.000571181   train's RMSPE: 0.394861 valid's rmse: 0.000654218   valid's RMSPE: 0.455304\n[402]   train's rmse: 0.0005694 train's RMSPE: 0.39363  valid's rmse: 0.000652547   valid's RMSPE: 0.45414\n[403]   train's rmse: 0.000569201   train's RMSPE: 0.393492 valid's rmse: 0.000652925   valid's RMSPE: 0.454403\n[404]   train's rmse: 0.000570225   train's RMSPE: 0.394201 valid's rmse: 0.00065272    valid's RMSPE: 0.454261\n[405]   train's rmse: 0.000569035   train's RMSPE: 0.393378 valid's rmse: 0.000652453   valid's RMSPE: 0.454075\n[406]   train's rmse: 0.000569876   train's RMSPE: 0.393959 valid's rmse: 0.00065228    valid's RMSPE: 0.453955\n[407]   train's rmse: 0.000569175   train's RMSPE: 0.393475 valid's rmse: 0.000651479   valid's RMSPE: 0.453397\n[408]   train's rmse: 0.000568459   train's RMSPE: 0.39298  valid's rmse: 0.000656919   valid's RMSPE: 0.457183\n[409]   train's rmse: 0.000566826   train's RMSPE: 0.391851 valid's rmse: 0.000656803   valid's RMSPE: 0.457102\n[410]   train's rmse: 0.000567651   train's RMSPE: 0.392421 valid's rmse: 0.000656322   valid's RMSPE: 0.456768\n[411]   train's rmse: 0.000568453   train's RMSPE: 0.392976 valid's rmse: 0.000655848   valid's RMSPE: 0.456438\n[412]   train's rmse: 0.00056946    train's RMSPE: 0.393672 valid's rmse: 0.000655456   valid's RMSPE: 0.456165\n[413]   train's rmse: 0.000570428   train's RMSPE: 0.39434  valid's rmse: 0.000655519   valid's RMSPE: 0.456208\n[414]   train's rmse: 0.000571346   train's RMSPE: 0.394975 valid's rmse: 0.000655462   valid's RMSPE: 0.456169\n[415]   train's rmse: 0.000572324   train's RMSPE: 0.395651 valid's rmse: 0.000655541   valid's RMSPE: 0.456224\n[416]   train's rmse: 0.000570769   train's RMSPE: 0.394577 valid's rmse: 0.000660128   valid's RMSPE: 0.459417\n[417]   train's rmse: 0.000568851   train's RMSPE: 0.39325  valid's rmse: 0.000658245   valid's RMSPE: 0.458106\n[418]   train's rmse: 0.000566794   train's RMSPE: 0.391829 valid's rmse: 0.000657135   valid's RMSPE: 0.457333\n[419]   train's rmse: 0.0005659 train's RMSPE: 0.39121  valid's rmse: 0.000656288   valid's RMSPE: 0.456744\n[420]   train's rmse: 0.000566781   train's RMSPE: 0.391819 valid's rmse: 0.000656424   valid's RMSPE: 0.456839\n[421]   train's rmse: 0.000567684   train's RMSPE: 0.392444 valid's rmse: 0.000656177   valid's RMSPE: 0.456667\n[422]   train's rmse: 0.000566645   train's RMSPE: 0.391726 valid's rmse: 0.000656924   valid's RMSPE: 0.457187\n[423]   train's rmse: 0.000567433   train's RMSPE: 0.392271 valid's rmse: 0.00065666    valid's RMSPE: 0.457003\n[424]   train's rmse: 0.000568473   train's RMSPE: 0.392989 valid's rmse: 0.000656601   valid's RMSPE: 0.456962\n[425]   train's rmse: 0.000569188   train's RMSPE: 0.393484 valid's rmse: 0.000656302   valid's RMSPE: 0.456754\n[426]   train's rmse: 0.000570002   train's RMSPE: 0.394046 valid's rmse: 0.000656514   valid's RMSPE: 0.456901\n[427]   train's rmse: 0.000568944   train's RMSPE: 0.393315 valid's rmse: 0.000656665   valid's RMSPE: 0.457006\n[428]   train's rmse: 0.000569829   train's RMSPE: 0.393927 valid's rmse: 0.000655945   valid's RMSPE: 0.456505\n[429]   train's rmse: 0.000570615   train's RMSPE: 0.39447  valid's rmse: 0.000655929   valid's RMSPE: 0.456494\n[430]   train's rmse: 0.0005716 train's RMSPE: 0.395151 valid's rmse: 0.000656191   valid's RMSPE: 0.456677\n[431]   train's rmse: 0.000570629   train's RMSPE: 0.39448  valid's rmse: 0.000656302   valid's RMSPE: 0.456754\n[432]   train's rmse: 0.000571518   train's RMSPE: 0.395094 valid's rmse: 0.000656193   valid's RMSPE: 0.456678\n[433]   train's rmse: 0.000570102   train's RMSPE: 0.394116 valid's rmse: 0.000656771   valid's RMSPE: 0.45708\n[434]   train's rmse: 0.000570861   train's RMSPE: 0.39464  valid's rmse: 0.000656919   valid's RMSPE: 0.457183\n[435]   train's rmse: 0.000570457   train's RMSPE: 0.394361 valid's rmse: 0.000657156   valid's RMSPE: 0.457348\n[436]   train's rmse: 0.000568669   train's RMSPE: 0.393125 valid's rmse: 0.000659888   valid's RMSPE: 0.459249\n[437]   train's rmse: 0.000569484   train's RMSPE: 0.393688 valid's rmse: 0.000659487   valid's RMSPE: 0.45897\n[438]   train's rmse: 0.000567799   train's RMSPE: 0.392523 valid's rmse: 0.000660335   valid's RMSPE: 0.45956\n[439]   train's rmse: 0.000568562   train's RMSPE: 0.393051 valid's rmse: 0.000659926   valid's RMSPE: 0.459276\n[440]   train's rmse: 0.000569435   train's RMSPE: 0.393654 valid's rmse: 0.000659175   valid's RMSPE: 0.458753\n[441]   train's rmse: 0.00057025    train's RMSPE: 0.394217 valid's rmse: 0.000658881   valid's RMSPE: 0.458549\n[442]   train's rmse: 0.000571074   train's RMSPE: 0.394788 valid's rmse: 0.000658748   valid's RMSPE: 0.458456\n[443]   train's rmse: 0.000571903   train's RMSPE: 0.395361 valid's rmse: 0.000659055   valid's RMSPE: 0.45867\n[444]   train's rmse: 0.000572649   train's RMSPE: 0.395876 valid's rmse: 0.000659148   valid's RMSPE: 0.458734\n[445]   train's rmse: 0.000569606   train's RMSPE: 0.393772 valid's rmse: 0.000661804   valid's RMSPE: 0.460583\n[446]   train's rmse: 0.000570567   train's RMSPE: 0.394437 valid's rmse: 0.000661732   valid's RMSPE: 0.460532\n[447]   train's rmse: 0.000571417   train's RMSPE: 0.395024 valid's rmse: 0.000661645   valid's RMSPE: 0.460472\n[448]   train's rmse: 0.00057014    train's RMSPE: 0.394142 valid's rmse: 0.00066617    valid's RMSPE: 0.463622\n[449]   train's rmse: 0.000571019   train's RMSPE: 0.39475  valid's rmse: 0.000666052   valid's RMSPE: 0.46354\n[450]   train's rmse: 0.000571883   train's RMSPE: 0.395347 valid's rmse: 0.000665966   valid's RMSPE: 0.463479\n[451]   train's rmse: 0.00057281    train's RMSPE: 0.395988 valid's rmse: 0.000665983   valid's RMSPE: 0.463491\n[452]   train's rmse: 0.000570418   train's RMSPE: 0.394334 valid's rmse: 0.000665788   valid's RMSPE: 0.463355\n[453]   train's rmse: 0.000568747   train's RMSPE: 0.393179 valid's rmse: 0.000666679   valid's RMSPE: 0.463976\n[454]   train's rmse: 0.000566135   train's RMSPE: 0.391373 valid's rmse: 0.000664486   valid's RMSPE: 0.462449\n[455]   train's rmse: 0.000567064   train's RMSPE: 0.392015 valid's rmse: 0.000664189   valid's RMSPE: 0.462243\n[456]   train's rmse: 0.000564572   train's RMSPE: 0.390292 valid's rmse: 0.000665199   valid's RMSPE: 0.462946\n[457]   train's rmse: 0.000565448   train's RMSPE: 0.390898 valid's rmse: 0.000664905   valid's RMSPE: 0.462741\n[458]   train's rmse: 0.000564603   train's RMSPE: 0.390314 valid's rmse: 0.000662345   valid's RMSPE: 0.460959\n[459]   train's rmse: 0.000564495   train's RMSPE: 0.390239 valid's rmse: 0.00066466    valid's RMSPE: 0.46257\n[460]   train's rmse: 0.000565296   train's RMSPE: 0.390793 valid's rmse: 0.000664721   valid's RMSPE: 0.462613\n[461]   train's rmse: 0.000566108   train's RMSPE: 0.391354 valid's rmse: 0.000664641   valid's RMSPE: 0.462557\n[462]   train's rmse: 0.000563912   train's RMSPE: 0.389836 valid's rmse: 0.000668848   valid's RMSPE: 0.465485\n[463]   train's rmse: 0.000562213   train's RMSPE: 0.388662 valid's rmse: 0.000669791   valid's RMSPE: 0.466141\n[464]   train's rmse: 0.000562962   train's RMSPE: 0.38918  valid's rmse: 0.000668763   valid's RMSPE: 0.465426\n[465]   train's rmse: 0.000560199   train's RMSPE: 0.387269 valid's rmse: 0.00066948    valid's RMSPE: 0.465925\n[466]   train's rmse: 0.000558023   train's RMSPE: 0.385765 valid's rmse: 0.000671764   valid's RMSPE: 0.467514\n[467]   train's rmse: 0.000556627   train's RMSPE: 0.3848   valid's rmse: 0.000671781   valid's RMSPE: 0.467526\n[468]   train's rmse: 0.000555184   train's RMSPE: 0.383802 valid's rmse: 0.000671517   valid's RMSPE: 0.467342\n[469]   train's rmse: 0.000553811   train's RMSPE: 0.382853 valid's rmse: 0.000670018   valid's RMSPE: 0.466299\n[470]   train's rmse: 0.000552315   train's RMSPE: 0.381819 valid's rmse: 0.000668823   valid's RMSPE: 0.465468\n[471]   train's rmse: 0.000553099   train's RMSPE: 0.382361 valid's rmse: 0.000668497   valid's RMSPE: 0.465241\n[472]   train's rmse: 0.000552469   train's RMSPE: 0.381926 valid's rmse: 0.000668646   valid's RMSPE: 0.465345\n[473]   train's rmse: 0.000550777   train's RMSPE: 0.380756 valid's rmse: 0.000674503   valid's RMSPE: 0.469421\n[474]   train's rmse: 0.000551526   train's RMSPE: 0.381273 valid's rmse: 0.000674269   valid's RMSPE: 0.469258\n[475]   train's rmse: 0.000550476   train's RMSPE: 0.380548 valid's rmse: 0.00067333    valid's RMSPE: 0.468604\n[476]   train's rmse: 0.000548667   train's RMSPE: 0.379297 valid's rmse: 0.000677053   valid's RMSPE: 0.471195\n[477]   train's rmse: 0.000549411   train's RMSPE: 0.379812 valid's rmse: 0.000676041   valid's RMSPE: 0.470491\n[478]   train's rmse: 0.000550172   train's RMSPE: 0.380338 valid's rmse: 0.000675729   valid's RMSPE: 0.470274\n[479]   train's rmse: 0.00054922    train's RMSPE: 0.37968  valid's rmse: 0.000674579   valid's RMSPE: 0.469474\n[480]   train's rmse: 0.000548775   train's RMSPE: 0.379372 valid's rmse: 0.000674616   valid's RMSPE: 0.469499\n[481]   train's rmse: 0.000549502   train's RMSPE: 0.379875 valid's rmse: 0.000674141   valid's RMSPE: 0.469169\n[482]   train's rmse: 0.000548017   train's RMSPE: 0.378848 valid's rmse: 0.000676308   valid's RMSPE: 0.470677\n[483]   train's rmse: 0.000548754   train's RMSPE: 0.379357 valid's rmse: 0.000675249   valid's RMSPE: 0.46994\n[484]   train's rmse: 0.000548072   train's RMSPE: 0.378886 valid's rmse: 0.000679483   valid's RMSPE: 0.472886\n[485]   train's rmse: 0.000548691   train's RMSPE: 0.379314 valid's rmse: 0.000679173   valid's RMSPE: 0.472671\n[486]   train's rmse: 0.000548179   train's RMSPE: 0.37896  valid's rmse: 0.000678783   valid's RMSPE: 0.472399\n[487]   train's rmse: 0.000548228   train's RMSPE: 0.378994 valid's rmse: 0.000680028   valid's RMSPE: 0.473266\n[488]   train's rmse: 0.000547578   train's RMSPE: 0.378545 valid's rmse: 0.000682124   valid's RMSPE: 0.474724\n[489]   train's rmse: 0.000546193   train's RMSPE: 0.377587 valid's rmse: 0.000681954   valid's RMSPE: 0.474606\n[490]   train's rmse: 0.000544421   train's RMSPE: 0.376362 valid's rmse: 0.000677428   valid's RMSPE: 0.471456\n[491]   train's rmse: 0.000545045   train's RMSPE: 0.376793 valid's rmse: 0.000676728   valid's RMSPE: 0.470969\n[492]   train's rmse: 0.000543259   train's RMSPE: 0.375559 valid's rmse: 0.000676152   valid's RMSPE: 0.470568\n[493]   train's rmse: 0.000543896   train's RMSPE: 0.375999 valid's rmse: 0.000675661   valid's RMSPE: 0.470227\n[494]   train's rmse: 0.000544663   train's RMSPE: 0.376529 valid's rmse: 0.000675167   valid's RMSPE: 0.469883\n[495]   train's rmse: 0.000545161   train's RMSPE: 0.376874 valid's rmse: 0.000673837   valid's RMSPE: 0.468957\n[496]   train's rmse: 0.0005458 train's RMSPE: 0.377315 valid's rmse: 0.000673451   valid's RMSPE: 0.468689\n[497]   train's rmse: 0.000543707   train's RMSPE: 0.375868 valid's rmse: 0.000672186   valid's RMSPE: 0.467808\n[498]   train's rmse: 0.000542  train's RMSPE: 0.374689 valid's rmse: 0.000672981   valid's RMSPE: 0.468361\n[499]   train's rmse: 0.000542509   train's RMSPE: 0.37504  valid's rmse: 0.000672797   valid's RMSPE: 0.468234\n[500]   train's rmse: 0.000543217   train's RMSPE: 0.37553  valid's rmse: 0.00067232    valid's RMSPE: 0.467902\n[501]   train's rmse: 0.000542702   train's RMSPE: 0.375173 valid's rmse: 0.000674297   valid's RMSPE: 0.469277\n[502]   train's rmse: 0.000543316   train's RMSPE: 0.375598 valid's rmse: 0.000673995   valid's RMSPE: 0.469067\n[503]   train's rmse: 0.000541607   train's RMSPE: 0.374416 valid's rmse: 0.000676039   valid's RMSPE: 0.470489\n[504]   train's rmse: 0.000542151   train's RMSPE: 0.374793 valid's rmse: 0.000675733   valid's RMSPE: 0.470277\n[505]   train's rmse: 0.000542681   train's RMSPE: 0.375159 valid's rmse: 0.000675406   valid's RMSPE: 0.470049\n[506]   train's rmse: 0.000540959   train's RMSPE: 0.373969 valid's rmse: 0.000676164   valid's RMSPE: 0.470577\n[507]   train's rmse: 0.000539341   train's RMSPE: 0.37285  valid's rmse: 0.000677652   valid's RMSPE: 0.471612\n[508]   train's rmse: 0.00053722    train's RMSPE: 0.371384 valid's rmse: 0.000678352   valid's RMSPE: 0.472099\n[509]   train's rmse: 0.000535913   train's RMSPE: 0.37048  valid's rmse: 0.000678771   valid's RMSPE: 0.472391\n[510]   train's rmse: 0.00053652    train's RMSPE: 0.3709   valid's rmse: 0.000678063   valid's RMSPE: 0.471898\n[511]   train's rmse: 0.000535525   train's RMSPE: 0.370212 valid's rmse: 0.00067991    valid's RMSPE: 0.473184\n[512]   train's rmse: 0.000536061   train's RMSPE: 0.370583 valid's rmse: 0.0006788 valid's RMSPE: 0.472411\n[513]   train's rmse: 0.00053672    train's RMSPE: 0.371038 valid's rmse: 0.000678085   valid's RMSPE: 0.471914\n[514]   train's rmse: 0.000537397   train's RMSPE: 0.371506 valid's rmse: 0.000677703   valid's RMSPE: 0.471647\n[515]   train's rmse: 0.000538131   train's RMSPE: 0.372014 valid's rmse: 0.000677483   valid's RMSPE: 0.471494\n[516]   train's rmse: 0.000538725   train's RMSPE: 0.372424 valid's rmse: 0.000677061   valid's RMSPE: 0.471201\n[517]   train's rmse: 0.00053945    train's RMSPE: 0.372925 valid's rmse: 0.000676565   valid's RMSPE: 0.470855\n[518]   train's rmse: 0.000540229   train's RMSPE: 0.373464 valid's rmse: 0.000676073   valid's RMSPE: 0.470514\n[519]   train's rmse: 0.000540996   train's RMSPE: 0.373994 valid's rmse: 0.000674999   valid's RMSPE: 0.469766\n[520]   train's rmse: 0.000541907   train's RMSPE: 0.374624 valid's rmse: 0.000673929   valid's RMSPE: 0.469021\n[521]   train's rmse: 0.000542765   train's RMSPE: 0.375217 valid's rmse: 0.000673474   valid's RMSPE: 0.468705\n[522]   train's rmse: 0.000541421   train's RMSPE: 0.374288 valid's rmse: 0.000673494   valid's RMSPE: 0.468718\n[523]   train's rmse: 0.000542198   train's RMSPE: 0.374825 valid's rmse: 0.000673149   valid's RMSPE: 0.468479\n[524]   train's rmse: 0.000543009   train's RMSPE: 0.375386 valid's rmse: 0.000672951   valid's RMSPE: 0.468341\n[525]   train's rmse: 0.000543837   train's RMSPE: 0.375958 valid's rmse: 0.000672628   valid's RMSPE: 0.468116\n[526]   train's rmse: 0.000544624   train's RMSPE: 0.376502 valid's rmse: 0.00067259    valid's RMSPE: 0.46809\n[527]   train's rmse: 0.000542921   train's RMSPE: 0.375325 valid's rmse: 0.000671687   valid's RMSPE: 0.467461\n[528]   train's rmse: 0.000541094   train's RMSPE: 0.374062 valid's rmse: 0.00066999    valid's RMSPE: 0.46628\n[529]   train's rmse: 0.000538875   train's RMSPE: 0.372528 valid's rmse: 0.000669766   valid's RMSPE: 0.466124\n[530]   train's rmse: 0.000539742   train's RMSPE: 0.373128 valid's rmse: 0.000669325   valid's RMSPE: 0.465817\n[531]   train's rmse: 0.000540551   train's RMSPE: 0.373686 valid's rmse: 0.000669102   valid's RMSPE: 0.465662\n[532]   train's rmse: 0.000539424   train's RMSPE: 0.372908 valid's rmse: 0.000673379   valid's RMSPE: 0.468638\n[533]   train's rmse: 0.000540139   train's RMSPE: 0.373402 valid's rmse: 0.000673305   valid's RMSPE: 0.468587\n[534]   train's rmse: 0.000538429   train's RMSPE: 0.372219 valid's rmse: 0.000674697   valid's RMSPE: 0.469556\n[535]   train's rmse: 0.000538128   train's RMSPE: 0.372011 valid's rmse: 0.000675687   valid's RMSPE: 0.470244\n[536]   train's rmse: 0.000537348   train's RMSPE: 0.371473 valid's rmse: 0.000675923   valid's RMSPE: 0.470409\n[537]   train's rmse: 0.000536075   train's RMSPE: 0.370592 valid's rmse: 0.000679657   valid's RMSPE: 0.473008\n[538]   train's rmse: 0.000536622   train's RMSPE: 0.37097  valid's rmse: 0.000679364   valid's RMSPE: 0.472804\n[539]   train's rmse: 0.000535912   train's RMSPE: 0.37048  valid's rmse: 0.000678732   valid's RMSPE: 0.472364\n[540]   train's rmse: 0.000536581   train's RMSPE: 0.370942 valid's rmse: 0.000678495   valid's RMSPE: 0.472199\n[541]   train's rmse: 0.000537433   train's RMSPE: 0.371531 valid's rmse: 0.000677999   valid's RMSPE: 0.471854\n[542]   train's rmse: 0.000536152   train's RMSPE: 0.370646 valid's rmse: 0.000679669   valid's RMSPE: 0.473016\n[543]   train's rmse: 0.00053525    train's RMSPE: 0.370022 valid's rmse: 0.00068114    valid's RMSPE: 0.47404\n[544]   train's rmse: 0.000533089   train's RMSPE: 0.368528 valid's rmse: 0.000682238   valid's RMSPE: 0.474804\n[545]   train's rmse: 0.000532032   train's RMSPE: 0.367798 valid's rmse: 0.000681058   valid's RMSPE: 0.473982\n[546]   train's rmse: 0.000531488   train's RMSPE: 0.367421 valid's rmse: 0.000681456   valid's RMSPE: 0.47426\n[547]   train's rmse: 0.00053217    train's RMSPE: 0.367893 valid's rmse: 0.000681096   valid's RMSPE: 0.474009\n[548]   train's rmse: 0.000531346   train's RMSPE: 0.367323 valid's rmse: 0.000681127   valid's RMSPE: 0.474031\n[549]   train's rmse: 0.000531898   train's RMSPE: 0.367705 valid's rmse: 0.000680666   valid's RMSPE: 0.47371\n[550]   train's rmse: 0.000532526   train's RMSPE: 0.368139 valid's rmse: 0.000680097   valid's RMSPE: 0.473314\n[551]   train's rmse: 0.000531156   train's RMSPE: 0.367192 valid's rmse: 0.000681566   valid's RMSPE: 0.474336\n[552]   train's rmse: 0.000531799   train's RMSPE: 0.367636 valid's rmse: 0.000681185   valid's RMSPE: 0.474071\n[553]   train's rmse: 0.000532548   train's RMSPE: 0.368154 valid's rmse: 0.00068059    valid's RMSPE: 0.473657\n[554]   train's rmse: 0.00053321    train's RMSPE: 0.368611 valid's rmse: 0.000680266   valid's RMSPE: 0.473432\n[555]   train's rmse: 0.000533848   train's RMSPE: 0.369053 valid's rmse: 0.000679797   valid's RMSPE: 0.473105\n[556]   train's rmse: 0.000532637   train's RMSPE: 0.368216 valid's rmse: 0.000678295   valid's RMSPE: 0.47206\n[557]   train's rmse: 0.000531933   train's RMSPE: 0.367729 valid's rmse: 0.000679565   valid's RMSPE: 0.472943\n[558]   train's rmse: 0.00053097    train's RMSPE: 0.367063 valid's rmse: 0.000680753   valid's RMSPE: 0.47377\n[559]   train's rmse: 0.000531723   train's RMSPE: 0.367584 valid's rmse: 0.000680156   valid's RMSPE: 0.473355\n[560]   train's rmse: 0.00053116    train's RMSPE: 0.367195 valid's rmse: 0.00068089    valid's RMSPE: 0.473865\n[561]   train's rmse: 0.000531772   train's RMSPE: 0.367618 valid's rmse: 0.000680598   valid's RMSPE: 0.473662\n[562]   train's rmse: 0.000532508   train's RMSPE: 0.368126 valid's rmse: 0.000680122   valid's RMSPE: 0.473331\n[563]   train's rmse: 0.000531575   train's RMSPE: 0.367481 valid's rmse: 0.000678298   valid's RMSPE: 0.472061\n[564]   train's rmse: 0.000532308   train's RMSPE: 0.367988 valid's rmse: 0.000677039   valid's RMSPE: 0.471185\n[565]   train's rmse: 0.000530875   train's RMSPE: 0.366998 valid's rmse: 0.000676222   valid's RMSPE: 0.470617\n[566]   train's rmse: 0.000531627   train's RMSPE: 0.367518 valid's rmse: 0.000675642   valid's RMSPE: 0.470213\n[567]   train's rmse: 0.000532254   train's RMSPE: 0.367951 valid's rmse: 0.000675162   valid's RMSPE: 0.469879\n[568]   train's rmse: 0.00053135    train's RMSPE: 0.367326 valid's rmse: 0.00067508    valid's RMSPE: 0.469822\n[569]   train's rmse: 0.00053187    train's RMSPE: 0.367685 valid's rmse: 0.000674639   valid's RMSPE: 0.469516\n[570]   train's rmse: 0.000532439   train's RMSPE: 0.368078 valid's rmse: 0.000674221   valid's RMSPE: 0.469225\n[571]   train's rmse: 0.000533159   train's RMSPE: 0.368577 valid's rmse: 0.000673922   valid's RMSPE: 0.469017\n[572]   train's rmse: 0.000533913   train's RMSPE: 0.369098 valid's rmse: 0.000673596   valid's RMSPE: 0.468789\n[573]   train's rmse: 0.000534659   train's RMSPE: 0.369614 valid's rmse: 0.000673206   valid's RMSPE: 0.468518\n[574]   train's rmse: 0.000533906   train's RMSPE: 0.369093 valid's rmse: 0.000676219   valid's RMSPE: 0.470615\n[575]   train's rmse: 0.000534615   train's RMSPE: 0.369583 valid's rmse: 0.000675952   valid's RMSPE: 0.470429\n[576]   train's rmse: 0.000535348   train's RMSPE: 0.37009  valid's rmse: 0.000675641   valid's RMSPE: 0.470212\n[577]   train's rmse: 0.000536022   train's RMSPE: 0.370556 valid's rmse: 0.000675543   valid's RMSPE: 0.470145\n[578]   train's rmse: 0.000536363   train's RMSPE: 0.370791 valid's rmse: 0.000678308   valid's RMSPE: 0.472069\n[579]   train's rmse: 0.000536048   train's RMSPE: 0.370573 valid's rmse: 0.000677162   valid's RMSPE: 0.471271\n[580]   train's rmse: 0.000536757   train's RMSPE: 0.371064 valid's rmse: 0.000676827   valid's RMSPE: 0.471038\n[581]   train's rmse: 0.000534986   train's RMSPE: 0.36984  valid's rmse: 0.000679579   valid's RMSPE: 0.472954\n[582]   train's rmse: 0.000535603   train's RMSPE: 0.370266 valid's rmse: 0.000679443   valid's RMSPE: 0.472858\n[583]   train's rmse: 0.000536214   train's RMSPE: 0.370688 valid's rmse: 0.000679356   valid's RMSPE: 0.472798\n[584]   train's rmse: 0.000534622   train's RMSPE: 0.369588 valid's rmse: 0.000681091   valid's RMSPE: 0.474006\n[585]   train's rmse: 0.000535319   train's RMSPE: 0.37007  valid's rmse: 0.000681  valid's RMSPE: 0.473943\n[586]   train's rmse: 0.000533708   train's RMSPE: 0.368956 valid's rmse: 0.000681174   valid's RMSPE: 0.474064\n[587]   train's rmse: 0.000532517   train's RMSPE: 0.368133 valid's rmse: 0.000681679   valid's RMSPE: 0.474415\n[588]   train's rmse: 0.000531682   train's RMSPE: 0.367556 valid's rmse: 0.000683876   valid's RMSPE: 0.475944\n[589]   train's rmse: 0.000532315   train's RMSPE: 0.367993 valid's rmse: 0.000683415   valid's RMSPE: 0.475623\n[590]   train's rmse: 0.000531685   train's RMSPE: 0.367557 valid's rmse: 0.000682341   valid's RMSPE: 0.474875\n[591]   train's rmse: 0.000532393   train's RMSPE: 0.368047 valid's rmse: 0.000681531   valid's RMSPE: 0.474312\n[592]   train's rmse: 0.000530895   train's RMSPE: 0.367011 valid's rmse: 0.000681215   valid's RMSPE: 0.474092\n[593]   train's rmse: 0.000531429   train's RMSPE: 0.36738  valid's rmse: 0.000680809   valid's RMSPE: 0.47381\n[594]   train's rmse: 0.000532029   train's RMSPE: 0.367795 valid's rmse: 0.000680523   valid's RMSPE: 0.47361\n[595]   train's rmse: 0.000530556   train's RMSPE: 0.366777 valid's rmse: 0.000677583   valid's RMSPE: 0.471564\n[596]   train's rmse: 0.000531269   train's RMSPE: 0.36727  valid's rmse: 0.000677227   valid's RMSPE: 0.471317\n[597]   train's rmse: 0.000532079   train's RMSPE: 0.36783  valid's rmse: 0.000676682   valid's RMSPE: 0.470937\n[598]   train's rmse: 0.000530931   train's RMSPE: 0.367037 valid's rmse: 0.000677245   valid's RMSPE: 0.471329\n[599]   train's rmse: 0.000530253   train's RMSPE: 0.366568 valid's rmse: 0.000675538   valid's RMSPE: 0.470141\n[600]   train's rmse: 0.000528937   train's RMSPE: 0.365658 valid's rmse: 0.000675517   valid's RMSPE: 0.470126\n[601]   train's rmse: 0.000527883   train's RMSPE: 0.364929 valid's rmse: 0.000675456   valid's RMSPE: 0.470084\n[602]   train's rmse: 0.000527755   train's RMSPE: 0.364841 valid's rmse: 0.000676696   valid's RMSPE: 0.470947\n[603]   train's rmse: 0.000528316   train's RMSPE: 0.365229 valid's rmse: 0.000676316   valid's RMSPE: 0.470683\n[604]   train's rmse: 0.000528995   train's RMSPE: 0.365698 valid's rmse: 0.000675192   valid's RMSPE: 0.4699\n[605]   train's rmse: 0.000527224   train's RMSPE: 0.364473 valid's rmse: 0.000679365   valid's RMSPE: 0.472804\n[606]   train's rmse: 0.000526197   train's RMSPE: 0.363764 valid's rmse: 0.000678984   valid's RMSPE: 0.472539\n[607]   train's rmse: 0.000525868   train's RMSPE: 0.363536 valid's rmse: 0.000681577   valid's RMSPE: 0.474344\n[608]   train's rmse: 0.000524892   train's RMSPE: 0.362861 valid's rmse: 0.000686668   valid's RMSPE: 0.477887\n[609]   train's rmse: 0.000525265   train's RMSPE: 0.363119 valid's rmse: 0.00068617    valid's RMSPE: 0.47754\n[610]   train's rmse: 0.000524242   train's RMSPE: 0.362412 valid's rmse: 0.000688068   valid's RMSPE: 0.478861\n[611]   train's rmse: 0.000523856   train's RMSPE: 0.362145 valid's rmse: 0.000694388   valid's RMSPE: 0.48326\n[612]   train's rmse: 0.000523214   train's RMSPE: 0.361702 valid's rmse: 0.000693686   valid's RMSPE: 0.482771\n[613]   train's rmse: 0.000521427   train's RMSPE: 0.360466 valid's rmse: 0.000693834   valid's RMSPE: 0.482874\n[614]   train's rmse: 0.00052189    train's RMSPE: 0.360786 valid's rmse: 0.000693156   valid's RMSPE: 0.482402\n[615]   train's rmse: 0.000521589   train's RMSPE: 0.360578 valid's rmse: 0.000697899   valid's RMSPE: 0.485703\n[616]   train's rmse: 0.000522043   train's RMSPE: 0.360892 valid's rmse: 0.000697354   valid's RMSPE: 0.485324\n[617]   train's rmse: 0.00052177    train's RMSPE: 0.360703 valid's rmse: 0.000699271   valid's RMSPE: 0.486658\n[618]   train's rmse: 0.00052034    train's RMSPE: 0.359715 valid's rmse: 0.000699611   valid's RMSPE: 0.486895\n[619]   train's rmse: 0.000520842   train's RMSPE: 0.360061 valid's rmse: 0.000698935   valid's RMSPE: 0.486424\n[620]   train's rmse: 0.000521238   train's RMSPE: 0.360336 valid's rmse: 0.000698554   valid's RMSPE: 0.486159\n[621]   train's rmse: 0.000521618   train's RMSPE: 0.360598 valid's rmse: 0.000698267   valid's RMSPE: 0.485959\n[622]   train's rmse: 0.000522054   train's RMSPE: 0.360899 valid's rmse: 0.000696458   valid's RMSPE: 0.484701\n[623]   train's rmse: 0.000522526   train's RMSPE: 0.361226 valid's rmse: 0.000695968   valid's RMSPE: 0.484359\n[624]   train's rmse: 0.000522567   train's RMSPE: 0.361254 valid's rmse: 0.000695881   valid's RMSPE: 0.484299\n[625]   train's rmse: 0.000521168   train's RMSPE: 0.360287 valid's rmse: 0.000697661   valid's RMSPE: 0.485537\n[626]   train's rmse: 0.000520799   train's RMSPE: 0.360032 valid's rmse: 0.000699028   valid's RMSPE: 0.486489\n[627]   train's rmse: 0.000521151   train's RMSPE: 0.360276 valid's rmse: 0.000698568   valid's RMSPE: 0.486169\n[628]   train's rmse: 0.000521537   train's RMSPE: 0.360542 valid's rmse: 0.000697909   valid's RMSPE: 0.48571\n[629]   train's rmse: 0.000521988   train's RMSPE: 0.360854 valid's rmse: 0.00069632    valid's RMSPE: 0.484604\n[630]   train's rmse: 0.000521983   train's RMSPE: 0.360851 valid's rmse: 0.000696975   valid's RMSPE: 0.48506\n[631]   train's rmse: 0.000522548   train's RMSPE: 0.361241 valid's rmse: 0.000696412   valid's RMSPE: 0.484668\n[632]   train's rmse: 0.000521416   train's RMSPE: 0.360459 valid's rmse: 0.000702151   valid's RMSPE: 0.488662\n[633]   train's rmse: 0.000521923   train's RMSPE: 0.360809 valid's rmse: 0.000701859   valid's RMSPE: 0.488459\n[634]   train's rmse: 0.000520978   train's RMSPE: 0.360156 valid's rmse: 0.000708692   valid's RMSPE: 0.493214\n[635]   train's rmse: 0.000521416   train's RMSPE: 0.360459 valid's rmse: 0.000707034   valid's RMSPE: 0.492061\n[636]   train's rmse: 0.000521089   train's RMSPE: 0.360232 valid's rmse: 0.0007112 valid's RMSPE: 0.49496\n[637]   train's rmse: 0.000519798   train's RMSPE: 0.35934  valid's rmse: 0.000710311   valid's RMSPE: 0.494342\n[638]   train's rmse: 0.000518654   train's RMSPE: 0.358549 valid's rmse: 0.000708028   valid's RMSPE: 0.492752\n[639]   train's rmse: 0.000517426   train's RMSPE: 0.3577   valid's rmse: 0.00071246    valid's RMSPE: 0.495837\n[640]   train's rmse: 0.000516908   train's RMSPE: 0.357342 valid's rmse: 0.000714285   valid's RMSPE: 0.497107\n[641]   train's rmse: 0.000517337   train's RMSPE: 0.357638 valid's rmse: 0.000713473   valid's RMSPE: 0.496542\n[642]   train's rmse: 0.000517754   train's RMSPE: 0.357927 valid's rmse: 0.000711593   valid's RMSPE: 0.495233\n[643]   train's rmse: 0.000517494   train's RMSPE: 0.357747 valid's rmse: 0.000716782   valid's RMSPE: 0.498845\n[644]   train's rmse: 0.000516705   train's RMSPE: 0.357201 valid's rmse: 0.000716931   valid's RMSPE: 0.498948\n[645]   train's rmse: 0.000517142   train's RMSPE: 0.357503 valid's rmse: 0.000716216   valid's RMSPE: 0.498451\n[646]   train's rmse: 0.000516904   train's RMSPE: 0.357339 valid's rmse: 0.00071834    valid's RMSPE: 0.499929\n[647]   train's rmse: 0.000516625   train's RMSPE: 0.357146 valid's rmse: 0.000717673   valid's RMSPE: 0.499465\n[648]   train's rmse: 0.000515609   train's RMSPE: 0.356444 valid's rmse: 0.000720076   valid's RMSPE: 0.501137\n[649]   train's rmse: 0.000516119   train's RMSPE: 0.356796 valid's rmse: 0.000719206   valid's RMSPE: 0.500532\n[650]   train's rmse: 0.000516542   train's RMSPE: 0.357089 valid's rmse: 0.000718446   valid's RMSPE: 0.500003\n[651]   train's rmse: 0.000516904   train's RMSPE: 0.357339 valid's rmse: 0.000717928   valid's RMSPE: 0.499642\n[652]   train's rmse: 0.00051608    train's RMSPE: 0.356769 valid's rmse: 0.000719063   valid's RMSPE: 0.500432\n[653]   train's rmse: 0.000516539   train's RMSPE: 0.357087 valid's rmse: 0.000718314   valid's RMSPE: 0.499911\n[654]   train's rmse: 0.000515573   train's RMSPE: 0.356419 valid's rmse: 0.00071749    valid's RMSPE: 0.499337\n[655]   train's rmse: 0.000515999   train's RMSPE: 0.356713 valid's rmse: 0.000716621   valid's RMSPE: 0.498733\n[656]   train's rmse: 0.000514339   train's RMSPE: 0.355566 valid's rmse: 0.00071645    valid's RMSPE: 0.498613\n[657]   train's rmse: 0.000513181   train's RMSPE: 0.354766 valid's rmse: 0.0007137 valid's RMSPE: 0.4967\n[658]   train's rmse: 0.000512834   train's RMSPE: 0.354525 valid's rmse: 0.000713122   valid's RMSPE: 0.496298\n[659]   train's rmse: 0.000512925   train's RMSPE: 0.354588 valid's rmse: 0.00071545    valid's RMSPE: 0.497918\n[660]   train's rmse: 0.000513425   train's RMSPE: 0.354934 valid's rmse: 0.000714786   valid's RMSPE: 0.497456\n[661]   train's rmse: 0.00051289    train's RMSPE: 0.354564 valid's rmse: 0.000715347   valid's RMSPE: 0.497846\n[662]   train's rmse: 0.00051228    train's RMSPE: 0.354143 valid's rmse: 0.000716499   valid's RMSPE: 0.498648\n[663]   train's rmse: 0.0005127 train's RMSPE: 0.354433 valid's rmse: 0.000715821   valid's RMSPE: 0.498176\n[664]   train's rmse: 0.000513057   train's RMSPE: 0.35468  valid's rmse: 0.000715188   valid's RMSPE: 0.497735\n[665]   train's rmse: 0.000513498   train's RMSPE: 0.354985 valid's rmse: 0.000714812   valid's RMSPE: 0.497474\n[666]   train's rmse: 0.000511869   train's RMSPE: 0.353859 valid's rmse: 0.000714399   valid's RMSPE: 0.497186\n[667]   train's rmse: 0.000512219   train's RMSPE: 0.354101 valid's rmse: 0.000713818   valid's RMSPE: 0.496782\n[668]   train's rmse: 0.000511059   train's RMSPE: 0.353298 valid's rmse: 0.000714624   valid's RMSPE: 0.497343\n[669]   train's rmse: 0.000511566   train's RMSPE: 0.353649 valid's rmse: 0.000713724   valid's RMSPE: 0.496716\nEarly stopping, best iteration is:\n[270]   0.44643691326634993\n269\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:183: UserWarning: Early stopping is not available in dart mode\n  _log_warning('Early stopping is not available in dart mode')\n\n\n[1] train's rmse: 0.0011208 train's RMSPE: 0.737681 valid's rmse: 0.00103301    valid's RMSPE: 0.841254\n[2] train's rmse: 0.00109189    train's RMSPE: 0.718649 valid's rmse: 0.00100326    valid's RMSPE: 0.817029\n[3] train's rmse: 0.00106288    train's RMSPE: 0.699559 valid's rmse: 0.000980839   valid's RMSPE: 0.79877\n[4] train's rmse: 0.00103749    train's RMSPE: 0.682849 valid's rmse: 0.000955038   valid's RMSPE: 0.777758\n[5] train's rmse: 0.0010122 train's RMSPE: 0.666201 valid's rmse: 0.000928968   valid's RMSPE: 0.756527\n[6] train's rmse: 0.000990282   train's RMSPE: 0.651776 valid's rmse: 0.000907598   valid's RMSPE: 0.739124\n[7] train's rmse: 0.000993463   train's RMSPE: 0.65387  valid's rmse: 0.00090784    valid's RMSPE: 0.739322\n[8] train's rmse: 0.000973497   train's RMSPE: 0.640729 valid's rmse: 0.000891454   valid's RMSPE: 0.725977\n[9] train's rmse: 0.000952896   train's RMSPE: 0.627169 valid's rmse: 0.000868728   valid's RMSPE: 0.70747\n[10]    train's rmse: 0.000956238   train's RMSPE: 0.629369 valid's rmse: 0.000875328   valid's RMSPE: 0.712844\n[11]    train's rmse: 0.000937655   train's RMSPE: 0.617138 valid's rmse: 0.000853181   valid's RMSPE: 0.694808\n[12]    train's rmse: 0.000942053   train's RMSPE: 0.620033 valid's rmse: 0.000859258   valid's RMSPE: 0.699758\n[13]    train's rmse: 0.000924938   train's RMSPE: 0.608768 valid's rmse: 0.000842403   valid's RMSPE: 0.686031\n[14]    train's rmse: 0.0009097 train's RMSPE: 0.598739 valid's rmse: 0.000828568   valid's RMSPE: 0.674764\n[15]    train's rmse: 0.000892325   train's RMSPE: 0.587304 valid's rmse: 0.000815727   valid's RMSPE: 0.664307\n[16]    train's rmse: 0.000875349   train's RMSPE: 0.57613  valid's rmse: 0.000801713   valid's RMSPE: 0.652895\n[17]    train's rmse: 0.000882596   train's RMSPE: 0.5809   valid's rmse: 0.000806021   valid's RMSPE: 0.656403\n[18]    train's rmse: 0.000871523   train's RMSPE: 0.573612 valid's rmse: 0.000801581   valid's RMSPE: 0.652787\n[19]    train's rmse: 0.000872368   train's RMSPE: 0.574168 valid's rmse: 0.000801211   valid's RMSPE: 0.652485\n[20]    train's rmse: 0.000872947   train's RMSPE: 0.574549 valid's rmse: 0.000802853   valid's RMSPE: 0.653822\n[21]    train's rmse: 0.000880755   train's RMSPE: 0.579689 valid's rmse: 0.00081084    valid's RMSPE: 0.660327\n[22]    train's rmse: 0.000903849   train's RMSPE: 0.594888 valid's rmse: 0.00077994    valid's RMSPE: 0.635163\n[23]    train's rmse: 0.000888042   train's RMSPE: 0.584484 valid's rmse: 0.000765825   valid's RMSPE: 0.623668\n[24]    train's rmse: 0.000934041   train's RMSPE: 0.61476  valid's rmse: 0.000773348   valid's RMSPE: 0.629795\n[25]    train's rmse: 0.000928025   train's RMSPE: 0.6108   valid's rmse: 0.000768265   valid's RMSPE: 0.625655\n[26]    train's rmse: 0.000913466   train's RMSPE: 0.601218 valid's rmse: 0.0007554 valid's RMSPE: 0.615179\n[27]    train's rmse: 0.000896572   train's RMSPE: 0.590099 valid's rmse: 0.000742415   valid's RMSPE: 0.604604\n[28]    train's rmse: 0.000901471   train's RMSPE: 0.593323 valid's rmse: 0.000746915   valid's RMSPE: 0.608268\n[29]    train's rmse: 0.000907181   train's RMSPE: 0.597081 valid's rmse: 0.000753269   valid's RMSPE: 0.613443\n[30]    train's rmse: 0.000889808   train's RMSPE: 0.585647 valid's rmse: 0.000740253   valid's RMSPE: 0.602843\n[31]    train's rmse: 0.000874261   train's RMSPE: 0.575414 valid's rmse: 0.00072694    valid's RMSPE: 0.592001\n[32]    train's rmse: 0.000880324   train's RMSPE: 0.579405 valid's rmse: 0.000732249   valid's RMSPE: 0.596325\n[33]    train's rmse: 0.000866975   train's RMSPE: 0.570619 valid's rmse: 0.000717694   valid's RMSPE: 0.584472\n[34]    train's rmse: 0.000855472   train's RMSPE: 0.563048 valid's rmse: 0.000709795   valid's RMSPE: 0.578039\n[35]    train's rmse: 0.000841592   train's RMSPE: 0.553913 valid's rmse: 0.000700186   valid's RMSPE: 0.570213\n[36]    train's rmse: 0.000829155   train's RMSPE: 0.545727 valid's rmse: 0.000689645   valid's RMSPE: 0.561629\n[37]    train's rmse: 0.000832103   train's RMSPE: 0.547667 valid's rmse: 0.000692815   valid's RMSPE: 0.56421\n[38]    train's rmse: 0.000862725   train's RMSPE: 0.567822 valid's rmse: 0.000701082   valid's RMSPE: 0.570943\n[39]    train's rmse: 0.000846139   train's RMSPE: 0.556905 valid's rmse: 0.000692529   valid's RMSPE: 0.563977\n[40]    train's rmse: 0.0008312 train's RMSPE: 0.547073 valid's rmse: 0.000679825   valid's RMSPE: 0.553632\n[41]    train's rmse: 0.000836536   train's RMSPE: 0.550584 valid's rmse: 0.000684527   valid's RMSPE: 0.557461\n[42]    train's rmse: 0.000840885   train's RMSPE: 0.553447 valid's rmse: 0.000689299   valid's RMSPE: 0.561347\n[43]    train's rmse: 0.000826495   train's RMSPE: 0.543976 valid's rmse: 0.000680083   valid's RMSPE: 0.553842\n[44]    train's rmse: 0.000814143   train's RMSPE: 0.535846 valid's rmse: 0.000669283   valid's RMSPE: 0.545047\n[45]    train's rmse: 0.000801948   train's RMSPE: 0.52782  valid's rmse: 0.000657537   valid's RMSPE: 0.535481\n[46]    train's rmse: 0.000808356   train's RMSPE: 0.532037 valid's rmse: 0.000663641   valid's RMSPE: 0.540452\n[47]    train's rmse: 0.000796989   train's RMSPE: 0.524556 valid's rmse: 0.000658079   valid's RMSPE: 0.535923\n[48]    train's rmse: 0.000802883   train's RMSPE: 0.528435 valid's rmse: 0.000664241   valid's RMSPE: 0.540941\n[49]    train's rmse: 0.000808891   train's RMSPE: 0.532389 valid's rmse: 0.000668661   valid's RMSPE: 0.54454\n[50]    train's rmse: 0.000798266   train's RMSPE: 0.525396 valid's rmse: 0.000660888   valid's RMSPE: 0.53821\n[51]    train's rmse: 0.000802445   train's RMSPE: 0.528147 valid's rmse: 0.000664536   valid's RMSPE: 0.541181\n[52]    train's rmse: 0.000805662   train's RMSPE: 0.530264 valid's rmse: 0.000666164   valid's RMSPE: 0.542507\n[53]    train's rmse: 0.000810043   train's RMSPE: 0.533148 valid's rmse: 0.000670082   valid's RMSPE: 0.545697\n[54]    train's rmse: 0.000798402   train's RMSPE: 0.525486 valid's rmse: 0.000660558   valid's RMSPE: 0.537941\n[55]    train's rmse: 0.000801697   train's RMSPE: 0.527654 valid's rmse: 0.000663667   valid's RMSPE: 0.540473\n[56]    train's rmse: 0.000790637   train's RMSPE: 0.520375 valid's rmse: 0.000655219   valid's RMSPE: 0.533593\n[57]    train's rmse: 0.000780436   train's RMSPE: 0.513661 valid's rmse: 0.000647175   valid's RMSPE: 0.527042\n[58]    train's rmse: 0.000771416   train's RMSPE: 0.507724 valid's rmse: 0.000642017   valid's RMSPE: 0.522842\n[59]    train's rmse: 0.00077562    train's RMSPE: 0.510491 valid's rmse: 0.000645582   valid's RMSPE: 0.525746\n[60]    train's rmse: 0.000769137   train's RMSPE: 0.506224 valid's rmse: 0.000639302   valid's RMSPE: 0.520631\n[61]    train's rmse: 0.00077554    train's RMSPE: 0.510439 valid's rmse: 0.000643835   valid's RMSPE: 0.524322\n[62]    train's rmse: 0.000769168   train's RMSPE: 0.506245 valid's rmse: 0.00063582    valid's RMSPE: 0.517795\n[63]    train's rmse: 0.000787599   train's RMSPE: 0.518376 valid's rmse: 0.000640391   valid's RMSPE: 0.521518\n[64]    train's rmse: 0.000807992   train's RMSPE: 0.531798 valid's rmse: 0.00064938    valid's RMSPE: 0.528838\n[65]    train's rmse: 0.000814491   train's RMSPE: 0.536075 valid's rmse: 0.000655247   valid's RMSPE: 0.533616\n[66]    train's rmse: 0.000799512   train's RMSPE: 0.526217 valid's rmse: 0.000643457   valid's RMSPE: 0.524015\n[67]    train's rmse: 0.000802755   train's RMSPE: 0.528351 valid's rmse: 0.000646021   valid's RMSPE: 0.526103\n[68]    train's rmse: 0.000790663   train's RMSPE: 0.520393 valid's rmse: 0.000638571   valid's RMSPE: 0.520035\n[69]    train's rmse: 0.000781721   train's RMSPE: 0.514507 valid's rmse: 0.000630408   valid's RMSPE: 0.513388\n[70]    train's rmse: 0.000786439   train's RMSPE: 0.517612 valid's rmse: 0.000635145   valid's RMSPE: 0.517245\n[71]    train's rmse: 0.000789966   train's RMSPE: 0.519933 valid's rmse: 0.000638286   valid's RMSPE: 0.519803\n[72]    train's rmse: 0.000777261   train's RMSPE: 0.511572 valid's rmse: 0.00063292    valid's RMSPE: 0.515434\n[73]    train's rmse: 0.000768837   train's RMSPE: 0.506027 valid's rmse: 0.000629048   valid's RMSPE: 0.51228\n[74]    train's rmse: 0.000773518   train's RMSPE: 0.509108 valid's rmse: 0.000632997   valid's RMSPE: 0.515496\n[75]    train's rmse: 0.000764671   train's RMSPE: 0.503285 valid's rmse: 0.000625894   valid's RMSPE: 0.509712\n[76]    train's rmse: 0.000769679   train's RMSPE: 0.506581 valid's rmse: 0.000630033   valid's RMSPE: 0.513083\n[77]    train's rmse: 0.000760157   train's RMSPE: 0.500314 valid's rmse: 0.000624107   valid's RMSPE: 0.508256\n[78]    train's rmse: 0.000760651   train's RMSPE: 0.500639 valid's rmse: 0.000624177   valid's RMSPE: 0.508314\n[79]    train's rmse: 0.000765634   train's RMSPE: 0.503919 valid's rmse: 0.000627987   valid's RMSPE: 0.511417\n[80]    train's rmse: 0.000768574   train's RMSPE: 0.505854 valid's rmse: 0.000630112   valid's RMSPE: 0.513147\n[81]    train's rmse: 0.000761017   train's RMSPE: 0.50088  valid's rmse: 0.000623013   valid's RMSPE: 0.507365\n[82]    train's rmse: 0.000752861   train's RMSPE: 0.495512 valid's rmse: 0.000614302   valid's RMSPE: 0.500272\n[83]    train's rmse: 0.000756609   train's RMSPE: 0.497979 valid's rmse: 0.000617499   valid's RMSPE: 0.502875\n[84]    train's rmse: 0.000750079   train's RMSPE: 0.493681 valid's rmse: 0.000616583   valid's RMSPE: 0.50213\n[85]    train's rmse: 0.000753193   train's RMSPE: 0.495731 valid's rmse: 0.000619017   valid's RMSPE: 0.504111\n[86]    train's rmse: 0.000757136   train's RMSPE: 0.498326 valid's rmse: 0.000621335   valid's RMSPE: 0.505999\n[87]    train's rmse: 0.000749062   train's RMSPE: 0.493012 valid's rmse: 0.00061452    valid's RMSPE: 0.500449\n[88]    train's rmse: 0.000751967   train's RMSPE: 0.494924 valid's rmse: 0.000617192   valid's RMSPE: 0.502625\n[89]    train's rmse: 0.000755928   train's RMSPE: 0.497531 valid's rmse: 0.000620685   valid's RMSPE: 0.50547\n[90]    train's rmse: 0.00076031    train's RMSPE: 0.500415 valid's rmse: 0.000624002   valid's RMSPE: 0.508171\n[91]    train's rmse: 0.000764628   train's RMSPE: 0.503257 valid's rmse: 0.000626572   valid's RMSPE: 0.510264\n[92]    train's rmse: 0.000758864   train's RMSPE: 0.499463 valid's rmse: 0.000624761   valid's RMSPE: 0.508789\n[93]    train's rmse: 0.000752303   train's RMSPE: 0.495145 valid's rmse: 0.000619934   valid's RMSPE: 0.504858\n[94]    train's rmse: 0.00074527    train's RMSPE: 0.490516 valid's rmse: 0.00061447    valid's RMSPE: 0.500409\n[95]    train's rmse: 0.000736511   train's RMSPE: 0.484751 valid's rmse: 0.000613556   valid's RMSPE: 0.499664\n[96]    train's rmse: 0.000733428   train's RMSPE: 0.482722 valid's rmse: 0.000609045   valid's RMSPE: 0.49599\n[97]    train's rmse: 0.000724166   train's RMSPE: 0.476626 valid's rmse: 0.00060928    valid's RMSPE: 0.496182\n[98]    train's rmse: 0.000727819   train's RMSPE: 0.47903  valid's rmse: 0.000612254   valid's RMSPE: 0.498603\n[99]    train's rmse: 0.000730535   train's RMSPE: 0.480818 valid's rmse: 0.00061356    valid's RMSPE: 0.499667\n[100]   train's rmse: 0.000733235   train's RMSPE: 0.482595 valid's rmse: 0.000614763   valid's RMSPE: 0.500647\n[101]   train's rmse: 0.000726366   train's RMSPE: 0.478074 valid's rmse: 0.000610824   valid's RMSPE: 0.497439\n[102]   train's rmse: 0.000719735   train's RMSPE: 0.473709 valid's rmse: 0.000607749   valid's RMSPE: 0.494935\n[103]   train's rmse: 0.000721965   train's RMSPE: 0.475177 valid's rmse: 0.000608485   valid's RMSPE: 0.495534\n[104]   train's rmse: 0.000724002   train's RMSPE: 0.476518 valid's rmse: 0.000610065   valid's RMSPE: 0.496821\n[105]   train's rmse: 0.000726779   train's RMSPE: 0.478345 valid's rmse: 0.000612181   valid's RMSPE: 0.498544\n[106]   train's rmse: 0.000738691   train's RMSPE: 0.486186 valid's rmse: 0.000612712   valid's RMSPE: 0.498977\n[107]   train's rmse: 0.000742405   train's RMSPE: 0.48863  valid's rmse: 0.000614749   valid's RMSPE: 0.500636\n[108]   train's rmse: 0.0007464 train's RMSPE: 0.491259 valid's rmse: 0.000617183   valid's RMSPE: 0.502618\n[109]   train's rmse: 0.000750431   train's RMSPE: 0.493913 valid's rmse: 0.000619601   valid's RMSPE: 0.504587\n[110]   train's rmse: 0.000742206   train's RMSPE: 0.488499 valid's rmse: 0.000612947   valid's RMSPE: 0.499168\n[111]   train's rmse: 0.000746003   train's RMSPE: 0.490998 valid's rmse: 0.00061525    valid's RMSPE: 0.501044\n[112]   train's rmse: 0.000750033   train's RMSPE: 0.493651 valid's rmse: 0.000618101   valid's RMSPE: 0.503366\n[113]   train's rmse: 0.000745426   train's RMSPE: 0.490619 valid's rmse: 0.000611998   valid's RMSPE: 0.498395\n[114]   train's rmse: 0.000749347   train's RMSPE: 0.4932   valid's rmse: 0.000615149   valid's RMSPE: 0.500961\n[115]   train's rmse: 0.000752398   train's RMSPE: 0.495208 valid's rmse: 0.000616992   valid's RMSPE: 0.502463\n[116]   train's rmse: 0.000743553   train's RMSPE: 0.489386 valid's rmse: 0.000615993   valid's RMSPE: 0.501649\n[117]   train's rmse: 0.000746008   train's RMSPE: 0.491002 valid's rmse: 0.000618  valid's RMSPE: 0.503283\n[118]   train's rmse: 0.000749266   train's RMSPE: 0.493146 valid's rmse: 0.000619966   valid's RMSPE: 0.504884\n[119]   train's rmse: 0.000751477   train's RMSPE: 0.494601 valid's rmse: 0.000620975   valid's RMSPE: 0.505706\n[120]   train's rmse: 0.000741518   train's RMSPE: 0.488046 valid's rmse: 0.00061515    valid's RMSPE: 0.500962\n[121]   train's rmse: 0.000744512   train's RMSPE: 0.490017 valid's rmse: 0.00061706    valid's RMSPE: 0.502517\n[122]   train's rmse: 0.00074813    train's RMSPE: 0.492398 valid's rmse: 0.000619561   valid's RMSPE: 0.504554\n[123]   train's rmse: 0.000757456   train's RMSPE: 0.498537 valid's rmse: 0.00062183    valid's RMSPE: 0.506403\n[124]   train's rmse: 0.000759782   train's RMSPE: 0.500067 valid's rmse: 0.000623797   valid's RMSPE: 0.508004\n[125]   train's rmse: 0.000749163   train's RMSPE: 0.493078 valid's rmse: 0.00061664    valid's RMSPE: 0.502176\n[126]   train's rmse: 0.000752109   train's RMSPE: 0.495017 valid's rmse: 0.000618873   valid's RMSPE: 0.503994\n[127]   train's rmse: 0.000754407   train's RMSPE: 0.496529 valid's rmse: 0.000620997   valid's RMSPE: 0.505724\n[128]   train's rmse: 0.00074613    train's RMSPE: 0.491082 valid's rmse: 0.000615697   valid's RMSPE: 0.501408\n[129]   train's rmse: 0.000737034   train's RMSPE: 0.485095 valid's rmse: 0.000613767   valid's RMSPE: 0.499836\n[130]   train's rmse: 0.000744608   train's RMSPE: 0.49008  valid's rmse: 0.000614843   valid's RMSPE: 0.500713\n[131]   train's rmse: 0.000737415   train's RMSPE: 0.485346 valid's rmse: 0.000610068   valid's RMSPE: 0.496824\n[132]   train's rmse: 0.000739954   train's RMSPE: 0.487017 valid's rmse: 0.000611955   valid's RMSPE: 0.49836\n[133]   train's rmse: 0.000730145   train's RMSPE: 0.480561 valid's rmse: 0.00060413    valid's RMSPE: 0.491987\n[134]   train's rmse: 0.000733626   train's RMSPE: 0.482852 valid's rmse: 0.000606253   valid's RMSPE: 0.493717\n[135]   train's rmse: 0.000725523   train's RMSPE: 0.477519 valid's rmse: 0.000600433   valid's RMSPE: 0.488977\n[136]   train's rmse: 0.000728732   train's RMSPE: 0.479631 valid's rmse: 0.000602885   valid's RMSPE: 0.490974\n[137]   train's rmse: 0.000732492   train's RMSPE: 0.482106 valid's rmse: 0.000605218   valid's RMSPE: 0.492874\n[138]   train's rmse: 0.000736226   train's RMSPE: 0.484564 valid's rmse: 0.000607654   valid's RMSPE: 0.494858\n[139]   train's rmse: 0.000738549   train's RMSPE: 0.486093 valid's rmse: 0.000608463   valid's RMSPE: 0.495516\n[140]   train's rmse: 0.000731572   train's RMSPE: 0.4815   valid's rmse: 0.000603673   valid's RMSPE: 0.491615\n[141]   train's rmse: 0.000723195   train's RMSPE: 0.475987 valid's rmse: 0.000597184   valid's RMSPE: 0.486331\n[142]   train's rmse: 0.000716421   train's RMSPE: 0.471528 valid's rmse: 0.000595839   valid's RMSPE: 0.485236\n[143]   train's rmse: 0.000709644   train's RMSPE: 0.467068 valid's rmse: 0.000595107   valid's RMSPE: 0.48464\n[144]   train's rmse: 0.000703653   train's RMSPE: 0.463125 valid's rmse: 0.000589924   valid's RMSPE: 0.480418\n[145]   train's rmse: 0.000706611   train's RMSPE: 0.465072 valid's rmse: 0.000591481   valid's RMSPE: 0.481686\n[146]   train's rmse: 0.000700981   train's RMSPE: 0.461366 valid's rmse: 0.000587379   valid's RMSPE: 0.478346\n[147]   train's rmse: 0.000703256   train's RMSPE: 0.462864 valid's rmse: 0.000588854   valid's RMSPE: 0.479548\n[148]   train's rmse: 0.000706153   train's RMSPE: 0.46477  valid's rmse: 0.000590109   valid's RMSPE: 0.48057\n[149]   train's rmse: 0.000702625   train's RMSPE: 0.462448 valid's rmse: 0.000586091   valid's RMSPE: 0.477297\n[150]   train's rmse: 0.0006953 train's RMSPE: 0.457627 valid's rmse: 0.000583381   valid's RMSPE: 0.475091\n[151]   train's rmse: 0.000698732   train's RMSPE: 0.459886 valid's rmse: 0.000585301   valid's RMSPE: 0.476654\n[152]   train's rmse: 0.000701746   train's RMSPE: 0.46187  valid's rmse: 0.000586905   valid's RMSPE: 0.47796\n[153]   train's rmse: 0.0007044 train's RMSPE: 0.463616 valid's rmse: 0.00058894    valid's RMSPE: 0.479618\n[154]   train's rmse: 0.000707754   train's RMSPE: 0.465824 valid's rmse: 0.000590608   valid's RMSPE: 0.480975\n[155]   train's rmse: 0.000711073   train's RMSPE: 0.468008 valid's rmse: 0.000592397   valid's RMSPE: 0.482433\n[156]   train's rmse: 0.000712938   train's RMSPE: 0.469236 valid's rmse: 0.000593683   valid's RMSPE: 0.48348\n[157]   train's rmse: 0.000716491   train's RMSPE: 0.471574 valid's rmse: 0.000595668   valid's RMSPE: 0.485096\n[158]   train's rmse: 0.00071956    train's RMSPE: 0.473595 valid's rmse: 0.000597577   valid's RMSPE: 0.486651\n[159]   train's rmse: 0.000722102   train's RMSPE: 0.475267 valid's rmse: 0.000599117   valid's RMSPE: 0.487906\n[160]   train's rmse: 0.000715339   train's RMSPE: 0.470816 valid's rmse: 0.000594361   valid's RMSPE: 0.484032\n[161]   train's rmse: 0.000717903   train's RMSPE: 0.472504 valid's rmse: 0.000596166   valid's RMSPE: 0.485503\n[162]   train's rmse: 0.000711235   train's RMSPE: 0.468115 valid's rmse: 0.000589929   valid's RMSPE: 0.480423\n[163]   train's rmse: 0.000717379   train's RMSPE: 0.472159 valid's rmse: 0.000591681   valid's RMSPE: 0.48185\n[164]   train's rmse: 0.000711038   train's RMSPE: 0.467986 valid's rmse: 0.000588412   valid's RMSPE: 0.479187\n[165]   train's rmse: 0.000717948   train's RMSPE: 0.472533 valid's rmse: 0.00058992    valid's RMSPE: 0.480415\n[166]   train's rmse: 0.000720742   train's RMSPE: 0.474373 valid's rmse: 0.000591665   valid's RMSPE: 0.481837\n[167]   train's rmse: 0.000714538   train's RMSPE: 0.470289 valid's rmse: 0.000591526   valid's RMSPE: 0.481723\n[168]   train's rmse: 0.000707918   train's RMSPE: 0.465932 valid's rmse: 0.000586558   valid's RMSPE: 0.477677\n[169]   train's rmse: 0.00070215    train's RMSPE: 0.462136 valid's rmse: 0.000585587   valid's RMSPE: 0.476887\n[170]   train's rmse: 0.000704917   train's RMSPE: 0.463957 valid's rmse: 0.000587323   valid's RMSPE: 0.478301\n[171]   train's rmse: 0.000707785   train's RMSPE: 0.465844 valid's rmse: 0.000589109   valid's RMSPE: 0.479755\n[172]   train's rmse: 0.000701058   train's RMSPE: 0.461417 valid's rmse: 0.000584449   valid's RMSPE: 0.47596\n[173]   train's rmse: 0.000697295   train's RMSPE: 0.45894  valid's rmse: 0.000581558   valid's RMSPE: 0.473606\n[174]   train's rmse: 0.000700097   train's RMSPE: 0.460784 valid's rmse: 0.000582992   valid's RMSPE: 0.474774\n[175]   train's rmse: 0.00069522    train's RMSPE: 0.457574 valid's rmse: 0.000579245   valid's RMSPE: 0.471722\n[176]   train's rmse: 0.000687506   train's RMSPE: 0.452497 valid's rmse: 0.000585671   valid's RMSPE: 0.476955\n[177]   train's rmse: 0.000690141   train's RMSPE: 0.454232 valid's rmse: 0.00058691    valid's RMSPE: 0.477964\n[178]   train's rmse: 0.000685266   train's RMSPE: 0.451023 valid's rmse: 0.000583086   valid's RMSPE: 0.47485\n[179]   train's rmse: 0.000679611   train's RMSPE: 0.447301 valid's rmse: 0.000581385   valid's RMSPE: 0.473465\n[180]   train's rmse: 0.000682516   train's RMSPE: 0.449213 valid's rmse: 0.000582665   valid's RMSPE: 0.474507\n[181]   train's rmse: 0.000684981   train's RMSPE: 0.450835 valid's rmse: 0.00058376    valid's RMSPE: 0.475399\n[182]   train's rmse: 0.000690944   train's RMSPE: 0.45476  valid's rmse: 0.000583113   valid's RMSPE: 0.474872\n[183]   train's rmse: 0.000684791   train's RMSPE: 0.450711 valid's rmse: 0.000578952   valid's RMSPE: 0.471483\n[184]   train's rmse: 0.000687245   train's RMSPE: 0.452326 valid's rmse: 0.000580097   valid's RMSPE: 0.472416\n[185]   train's rmse: 0.000680747   train's RMSPE: 0.448048 valid's rmse: 0.000576619   valid's RMSPE: 0.469584\n[186]   train's rmse: 0.000683698   train's RMSPE: 0.449991 valid's rmse: 0.000578208   valid's RMSPE: 0.470878\n[187]   train's rmse: 0.000686302   train's RMSPE: 0.451705 valid's rmse: 0.000579974   valid's RMSPE: 0.472316\n[188]   train's rmse: 0.000681378   train's RMSPE: 0.448464 valid's rmse: 0.000577471   valid's RMSPE: 0.470278\n[189]   train's rmse: 0.000684121   train's RMSPE: 0.450269 valid's rmse: 0.000578456   valid's RMSPE: 0.47108\n[190]   train's rmse: 0.000680619   train's RMSPE: 0.447965 valid's rmse: 0.000574759   valid's RMSPE: 0.468069\n[191]   train's rmse: 0.000683349   train's RMSPE: 0.449761 valid's rmse: 0.000576708   valid's RMSPE: 0.469656\n[192]   train's rmse: 0.000678787   train's RMSPE: 0.446758 valid's rmse: 0.000575363   valid's RMSPE: 0.468561\n[193]   train's rmse: 0.000681496   train's RMSPE: 0.448542 valid's rmse: 0.000576789   valid's RMSPE: 0.469722\n[194]   train's rmse: 0.000678485   train's RMSPE: 0.44656  valid's rmse: 0.000580918   valid's RMSPE: 0.473084\n[195]   train's rmse: 0.000681562   train's RMSPE: 0.448585 valid's rmse: 0.000581494   valid's RMSPE: 0.473554\n[196]   train's rmse: 0.000678455   train's RMSPE: 0.44654  valid's rmse: 0.000578932   valid's RMSPE: 0.471467\n[197]   train's rmse: 0.000681012   train's RMSPE: 0.448223 valid's rmse: 0.000579759   valid's RMSPE: 0.472141\n[198]   train's rmse: 0.000683077   train's RMSPE: 0.449582 valid's rmse: 0.000580553   valid's RMSPE: 0.472787\n[199]   train's rmse: 0.000685671   train's RMSPE: 0.45129  valid's rmse: 0.000581981   valid's RMSPE: 0.473951\n[200]   train's rmse: 0.000687665   train's RMSPE: 0.452602 valid's rmse: 0.000582657   valid's RMSPE: 0.474501\n[201]   train's rmse: 0.000690032   train's RMSPE: 0.45416  valid's rmse: 0.000583546   valid's RMSPE: 0.475225\n[202]   train's rmse: 0.000692185   train's RMSPE: 0.455577 valid's rmse: 0.000584754   valid's RMSPE: 0.476208\n[203]   train's rmse: 0.000694749   train's RMSPE: 0.457265 valid's rmse: 0.000585818   valid's RMSPE: 0.477075\n[204]   train's rmse: 0.000697044   train's RMSPE: 0.458775 valid's rmse: 0.000586934   valid's RMSPE: 0.477984\n[205]   train's rmse: 0.000693028   train's RMSPE: 0.456132 valid's rmse: 0.000584086   valid's RMSPE: 0.475664\n[206]   train's rmse: 0.000695682   train's RMSPE: 0.457879 valid's rmse: 0.000585613   valid's RMSPE: 0.476908\n[207]   train's rmse: 0.000698065   train's RMSPE: 0.459447 valid's rmse: 0.000587041   valid's RMSPE: 0.478071\n[208]   train's rmse: 0.000700543   train's RMSPE: 0.461078 valid's rmse: 0.000588345   valid's RMSPE: 0.479133\n[209]   train's rmse: 0.000695296   train's RMSPE: 0.457624 valid's rmse: 0.000587794   valid's RMSPE: 0.478685\n[210]   train's rmse: 0.000692896   train's RMSPE: 0.456045 valid's rmse: 0.000583669   valid's RMSPE: 0.475325\n[211]   train's rmse: 0.000688953   train's RMSPE: 0.45345  valid's rmse: 0.000587367   valid's RMSPE: 0.478337\n[212]   train's rmse: 0.000685449   train's RMSPE: 0.451144 valid's rmse: 0.000587402   valid's RMSPE: 0.478365\n[213]   train's rmse: 0.000679239   train's RMSPE: 0.447056 valid's rmse: 0.000590018   valid's RMSPE: 0.480496\n[214]   train's rmse: 0.00068268    train's RMSPE: 0.449321 valid's rmse: 0.000588768   valid's RMSPE: 0.479478\n[215]   train's rmse: 0.000679364   train's RMSPE: 0.447138 valid's rmse: 0.000590291   valid's RMSPE: 0.480718\n[216]   train's rmse: 0.00067593    train's RMSPE: 0.444878 valid's rmse: 0.000587857   valid's RMSPE: 0.478736\n[217]   train's rmse: 0.000677651   train's RMSPE: 0.446011 valid's rmse: 0.000588244   valid's RMSPE: 0.47905\n[218]   train's rmse: 0.000679274   train's RMSPE: 0.447079 valid's rmse: 0.00058855    valid's RMSPE: 0.4793\n[219]   train's rmse: 0.000675356   train's RMSPE: 0.4445   valid's rmse: 0.000587971   valid's RMSPE: 0.478828\n[220]   train's rmse: 0.000677307   train's RMSPE: 0.445784 valid's rmse: 0.000588258   valid's RMSPE: 0.479062\n[221]   train's rmse: 0.000679047   train's RMSPE: 0.44693  valid's rmse: 0.000588596   valid's RMSPE: 0.479337\n[222]   train's rmse: 0.000673526   train's RMSPE: 0.443296 valid's rmse: 0.000586133   valid's RMSPE: 0.477332\n[223]   train's rmse: 0.000667592   train's RMSPE: 0.43939  valid's rmse: 0.000587982   valid's RMSPE: 0.478837\n[224]   train's rmse: 0.000664354   train's RMSPE: 0.437259 valid's rmse: 0.000585321   valid's RMSPE: 0.47667\n[225]   train's rmse: 0.000664316   train's RMSPE: 0.437234 valid's rmse: 0.000585322   valid's RMSPE: 0.476671\n[226]   train's rmse: 0.000661001   train's RMSPE: 0.435052 valid's rmse: 0.000583242   valid's RMSPE: 0.474977\n[227]   train's rmse: 0.000662705   train's RMSPE: 0.436174 valid's rmse: 0.000583335   valid's RMSPE: 0.475053\n[228]   train's rmse: 0.000659736   train's RMSPE: 0.43422  valid's rmse: 0.000585608   valid's RMSPE: 0.476904\n[229]   train's rmse: 0.000659663   train's RMSPE: 0.434172 valid's rmse: 0.000585236   valid's RMSPE: 0.476601\n[230]   train's rmse: 0.000658925   train's RMSPE: 0.433686 valid's rmse: 0.000583515   valid's RMSPE: 0.475199\n[231]   train's rmse: 0.000660528   train's RMSPE: 0.434741 valid's rmse: 0.000583413   valid's RMSPE: 0.475117\n[232]   train's rmse: 0.000660147   train's RMSPE: 0.43449  valid's rmse: 0.000581274   valid's RMSPE: 0.473374\n[233]   train's rmse: 0.000657625   train's RMSPE: 0.432831 valid's rmse: 0.000579768   valid's RMSPE: 0.472148\n[234]   train's rmse: 0.000658769   train's RMSPE: 0.433583 valid's rmse: 0.000579408   valid's RMSPE: 0.471855\n[235]   train's rmse: 0.00066004    train's RMSPE: 0.43442  valid's rmse: 0.000579144   valid's RMSPE: 0.47164\n[236]   train's rmse: 0.000661443   train's RMSPE: 0.435343 valid's rmse: 0.000579216   valid's RMSPE: 0.471699\n[237]   train's rmse: 0.00066271    train's RMSPE: 0.436177 valid's rmse: 0.000579624   valid's RMSPE: 0.472031\n[238]   train's rmse: 0.000664067   train's RMSPE: 0.43707  valid's rmse: 0.000579912   valid's RMSPE: 0.472265\n[239]   train's rmse: 0.000665863   train's RMSPE: 0.438252 valid's rmse: 0.000580001   valid's RMSPE: 0.472338\n[240]   train's rmse: 0.000664253   train's RMSPE: 0.437193 valid's rmse: 0.000578061   valid's RMSPE: 0.470758\n[241]   train's rmse: 0.000665982   train's RMSPE: 0.438331 valid's rmse: 0.000578153   valid's RMSPE: 0.470833\n[242]   train's rmse: 0.000667588   train's RMSPE: 0.439388 valid's rmse: 0.000579242   valid's RMSPE: 0.471719\n[243]   train's rmse: 0.000669504   train's RMSPE: 0.440649 valid's rmse: 0.000579767   valid's RMSPE: 0.472147\n[244]   train's rmse: 0.000667433   train's RMSPE: 0.439286 valid's rmse: 0.000587485   valid's RMSPE: 0.478433\n[245]   train's rmse: 0.000664612   train's RMSPE: 0.437429 valid's rmse: 0.000585339   valid's RMSPE: 0.476685\n[246]   train's rmse: 0.000664845   train's RMSPE: 0.437583 valid's rmse: 0.000583481   valid's RMSPE: 0.475172\n[247]   train's rmse: 0.000664623   train's RMSPE: 0.437436 valid's rmse: 0.000583679   valid's RMSPE: 0.475333\n[248]   train's rmse: 0.000665578   train's RMSPE: 0.438065 valid's rmse: 0.000584078   valid's RMSPE: 0.475658\n[249]   train's rmse: 0.000665018   train's RMSPE: 0.437696 valid's rmse: 0.000589233   valid's RMSPE: 0.479856\n[250]   train's rmse: 0.000666577   train's RMSPE: 0.438722 valid's rmse: 0.000588276   valid's RMSPE: 0.479077\n[251]   train's rmse: 0.000661652   train's RMSPE: 0.435481 valid's rmse: 0.000586826   valid's RMSPE: 0.477896\n[252]   train's rmse: 0.000659182   train's RMSPE: 0.433855 valid's rmse: 0.000589783   valid's RMSPE: 0.480304\n[253]   train's rmse: 0.000660548   train's RMSPE: 0.434754 valid's rmse: 0.000589579   valid's RMSPE: 0.480138\n[254]   train's rmse: 0.000659605   train's RMSPE: 0.434134 valid's rmse: 0.000589341   valid's RMSPE: 0.479944\n[255]   train's rmse: 0.000660965   train's RMSPE: 0.435029 valid's rmse: 0.000588352   valid's RMSPE: 0.479139\n[256]   train's rmse: 0.000662034   train's RMSPE: 0.435733 valid's rmse: 0.000587574   valid's RMSPE: 0.478505\n[257]   train's rmse: 0.000658386   train's RMSPE: 0.433331 valid's rmse: 0.000587649   valid's RMSPE: 0.478566\n[258]   train's rmse: 0.000659619   train's RMSPE: 0.434143 valid's rmse: 0.000587195   valid's RMSPE: 0.478196\n[259]   train's rmse: 0.000660613   train's RMSPE: 0.434797 valid's rmse: 0.000587596   valid's RMSPE: 0.478523\n[260]   train's rmse: 0.000657346   train's RMSPE: 0.432647 valid's rmse: 0.000586946   valid's RMSPE: 0.477994\n[261]   train's rmse: 0.000658267   train's RMSPE: 0.433253 valid's rmse: 0.000586854   valid's RMSPE: 0.477918\n[262]   train's rmse: 0.000659303   train's RMSPE: 0.433935 valid's rmse: 0.000586338   valid's RMSPE: 0.477498\n[263]   train's rmse: 0.000660514   train's RMSPE: 0.434732 valid's rmse: 0.000586284   valid's RMSPE: 0.477455\n[264]   train's rmse: 0.000662636   train's RMSPE: 0.436128 valid's rmse: 0.000584515   valid's RMSPE: 0.476014\n[265]   train's rmse: 0.000659685   train's RMSPE: 0.434187 valid's rmse: 0.000585817   valid's RMSPE: 0.477074\n[266]   train's rmse: 0.000660952   train's RMSPE: 0.43502  valid's rmse: 0.000585803   valid's RMSPE: 0.477063\n[267]   train's rmse: 0.000658703   train's RMSPE: 0.43354  valid's rmse: 0.000584893   valid's RMSPE: 0.476322\n[268]   train's rmse: 0.000656981   train's RMSPE: 0.432406 valid's rmse: 0.000583211   valid's RMSPE: 0.474952\n[269]   train's rmse: 0.000652009   train's RMSPE: 0.429134 valid's rmse: 0.000583396   valid's RMSPE: 0.475103\n[270]   train's rmse: 0.00064819    train's RMSPE: 0.426621 valid's rmse: 0.000587123   valid's RMSPE: 0.478137\n[271]   train's rmse: 0.000649413   train's RMSPE: 0.427426 valid's rmse: 0.000586469   valid's RMSPE: 0.477605\n[272]   train's rmse: 0.00065032    train's RMSPE: 0.428022 valid's rmse: 0.00058631    valid's RMSPE: 0.477475\n[273]   train's rmse: 0.000651782   train's RMSPE: 0.428984 valid's rmse: 0.000585731   valid's RMSPE: 0.477004\n[274]   train's rmse: 0.000651984   train's RMSPE: 0.429118 valid's rmse: 0.000582113   valid's RMSPE: 0.474058\n[275]   train's rmse: 0.000649998   train's RMSPE: 0.42781  valid's rmse: 0.000585081   valid's RMSPE: 0.476475\n[276]   train's rmse: 0.000651441   train's RMSPE: 0.42876  valid's rmse: 0.000584904   valid's RMSPE: 0.476331\n[277]   train's rmse: 0.000647346   train's RMSPE: 0.426065 valid's rmse: 0.000593426   valid's RMSPE: 0.483271\n[278]   train's rmse: 0.000645693   train's RMSPE: 0.424977 valid's rmse: 0.000597305   valid's RMSPE: 0.48643\n[279]   train's rmse: 0.00064689    train's RMSPE: 0.425765 valid's rmse: 0.00059687    valid's RMSPE: 0.486076\n[280]   train's rmse: 0.000644209   train's RMSPE: 0.424001 valid's rmse: 0.000598466   valid's RMSPE: 0.487375\n[281]   train's rmse: 0.000645446   train's RMSPE: 0.424815 valid's rmse: 0.000598298   valid's RMSPE: 0.487239\n[282]   train's rmse: 0.000646469   train's RMSPE: 0.425488 valid's rmse: 0.000598632   valid's RMSPE: 0.48751\n[283]   train's rmse: 0.0006432 train's RMSPE: 0.423336 valid's rmse: 0.000597748   valid's RMSPE: 0.486791\n[284]   train's rmse: 0.000644577   train's RMSPE: 0.424243 valid's rmse: 0.000597428   valid's RMSPE: 0.48653\n[285]   train's rmse: 0.000641756   train's RMSPE: 0.422386 valid's rmse: 0.000602885   valid's RMSPE: 0.490974\n[286]   train's rmse: 0.000643046   train's RMSPE: 0.423235 valid's rmse: 0.000602407   valid's RMSPE: 0.490584\n[287]   train's rmse: 0.000640138   train's RMSPE: 0.421321 valid's rmse: 0.000607705   valid's RMSPE: 0.4949\n[288]   train's rmse: 0.000641525   train's RMSPE: 0.422234 valid's rmse: 0.00060648    valid's RMSPE: 0.493902\n[289]   train's rmse: 0.000642881   train's RMSPE: 0.423127 valid's rmse: 0.000605876   valid's RMSPE: 0.493409\n[290]   train's rmse: 0.000639681   train's RMSPE: 0.42102  valid's rmse: 0.000607512   valid's RMSPE: 0.494742\n[291]   train's rmse: 0.000637236   train's RMSPE: 0.419411 valid's rmse: 0.000605929   valid's RMSPE: 0.493453\n[292]   train's rmse: 0.000638637   train's RMSPE: 0.420333 valid's rmse: 0.000605258   valid's RMSPE: 0.492907\n[293]   train's rmse: 0.000635864   train's RMSPE: 0.418508 valid's rmse: 0.000603763   valid's RMSPE: 0.491689\n[294]   train's rmse: 0.000637194   train's RMSPE: 0.419384 valid's rmse: 0.000603399   valid's RMSPE: 0.491393\n[295]   train's rmse: 0.000638574   train's RMSPE: 0.420292 valid's rmse: 0.000602427   valid's RMSPE: 0.490601\n[296]   train's rmse: 0.000639761   train's RMSPE: 0.421073 valid's rmse: 0.000601788   valid's RMSPE: 0.49008\n[297]   train's rmse: 0.000639083   train's RMSPE: 0.420627 valid's rmse: 0.000599539   valid's RMSPE: 0.488249\n[298]   train's rmse: 0.000640374   train's RMSPE: 0.421476 valid's rmse: 0.00059929    valid's RMSPE: 0.488046\n[299]   train's rmse: 0.000636558   train's RMSPE: 0.418964 valid's rmse: 0.000596419   valid's RMSPE: 0.485708\n[300]   train's rmse: 0.000633792   train's RMSPE: 0.417144 valid's rmse: 0.000596084   valid's RMSPE: 0.485436\n[301]   train's rmse: 0.00063064    train's RMSPE: 0.41507  valid's rmse: 0.000595405   valid's RMSPE: 0.484882\n[302]   train's rmse: 0.00062764    train's RMSPE: 0.413095 valid's rmse: 0.000595629   valid's RMSPE: 0.485064\n[303]   train's rmse: 0.000628682   train's RMSPE: 0.413781 valid's rmse: 0.000594526   valid's RMSPE: 0.484167\n[304]   train's rmse: 0.000625713   train's RMSPE: 0.411827 valid's rmse: 0.000594251   valid's RMSPE: 0.483943\n[305]   train's rmse: 0.000623278   train's RMSPE: 0.410225 valid's rmse: 0.000602732   valid's RMSPE: 0.490849\n[306]   train's rmse: 0.000624667   train's RMSPE: 0.411138 valid's rmse: 0.000601719   valid's RMSPE: 0.490024\n[307]   train's rmse: 0.000623139   train's RMSPE: 0.410133 valid's rmse: 0.0006016 valid's RMSPE: 0.489927\n[308]   train's rmse: 0.00062424    train's RMSPE: 0.410857 valid's rmse: 0.000601661   valid's RMSPE: 0.489977\n[309]   train's rmse: 0.000621146   train's RMSPE: 0.408821 valid's rmse: 0.00060178    valid's RMSPE: 0.490074\n[310]   train's rmse: 0.000618558   train's RMSPE: 0.407117 valid's rmse: 0.000611849   valid's RMSPE: 0.498274\n[311]   train's rmse: 0.000618908   train's RMSPE: 0.407348 valid's rmse: 0.000612757   valid's RMSPE: 0.499013\n[312]   train's rmse: 0.000620003   train's RMSPE: 0.408069 valid's rmse: 0.000612081   valid's RMSPE: 0.498463\n[313]   train's rmse: 0.00062121    train's RMSPE: 0.408863 valid's rmse: 0.000611862   valid's RMSPE: 0.498285\n[314]   train's rmse: 0.000619493   train's RMSPE: 0.407733 valid's rmse: 0.000611502   valid's RMSPE: 0.497991\n[315]   train's rmse: 0.000618757   train's RMSPE: 0.407249 valid's rmse: 0.000610671   valid's RMSPE: 0.497314\n[316]   train's rmse: 0.000616609   train's RMSPE: 0.405835 valid's rmse: 0.000619134   valid's RMSPE: 0.504207\n[317]   train's rmse: 0.000617469   train's RMSPE: 0.406401 valid's rmse: 0.000618122   valid's RMSPE: 0.503383\n[318]   train's rmse: 0.000616814   train's RMSPE: 0.40597  valid's rmse: 0.000620257   valid's RMSPE: 0.505121\n[319]   train's rmse: 0.00061798    train's RMSPE: 0.406737 valid's rmse: 0.000618645   valid's RMSPE: 0.503808\n[320]   train's rmse: 0.000618936   train's RMSPE: 0.407366 valid's rmse: 0.000618013   valid's RMSPE: 0.503294\n[321]   train's rmse: 0.000619984   train's RMSPE: 0.408056 valid's rmse: 0.00061718    valid's RMSPE: 0.502615\n[322]   train's rmse: 0.000621199   train's RMSPE: 0.408856 valid's rmse: 0.000615402   valid's RMSPE: 0.501167\n[323]   train's rmse: 0.000622267   train's RMSPE: 0.409559 valid's rmse: 0.000614502   valid's RMSPE: 0.500435\n[324]   train's rmse: 0.000623416   train's RMSPE: 0.410315 valid's rmse: 0.000613718   valid's RMSPE: 0.499796\n[325]   train's rmse: 0.000622492   train's RMSPE: 0.409707 valid's rmse: 0.000613348   valid's RMSPE: 0.499495\n[326]   train's rmse: 0.00062076    train's RMSPE: 0.408567 valid's rmse: 0.000618683   valid's RMSPE: 0.503839\n[327]   train's rmse: 0.000621767   train's RMSPE: 0.40923  valid's rmse: 0.000618118   valid's RMSPE: 0.50338\n[328]   train's rmse: 0.000619457   train's RMSPE: 0.407709 valid's rmse: 0.000621849   valid's RMSPE: 0.506418\n[329]   train's rmse: 0.000620343   train's RMSPE: 0.408292 valid's rmse: 0.000621282   valid's RMSPE: 0.505956\n[330]   train's rmse: 0.00062115    train's RMSPE: 0.408824 valid's rmse: 0.000620443   valid's RMSPE: 0.505273\n[331]   train's rmse: 0.000621957   train's RMSPE: 0.409355 valid's rmse: 0.000619601   valid's RMSPE: 0.504587\n[332]   train's rmse: 0.000619351   train's RMSPE: 0.40764  valid's rmse: 0.000620205   valid's RMSPE: 0.505079\n[333]   train's rmse: 0.000620359   train's RMSPE: 0.408303 valid's rmse: 0.000619563   valid's RMSPE: 0.504556\n[334]   train's rmse: 0.000621602   train's RMSPE: 0.409121 valid's rmse: 0.000616376   valid's RMSPE: 0.501961\n[335]   train's rmse: 0.000620486   train's RMSPE: 0.408387 valid's rmse: 0.000614965   valid's RMSPE: 0.500812\n[336]   train's rmse: 0.000621759   train's RMSPE: 0.409224 valid's rmse: 0.000613785   valid's RMSPE: 0.499851\n[337]   train's rmse: 0.000622776   train's RMSPE: 0.409894 valid's rmse: 0.000613315   valid's RMSPE: 0.499468\n[338]   train's rmse: 0.000622521   train's RMSPE: 0.409726 valid's rmse: 0.000610828   valid's RMSPE: 0.497443\n[339]   train's rmse: 0.000623737   train's RMSPE: 0.410526 valid's rmse: 0.000610481   valid's RMSPE: 0.49716\n[340]   train's rmse: 0.000621333   train's RMSPE: 0.408944 valid's rmse: 0.000605366   valid's RMSPE: 0.492995\n[341]   train's rmse: 0.000622391   train's RMSPE: 0.40964  valid's rmse: 0.000604533   valid's RMSPE: 0.492316\n[342]   train's rmse: 0.000620978   train's RMSPE: 0.40871  valid's rmse: 0.000610022   valid's RMSPE: 0.496786\n[343]   train's rmse: 0.000621947   train's RMSPE: 0.409348 valid's rmse: 0.000609419   valid's RMSPE: 0.496295\n[344]   train's rmse: 0.000619719   train's RMSPE: 0.407882 valid's rmse: 0.000609172   valid's RMSPE: 0.496094\n[345]   train's rmse: 0.000617045   train's RMSPE: 0.406122 valid's rmse: 0.000608814   valid's RMSPE: 0.495802\n[346]   train's rmse: 0.000617993   train's RMSPE: 0.406746 valid's rmse: 0.000608155   valid's RMSPE: 0.495266\n[347]   train's rmse: 0.000615817   train's RMSPE: 0.405314 valid's rmse: 0.000612262   valid's RMSPE: 0.49861\n[348]   train's rmse: 0.000614355   train's RMSPE: 0.404351 valid's rmse: 0.000620439   valid's RMSPE: 0.505269\n[349]   train's rmse: 0.000615389   train's RMSPE: 0.405032 valid's rmse: 0.000619529   valid's RMSPE: 0.504528\n[350]   train's rmse: 0.000616389   train's RMSPE: 0.40569  valid's rmse: 0.000618675   valid's RMSPE: 0.503833\n[351]   train's rmse: 0.000617654   train's RMSPE: 0.406523 valid's rmse: 0.000615071   valid's RMSPE: 0.500898\n[352]   train's rmse: 0.000618678   train's RMSPE: 0.407197 valid's rmse: 0.000614147   valid's RMSPE: 0.500145\n[353]   train's rmse: 0.000619625   train's RMSPE: 0.40782  valid's rmse: 0.00061297    valid's RMSPE: 0.499187\n[354]   train's rmse: 0.000619363   train's RMSPE: 0.407647 valid's rmse: 0.000614672   valid's RMSPE: 0.500573\n[355]   train's rmse: 0.000620358   train's RMSPE: 0.408302 valid's rmse: 0.000613845   valid's RMSPE: 0.4999\n[356]   train's rmse: 0.000621557   train's RMSPE: 0.409091 valid's rmse: 0.000610839   valid's RMSPE: 0.497451\n[357]   train's rmse: 0.000622715   train's RMSPE: 0.409854 valid's rmse: 0.000609666   valid's RMSPE: 0.496496\n[358]   train's rmse: 0.000623966   train's RMSPE: 0.410677 valid's rmse: 0.000608498   valid's RMSPE: 0.495545\n[359]   train's rmse: 0.000625043   train's RMSPE: 0.411386 valid's rmse: 0.00060786    valid's RMSPE: 0.495026\n[360]   train's rmse: 0.000621956   train's RMSPE: 0.409354 valid's rmse: 0.000606632   valid's RMSPE: 0.494025\n[361]   train's rmse: 0.00062282    train's RMSPE: 0.409923 valid's rmse: 0.000606414   valid's RMSPE: 0.493848\n[362]   train's rmse: 0.000621377   train's RMSPE: 0.408973 valid's rmse: 0.000605164   valid's RMSPE: 0.492829\n[363]   train's rmse: 0.000622735   train's RMSPE: 0.409867 valid's rmse: 0.000605142   valid's RMSPE: 0.492812\n[364]   train's rmse: 0.000620345   train's RMSPE: 0.408294 valid's rmse: 0.000606512   valid's RMSPE: 0.493928\n[365]   train's rmse: 0.000621572   train's RMSPE: 0.409101 valid's rmse: 0.00060592    valid's RMSPE: 0.493446\n[366]   train's rmse: 0.000618601   train's RMSPE: 0.407146 valid's rmse: 0.000605223   valid's RMSPE: 0.492878\n[367]   train's rmse: 0.000620026   train's RMSPE: 0.408084 valid's rmse: 0.000603335   valid's RMSPE: 0.49134\n[368]   train's rmse: 0.000621253   train's RMSPE: 0.408891 valid's rmse: 0.000603052   valid's RMSPE: 0.49111\n[369]   train's rmse: 0.000618575   train's RMSPE: 0.407129 valid's rmse: 0.000600086   valid's RMSPE: 0.488694\n[370]   train's rmse: 0.000619727   train's RMSPE: 0.407887 valid's rmse: 0.000599167   valid's RMSPE: 0.487946\n[371]   train's rmse: 0.000619353   train's RMSPE: 0.407641 valid's rmse: 0.000599774   valid's RMSPE: 0.48844\n[372]   train's rmse: 0.000620343   train's RMSPE: 0.408293 valid's rmse: 0.000599448   valid's RMSPE: 0.488175\n[373]   train's rmse: 0.000617967   train's RMSPE: 0.406729 valid's rmse: 0.000600574   valid's RMSPE: 0.489092\n[374]   train's rmse: 0.000615808   train's RMSPE: 0.405308 valid's rmse: 0.000598621   valid's RMSPE: 0.487502\n[375]   train's rmse: 0.000617063   train's RMSPE: 0.406134 valid's rmse: 0.000598013   valid's RMSPE: 0.487006\n[376]   train's rmse: 0.000618118   train's RMSPE: 0.406828 valid's rmse: 0.000597698   valid's RMSPE: 0.48675\n[377]   train's rmse: 0.000615066   train's RMSPE: 0.404819 valid's rmse: 0.000600533   valid's RMSPE: 0.489058\n[378]   train's rmse: 0.000614771   train's RMSPE: 0.404625 valid's rmse: 0.000600567   valid's RMSPE: 0.489086\n[379]   train's rmse: 0.000613245   train's RMSPE: 0.403621 valid's rmse: 0.000599873   valid's RMSPE: 0.488521\n[380]   train's rmse: 0.000610919   train's RMSPE: 0.40209  valid's rmse: 0.000608345   valid's RMSPE: 0.495421\n[381]   train's rmse: 0.00061198    train's RMSPE: 0.402788 valid's rmse: 0.000607359   valid's RMSPE: 0.494618\n[382]   train's rmse: 0.000613056   train's RMSPE: 0.403496 valid's rmse: 0.00060688    valid's RMSPE: 0.494227\n[383]   train's rmse: 0.000614036   train's RMSPE: 0.404141 valid's rmse: 0.000605847   valid's RMSPE: 0.493386\n[384]   train's rmse: 0.000611678   train's RMSPE: 0.40259  valid's rmse: 0.000607679   valid's RMSPE: 0.494878\n[385]   train's rmse: 0.000608866   train's RMSPE: 0.400739 valid's rmse: 0.000607647   valid's RMSPE: 0.494852\n[386]   train's rmse: 0.000609777   train's RMSPE: 0.401338 valid's rmse: 0.000607211   valid's RMSPE: 0.494497\n[387]   train's rmse: 0.000610938   train's RMSPE: 0.402103 valid's rmse: 0.000606235   valid's RMSPE: 0.493702\n[388]   train's rmse: 0.000609049   train's RMSPE: 0.400859 valid's rmse: 0.000609293   valid's RMSPE: 0.496193\n[389]   train's rmse: 0.000608428   train's RMSPE: 0.40045  valid's rmse: 0.000612671   valid's RMSPE: 0.498944\n[390]   train's rmse: 0.000609222   train's RMSPE: 0.400973 valid's rmse: 0.000612068   valid's RMSPE: 0.498453\n[391]   train's rmse: 0.000610322   train's RMSPE: 0.401697 valid's rmse: 0.000611529   valid's RMSPE: 0.498013\n[392]   train's rmse: 0.000611389   train's RMSPE: 0.402399 valid's rmse: 0.00061111    valid's RMSPE: 0.497672\n[393]   train's rmse: 0.000612447   train's RMSPE: 0.403095 valid's rmse: 0.0006102 valid's RMSPE: 0.496931\n[394]   train's rmse: 0.000613616   train's RMSPE: 0.403865 valid's rmse: 0.000607863   valid's RMSPE: 0.495028\n[395]   train's rmse: 0.000614605   train's RMSPE: 0.404516 valid's rmse: 0.000607267   valid's RMSPE: 0.494543\n[396]   train's rmse: 0.000612116   train's RMSPE: 0.402878 valid's rmse: 0.000607731   valid's RMSPE: 0.49492\n[397]   train's rmse: 0.000613189   train's RMSPE: 0.403584 valid's rmse: 0.000606568   valid's RMSPE: 0.493973\n[398]   train's rmse: 0.000610903   train's RMSPE: 0.402079 valid's rmse: 0.000612519   valid's RMSPE: 0.498819\n[399]   train's rmse: 0.000611902   train's RMSPE: 0.402737 valid's rmse: 0.000611499   valid's RMSPE: 0.497989\n[400]   train's rmse: 0.000610771   train's RMSPE: 0.401992 valid's rmse: 0.000618197   valid's RMSPE: 0.503444\n[401]   train's rmse: 0.000611755   train's RMSPE: 0.40264  valid's rmse: 0.000617413   valid's RMSPE: 0.502805\n[402]   train's rmse: 0.000609057   train's RMSPE: 0.400864 valid's rmse: 0.000619404   valid's RMSPE: 0.504427\n[403]   train's rmse: 0.000606593   train's RMSPE: 0.399243 valid's rmse: 0.000620321   valid's RMSPE: 0.505173\n[404]   train's rmse: 0.00060752    train's RMSPE: 0.399853 valid's rmse: 0.000619425   valid's RMSPE: 0.504443\n[405]   train's rmse: 0.000606445   train's RMSPE: 0.399145 valid's rmse: 0.000627422   valid's RMSPE: 0.510956\n[406]   train's rmse: 0.00060748    train's RMSPE: 0.399827 valid's rmse: 0.000626296   valid's RMSPE: 0.510039\n[407]   train's rmse: 0.000607304   train's RMSPE: 0.399711 valid's rmse: 0.000637574   valid's RMSPE: 0.519224\n[408]   train's rmse: 0.000604637   train's RMSPE: 0.397955 valid's rmse: 0.00063723    valid's RMSPE: 0.518943\n[409]   train's rmse: 0.000602586   train's RMSPE: 0.396605 valid's rmse: 0.000638312   valid's RMSPE: 0.519825\n[410]   train's rmse: 0.000603647   train's RMSPE: 0.397304 valid's rmse: 0.000637437   valid's RMSPE: 0.519112\n[411]   train's rmse: 0.00060458    train's RMSPE: 0.397918 valid's rmse: 0.000636713   valid's RMSPE: 0.518523\n[412]   train's rmse: 0.0006056 train's RMSPE: 0.398589 valid's rmse: 0.000635462   valid's RMSPE: 0.517504\n[413]   train's rmse: 0.000606495   train's RMSPE: 0.399178 valid's rmse: 0.000634066   valid's RMSPE: 0.516367\n[414]   train's rmse: 0.000607493   train's RMSPE: 0.399835 valid's rmse: 0.0006329 valid's RMSPE: 0.515417\n[415]   train's rmse: 0.000608459   train's RMSPE: 0.400471 valid's rmse: 0.00063186    valid's RMSPE: 0.514571\n[416]   train's rmse: 0.000608449   train's RMSPE: 0.400464 valid's rmse: 0.000631115   valid's RMSPE: 0.513963\n[417]   train's rmse: 0.000605961   train's RMSPE: 0.398827 valid's rmse: 0.000630105   valid's RMSPE: 0.513141\n[418]   train's rmse: 0.000603935   train's RMSPE: 0.397493 valid's rmse: 0.000629449   valid's RMSPE: 0.512607\n[419]   train's rmse: 0.000602651   train's RMSPE: 0.396648 valid's rmse: 0.000631374   valid's RMSPE: 0.514174\n[420]   train's rmse: 0.000603519   train's RMSPE: 0.397219 valid's rmse: 0.000630495   valid's RMSPE: 0.513459\n[421]   train's rmse: 0.000604593   train's RMSPE: 0.397926 valid's rmse: 0.000629605   valid's RMSPE: 0.512734\n[422]   train's rmse: 0.000602263   train's RMSPE: 0.396393 valid's rmse: 0.000636433   valid's RMSPE: 0.518294\n[423]   train's rmse: 0.000603138   train's RMSPE: 0.396968 valid's rmse: 0.000634821   valid's RMSPE: 0.516982\n[424]   train's rmse: 0.00060411    train's RMSPE: 0.397609 valid's rmse: 0.000633601   valid's RMSPE: 0.515988\n[425]   train's rmse: 0.000604904   train's RMSPE: 0.398131 valid's rmse: 0.000633175   valid's RMSPE: 0.515641\n[426]   train's rmse: 0.000606007   train's RMSPE: 0.398857 valid's rmse: 0.000632511   valid's RMSPE: 0.515101\n[427]   train's rmse: 0.000604207   train's RMSPE: 0.397672 valid's rmse: 0.000640142   valid's RMSPE: 0.521315\n[428]   train's rmse: 0.000605293   train's RMSPE: 0.398387 valid's rmse: 0.00063759    valid's RMSPE: 0.519237\n[429]   train's rmse: 0.000606211   train's RMSPE: 0.398991 valid's rmse: 0.000635965   valid's RMSPE: 0.517913\n[430]   train's rmse: 0.00060719    train's RMSPE: 0.399636 valid's rmse: 0.000634453   valid's RMSPE: 0.516682\n[431]   train's rmse: 0.000605228   train's RMSPE: 0.398344 valid's rmse: 0.000633098   valid's RMSPE: 0.515579\n[432]   train's rmse: 0.000606285   train's RMSPE: 0.39904  valid's rmse: 0.000632052   valid's RMSPE: 0.514727\n[433]   train's rmse: 0.000603715   train's RMSPE: 0.397348 valid's rmse: 0.000630651   valid's RMSPE: 0.513585\n[434]   train's rmse: 0.000604571   train's RMSPE: 0.397912 valid's rmse: 0.000629743   valid's RMSPE: 0.512846\n[435]   train's rmse: 0.000603183   train's RMSPE: 0.396998 valid's rmse: 0.000632557   valid's RMSPE: 0.515138\n[436]   train's rmse: 0.000601311   train's RMSPE: 0.395766 valid's rmse: 0.000639156   valid's RMSPE: 0.520512\n[437]   train's rmse: 0.00060241    train's RMSPE: 0.396489 valid's rmse: 0.000638457   valid's RMSPE: 0.519943\n[438]   train's rmse: 0.000601535   train's RMSPE: 0.395914 valid's rmse: 0.000637115   valid's RMSPE: 0.51885\n[439]   train's rmse: 0.000602486   train's RMSPE: 0.39654  valid's rmse: 0.000635786   valid's RMSPE: 0.517768\n[440]   train's rmse: 0.0006036 train's RMSPE: 0.397272 valid's rmse: 0.000632978   valid's RMSPE: 0.515481\n[441]   train's rmse: 0.000604578   train's RMSPE: 0.397917 valid's rmse: 0.000632431   valid's RMSPE: 0.515036\n[442]   train's rmse: 0.000605682   train's RMSPE: 0.398643 valid's rmse: 0.000631198   valid's RMSPE: 0.514032\n[443]   train's rmse: 0.000606636   train's RMSPE: 0.399271 valid's rmse: 0.000630317   valid's RMSPE: 0.513314\n[444]   train's rmse: 0.000607543   train's RMSPE: 0.399868 valid's rmse: 0.00062944    valid's RMSPE: 0.512599\n[445]   train's rmse: 0.000604748   train's RMSPE: 0.398028 valid's rmse: 0.000628024   valid's RMSPE: 0.511446\n[446]   train's rmse: 0.000605839   train's RMSPE: 0.398747 valid's rmse: 0.000627198   valid's RMSPE: 0.510774\n[447]   train's rmse: 0.000606831   train's RMSPE: 0.399399 valid's rmse: 0.000625922   valid's RMSPE: 0.509735\n[448]   train's rmse: 0.000604482   train's RMSPE: 0.397853 valid's rmse: 0.000625983   valid's RMSPE: 0.509785\n[449]   train's rmse: 0.000605552   train's RMSPE: 0.398558 valid's rmse: 0.000624734   valid's RMSPE: 0.508767\n[450]   train's rmse: 0.00060658    train's RMSPE: 0.399234 valid's rmse: 0.000623706   valid's RMSPE: 0.50793\n[451]   train's rmse: 0.000607511   train's RMSPE: 0.399847 valid's rmse: 0.000623072   valid's RMSPE: 0.507413\n[452]   train's rmse: 0.000606655   train's RMSPE: 0.399283 valid's rmse: 0.000630704   valid's RMSPE: 0.513629\n[453]   train's rmse: 0.000604917   train's RMSPE: 0.39814  valid's rmse: 0.000637652   valid's RMSPE: 0.519287\n[454]   train's rmse: 0.000604444   train's RMSPE: 0.397828 valid's rmse: 0.000641518   valid's RMSPE: 0.522436\n[455]   train's rmse: 0.000605425   train's RMSPE: 0.398474 valid's rmse: 0.000639915   valid's RMSPE: 0.52113\n[456]   train's rmse: 0.000602762   train's RMSPE: 0.396721 valid's rmse: 0.000635997   valid's RMSPE: 0.517939\n[457]   train's rmse: 0.000603658   train's RMSPE: 0.397311 valid's rmse: 0.000635057   valid's RMSPE: 0.517174\n[458]   train's rmse: 0.00060144    train's RMSPE: 0.395851 valid's rmse: 0.000635248   valid's RMSPE: 0.517329\n[459]   train's rmse: 0.000599476   train's RMSPE: 0.394559 valid's rmse: 0.000637743   valid's RMSPE: 0.519362\n[460]   train's rmse: 0.000600297   train's RMSPE: 0.395099 valid's rmse: 0.000636645   valid's RMSPE: 0.518468\n[461]   train's rmse: 0.000601251   train's RMSPE: 0.395726 valid's rmse: 0.00063577    valid's RMSPE: 0.517754\n[462]   train's rmse: 0.000599968   train's RMSPE: 0.394883 valid's rmse: 0.000634661   valid's RMSPE: 0.516851\n[463]   train's rmse: 0.000597088   train's RMSPE: 0.392987 valid's rmse: 0.000636889   valid's RMSPE: 0.518666\n[464]   train's rmse: 0.000598116   train's RMSPE: 0.393663 valid's rmse: 0.000634182   valid's RMSPE: 0.516462\n[465]   train's rmse: 0.000595875   train's RMSPE: 0.392188 valid's rmse: 0.000644408   valid's RMSPE: 0.524789\n[466]   train's rmse: 0.000594288   train's RMSPE: 0.391144 valid's rmse: 0.000649479   valid's RMSPE: 0.528919\n[467]   train's rmse: 0.000594625   train's RMSPE: 0.391366 valid's rmse: 0.000649746   valid's RMSPE: 0.529136\n[468]   train's rmse: 0.000593031   train's RMSPE: 0.390317 valid's rmse: 0.000655024   valid's RMSPE: 0.533435\n[469]   train's rmse: 0.000593266   train's RMSPE: 0.390471 valid's rmse: 0.000656335   valid's RMSPE: 0.534502\n[470]   train's rmse: 0.000591459   train's RMSPE: 0.389282 valid's rmse: 0.000656135   valid's RMSPE: 0.53434\n[471]   train's rmse: 0.000592184   train's RMSPE: 0.389759 valid's rmse: 0.00065505    valid's RMSPE: 0.533456\n[472]   train's rmse: 0.000592398   train's RMSPE: 0.3899   valid's rmse: 0.000653591   valid's RMSPE: 0.532267\n[473]   train's rmse: 0.000591742   train's RMSPE: 0.389468 valid's rmse: 0.000663331   valid's RMSPE: 0.5402\n[474]   train's rmse: 0.000592505   train's RMSPE: 0.389971 valid's rmse: 0.000661432   valid's RMSPE: 0.538653\n[475]   train's rmse: 0.000591268   train's RMSPE: 0.389156 valid's rmse: 0.000666929   valid's RMSPE: 0.54313\n[476]   train's rmse: 0.000589334   train's RMSPE: 0.387883 valid's rmse: 0.000669227   valid's RMSPE: 0.545001\n[477]   train's rmse: 0.000590168   train's RMSPE: 0.388432 valid's rmse: 0.000667447   valid's RMSPE: 0.543552\n[478]   train's rmse: 0.000590902   train's RMSPE: 0.388915 valid's rmse: 0.000665942   valid's RMSPE: 0.542326\n[479]   train's rmse: 0.000589399   train's RMSPE: 0.387926 valid's rmse: 0.00066679    valid's RMSPE: 0.543016\n[480]   train's rmse: 0.000589182   train's RMSPE: 0.387783 valid's rmse: 0.0006733 valid's RMSPE: 0.548318\n[481]   train's rmse: 0.00058978    train's RMSPE: 0.388176 valid's rmse: 0.000671384   valid's RMSPE: 0.546758\n[482]   train's rmse: 0.000589878   train's RMSPE: 0.388241 valid's rmse: 0.000677663   valid's RMSPE: 0.551871\n[483]   train's rmse: 0.000590518   train's RMSPE: 0.388662 valid's rmse: 0.000673544   valid's RMSPE: 0.548517\n[484]   train's rmse: 0.000588723   train's RMSPE: 0.387481 valid's rmse: 0.000669708   valid's RMSPE: 0.545393\n[485]   train's rmse: 0.000589298   train's RMSPE: 0.387859 valid's rmse: 0.000668517   valid's RMSPE: 0.544423\n[486]   train's rmse: 0.000588337   train's RMSPE: 0.387227 valid's rmse: 0.000675156   valid's RMSPE: 0.54983\n[487]   train's rmse: 0.000586444   train's RMSPE: 0.385981 valid's rmse: 0.00068107    valid's RMSPE: 0.554646\n[488]   train's rmse: 0.000584616   train's RMSPE: 0.384778 valid's rmse: 0.000679794   valid's RMSPE: 0.553607\n[489]   train's rmse: 0.000583234   train's RMSPE: 0.383868 valid's rmse: 0.000681486   valid's RMSPE: 0.554984\n[490]   train's rmse: 0.000581989   train's RMSPE: 0.383049 valid's rmse: 0.000678992   valid's RMSPE: 0.552954\n[491]   train's rmse: 0.000582493   train's RMSPE: 0.383381 valid's rmse: 0.000677823   valid's RMSPE: 0.552002\n[492]   train's rmse: 0.000581243   train's RMSPE: 0.382558 valid's rmse: 0.000682736   valid's RMSPE: 0.556003\n[493]   train's rmse: 0.000581757   train's RMSPE: 0.382896 valid's rmse: 0.00068088    valid's RMSPE: 0.554491\n[494]   train's rmse: 0.000582414   train's RMSPE: 0.383328 valid's rmse: 0.000679133   valid's RMSPE: 0.553068\n[495]   train's rmse: 0.000583042   train's RMSPE: 0.383742 valid's rmse: 0.000675397   valid's RMSPE: 0.550026\n[496]   train's rmse: 0.000583697   train's RMSPE: 0.384173 valid's rmse: 0.000673877   valid's RMSPE: 0.548788\n[497]   train's rmse: 0.000581917   train's RMSPE: 0.383001 valid's rmse: 0.000676729   valid's RMSPE: 0.55111\n[498]   train's rmse: 0.000580647   train's RMSPE: 0.382165 valid's rmse: 0.000681343   valid's RMSPE: 0.554868\n[499]   train's rmse: 0.000581347   train's RMSPE: 0.382627 valid's rmse: 0.000680175   valid's RMSPE: 0.553917\n[500]   train's rmse: 0.000582001   train's RMSPE: 0.383057 valid's rmse: 0.000678523   valid's RMSPE: 0.552571\n[501]   train's rmse: 0.000580332   train's RMSPE: 0.381959 valid's rmse: 0.000679392   valid's RMSPE: 0.55328\n[502]   train's rmse: 0.000580949   train's RMSPE: 0.382364 valid's rmse: 0.000677798   valid's RMSPE: 0.551981\n[503]   train's rmse: 0.000579808   train's RMSPE: 0.381613 valid's rmse: 0.000683698   valid's RMSPE: 0.556786\n[504]   train's rmse: 0.000580437   train's RMSPE: 0.382028 valid's rmse: 0.000682341   valid's RMSPE: 0.555681\n[505]   train's rmse: 0.000581111   train's RMSPE: 0.382471 valid's rmse: 0.000681138   valid's RMSPE: 0.554701\n[506]   train's rmse: 0.000579709   train's RMSPE: 0.381549 valid's rmse: 0.000680008   valid's RMSPE: 0.553781\n[507]   train's rmse: 0.000578408   train's RMSPE: 0.380692 valid's rmse: 0.000678931   valid's RMSPE: 0.552904\n[508]   train's rmse: 0.000577426   train's RMSPE: 0.380045 valid's rmse: 0.00068195    valid's RMSPE: 0.555362\n[509]   train's rmse: 0.000576116   train's RMSPE: 0.379184 valid's rmse: 0.000686512   valid's RMSPE: 0.559077\n[510]   train's rmse: 0.000576852   train's RMSPE: 0.379668 valid's rmse: 0.000684733   valid's RMSPE: 0.557629\n[511]   train's rmse: 0.000575564   train's RMSPE: 0.378821 valid's rmse: 0.000687688   valid's RMSPE: 0.560035\n[512]   train's rmse: 0.000576116   train's RMSPE: 0.379184 valid's rmse: 0.000684243   valid's RMSPE: 0.55723\n[513]   train's rmse: 0.000576763   train's RMSPE: 0.379609 valid's rmse: 0.000682211   valid's RMSPE: 0.555575\n[514]   train's rmse: 0.000577379   train's RMSPE: 0.380015 valid's rmse: 0.000680427   valid's RMSPE: 0.554122\n[515]   train's rmse: 0.000578053   train's RMSPE: 0.380458 valid's rmse: 0.000679465   valid's RMSPE: 0.553339\n[516]   train's rmse: 0.000578675   train's RMSPE: 0.380868 valid's rmse: 0.000678019   valid's RMSPE: 0.552161\n[517]   train's rmse: 0.000579437   train's RMSPE: 0.381369 valid's rmse: 0.000677015   valid's RMSPE: 0.551344\n[518]   train's rmse: 0.000580085   train's RMSPE: 0.381796 valid's rmse: 0.000674984   valid's RMSPE: 0.549689\n[519]   train's rmse: 0.000580901   train's RMSPE: 0.382333 valid's rmse: 0.000671766   valid's RMSPE: 0.547069\n[520]   train's rmse: 0.000581812   train's RMSPE: 0.382932 valid's rmse: 0.000668751   valid's RMSPE: 0.544614\n[521]   train's rmse: 0.000582585   train's RMSPE: 0.383441 valid's rmse: 0.000667285   valid's RMSPE: 0.543419\n[522]   train's rmse: 0.00058091    train's RMSPE: 0.382339 valid's rmse: 0.000669833   valid's RMSPE: 0.545495\n[523]   train's rmse: 0.00058161    train's RMSPE: 0.3828   valid's rmse: 0.00066847    valid's RMSPE: 0.544385\n[524]   train's rmse: 0.000582436   train's RMSPE: 0.383343 valid's rmse: 0.000666879   valid's RMSPE: 0.543089\n[525]   train's rmse: 0.000583348   train's RMSPE: 0.383943 valid's rmse: 0.000665732   valid's RMSPE: 0.542155\n[526]   train's rmse: 0.000584124   train's RMSPE: 0.384454 valid's rmse: 0.00066447    valid's RMSPE: 0.541127\n[527]   train's rmse: 0.000582405   train's RMSPE: 0.383323 valid's rmse: 0.000665634   valid's RMSPE: 0.542075\n[528]   train's rmse: 0.000581068   train's RMSPE: 0.382443 valid's rmse: 0.000664578   valid's RMSPE: 0.541215\n[529]   train's rmse: 0.000579199   train's RMSPE: 0.381212 valid's rmse: 0.000663865   valid's RMSPE: 0.540635\n[530]   train's rmse: 0.00058007    train's RMSPE: 0.381786 valid's rmse: 0.000663097   valid's RMSPE: 0.540009\n[531]   train's rmse: 0.000580731   train's RMSPE: 0.382221 valid's rmse: 0.000662076   valid's RMSPE: 0.539178\n[532]   train's rmse: 0.000578751   train's RMSPE: 0.380918 valid's rmse: 0.000672105   valid's RMSPE: 0.547345\n[533]   train's rmse: 0.00057956    train's RMSPE: 0.38145  valid's rmse: 0.000671043   valid's RMSPE: 0.54648\n[534]   train's rmse: 0.000578475   train's RMSPE: 0.380736 valid's rmse: 0.000674963   valid's RMSPE: 0.549672\n[535]   train's rmse: 0.000577086   train's RMSPE: 0.379822 valid's rmse: 0.00067888    valid's RMSPE: 0.552862\n[536]   train's rmse: 0.000577013   train's RMSPE: 0.379774 valid's rmse: 0.000680363   valid's RMSPE: 0.55407\n[537]   train's rmse: 0.000575855   train's RMSPE: 0.379012 valid's rmse: 0.000690174   valid's RMSPE: 0.56206\n[538]   train's rmse: 0.000576512   train's RMSPE: 0.379444 valid's rmse: 0.000689522   valid's RMSPE: 0.561529\n[539]   train's rmse: 0.000575116   train's RMSPE: 0.378525 valid's rmse: 0.00068988    valid's RMSPE: 0.56182\n[540]   train's rmse: 0.000575805   train's RMSPE: 0.378979 valid's rmse: 0.000687892   valid's RMSPE: 0.560202\n[541]   train's rmse: 0.000576618   train's RMSPE: 0.379514 valid's rmse: 0.000686195   valid's RMSPE: 0.55882\n[542]   train's rmse: 0.000576001   train's RMSPE: 0.379108 valid's rmse: 0.000685326   valid's RMSPE: 0.558112\n[543]   train's rmse: 0.0005746 train's RMSPE: 0.378186 valid's rmse: 0.000682183   valid's RMSPE: 0.555552\n[544]   train's rmse: 0.000572967   train's RMSPE: 0.377111 valid's rmse: 0.000681625   valid's RMSPE: 0.555098\n[545]   train's rmse: 0.000571193   train's RMSPE: 0.375944 valid's rmse: 0.000682166   valid's RMSPE: 0.555538\n[546]   train's rmse: 0.000569879   train's RMSPE: 0.375079 valid's rmse: 0.000683045   valid's RMSPE: 0.556254\n[547]   train's rmse: 0.000570499   train's RMSPE: 0.375486 valid's rmse: 0.000681711   valid's RMSPE: 0.555168\n[548]   train's rmse: 0.00056931    train's RMSPE: 0.374704 valid's rmse: 0.000691136   valid's RMSPE: 0.562843\n[549]   train's rmse: 0.000569914   train's RMSPE: 0.375102 valid's rmse: 0.000689853   valid's RMSPE: 0.561799\n[550]   train's rmse: 0.000570643   train's RMSPE: 0.375581 valid's rmse: 0.000688151   valid's RMSPE: 0.560412\n[551]   train's rmse: 0.000570041   train's RMSPE: 0.375185 valid's rmse: 0.000688313   valid's RMSPE: 0.560544\n[552]   train's rmse: 0.000570619   train's RMSPE: 0.375566 valid's rmse: 0.000687075   valid's RMSPE: 0.559536\n[553]   train's rmse: 0.000571313   train's RMSPE: 0.376022 valid's rmse: 0.000685794   valid's RMSPE: 0.558493\n[554]   train's rmse: 0.000571945   train's RMSPE: 0.376438 valid's rmse: 0.00068492    valid's RMSPE: 0.557781\n[555]   train's rmse: 0.000572579   train's RMSPE: 0.376856 valid's rmse: 0.000683324   valid's RMSPE: 0.556482\n[556]   train's rmse: 0.000571456   train's RMSPE: 0.376116 valid's rmse: 0.000689084   valid's RMSPE: 0.561172\n[557]   train's rmse: 0.00057009    train's RMSPE: 0.375217 valid's rmse: 0.000688181   valid's RMSPE: 0.560437\n[558]   train's rmse: 0.000569565   train's RMSPE: 0.374872 valid's rmse: 0.000695147   valid's RMSPE: 0.566109\n[559]   train's rmse: 0.000570259   train's RMSPE: 0.375328 valid's rmse: 0.000693689   valid's RMSPE: 0.564923\n[560]   train's rmse: 0.000569178   train's RMSPE: 0.374617 valid's rmse: 0.000695998   valid's RMSPE: 0.566802\n[561]   train's rmse: 0.00056981    train's RMSPE: 0.375033 valid's rmse: 0.00069524    valid's RMSPE: 0.566185\n[562]   train's rmse: 0.000570569   train's RMSPE: 0.375533 valid's rmse: 0.00069381    valid's RMSPE: 0.565021\n[563]   train's rmse: 0.000569235   train's RMSPE: 0.374654 valid's rmse: 0.00069062    valid's RMSPE: 0.562423\n[564]   train's rmse: 0.000569935   train's RMSPE: 0.375116 valid's rmse: 0.000686796   valid's RMSPE: 0.559308\n[565]   train's rmse: 0.000568581   train's RMSPE: 0.374224 valid's rmse: 0.000691512   valid's RMSPE: 0.56315\n[566]   train's rmse: 0.000569253   train's RMSPE: 0.374666 valid's rmse: 0.000689967   valid's RMSPE: 0.561891\n[567]   train's rmse: 0.000569882   train's RMSPE: 0.37508  valid's rmse: 0.000688411   valid's RMSPE: 0.560624\n[568]   train's rmse: 0.000568344   train's RMSPE: 0.374068 valid's rmse: 0.00069028    valid's RMSPE: 0.562146\n[569]   train's rmse: 0.000568957   train's RMSPE: 0.374472 valid's rmse: 0.000688814   valid's RMSPE: 0.560952\n[570]   train's rmse: 0.000569545   train's RMSPE: 0.374859 valid's rmse: 0.000687719   valid's RMSPE: 0.56006\n[571]   train's rmse: 0.000570331   train's RMSPE: 0.375376 valid's rmse: 0.000685484   valid's RMSPE: 0.558241\n[572]   train's rmse: 0.000571078   train's RMSPE: 0.375868 valid's rmse: 0.000684296   valid's RMSPE: 0.557273\n[573]   train's rmse: 0.000571905   train's RMSPE: 0.376412 valid's rmse: 0.000682728   valid's RMSPE: 0.555996\n[574]   train's rmse: 0.000571629   train's RMSPE: 0.376231 valid's rmse: 0.000683001   valid's RMSPE: 0.556218\n[575]   train's rmse: 0.000572276   train's RMSPE: 0.376656 valid's rmse: 0.000682007   valid's RMSPE: 0.555409\n[576]   train's rmse: 0.000572989   train's RMSPE: 0.377125 valid's rmse: 0.000680465   valid's RMSPE: 0.554153\n[577]   train's rmse: 0.000573784   train's RMSPE: 0.377649 valid's rmse: 0.000679558   valid's RMSPE: 0.553414\n[578]   train's rmse: 0.00057304    train's RMSPE: 0.377159 valid's rmse: 0.000681775   valid's RMSPE: 0.55522\n[579]   train's rmse: 0.00057159    train's RMSPE: 0.376205 valid's rmse: 0.000685725   valid's RMSPE: 0.558437\n[580]   train's rmse: 0.000572305   train's RMSPE: 0.376675 valid's rmse: 0.000683892   valid's RMSPE: 0.556944\n[581]   train's rmse: 0.000569822   train's RMSPE: 0.375041 valid's rmse: 0.000682975   valid's RMSPE: 0.556197\n[582]   train's rmse: 0.000570373   train's RMSPE: 0.375404 valid's rmse: 0.000681811   valid's RMSPE: 0.555249\n[583]   train's rmse: 0.000570917   train's RMSPE: 0.375762 valid's rmse: 0.000680967   valid's RMSPE: 0.554562\n[584]   train's rmse: 0.000569054   train's RMSPE: 0.374536 valid's rmse: 0.000684717   valid's RMSPE: 0.557616\n[585]   train's rmse: 0.000569751   train's RMSPE: 0.374994 valid's rmse: 0.000683579   valid's RMSPE: 0.556689\n[586]   train's rmse: 0.00056772    train's RMSPE: 0.373657 valid's rmse: 0.000684148   valid's RMSPE: 0.557152\n[587]   train's rmse: 0.000566305   train's RMSPE: 0.372726 valid's rmse: 0.000686295   valid's RMSPE: 0.558901\n[588]   train's rmse: 0.000566336   train's RMSPE: 0.372747 valid's rmse: 0.00069431    valid's RMSPE: 0.565428\n[589]   train's rmse: 0.000567037   train's RMSPE: 0.373208 valid's rmse: 0.000693201   valid's RMSPE: 0.564525\nEarly stopping, best iteration is:\n[190]   0.4680685766972542\n189\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/callback.py:183: UserWarning: Early stopping is not available in dart mode\n  _log_warning('Early stopping is not available in dart mode')\n\n\n[1] train's rmse: 0.00109055    train's RMSPE: 0.757936 valid's rmse: 0.00109764    valid's RMSPE: 0.747566\n[2] train's rmse: 0.00106299    train's RMSPE: 0.738781 valid's rmse: 0.00106913    valid's RMSPE: 0.728144\n[3] train's rmse: 0.00103989    train's RMSPE: 0.722729 valid's rmse: 0.00104385    valid's RMSPE: 0.710932\n[4] train's rmse: 0.00101888    train's RMSPE: 0.708125 valid's rmse: 0.00101935    valid's RMSPE: 0.694243\n[5] train's rmse: 0.000994633   train's RMSPE: 0.691273 valid's rmse: 0.000996931   valid's RMSPE: 0.678974\n[6] train's rmse: 0.000977325   train's RMSPE: 0.679245 valid's rmse: 0.000974658   valid's RMSPE: 0.663805\n[7] train's rmse: 0.000976785   train's RMSPE: 0.678869 valid's rmse: 0.000974485   valid's RMSPE: 0.663687\n[8] train's rmse: 0.000956633   train's RMSPE: 0.664863 valid's rmse: 0.000955151   valid's RMSPE: 0.650519\n[9] train's rmse: 0.00093296    train's RMSPE: 0.64841  valid's rmse: 0.000933871   valid's RMSPE: 0.636026\n[10]    train's rmse: 0.000934559   train's RMSPE: 0.649522 valid's rmse: 0.000937393   valid's RMSPE: 0.638424\n[11]    train's rmse: 0.000918924   train's RMSPE: 0.638655 valid's rmse: 0.000917002   valid's RMSPE: 0.624537\n[12]    train's rmse: 0.000921543   train's RMSPE: 0.640475 valid's rmse: 0.000920005   valid's RMSPE: 0.626582\n[13]    train's rmse: 0.00089945    train's RMSPE: 0.625121 valid's rmse: 0.000905689   valid's RMSPE: 0.616832\n[14]    train's rmse: 0.000880848   train's RMSPE: 0.612192 valid's rmse: 0.000887239   valid's RMSPE: 0.604266\n[15]    train's rmse: 0.000866499   train's RMSPE: 0.60222  valid's rmse: 0.000873556   valid's RMSPE: 0.594948\n[16]    train's rmse: 0.000851599   train's RMSPE: 0.591864 valid's rmse: 0.000859066   valid's RMSPE: 0.585079\n[17]    train's rmse: 0.000856686   train's RMSPE: 0.5954   valid's rmse: 0.000863689   valid's RMSPE: 0.588227\n[18]    train's rmse: 0.000844809   train's RMSPE: 0.587145 valid's rmse: 0.000850691   valid's RMSPE: 0.579375\n[19]    train's rmse: 0.000845369   train's RMSPE: 0.587535 valid's rmse: 0.000849995   valid's RMSPE: 0.578901\n[20]    train's rmse: 0.000848456   train's RMSPE: 0.58968  valid's rmse: 0.000851703   valid's RMSPE: 0.580064\n[21]    train's rmse: 0.00085683    train's RMSPE: 0.5955   valid's rmse: 0.000857205   valid's RMSPE: 0.583811\n[22]    train's rmse: 0.000872355   train's RMSPE: 0.60629  valid's rmse: 0.000876192   valid's RMSPE: 0.596743\n[23]    train's rmse: 0.000859862   train's RMSPE: 0.597607 valid's rmse: 0.000857811   valid's RMSPE: 0.584224\n[24]    train's rmse: 0.000895557   train's RMSPE: 0.622415 valid's rmse: 0.00089685    valid's RMSPE: 0.610812\n[25]    train's rmse: 0.000889633   train's RMSPE: 0.618298 valid's rmse: 0.000892879   valid's RMSPE: 0.608108\n[26]    train's rmse: 0.000870624   train's RMSPE: 0.605086 valid's rmse: 0.000871487   valid's RMSPE: 0.593538\n[27]    train's rmse: 0.000858139   train's RMSPE: 0.59641  valid's rmse: 0.000854016   valid's RMSPE: 0.58164\n[28]    train's rmse: 0.000862223   train's RMSPE: 0.599248 valid's rmse: 0.000858274   valid's RMSPE: 0.584539\n[29]    train's rmse: 0.000867275   train's RMSPE: 0.602759 valid's rmse: 0.000864292   valid's RMSPE: 0.588638\n[30]    train's rmse: 0.000848609   train's RMSPE: 0.589787 valid's rmse: 0.000847453   valid's RMSPE: 0.57717\n[31]    train's rmse: 0.000835312   train's RMSPE: 0.580545 valid's rmse: 0.000833363   valid's RMSPE: 0.567574\n[32]    train's rmse: 0.000842089   train's RMSPE: 0.585255 valid's rmse: 0.000841761   valid's RMSPE: 0.573293\n[33]    train's rmse: 0.000829855   train's RMSPE: 0.576752 valid's rmse: 0.000828868   valid's RMSPE: 0.564512\n[34]    train's rmse: 0.000818951   train's RMSPE: 0.569174 valid's rmse: 0.000816483   valid's RMSPE: 0.556077\n[35]    train's rmse: 0.000805014   train's RMSPE: 0.559488 valid's rmse: 0.000805653   valid's RMSPE: 0.548701\n[36]    train's rmse: 0.000796876   train's RMSPE: 0.553832 valid's rmse: 0.000795792   valid's RMSPE: 0.541985\n[37]    train's rmse: 0.000799209   train's RMSPE: 0.555453 valid's rmse: 0.000798704   valid's RMSPE: 0.543969\n[38]    train's rmse: 0.000824665   train's RMSPE: 0.573145 valid's rmse: 0.000822476   valid's RMSPE: 0.560159\n[39]    train's rmse: 0.000808723   train's RMSPE: 0.562065 valid's rmse: 0.00080675    valid's RMSPE: 0.549449\n[40]    train's rmse: 0.000798397   train's RMSPE: 0.554889 valid's rmse: 0.000793524   valid's RMSPE: 0.54044\n[41]    train's rmse: 0.000803508   train's RMSPE: 0.558441 valid's rmse: 0.000799016   valid's RMSPE: 0.544181\n[42]    train's rmse: 0.00080698    train's RMSPE: 0.560854 valid's rmse: 0.000803898   valid's RMSPE: 0.547506\n[43]    train's rmse: 0.00079339    train's RMSPE: 0.551409 valid's rmse: 0.000790686   valid's RMSPE: 0.538508\n[44]    train's rmse: 0.000785001   train's RMSPE: 0.545578 valid's rmse: 0.000778548   valid's RMSPE: 0.530241\n[45]    train's rmse: 0.000772684   train's RMSPE: 0.537018 valid's rmse: 0.000768833   valid's RMSPE: 0.523624\n[46]    train's rmse: 0.000777448   train's RMSPE: 0.540329 valid's rmse: 0.000773804   valid's RMSPE: 0.52701\n[47]    train's rmse: 0.000764747   train's RMSPE: 0.531502 valid's rmse: 0.000761019   valid's RMSPE: 0.518302\n[48]    train's rmse: 0.00077072    train's RMSPE: 0.535653 valid's rmse: 0.000766526   valid's RMSPE: 0.522054\n[49]    train's rmse: 0.000775966   train's RMSPE: 0.539299 valid's rmse: 0.000771324   valid's RMSPE: 0.525321\n[50]    train's rmse: 0.000765719   train's RMSPE: 0.532177 valid's rmse: 0.000762328   valid's RMSPE: 0.519194\n[51]    train's rmse: 0.000769333   train's RMSPE: 0.534689 valid's rmse: 0.000766307   valid's RMSPE: 0.521904\n[52]    train's rmse: 0.000771411   train's RMSPE: 0.536133 valid's rmse: 0.00076788    valid's RMSPE: 0.522976\n[53]    train's rmse: 0.000774726   train's RMSPE: 0.538437 valid's rmse: 0.000771862   valid's RMSPE: 0.525687\n[54]    train's rmse: 0.000762197   train's RMSPE: 0.52973  valid's rmse: 0.000759823   valid's RMSPE: 0.517488\n[55]    train's rmse: 0.000765166   train's RMSPE: 0.531793 valid's rmse: 0.00076381    valid's RMSPE: 0.520204\n[56]    train's rmse: 0.000755407   train's RMSPE: 0.52501  valid's rmse: 0.000756254   valid's RMSPE: 0.515058\n[57]    train's rmse: 0.000745275   train's RMSPE: 0.517969 valid's rmse: 0.000747935   valid's RMSPE: 0.509391\n[58]    train's rmse: 0.000737915   train's RMSPE: 0.512854 valid's rmse: 0.000737129   valid's RMSPE: 0.502032\n[59]    train's rmse: 0.00074183    train's RMSPE: 0.515575 valid's rmse: 0.000741685   valid's RMSPE: 0.505135\n[60]    train's rmse: 0.000737673   train's RMSPE: 0.512686 valid's rmse: 0.00073463    valid's RMSPE: 0.50033\n[61]    train's rmse: 0.000743288   train's RMSPE: 0.516588 valid's rmse: 0.000740757   valid's RMSPE: 0.504503\n[62]    train's rmse: 0.000733025   train's RMSPE: 0.509455 valid's rmse: 0.000733058   valid's RMSPE: 0.49926\n[63]    train's rmse: 0.000747865   train's RMSPE: 0.519769 valid's rmse: 0.000745544   valid's RMSPE: 0.507763\n[64]    train's rmse: 0.000763286   train's RMSPE: 0.530486 valid's rmse: 0.000760582   valid's RMSPE: 0.518005\n[65]    train's rmse: 0.000768828   train's RMSPE: 0.534338 valid's rmse: 0.000766806   valid's RMSPE: 0.522244\n[66]    train's rmse: 0.000756015   train's RMSPE: 0.525433 valid's rmse: 0.000755912   valid's RMSPE: 0.514825\n[67]    train's rmse: 0.000758834   train's RMSPE: 0.527392 valid's rmse: 0.000757974   valid's RMSPE: 0.516229\n[68]    train's rmse: 0.000746158   train's RMSPE: 0.518582 valid's rmse: 0.000748757   valid's RMSPE: 0.509951\n[69]    train's rmse: 0.00073831    train's RMSPE: 0.513128 valid's rmse: 0.000739855   valid's RMSPE: 0.503888\n[70]    train's rmse: 0.000742579   train's RMSPE: 0.516095 valid's rmse: 0.000744432   valid's RMSPE: 0.507006\n[71]    train's rmse: 0.000745732   train's RMSPE: 0.518287 valid's rmse: 0.000747783   valid's RMSPE: 0.509288\n[72]    train's rmse: 0.000734718   train's RMSPE: 0.510632 valid's rmse: 0.000738292   valid's RMSPE: 0.502824\n[73]    train's rmse: 0.000727348   train's RMSPE: 0.505509 valid's rmse: 0.000728205   valid's RMSPE: 0.495954\n[74]    train's rmse: 0.000731837   train's RMSPE: 0.508629 valid's rmse: 0.000732237   valid's RMSPE: 0.4987\n[75]    train's rmse: 0.000721453   train's RMSPE: 0.501412 valid's rmse: 0.000724896   valid's RMSPE: 0.493701\n[76]    train's rmse: 0.000725317   train's RMSPE: 0.504098 valid's rmse: 0.000728889   valid's RMSPE: 0.49642\n[77]    train's rmse: 0.000716591   train's RMSPE: 0.498033 valid's rmse: 0.000720989   valid's RMSPE: 0.491039\n[78]    train's rmse: 0.000716185   train's RMSPE: 0.497751 valid's rmse: 0.000719675   valid's RMSPE: 0.490145\n[79]    train's rmse: 0.000720503   train's RMSPE: 0.500752 valid's rmse: 0.000723692   valid's RMSPE: 0.492881\n[80]    train's rmse: 0.000723455   train's RMSPE: 0.502804 valid's rmse: 0.000726376   valid's RMSPE: 0.494709\n[81]    train's rmse: 0.000714695   train's RMSPE: 0.496715 valid's rmse: 0.000718019   valid's RMSPE: 0.489017\n[82]    train's rmse: 0.000707209   train's RMSPE: 0.491513 valid's rmse: 0.000711999   valid's RMSPE: 0.484917\n[83]    train's rmse: 0.000711925   train's RMSPE: 0.49479  valid's rmse: 0.000715683   valid's RMSPE: 0.487426\n[84]    train's rmse: 0.0007032 train's RMSPE: 0.488727 valid's rmse: 0.000709888   valid's RMSPE: 0.483479\n[85]    train's rmse: 0.000706992   train's RMSPE: 0.491362 valid's rmse: 0.000713227   valid's RMSPE: 0.485753\n[86]    train's rmse: 0.000711261   train's RMSPE: 0.494329 valid's rmse: 0.000717212   valid's RMSPE: 0.488467\n[87]    train's rmse: 0.000703414   train's RMSPE: 0.488875 valid's rmse: 0.000710383   valid's RMSPE: 0.483817\n[88]    train's rmse: 0.000706094   train's RMSPE: 0.490738 valid's rmse: 0.000712719   valid's RMSPE: 0.485407\n[89]    train's rmse: 0.000710133   train's RMSPE: 0.493545 valid's rmse: 0.000716554   valid's RMSPE: 0.488019\n[90]    train's rmse: 0.000714734   train's RMSPE: 0.496743 valid's rmse: 0.00072042    valid's RMSPE: 0.490652\n[91]    train's rmse: 0.000719307   train's RMSPE: 0.499921 valid's rmse: 0.000724476   valid's RMSPE: 0.493415\n[92]    train's rmse: 0.000711147   train's RMSPE: 0.49425  valid's rmse: 0.000716959   valid's RMSPE: 0.488295\n[93]    train's rmse: 0.000704156   train's RMSPE: 0.489391 valid's rmse: 0.000709915   valid's RMSPE: 0.483498\n[94]    train's rmse: 0.000699253   train's RMSPE: 0.485983 valid's rmse: 0.000705525   valid's RMSPE: 0.480508\n[95]    train's rmse: 0.000693448   train's RMSPE: 0.481948 valid's rmse: 0.00070216    valid's RMSPE: 0.478216\n[96]    train's rmse: 0.000686487   train's RMSPE: 0.477111 valid's rmse: 0.000696091   valid's RMSPE: 0.474083\n[97]    train's rmse: 0.00068071    train's RMSPE: 0.473095 valid's rmse: 0.000696437   valid's RMSPE: 0.474318\n[98]    train's rmse: 0.000684307   train's RMSPE: 0.475596 valid's rmse: 0.000699712   valid's RMSPE: 0.476549\n[99]    train's rmse: 0.00068727    train's RMSPE: 0.477655 valid's rmse: 0.000701434   valid's RMSPE: 0.477721\n[100]   train's rmse: 0.000690661   train's RMSPE: 0.480012 valid's rmse: 0.000704472   valid's RMSPE: 0.47979\n[101]   train's rmse: 0.000683596   train's RMSPE: 0.475102 valid's rmse: 0.000699419   valid's RMSPE: 0.476349\n[102]   train's rmse: 0.000679217   train's RMSPE: 0.472058 valid's rmse: 0.000692865   valid's RMSPE: 0.471886\n[103]   train's rmse: 0.000682347   train's RMSPE: 0.474233 valid's rmse: 0.000695468   valid's RMSPE: 0.473658\n[104]   train's rmse: 0.000684952   train's RMSPE: 0.476044 valid's rmse: 0.00069793    valid's RMSPE: 0.475335\n[105]   train's rmse: 0.000687291   train's RMSPE: 0.47767  valid's rmse: 0.000700449   valid's RMSPE: 0.477051\n[106]   train's rmse: 0.000697594   train's RMSPE: 0.48483  valid's rmse: 0.000707412   valid's RMSPE: 0.481793\n[107]   train's rmse: 0.000700946   train's RMSPE: 0.48716  valid's rmse: 0.000710522   valid's RMSPE: 0.483911\n[108]   train's rmse: 0.000704893   train's RMSPE: 0.489903 valid's rmse: 0.000713663   valid's RMSPE: 0.48605\n[109]   train's rmse: 0.000708104   train's RMSPE: 0.492135 valid's rmse: 0.000716607   valid's RMSPE: 0.488055\n[110]   train's rmse: 0.000703927   train's RMSPE: 0.489232 valid's rmse: 0.000708886   valid's RMSPE: 0.482797\n[111]   train's rmse: 0.000707661   train's RMSPE: 0.491827 valid's rmse: 0.000712286   valid's RMSPE: 0.485113\n[112]   train's rmse: 0.000711703   train's RMSPE: 0.494636 valid's rmse: 0.000716147   valid's RMSPE: 0.487742\n[113]   train's rmse: 0.000703691   train's RMSPE: 0.489068 valid's rmse: 0.000709845   valid's RMSPE: 0.48345\n[114]   train's rmse: 0.00070774    train's RMSPE: 0.491882 valid's rmse: 0.000713793   valid's RMSPE: 0.486139\n[115]   train's rmse: 0.000711224   train's RMSPE: 0.494303 valid's rmse: 0.00071624    valid's RMSPE: 0.487805\n[116]   train's rmse: 0.000704247   train's RMSPE: 0.489454 valid's rmse: 0.000709456   valid's RMSPE: 0.483185\n[117]   train's rmse: 0.000706061   train's RMSPE: 0.490715 valid's rmse: 0.000711395   valid's RMSPE: 0.484506\n[118]   train's rmse: 0.000709011   train's RMSPE: 0.492765 valid's rmse: 0.000714407   valid's RMSPE: 0.486557\n[119]   train's rmse: 0.000711213   train's RMSPE: 0.494296 valid's rmse: 0.000716688   valid's RMSPE: 0.48811\n[120]   train's rmse: 0.000705768   train's RMSPE: 0.490511 valid's rmse: 0.000710659   valid's RMSPE: 0.484004\n[121]   train's rmse: 0.000708706   train's RMSPE: 0.492553 valid's rmse: 0.000713048   valid's RMSPE: 0.485631\n[122]   train's rmse: 0.000712607   train's RMSPE: 0.495264 valid's rmse: 0.000716666   valid's RMSPE: 0.488096\n[123]   train's rmse: 0.000720536   train's RMSPE: 0.500775 valid's rmse: 0.000723226   valid's RMSPE: 0.492563\n[124]   train's rmse: 0.000722643   train's RMSPE: 0.50224  valid's rmse: 0.000725338   valid's RMSPE: 0.494002\n[125]   train's rmse: 0.000716626   train's RMSPE: 0.498057 valid's rmse: 0.000717847   valid's RMSPE: 0.4889\n[126]   train's rmse: 0.000719078   train's RMSPE: 0.499762 valid's rmse: 0.000720556   valid's RMSPE: 0.490745\n[127]   train's rmse: 0.000721351   train's RMSPE: 0.501341 valid's rmse: 0.000723314   valid's RMSPE: 0.492623\n[128]   train's rmse: 0.000715223   train's RMSPE: 0.497083 valid's rmse: 0.000715525   valid's RMSPE: 0.487318\n[129]   train's rmse: 0.000707397   train's RMSPE: 0.491643 valid's rmse: 0.000710425   valid's RMSPE: 0.483845\n[130]   train's rmse: 0.000714477   train's RMSPE: 0.496564 valid's rmse: 0.000716184   valid's RMSPE: 0.487767\n[131]   train's rmse: 0.000709543   train's RMSPE: 0.493135 valid's rmse: 0.000707243   valid's RMSPE: 0.481677\n[132]   train's rmse: 0.000712112   train's RMSPE: 0.49492  valid's rmse: 0.000710174   valid's RMSPE: 0.483674\n[133]   train's rmse: 0.000703859   train's RMSPE: 0.489184 valid's rmse: 0.000705061   valid's RMSPE: 0.480191\n[134]   train's rmse: 0.000706665   train's RMSPE: 0.491134 valid's rmse: 0.000707683   valid's RMSPE: 0.481978\n[135]   train's rmse: 0.000699607   train's RMSPE: 0.48623  valid's rmse: 0.000702806   valid's RMSPE: 0.478656\n[136]   train's rmse: 0.000702085   train's RMSPE: 0.487952 valid's rmse: 0.000705722   valid's RMSPE: 0.480642\n[137]   train's rmse: 0.000705018   train's RMSPE: 0.48999  valid's rmse: 0.00070867    valid's RMSPE: 0.48265\n[138]   train's rmse: 0.000708077   train's RMSPE: 0.492116 valid's rmse: 0.000711861   valid's RMSPE: 0.484823\n[139]   train's rmse: 0.000710353   train's RMSPE: 0.493697 valid's rmse: 0.000714003   valid's RMSPE: 0.486282\n[140]   train's rmse: 0.000702362   train's RMSPE: 0.488144 valid's rmse: 0.000709246   valid's RMSPE: 0.483042\n[141]   train's rmse: 0.000694419   train's RMSPE: 0.482624 valid's rmse: 0.000702316   valid's RMSPE: 0.478322\n[142]   train's rmse: 0.000684008   train's RMSPE: 0.475388 valid's rmse: 0.000699637   valid's RMSPE: 0.476497\n[143]   train's rmse: 0.00067542    train's RMSPE: 0.469419 valid's rmse: 0.000693692   valid's RMSPE: 0.472448\n[144]   train's rmse: 0.0006729 train's RMSPE: 0.467668 valid's rmse: 0.000687993   valid's RMSPE: 0.468567\n[145]   train's rmse: 0.000675848   train's RMSPE: 0.469717 valid's rmse: 0.000690305   valid's RMSPE: 0.470142\n[146]   train's rmse: 0.000671742   train's RMSPE: 0.466863 valid's rmse: 0.000685709   valid's RMSPE: 0.467012\n[147]   train's rmse: 0.000674296   train's RMSPE: 0.468638 valid's rmse: 0.000687622   valid's RMSPE: 0.468314\n[148]   train's rmse: 0.00067745    train's RMSPE: 0.47083  valid's rmse: 0.000689276   valid's RMSPE: 0.469441\n[149]   train's rmse: 0.000671028   train's RMSPE: 0.466367 valid's rmse: 0.000684534   valid's RMSPE: 0.466211\n[150]   train's rmse: 0.000664502   train's RMSPE: 0.461831 valid's rmse: 0.000682313   valid's RMSPE: 0.464699\n[151]   train's rmse: 0.000667798   train's RMSPE: 0.464122 valid's rmse: 0.000684545   valid's RMSPE: 0.466219\n[152]   train's rmse: 0.000670629   train's RMSPE: 0.466089 valid's rmse: 0.000686809   valid's RMSPE: 0.467761\n[153]   train's rmse: 0.000673297   train's RMSPE: 0.467944 valid's rmse: 0.000688769   valid's RMSPE: 0.469096\n[154]   train's rmse: 0.000676513   train's RMSPE: 0.470179 valid's rmse: 0.000691374   valid's RMSPE: 0.47087\n[155]   train's rmse: 0.000679741   train's RMSPE: 0.472422 valid's rmse: 0.000693837   valid's RMSPE: 0.472547\n[156]   train's rmse: 0.000681651   train's RMSPE: 0.47375  valid's rmse: 0.000695502   valid's RMSPE: 0.473681\n[157]   train's rmse: 0.000684769   train's RMSPE: 0.475917 valid's rmse: 0.000697925   valid's RMSPE: 0.475332\n[158]   train's rmse: 0.000687611   train's RMSPE: 0.477892 valid's rmse: 0.000700354   valid's RMSPE: 0.476986\n[159]   train's rmse: 0.000690068   train's RMSPE: 0.4796   valid's rmse: 0.000702462   valid's RMSPE: 0.478422\n[160]   train's rmse: 0.000682567   train's RMSPE: 0.474386 valid's rmse: 0.000699253   valid's RMSPE: 0.476236\n[161]   train's rmse: 0.000685253   train's RMSPE: 0.476253 valid's rmse: 0.000701221   valid's RMSPE: 0.477576\n[162]   train's rmse: 0.000681744   train's RMSPE: 0.473815 valid's rmse: 0.000693946   valid's RMSPE: 0.472622\n[163]   train's rmse: 0.000687119   train's RMSPE: 0.47755  valid's rmse: 0.000697696   valid's RMSPE: 0.475175\n[164]   train's rmse: 0.000680328   train's RMSPE: 0.47283  valid's rmse: 0.000691705   valid's RMSPE: 0.471095\n[165]   train's rmse: 0.000686089   train's RMSPE: 0.476834 valid's rmse: 0.000695314   valid's RMSPE: 0.473553\n[166]   train's rmse: 0.000688408   train's RMSPE: 0.478446 valid's rmse: 0.000697757   valid's RMSPE: 0.475217\n[167]   train's rmse: 0.000680046   train's RMSPE: 0.472634 valid's rmse: 0.000694227   valid's RMSPE: 0.472813\n[168]   train's rmse: 0.000673481   train's RMSPE: 0.468072 valid's rmse: 0.000689379   valid's RMSPE: 0.469511\n[169]   train's rmse: 0.000668476   train's RMSPE: 0.464593 valid's rmse: 0.000683773   valid's RMSPE: 0.465693\n[170]   train's rmse: 0.000671173   train's RMSPE: 0.466468 valid's rmse: 0.000685761   valid's RMSPE: 0.467047\n[171]   train's rmse: 0.0006738 train's RMSPE: 0.468294 valid's rmse: 0.00068785    valid's RMSPE: 0.46847\n[172]   train's rmse: 0.000667001   train's RMSPE: 0.463568 valid's rmse: 0.000684849   valid's RMSPE: 0.466426\n[173]   train's rmse: 0.000660174   train's RMSPE: 0.458824 valid's rmse: 0.000683386   valid's RMSPE: 0.46543\n[174]   train's rmse: 0.000662762   train's RMSPE: 0.460622 valid's rmse: 0.000685103   valid's RMSPE: 0.466599\n[175]   train's rmse: 0.000657487   train's RMSPE: 0.456955 valid's rmse: 0.000680479   valid's RMSPE: 0.463449\n[176]   train's rmse: 0.000652833   train's RMSPE: 0.453721 valid's rmse: 0.00067725    valid's RMSPE: 0.461251\n[177]   train's rmse: 0.000655704   train's RMSPE: 0.455717 valid's rmse: 0.000678861   valid's RMSPE: 0.462347\n[178]   train's rmse: 0.000651288   train's RMSPE: 0.452648 valid's rmse: 0.000675277   valid's RMSPE: 0.459907\n[179]   train's rmse: 0.000647323   train's RMSPE: 0.449892 valid's rmse: 0.000672158   valid's RMSPE: 0.457782\n[180]   train's rmse: 0.000649452   train's RMSPE: 0.451371 valid's rmse: 0.000673983   valid's RMSPE: 0.459026\n[181]   train's rmse: 0.000651786   train's RMSPE: 0.452994 valid's rmse: 0.00067596    valid's RMSPE: 0.460372\n[182]   train's rmse: 0.000657782   train's RMSPE: 0.457161 valid's rmse: 0.00067838    valid's RMSPE: 0.46202\n[183]   train's rmse: 0.000651528   train's RMSPE: 0.452814 valid's rmse: 0.000675345   valid's RMSPE: 0.459953\n[184]   train's rmse: 0.000653967   train's RMSPE: 0.45451  valid's rmse: 0.000677182   valid's RMSPE: 0.461204\n[185]   train's rmse: 0.000651966   train's RMSPE: 0.453119 valid's rmse: 0.000674346   valid's RMSPE: 0.459272\n[186]   train's rmse: 0.000654509   train's RMSPE: 0.454886 valid's rmse: 0.000676075   valid's RMSPE: 0.46045\n[187]   train's rmse: 0.000656613   train's RMSPE: 0.456348 valid's rmse: 0.000678025   valid's RMSPE: 0.461778\n[188]   train's rmse: 0.000652124   train's RMSPE: 0.453228 valid's rmse: 0.000674766   valid's RMSPE: 0.459559\n[189]   train's rmse: 0.000654371   train's RMSPE: 0.45479  valid's rmse: 0.000676345   valid's RMSPE: 0.460634\n[190]   train's rmse: 0.000648575   train's RMSPE: 0.450762 valid's rmse: 0.000672928   valid's RMSPE: 0.458307\n[191]   train's rmse: 0.00065102    train's RMSPE: 0.452461 valid's rmse: 0.000674427   valid's RMSPE: 0.459328\n[192]   train's rmse: 0.000644178   train's RMSPE: 0.447706 valid's rmse: 0.000671061   valid's RMSPE: 0.457035\n[193]   train's rmse: 0.000646926   train's RMSPE: 0.449616 valid's rmse: 0.000672565   valid's RMSPE: 0.45806\n[194]   train's rmse: 0.000641745   train's RMSPE: 0.446015 valid's rmse: 0.000669134   valid's RMSPE: 0.455723\n[195]   train's rmse: 0.000644656   train's RMSPE: 0.448038 valid's rmse: 0.000670731   valid's RMSPE: 0.45681\n[196]   train's rmse: 0.000640229   train's RMSPE: 0.444962 valid's rmse: 0.00066798    valid's RMSPE: 0.454937\n[197]   train's rmse: 0.000642302   train's RMSPE: 0.446402 valid's rmse: 0.00066951    valid's RMSPE: 0.455979\n[198]   train's rmse: 0.000644379   train's RMSPE: 0.447845 valid's rmse: 0.000671138   valid's RMSPE: 0.457088\n[199]   train's rmse: 0.000646892   train's RMSPE: 0.449592 valid's rmse: 0.00067288    valid's RMSPE: 0.458274\n[200]   train's rmse: 0.000649048   train's RMSPE: 0.451091 valid's rmse: 0.000674149   valid's RMSPE: 0.459139\n[201]   train's rmse: 0.000651634   train's RMSPE: 0.452888 valid's rmse: 0.000675772   valid's RMSPE: 0.460244\n[202]   train's rmse: 0.000653757   train's RMSPE: 0.454364 valid's rmse: 0.000676849   valid's RMSPE: 0.460977\n[203]   train's rmse: 0.000656017   train's RMSPE: 0.455934 valid's rmse: 0.000678643   valid's RMSPE: 0.462199\n[204]   train's rmse: 0.000658561   train's RMSPE: 0.457702 valid's rmse: 0.00068023    valid's RMSPE: 0.46328\n[205]   train's rmse: 0.000653061   train's RMSPE: 0.45388  valid's rmse: 0.000677089   valid's RMSPE: 0.461141\n[206]   train's rmse: 0.000655607   train's RMSPE: 0.455649 valid's rmse: 0.000678718   valid's RMSPE: 0.462251\n[207]   train's rmse: 0.000658075   train's RMSPE: 0.457364 valid's rmse: 0.000680347   valid's RMSPE: 0.46336\n[208]   train's rmse: 0.000660568   train's RMSPE: 0.459097 valid's rmse: 0.000681874   valid's RMSPE: 0.4644\n[209]   train's rmse: 0.000653995   train's RMSPE: 0.454529 valid's rmse: 0.000679764   valid's RMSPE: 0.462963\n[210]   train's rmse: 0.000647684   train's RMSPE: 0.450143 valid's rmse: 0.000677131   valid's RMSPE: 0.461169\n[211]   train's rmse: 0.000644906   train's RMSPE: 0.448212 valid's rmse: 0.000675411   valid's RMSPE: 0.459998\n[212]   train's rmse: 0.000639631   train's RMSPE: 0.444546 valid's rmse: 0.000670829   valid's RMSPE: 0.456877\n[213]   train's rmse: 0.000635258   train's RMSPE: 0.441507 valid's rmse: 0.000667029   valid's RMSPE: 0.45429\n[214]   train's rmse: 0.000639037   train's RMSPE: 0.444133 valid's rmse: 0.000668268   valid's RMSPE: 0.455133\n[215]   train's rmse: 0.000634457   train's RMSPE: 0.44095  valid's rmse: 0.000663652   valid's RMSPE: 0.451989\n[216]   train's rmse: 0.000632471   train's RMSPE: 0.439569 valid's rmse: 0.000666066   valid's RMSPE: 0.453633\n[217]   train's rmse: 0.000634106   train's RMSPE: 0.440706 valid's rmse: 0.000667068   valid's RMSPE: 0.454316\n[218]   train's rmse: 0.000636078   train's RMSPE: 0.442076 valid's rmse: 0.000668052   valid's RMSPE: 0.454986\n[219]   train's rmse: 0.000632635   train's RMSPE: 0.439683 valid's rmse: 0.00066961    valid's RMSPE: 0.456047\n[220]   train's rmse: 0.000634702   train's RMSPE: 0.44112  valid's rmse: 0.000670541   valid's RMSPE: 0.456681\n[221]   train's rmse: 0.00063693    train's RMSPE: 0.442668 valid's rmse: 0.000671453   valid's RMSPE: 0.457302\n[222]   train's rmse: 0.000632433   train's RMSPE: 0.439543 valid's rmse: 0.000669855   valid's RMSPE: 0.456214\n[223]   train's rmse: 0.000628836   train's RMSPE: 0.437043 valid's rmse: 0.000667022   valid's RMSPE: 0.454285\n[224]   train's rmse: 0.00062453    train's RMSPE: 0.434051 valid's rmse: 0.000664499   valid's RMSPE: 0.452567\n[225]   train's rmse: 0.000621552   train's RMSPE: 0.431981 valid's rmse: 0.000663712   valid's RMSPE: 0.45203\n[226]   train's rmse: 0.000618675   train's RMSPE: 0.429981 valid's rmse: 0.00066223    valid's RMSPE: 0.451021\n[227]   train's rmse: 0.000620282   train's RMSPE: 0.431098 valid's rmse: 0.000662486   valid's RMSPE: 0.451196\n[228]   train's rmse: 0.000615318   train's RMSPE: 0.427648 valid's rmse: 0.000662162   valid's RMSPE: 0.450975\n[229]   train's rmse: 0.000611478   train's RMSPE: 0.424979 valid's rmse: 0.000666151   valid's RMSPE: 0.453692\n[230]   train's rmse: 0.00060964    train's RMSPE: 0.423702 valid's rmse: 0.000667901   valid's RMSPE: 0.454884\n[231]   train's rmse: 0.000611788   train's RMSPE: 0.425195 valid's rmse: 0.00066804    valid's RMSPE: 0.454978\n[232]   train's rmse: 0.000610892   train's RMSPE: 0.424572 valid's rmse: 0.000666844   valid's RMSPE: 0.454163\n[233]   train's rmse: 0.00060661    train's RMSPE: 0.421596 valid's rmse: 0.000667315   valid's RMSPE: 0.454484\n[234]   train's rmse: 0.000608252   train's RMSPE: 0.422738 valid's rmse: 0.000667274   valid's RMSPE: 0.454456\n[235]   train's rmse: 0.000610127   train's RMSPE: 0.424041 valid's rmse: 0.000667612   valid's RMSPE: 0.454686\n[236]   train's rmse: 0.000612001   train's RMSPE: 0.425343 valid's rmse: 0.000668029   valid's RMSPE: 0.45497\n[237]   train's rmse: 0.00061338    train's RMSPE: 0.426301 valid's rmse: 0.000668717   valid's RMSPE: 0.455439\n[238]   train's rmse: 0.000614686   train's RMSPE: 0.427209 valid's rmse: 0.000668861   valid's RMSPE: 0.455537\n[239]   train's rmse: 0.000616615   train's RMSPE: 0.42855  valid's rmse: 0.000669484   valid's RMSPE: 0.455961\n[240]   train's rmse: 0.000613509   train's RMSPE: 0.426391 valid's rmse: 0.000669551   valid's RMSPE: 0.456007\n[241]   train's rmse: 0.000615338   train's RMSPE: 0.427662 valid's rmse: 0.000669678   valid's RMSPE: 0.456094\n[242]   train's rmse: 0.000617375   train's RMSPE: 0.429078 valid's rmse: 0.0006702 valid's RMSPE: 0.456449\n[243]   train's rmse: 0.0006197 train's RMSPE: 0.430693 valid's rmse: 0.000671144   valid's RMSPE: 0.457092\n[244]   train's rmse: 0.000616218   train's RMSPE: 0.428274 valid's rmse: 0.000668953   valid's RMSPE: 0.4556\n[245]   train's rmse: 0.000613557   train's RMSPE: 0.426424 valid's rmse: 0.0006671 valid's RMSPE: 0.454338\n[246]   train's rmse: 0.000611996   train's RMSPE: 0.425339 valid's rmse: 0.000665068   valid's RMSPE: 0.452954\n[247]   train's rmse: 0.000609505   train's RMSPE: 0.423608 valid's rmse: 0.000661961   valid's RMSPE: 0.450838\n[248]   train's rmse: 0.000611234   train's RMSPE: 0.424809 valid's rmse: 0.000662489   valid's RMSPE: 0.451197\n[249]   train's rmse: 0.000607809   train's RMSPE: 0.422429 valid's rmse: 0.000660816   valid's RMSPE: 0.450058\n[250]   train's rmse: 0.000609441   train's RMSPE: 0.423564 valid's rmse: 0.000661214   valid's RMSPE: 0.450329\n[251]   train's rmse: 0.000605836   train's RMSPE: 0.421058 valid's rmse: 0.000664606   valid's RMSPE: 0.452639\n[252]   train's rmse: 0.000605317   train's RMSPE: 0.420698 valid's rmse: 0.00066235    valid's RMSPE: 0.451103\n[253]   train's rmse: 0.000607118   train's RMSPE: 0.421949 valid's rmse: 0.000662414   valid's RMSPE: 0.451146\n[254]   train's rmse: 0.000606673   train's RMSPE: 0.42164  valid's rmse: 0.000659828   valid's RMSPE: 0.449385\n[255]   train's rmse: 0.000608149   train's RMSPE: 0.422666 valid's rmse: 0.000660301   valid's RMSPE: 0.449707\n[256]   train's rmse: 0.000609635   train's RMSPE: 0.423699 valid's rmse: 0.000660752   valid's RMSPE: 0.450014\n[257]   train's rmse: 0.000605281   train's RMSPE: 0.420672 valid's rmse: 0.000660481   valid's RMSPE: 0.44983\n[258]   train's rmse: 0.000606922   train's RMSPE: 0.421813 valid's rmse: 0.000660656   valid's RMSPE: 0.449949\n[259]   train's rmse: 0.000608471   train's RMSPE: 0.42289  valid's rmse: 0.000661086   valid's RMSPE: 0.450242\n[260]   train's rmse: 0.000608257   train's RMSPE: 0.422741 valid's rmse: 0.000659998   valid's RMSPE: 0.449501\n[261]   train's rmse: 0.000609479   train's RMSPE: 0.42359  valid's rmse: 0.000660089   valid's RMSPE: 0.449563\n[262]   train's rmse: 0.000610695   train's RMSPE: 0.424435 valid's rmse: 0.000660463   valid's RMSPE: 0.449818\n[263]   train's rmse: 0.000612152   train's RMSPE: 0.425448 valid's rmse: 0.000660718   valid's RMSPE: 0.449991\n[264]   train's rmse: 0.000614162   train's RMSPE: 0.426845 valid's rmse: 0.000660875   valid's RMSPE: 0.450098\n[265]   train's rmse: 0.000613324   train's RMSPE: 0.426262 valid's rmse: 0.000658401   valid's RMSPE: 0.448414\n[266]   train's rmse: 0.000614827   train's RMSPE: 0.427307 valid's rmse: 0.000658754   valid's RMSPE: 0.448654\n[267]   train's rmse: 0.000611832   train's RMSPE: 0.425225 valid's rmse: 0.000657896   valid's RMSPE: 0.448069\n[268]   train's rmse: 0.000607883   train's RMSPE: 0.422481 valid's rmse: 0.000657969   valid's RMSPE: 0.448119\n[269]   train's rmse: 0.000605535   train's RMSPE: 0.420849 valid's rmse: 0.000657163   valid's RMSPE: 0.44757\n[270]   train's rmse: 0.000604631   train's RMSPE: 0.42022  valid's rmse: 0.000658199   valid's RMSPE: 0.448276\n[271]   train's rmse: 0.000605899   train's RMSPE: 0.421102 valid's rmse: 0.000658478   valid's RMSPE: 0.448466\n[272]   train's rmse: 0.000607229   train's RMSPE: 0.422027 valid's rmse: 0.000658519   valid's RMSPE: 0.448494\n[273]   train's rmse: 0.000608606   train's RMSPE: 0.422983 valid's rmse: 0.000659104   valid's RMSPE: 0.448892\n[274]   train's rmse: 0.000604415   train's RMSPE: 0.42007  valid's rmse: 0.000658002   valid's RMSPE: 0.448141\n[275]   train's rmse: 0.00060377    train's RMSPE: 0.419622 valid's rmse: 0.000658813   valid's RMSPE: 0.448694\n[276]   train's rmse: 0.000605075   train's RMSPE: 0.420529 valid's rmse: 0.000658817   valid's RMSPE: 0.448697\n[277]   train's rmse: 0.000602275   train's RMSPE: 0.418583 valid's rmse: 0.00065909    valid's RMSPE: 0.448882\n[278]   train's rmse: 0.00059939    train's RMSPE: 0.416578 valid's rmse: 0.000659187   valid's RMSPE: 0.448949\n[279]   train's rmse: 0.000600675   train's RMSPE: 0.417471 valid's rmse: 0.000659223   valid's RMSPE: 0.448973\n[280]   train's rmse: 0.000597987   train's RMSPE: 0.415603 valid's rmse: 0.000659358   valid's RMSPE: 0.449065\n[281]   train's rmse: 0.00059934    train's RMSPE: 0.416543 valid's rmse: 0.000659315   valid's RMSPE: 0.449036\n[282]   train's rmse: 0.000600646   train's RMSPE: 0.417451 valid's rmse: 0.000659595   valid's RMSPE: 0.449226\n[283]   train's rmse: 0.000598281   train's RMSPE: 0.415807 valid's rmse: 0.000659181   valid's RMSPE: 0.448945\n[284]   train's rmse: 0.00059964    train's RMSPE: 0.416752 valid's rmse: 0.000659435   valid's RMSPE: 0.449118\n[285]   train's rmse: 0.000596299   train's RMSPE: 0.41443  valid's rmse: 0.000660293   valid's RMSPE: 0.449702\n[286]   train's rmse: 0.000597577   train's RMSPE: 0.415318 valid's rmse: 0.000660461   valid's RMSPE: 0.449816\n[287]   train's rmse: 0.000595309   train's RMSPE: 0.413742 valid's rmse: 0.000659079   valid's RMSPE: 0.448875\n[288]   train's rmse: 0.000596543   train's RMSPE: 0.4146   valid's rmse: 0.000659212   valid's RMSPE: 0.448966\n[289]   train's rmse: 0.000597838   train's RMSPE: 0.415499 valid's rmse: 0.000659491   valid's RMSPE: 0.449155\n[290]   train's rmse: 0.000598518   train's RMSPE: 0.415972 valid's rmse: 0.000662132   valid's RMSPE: 0.450954\n[291]   train's rmse: 0.00059563    train's RMSPE: 0.413965 valid's rmse: 0.000664339   valid's RMSPE: 0.452457\n[292]   train's rmse: 0.00059697    train's RMSPE: 0.414896 valid's rmse: 0.00066441    valid's RMSPE: 0.452506\n[293]   train's rmse: 0.000595984   train's RMSPE: 0.414211 valid's rmse: 0.000662725   valid's RMSPE: 0.451358\n[294]   train's rmse: 0.000597028   train's RMSPE: 0.414936 valid's rmse: 0.000662653   valid's RMSPE: 0.451309\n[295]   train's rmse: 0.00059853    train's RMSPE: 0.415981 valid's rmse: 0.00066251    valid's RMSPE: 0.451212\n[296]   train's rmse: 0.000599677   train's RMSPE: 0.416777 valid's rmse: 0.000662924   valid's RMSPE: 0.451494\n[297]   train's rmse: 0.000597011   train's RMSPE: 0.414925 valid's rmse: 0.000665825   valid's RMSPE: 0.45347\n[298]   train's rmse: 0.000598109   train's RMSPE: 0.415688 valid's rmse: 0.000665878   valid's RMSPE: 0.453506\n[299]   train's rmse: 0.000595006   train's RMSPE: 0.413532 valid's rmse: 0.000664527   valid's RMSPE: 0.452585\n[300]   train's rmse: 0.000592704   train's RMSPE: 0.411931 valid's rmse: 0.000663641   valid's RMSPE: 0.451982\n[301]   train's rmse: 0.000589891   train's RMSPE: 0.409976 valid's rmse: 0.000663736   valid's RMSPE: 0.452047\n[302]   train's rmse: 0.000586343   train's RMSPE: 0.40751  valid's rmse: 0.000662441   valid's RMSPE: 0.451164\n[303]   train's rmse: 0.000587379   train's RMSPE: 0.408231 valid's rmse: 0.000661934   valid's RMSPE: 0.450819\n[304]   train's rmse: 0.000585354   train's RMSPE: 0.406823 valid's rmse: 0.000660943   valid's RMSPE: 0.450144\n[305]   train's rmse: 0.000583339   train's RMSPE: 0.405423 valid's rmse: 0.000659444   valid's RMSPE: 0.449124\n[306]   train's rmse: 0.00058466    train's RMSPE: 0.40634  valid's rmse: 0.000659263   valid's RMSPE: 0.449\n[307]   train's rmse: 0.000583953   train's RMSPE: 0.405849 valid's rmse: 0.000658969   valid's RMSPE: 0.4488\n[308]   train's rmse: 0.000585  train's RMSPE: 0.406577 valid's rmse: 0.000658871   valid's RMSPE: 0.448733\n[309]   train's rmse: 0.000582718   train's RMSPE: 0.404991 valid's rmse: 0.000659378   valid's RMSPE: 0.449079\n[310]   train's rmse: 0.000581703   train's RMSPE: 0.404285 valid's rmse: 0.000662045   valid's RMSPE: 0.450895\n[311]   train's rmse: 0.000579256   train's RMSPE: 0.402585 valid's rmse: 0.000660798   valid's RMSPE: 0.450046\n[312]   train's rmse: 0.00058044    train's RMSPE: 0.403408 valid's rmse: 0.000660376   valid's RMSPE: 0.449758\n[313]   train's rmse: 0.000581438   train's RMSPE: 0.404101 valid's rmse: 0.00066011    valid's RMSPE: 0.449577\n[314]   train's rmse: 0.000579616   train's RMSPE: 0.402835 valid's rmse: 0.000664247   valid's RMSPE: 0.452395\n[315]   train's rmse: 0.000579896   train's RMSPE: 0.40303  valid's rmse: 0.000664271   valid's RMSPE: 0.452411\n[316]   train's rmse: 0.000577872   train's RMSPE: 0.401623 valid's rmse: 0.000665469   valid's RMSPE: 0.453227\n[317]   train's rmse: 0.000578798   train's RMSPE: 0.402267 valid's rmse: 0.000665011   valid's RMSPE: 0.452915\n[318]   train's rmse: 0.000577993   train's RMSPE: 0.401707 valid's rmse: 0.000665531   valid's RMSPE: 0.45327\n[319]   train's rmse: 0.000579319   train's RMSPE: 0.402629 valid's rmse: 0.000665086   valid's RMSPE: 0.452966\n[320]   train's rmse: 0.000580275   train's RMSPE: 0.403293 valid's rmse: 0.000664365   valid's RMSPE: 0.452475\n[321]   train's rmse: 0.000581449   train's RMSPE: 0.404109 valid's rmse: 0.000663772   valid's RMSPE: 0.452071\n[322]   train's rmse: 0.000582563   train's RMSPE: 0.404884 valid's rmse: 0.000663624   valid's RMSPE: 0.45197\n[323]   train's rmse: 0.000583642   train's RMSPE: 0.405633 valid's rmse: 0.000663395   valid's RMSPE: 0.451814\n[324]   train's rmse: 0.000584741   train's RMSPE: 0.406397 valid's rmse: 0.000663376   valid's RMSPE: 0.451802\n[325]   train's rmse: 0.000582525   train's RMSPE: 0.404857 valid's rmse: 0.000663821   valid's RMSPE: 0.452105\n[326]   train's rmse: 0.000582144   train's RMSPE: 0.404592 valid's rmse: 0.000664568   valid's RMSPE: 0.452614\n[327]   train's rmse: 0.000583194   train's RMSPE: 0.405322 valid's rmse: 0.000664275   valid's RMSPE: 0.452414\n[328]   train's rmse: 0.000580143   train's RMSPE: 0.403201 valid's rmse: 0.000663021   valid's RMSPE: 0.45156\n[329]   train's rmse: 0.000581123   train's RMSPE: 0.403883 valid's rmse: 0.000662942   valid's RMSPE: 0.451506\n[330]   train's rmse: 0.000582092   train's RMSPE: 0.404556 valid's rmse: 0.000662505   valid's RMSPE: 0.451208\n[331]   train's rmse: 0.000583162   train's RMSPE: 0.4053   valid's rmse: 0.000662266   valid's RMSPE: 0.451046\n[332]   train's rmse: 0.000581563   train's RMSPE: 0.404188 valid's rmse: 0.000660365   valid's RMSPE: 0.449751\n[333]   train's rmse: 0.000582645   train's RMSPE: 0.40494  valid's rmse: 0.000660015   valid's RMSPE: 0.449512\n[334]   train's rmse: 0.000584042   train's RMSPE: 0.405912 valid's rmse: 0.000658624   valid's RMSPE: 0.448565\n[335]   train's rmse: 0.000583463   train's RMSPE: 0.405509 valid's rmse: 0.000657888   valid's RMSPE: 0.448064\n[336]   train's rmse: 0.000584694   train's RMSPE: 0.406364 valid's rmse: 0.000657813   valid's RMSPE: 0.448013\n[337]   train's rmse: 0.00058561    train's RMSPE: 0.407001 valid's rmse: 0.000657936   valid's RMSPE: 0.448097\n[338]   train's rmse: 0.000585356   train's RMSPE: 0.406824 valid's rmse: 0.000656888   valid's RMSPE: 0.447383\n[339]   train's rmse: 0.000586566   train's RMSPE: 0.407665 valid's rmse: 0.000656952   valid's RMSPE: 0.447426\n[340]   train's rmse: 0.000584421   train's RMSPE: 0.406175 valid's rmse: 0.000656026   valid's RMSPE: 0.446795\n[341]   train's rmse: 0.000585581   train's RMSPE: 0.406981 valid's rmse: 0.000655971   valid's RMSPE: 0.446758\n[342]   train's rmse: 0.000583555   train's RMSPE: 0.405573 valid's rmse: 0.000655322   valid's RMSPE: 0.446317\n[343]   train's rmse: 0.000584648   train's RMSPE: 0.406332 valid's rmse: 0.000655354   valid's RMSPE: 0.446338\n[344]   train's rmse: 0.00058176    train's RMSPE: 0.404325 valid's rmse: 0.000656306   valid's RMSPE: 0.446986\n[345]   train's rmse: 0.000582472   train's RMSPE: 0.40482  valid's rmse: 0.000657424   valid's RMSPE: 0.447748\n[346]   train's rmse: 0.000583517   train's RMSPE: 0.405546 valid's rmse: 0.000657103   valid's RMSPE: 0.447529\n[347]   train's rmse: 0.000582561   train's RMSPE: 0.404882 valid's rmse: 0.000657537   valid's RMSPE: 0.447825\n[348]   train's rmse: 0.0005811 train's RMSPE: 0.403866 valid's rmse: 0.000655954   valid's RMSPE: 0.446747\n[349]   train's rmse: 0.000581924   train's RMSPE: 0.404439 valid's rmse: 0.000655831   valid's RMSPE: 0.446663\n[350]   train's rmse: 0.000582748   train's RMSPE: 0.405012 valid's rmse: 0.000655565   valid's RMSPE: 0.446482\n[351]   train's rmse: 0.000583907   train's RMSPE: 0.405817 valid's rmse: 0.000654434   valid's RMSPE: 0.445711\n[352]   train's rmse: 0.000584802   train's RMSPE: 0.40644  valid's rmse: 0.0006542 valid's RMSPE: 0.445552\n[353]   train's rmse: 0.000585964   train's RMSPE: 0.407247 valid's rmse: 0.000654574   valid's RMSPE: 0.445807\n[354]   train's rmse: 0.000585521   train's RMSPE: 0.406939 valid's rmse: 0.000652774   valid's RMSPE: 0.444581\n[355]   train's rmse: 0.000586681   train's RMSPE: 0.407745 valid's rmse: 0.000652588   valid's RMSPE: 0.444454\n[356]   train's rmse: 0.000587973   train's RMSPE: 0.408643 valid's rmse: 0.000652083   valid's RMSPE: 0.44411\n[357]   train's rmse: 0.000589046   train's RMSPE: 0.409389 valid's rmse: 0.00065232    valid's RMSPE: 0.444271\n[358]   train's rmse: 0.000590257   train's RMSPE: 0.410231 valid's rmse: 0.000652596   valid's RMSPE: 0.44446\n[359]   train's rmse: 0.000591232   train's RMSPE: 0.410908 valid's rmse: 0.000652647   valid's RMSPE: 0.444494\n[360]   train's rmse: 0.000588761   train's RMSPE: 0.409191 valid's rmse: 0.000652782   valid's RMSPE: 0.444586\n[361]   train's rmse: 0.000589839   train's RMSPE: 0.40994  valid's rmse: 0.000652744   valid's RMSPE: 0.44456\n[362]   train's rmse: 0.000586771   train's RMSPE: 0.407808 valid's rmse: 0.000654507   valid's RMSPE: 0.445761\n[363]   train's rmse: 0.000587939   train's RMSPE: 0.40862  valid's rmse: 0.000654637   valid's RMSPE: 0.445849\n[364]   train's rmse: 0.000586053   train's RMSPE: 0.407309 valid's rmse: 0.000656635   valid's RMSPE: 0.44721\n[365]   train's rmse: 0.000587157   train's RMSPE: 0.408076 valid's rmse: 0.000656635   valid's RMSPE: 0.44721\n[366]   train's rmse: 0.000585808   train's RMSPE: 0.407139 valid's rmse: 0.000658853   valid's RMSPE: 0.448721\n[367]   train's rmse: 0.00058707    train's RMSPE: 0.408016 valid's rmse: 0.000658167   valid's RMSPE: 0.448254\n[368]   train's rmse: 0.000588287   train's RMSPE: 0.408861 valid's rmse: 0.000658198   valid's RMSPE: 0.448275\n[369]   train's rmse: 0.000588687   train's RMSPE: 0.409139 valid's rmse: 0.000659335   valid's RMSPE: 0.44905\n[370]   train's rmse: 0.000589632   train's RMSPE: 0.409797 valid's rmse: 0.000659283   valid's RMSPE: 0.449014\n[371]   train's rmse: 0.000586782   train's RMSPE: 0.407816 valid's rmse: 0.000660535   valid's RMSPE: 0.449867\n[372]   train's rmse: 0.000587464   train's RMSPE: 0.408289 valid's rmse: 0.00066055    valid's RMSPE: 0.449877\n[373]   train's rmse: 0.000586705   train's RMSPE: 0.407762 valid's rmse: 0.000659803   valid's RMSPE: 0.449368\n[374]   train's rmse: 0.000584139   train's RMSPE: 0.405979 valid's rmse: 0.000659172   valid's RMSPE: 0.448939\n[375]   train's rmse: 0.000585001   train's RMSPE: 0.406578 valid's rmse: 0.000659004   valid's RMSPE: 0.448824\n[376]   train's rmse: 0.000585786   train's RMSPE: 0.407123 valid's rmse: 0.000659006   valid's RMSPE: 0.448825\n[377]   train's rmse: 0.000582802   train's RMSPE: 0.405049 valid's rmse: 0.000665048   valid's RMSPE: 0.452941\n[378]   train's rmse: 0.00058083    train's RMSPE: 0.403679 valid's rmse: 0.000665907   valid's RMSPE: 0.453525\n[379]   train's rmse: 0.000579932   train's RMSPE: 0.403055 valid's rmse: 0.000664856   valid's RMSPE: 0.45281\n[380]   train's rmse: 0.000577055   train's RMSPE: 0.401055 valid's rmse: 0.000664842   valid's RMSPE: 0.4528\n[381]   train's rmse: 0.000577903   train's RMSPE: 0.401645 valid's rmse: 0.000664803   valid's RMSPE: 0.452774\n[382]   train's rmse: 0.000578852   train's RMSPE: 0.402304 valid's rmse: 0.000664716   valid's RMSPE: 0.452714\n[383]   train's rmse: 0.00057972    train's RMSPE: 0.402907 valid's rmse: 0.000664471   valid's RMSPE: 0.452548\n[384]   train's rmse: 0.000577149   train's RMSPE: 0.40112  valid's rmse: 0.000664045   valid's RMSPE: 0.452257\n[385]   train's rmse: 0.000574722   train's RMSPE: 0.399434 valid's rmse: 0.000666619   valid's RMSPE: 0.45401\n[386]   train's rmse: 0.000575718   train's RMSPE: 0.400126 valid's rmse: 0.000666246   valid's RMSPE: 0.453756\n[387]   train's rmse: 0.000576612   train's RMSPE: 0.400747 valid's rmse: 0.000665673   valid's RMSPE: 0.453366\n[388]   train's rmse: 0.000574331   train's RMSPE: 0.399162 valid's rmse: 0.000663164   valid's RMSPE: 0.451657\n[389]   train's rmse: 0.000571994   train's RMSPE: 0.397538 valid's rmse: 0.000664193   valid's RMSPE: 0.452358\n[390]   train's rmse: 0.000572902   train's RMSPE: 0.398169 valid's rmse: 0.000663893   valid's RMSPE: 0.452153\n[391]   train's rmse: 0.000573969   train's RMSPE: 0.398911 valid's rmse: 0.000663731   valid's RMSPE: 0.452043\n[392]   train's rmse: 0.00057502    train's RMSPE: 0.399641 valid's rmse: 0.000663227   valid's RMSPE: 0.4517\n[393]   train's rmse: 0.000576142   train's RMSPE: 0.40042  valid's rmse: 0.0006631 valid's RMSPE: 0.451614\n[394]   train's rmse: 0.000577402   train's RMSPE: 0.401296 valid's rmse: 0.000662077   valid's RMSPE: 0.450917\n[395]   train's rmse: 0.000578451   train's RMSPE: 0.402026 valid's rmse: 0.00066183    valid's RMSPE: 0.450748\n[396]   train's rmse: 0.000575884   train's RMSPE: 0.400242 valid's rmse: 0.000661718   valid's RMSPE: 0.450672\n[397]   train's rmse: 0.000576853   train's RMSPE: 0.400915 valid's rmse: 0.000661455   valid's RMSPE: 0.450493\n[398]   train's rmse: 0.000575642   train's RMSPE: 0.400074 valid's rmse: 0.000660924   valid's RMSPE: 0.450131\n[399]   train's rmse: 0.0005768 train's RMSPE: 0.400878 valid's rmse: 0.000660677   valid's RMSPE: 0.449963\n[400]   train's rmse: 0.000576439   train's RMSPE: 0.400627 valid's rmse: 0.000661245   valid's RMSPE: 0.45035\n[401]   train's rmse: 0.000577297   train's RMSPE: 0.401223 valid's rmse: 0.000661085   valid's RMSPE: 0.450241\n[402]   train's rmse: 0.000575234   train's RMSPE: 0.39979  valid's rmse: 0.000661088   valid's RMSPE: 0.450243\n[403]   train's rmse: 0.000573074   train's RMSPE: 0.398288 valid's rmse: 0.000660162   valid's RMSPE: 0.449613\n[404]   train's rmse: 0.000573979   train's RMSPE: 0.398918 valid's rmse: 0.000660138   valid's RMSPE: 0.449596\n[405]   train's rmse: 0.000571468   train's RMSPE: 0.397172 valid's rmse: 0.000661917   valid's RMSPE: 0.450808\n[406]   train's rmse: 0.000572417   train's RMSPE: 0.397832 valid's rmse: 0.000661518   valid's RMSPE: 0.450536\n[407]   train's rmse: 0.000570429   train's RMSPE: 0.39645  valid's rmse: 0.00066149    valid's RMSPE: 0.450517\n[408]   train's rmse: 0.000569582   train's RMSPE: 0.395861 valid's rmse: 0.000666295   valid's RMSPE: 0.453789\n[409]   train's rmse: 0.000569674   train's RMSPE: 0.395925 valid's rmse: 0.000666064   valid's RMSPE: 0.453632\n[410]   train's rmse: 0.00057056    train's RMSPE: 0.396541 valid's rmse: 0.000665768   valid's RMSPE: 0.45343\n[411]   train's rmse: 0.000571474   train's RMSPE: 0.397176 valid's rmse: 0.000665498   valid's RMSPE: 0.453247\n[412]   train's rmse: 0.00057239    train's RMSPE: 0.397813 valid's rmse: 0.000665167   valid's RMSPE: 0.453021\n[413]   train's rmse: 0.000573305   train's RMSPE: 0.398449 valid's rmse: 0.000664926   valid's RMSPE: 0.452857\n[414]   train's rmse: 0.000574237   train's RMSPE: 0.399097 valid's rmse: 0.000664742   valid's RMSPE: 0.452732\n[415]   train's rmse: 0.000575195   train's RMSPE: 0.399762 valid's rmse: 0.000664425   valid's RMSPE: 0.452516\n[416]   train's rmse: 0.000572776   train's RMSPE: 0.398081 valid's rmse: 0.0006635 valid's RMSPE: 0.451886\n[417]   train's rmse: 0.000572469   train's RMSPE: 0.397868 valid's rmse: 0.000664717   valid's RMSPE: 0.452715\n[418]   train's rmse: 0.000570192   train's RMSPE: 0.396286 valid's rmse: 0.000667882   valid's RMSPE: 0.45487\n[419]   train's rmse: 0.000570404   train's RMSPE: 0.396433 valid's rmse: 0.000666775   valid's RMSPE: 0.454116\n[420]   train's rmse: 0.000571359   train's RMSPE: 0.397097 valid's rmse: 0.000666232   valid's RMSPE: 0.453747\n[421]   train's rmse: 0.000572358   train's RMSPE: 0.397791 valid's rmse: 0.000665757   valid's RMSPE: 0.453423\n[422]   train's rmse: 0.000571216   train's RMSPE: 0.396997 valid's rmse: 0.00066755    valid's RMSPE: 0.454644\n[423]   train's rmse: 0.000572197   train's RMSPE: 0.397679 valid's rmse: 0.000667162   valid's RMSPE: 0.45438\n[424]   train's rmse: 0.000573074   train's RMSPE: 0.398289 valid's rmse: 0.000666846   valid's RMSPE: 0.454165\n[425]   train's rmse: 0.000573859   train's RMSPE: 0.398834 valid's rmse: 0.000666846   valid's RMSPE: 0.454165\n[426]   train's rmse: 0.000574848   train's RMSPE: 0.399522 valid's rmse: 0.00066664    valid's RMSPE: 0.454025\n[427]   train's rmse: 0.000573794   train's RMSPE: 0.398788 valid's rmse: 0.000664991   valid's RMSPE: 0.452901\n[428]   train's rmse: 0.000574834   train's RMSPE: 0.399512 valid's rmse: 0.000663775   valid's RMSPE: 0.452073\n[429]   train's rmse: 0.000575811   train's RMSPE: 0.40019  valid's rmse: 0.000663422   valid's RMSPE: 0.451833\n[430]   train's rmse: 0.000576771   train's RMSPE: 0.400858 valid's rmse: 0.000663159   valid's RMSPE: 0.451653\n[431]   train's rmse: 0.000574832   train's RMSPE: 0.39951  valid's rmse: 0.000666007   valid's RMSPE: 0.453593\n[432]   train's rmse: 0.000575661   train's RMSPE: 0.400087 valid's rmse: 0.000665484   valid's RMSPE: 0.453237\n[433]   train's rmse: 0.000573291   train's RMSPE: 0.398439 valid's rmse: 0.000664468   valid's RMSPE: 0.452545\n[434]   train's rmse: 0.000574201   train's RMSPE: 0.399072 valid's rmse: 0.000664411   valid's RMSPE: 0.452507\n[435]   train's rmse: 0.000572441   train's RMSPE: 0.397849 valid's rmse: 0.00066327    valid's RMSPE: 0.451729\n[436]   train's rmse: 0.000571198   train's RMSPE: 0.396984 valid's rmse: 0.00066483    valid's RMSPE: 0.452792\n[437]   train's rmse: 0.000572156   train's RMSPE: 0.39765  valid's rmse: 0.000664497   valid's RMSPE: 0.452565\n[438]   train's rmse: 0.000569418   train's RMSPE: 0.395747 valid's rmse: 0.000667076   valid's RMSPE: 0.454321\n[439]   train's rmse: 0.000570282   train's RMSPE: 0.396348 valid's rmse: 0.000666695   valid's RMSPE: 0.454062\n[440]   train's rmse: 0.000571383   train's RMSPE: 0.397113 valid's rmse: 0.000665291   valid's RMSPE: 0.453105\n[441]   train's rmse: 0.000572293   train's RMSPE: 0.397745 valid's rmse: 0.000665151   valid's RMSPE: 0.45301\n[442]   train's rmse: 0.000573247   train's RMSPE: 0.398409 valid's rmse: 0.000665209   valid's RMSPE: 0.45305\n[443]   train's rmse: 0.000574025   train's RMSPE: 0.398949 valid's rmse: 0.000664988   valid's RMSPE: 0.4529\n[444]   train's rmse: 0.000574922   train's RMSPE: 0.399573 valid's rmse: 0.000664826   valid's RMSPE: 0.452789\n[445]   train's rmse: 0.000573752   train's RMSPE: 0.39876  valid's rmse: 0.000670199   valid's RMSPE: 0.456449\n[446]   train's rmse: 0.000574527   train's RMSPE: 0.399298 valid's rmse: 0.000669642   valid's RMSPE: 0.456069\n[447]   train's rmse: 0.000575352   train's RMSPE: 0.399872 valid's rmse: 0.000669276   valid's RMSPE: 0.45582\n[448]   train's rmse: 0.000572919   train's RMSPE: 0.398181 valid's rmse: 0.000671671   valid's RMSPE: 0.457451\n[449]   train's rmse: 0.000573852   train's RMSPE: 0.398829 valid's rmse: 0.000671886   valid's RMSPE: 0.457597\n[450]   train's rmse: 0.000574823   train's RMSPE: 0.399504 valid's rmse: 0.000671553   valid's RMSPE: 0.45737\n[451]   train's rmse: 0.000575787   train's RMSPE: 0.400174 valid's rmse: 0.000671212   valid's RMSPE: 0.457138\n[452]   train's rmse: 0.000573646   train's RMSPE: 0.398686 valid's rmse: 0.000674001   valid's RMSPE: 0.459038\n[453]   train's rmse: 0.000573036   train's RMSPE: 0.398262 valid's rmse: 0.000675687   valid's RMSPE: 0.460186\n[454]   train's rmse: 0.000571261   train's RMSPE: 0.397029 valid's rmse: 0.000678677   valid's RMSPE: 0.462223\n[455]   train's rmse: 0.000572206   train's RMSPE: 0.397685 valid's rmse: 0.000678095   valid's RMSPE: 0.461826\n[456]   train's rmse: 0.000569349   train's RMSPE: 0.395699 valid's rmse: 0.000677472   valid's RMSPE: 0.461402\n[457]   train's rmse: 0.000570254   train's RMSPE: 0.396328 valid's rmse: 0.000677061   valid's RMSPE: 0.461122\n[458]   train's rmse: 0.000570931   train's RMSPE: 0.396799 valid's rmse: 0.00067775    valid's RMSPE: 0.461591\n[459]   train's rmse: 0.000570484   train's RMSPE: 0.396488 valid's rmse: 0.000676851   valid's RMSPE: 0.460979\n[460]   train's rmse: 0.000571212   train's RMSPE: 0.396995 valid's rmse: 0.000676539   valid's RMSPE: 0.460766\n[461]   train's rmse: 0.000571897   train's RMSPE: 0.397471 valid's rmse: 0.000675888   valid's RMSPE: 0.460323\n[462]   train's rmse: 0.000571754   train's RMSPE: 0.397371 valid's rmse: 0.000675041   valid's RMSPE: 0.459746\n[463]   train's rmse: 0.000572115   train's RMSPE: 0.397622 valid's rmse: 0.000676898   valid's RMSPE: 0.461011\n[464]   train's rmse: 0.000572686   train's RMSPE: 0.398019 valid's rmse: 0.000675277   valid's RMSPE: 0.459907\n[465]   train's rmse: 0.000571356   train's RMSPE: 0.397094 valid's rmse: 0.000677729   valid's RMSPE: 0.461577\n[466]   train's rmse: 0.000569505   train's RMSPE: 0.395808 valid's rmse: 0.000677507   valid's RMSPE: 0.461426\n[467]   train's rmse: 0.000567187   train's RMSPE: 0.394197 valid's rmse: 0.000678905   valid's RMSPE: 0.462378\n[468]   train's rmse: 0.00056523    train's RMSPE: 0.392837 valid's rmse: 0.000676793   valid's RMSPE: 0.460939\n[469]   train's rmse: 0.000564877   train's RMSPE: 0.392592 valid's rmse: 0.000680374   valid's RMSPE: 0.463378\n[470]   train's rmse: 0.000564922   train's RMSPE: 0.392622 valid's rmse: 0.000683736   valid's RMSPE: 0.465668\n[471]   train's rmse: 0.000565594   train's RMSPE: 0.39309  valid's rmse: 0.000682528   valid's RMSPE: 0.464845\n[472]   train's rmse: 0.000563665   train's RMSPE: 0.391749 valid's rmse: 0.000682878   valid's RMSPE: 0.465084\n[473]   train's rmse: 0.000561724   train's RMSPE: 0.3904   valid's rmse: 0.000681608   valid's RMSPE: 0.464219\n[474]   train's rmse: 0.000562344   train's RMSPE: 0.390831 valid's rmse: 0.000680853   valid's RMSPE: 0.463705\n[475]   train's rmse: 0.000561679   train's RMSPE: 0.390369 valid's rmse: 0.000681534   valid's RMSPE: 0.464168\n[476]   train's rmse: 0.000560323   train's RMSPE: 0.389427 valid's rmse: 0.000680093   valid's RMSPE: 0.463187\n[477]   train's rmse: 0.000560944   train's RMSPE: 0.389858 valid's rmse: 0.000679285   valid's RMSPE: 0.462636\n[478]   train's rmse: 0.000561534   train's RMSPE: 0.390268 valid's rmse: 0.000678737   valid's RMSPE: 0.462264\n[479]   train's rmse: 0.000561046   train's RMSPE: 0.389929 valid's rmse: 0.00067888    valid's RMSPE: 0.46236\n[480]   train's rmse: 0.000559323   train's RMSPE: 0.388731 valid's rmse: 0.000680517   valid's RMSPE: 0.463476\n[481]   train's rmse: 0.000559915   train's RMSPE: 0.389143 valid's rmse: 0.000679974   valid's RMSPE: 0.463106\n[482]   train's rmse: 0.000559505   train's RMSPE: 0.388858 valid's rmse: 0.000683668   valid's RMSPE: 0.465622\n[483]   train's rmse: 0.00056   train's RMSPE: 0.389202 valid's rmse: 0.000681697   valid's RMSPE: 0.464279\n[484]   train's rmse: 0.000558087   train's RMSPE: 0.387872 valid's rmse: 0.00068525    valid's RMSPE: 0.466699\n[485]   train's rmse: 0.000558588   train's RMSPE: 0.388221 valid's rmse: 0.000684655   valid's RMSPE: 0.466294\n[486]   train's rmse: 0.000556499   train's RMSPE: 0.386769 valid's rmse: 0.000684205   valid's RMSPE: 0.465987\n[487]   train's rmse: 0.00055475    train's RMSPE: 0.385553 valid's rmse: 0.000684888   valid's RMSPE: 0.466452\n[488]   train's rmse: 0.000552503   train's RMSPE: 0.383991 valid's rmse: 0.000684149   valid's RMSPE: 0.465949\n[489]   train's rmse: 0.000553193   train's RMSPE: 0.384471 valid's rmse: 0.000685725   valid's RMSPE: 0.467022\n[490]   train's rmse: 0.000551469   train's RMSPE: 0.383273 valid's rmse: 0.000687966   valid's RMSPE: 0.468549\n[491]   train's rmse: 0.000552  train's RMSPE: 0.383642 valid's rmse: 0.000686855   valid's RMSPE: 0.467792\n[492]   train's rmse: 0.000550354   train's RMSPE: 0.382498 valid's rmse: 0.000685231   valid's RMSPE: 0.466686\n[493]   train's rmse: 0.000550943   train's RMSPE: 0.382907 valid's rmse: 0.000684426   valid's RMSPE: 0.466138\n[494]   train's rmse: 0.000551562   train's RMSPE: 0.383338 valid's rmse: 0.000683518   valid's RMSPE: 0.465519\n[495]   train's rmse: 0.000552108   train's RMSPE: 0.383717 valid's rmse: 0.000681345   valid's RMSPE: 0.464039\n[496]   train's rmse: 0.000552806   train's RMSPE: 0.384202 valid's rmse: 0.000680807   valid's RMSPE: 0.463673\n[497]   train's rmse: 0.000552619   train's RMSPE: 0.384072 valid's rmse: 0.000681632   valid's RMSPE: 0.464235\n[498]   train's rmse: 0.000551298   train's RMSPE: 0.383154 valid's rmse: 0.000683821   valid's RMSPE: 0.465726\n[499]   train's rmse: 0.00055175    train's RMSPE: 0.383468 valid's rmse: 0.000683186   valid's RMSPE: 0.465294\n[500]   train's rmse: 0.000552332   train's RMSPE: 0.383873 valid's rmse: 0.000682575   valid's RMSPE: 0.464877\n[501]   train's rmse: 0.000551131   train's RMSPE: 0.383038 valid's rmse: 0.000681347   valid's RMSPE: 0.464041\n[502]   train's rmse: 0.000551731   train's RMSPE: 0.383455 valid's rmse: 0.000680739   valid's RMSPE: 0.463627\n[503]   train's rmse: 0.000550301   train's RMSPE: 0.382461 valid's rmse: 0.000680107   valid's RMSPE: 0.463196\n[504]   train's rmse: 0.000550873   train's RMSPE: 0.382859 valid's rmse: 0.000679294   valid's RMSPE: 0.462643\n[505]   train's rmse: 0.000551499   train's RMSPE: 0.383294 valid's rmse: 0.000678881   valid's RMSPE: 0.462361\n[506]   train's rmse: 0.000551677   train's RMSPE: 0.383417 valid's rmse: 0.000677338   valid's RMSPE: 0.461311\n[507]   train's rmse: 0.00055151    train's RMSPE: 0.383302 valid's rmse: 0.000676989   valid's RMSPE: 0.461073\n[508]   train's rmse: 0.000552705   train's RMSPE: 0.384132 valid's rmse: 0.000679116   valid's RMSPE: 0.462522\n[509]   train's rmse: 0.000550986   train's RMSPE: 0.382937 valid's rmse: 0.000680644   valid's RMSPE: 0.463562\n[510]   train's rmse: 0.000551528   train's RMSPE: 0.383314 valid's rmse: 0.000679975   valid's RMSPE: 0.463107\n[511]   train's rmse: 0.000549608   train's RMSPE: 0.381979 valid's rmse: 0.000682453   valid's RMSPE: 0.464794\n[512]   train's rmse: 0.000550187   train's RMSPE: 0.382382 valid's rmse: 0.000680419   valid's RMSPE: 0.463409\n[513]   train's rmse: 0.000550788   train's RMSPE: 0.3828   valid's rmse: 0.000679343   valid's RMSPE: 0.462676\n[514]   train's rmse: 0.000551419   train's RMSPE: 0.383238 valid's rmse: 0.000678925   valid's RMSPE: 0.462391\n[515]   train's rmse: 0.000552006   train's RMSPE: 0.383646 valid's rmse: 0.000678321   valid's RMSPE: 0.46198\n[516]   train's rmse: 0.000552577   train's RMSPE: 0.384043 valid's rmse: 0.00067768    valid's RMSPE: 0.461543\n[517]   train's rmse: 0.00055324    train's RMSPE: 0.384504 valid's rmse: 0.000677057   valid's RMSPE: 0.461119\n[518]   train's rmse: 0.00055395    train's RMSPE: 0.384997 valid's rmse: 0.000676577   valid's RMSPE: 0.460792\n[519]   train's rmse: 0.000554707   train's RMSPE: 0.385523 valid's rmse: 0.000674984   valid's RMSPE: 0.459707\n[520]   train's rmse: 0.000555395   train's RMSPE: 0.386001 valid's rmse: 0.00067359    valid's RMSPE: 0.458758\n[521]   train's rmse: 0.000556185   train's RMSPE: 0.38655  valid's rmse: 0.000673045   valid's RMSPE: 0.458387\n[522]   train's rmse: 0.0005531 train's RMSPE: 0.384407 valid's rmse: 0.000672403   valid's RMSPE: 0.45795\n[523]   train's rmse: 0.000553796   train's RMSPE: 0.38489  valid's rmse: 0.00067178    valid's RMSPE: 0.457525\n[524]   train's rmse: 0.000554595   train's RMSPE: 0.385446 valid's rmse: 0.000671192   valid's RMSPE: 0.457125\n[525]   train's rmse: 0.000555264   train's RMSPE: 0.385911 valid's rmse: 0.000670932   valid's RMSPE: 0.456948\n[526]   train's rmse: 0.000555955   train's RMSPE: 0.38639  valid's rmse: 0.00067056    valid's RMSPE: 0.456694\n[527]   train's rmse: 0.00055453    train's RMSPE: 0.3854   valid's rmse: 0.000670348   valid's RMSPE: 0.45655\n[528]   train's rmse: 0.000552253   train's RMSPE: 0.383818 valid's rmse: 0.000676316   valid's RMSPE: 0.460614\n[529]   train's rmse: 0.000550739   train's RMSPE: 0.382765 valid's rmse: 0.000676037   valid's RMSPE: 0.460424\n[530]   train's rmse: 0.000551508   train's RMSPE: 0.3833   valid's rmse: 0.000675178   valid's RMSPE: 0.459839\n[531]   train's rmse: 0.000552245   train's RMSPE: 0.383812 valid's rmse: 0.000674705   valid's RMSPE: 0.459517\n[532]   train's rmse: 0.000550761   train's RMSPE: 0.382781 valid's rmse: 0.000674862   valid's RMSPE: 0.459624\n[533]   train's rmse: 0.00055147    train's RMSPE: 0.383274 valid's rmse: 0.000674286   valid's RMSPE: 0.459232\n[534]   train's rmse: 0.000549918   train's RMSPE: 0.382195 valid's rmse: 0.000676622   valid's RMSPE: 0.460823\n[535]   train's rmse: 0.000547636   train's RMSPE: 0.380609 valid's rmse: 0.000680064   valid's RMSPE: 0.463167\n[536]   train's rmse: 0.00054611    train's RMSPE: 0.379548 valid's rmse: 0.000679218   valid's RMSPE: 0.462591\n[537]   train's rmse: 0.000544764   train's RMSPE: 0.378613 valid's rmse: 0.000678423   valid's RMSPE: 0.462049\n[538]   train's rmse: 0.000545218   train's RMSPE: 0.378929 valid's rmse: 0.000677795   valid's RMSPE: 0.461622\n[539]   train's rmse: 0.000543271   train's RMSPE: 0.377575 valid's rmse: 0.000678218   valid's RMSPE: 0.46191\n[540]   train's rmse: 0.00054408    train's RMSPE: 0.378137 valid's rmse: 0.000677293   valid's RMSPE: 0.46128\n[541]   train's rmse: 0.000544715   train's RMSPE: 0.378579 valid's rmse: 0.000676401   valid's RMSPE: 0.460672\n[542]   train's rmse: 0.00054437    train's RMSPE: 0.378339 valid's rmse: 0.000681256   valid's RMSPE: 0.463979\n[543]   train's rmse: 0.000543495   train's RMSPE: 0.377731 valid's rmse: 0.000682491   valid's RMSPE: 0.46482\n[544]   train's rmse: 0.000541727   train's RMSPE: 0.376502 valid's rmse: 0.000683471   valid's RMSPE: 0.465487\n[545]   train's rmse: 0.000540299   train's RMSPE: 0.37551  valid's rmse: 0.0006839 valid's RMSPE: 0.46578\n[546]   train's rmse: 0.00053845    train's RMSPE: 0.374224 valid's rmse: 0.00068819    valid's RMSPE: 0.468701\n[547]   train's rmse: 0.000539009   train's RMSPE: 0.374613 valid's rmse: 0.000687433   valid's RMSPE: 0.468186\n[548]   train's rmse: 0.000537611   train's RMSPE: 0.373641 valid's rmse: 0.000690113   valid's RMSPE: 0.470011\n[549]   train's rmse: 0.000538199   train's RMSPE: 0.37405  valid's rmse: 0.000689083   valid's RMSPE: 0.46931\n[550]   train's rmse: 0.000538879   train's RMSPE: 0.374523 valid's rmse: 0.000688382   valid's RMSPE: 0.468832\n[551]   train's rmse: 0.000538503   train's RMSPE: 0.374261 valid's rmse: 0.000691467   valid's RMSPE: 0.470933\n[552]   train's rmse: 0.000539091   train's RMSPE: 0.37467  valid's rmse: 0.000690725   valid's RMSPE: 0.470428\n[553]   train's rmse: 0.000539691   train's RMSPE: 0.375087 valid's rmse: 0.000689783   valid's RMSPE: 0.469786\n[554]   train's rmse: 0.000540252   train's RMSPE: 0.375477 valid's rmse: 0.000689122   valid's RMSPE: 0.469336\n[555]   train's rmse: 0.000540668   train's RMSPE: 0.375766 valid's rmse: 0.000688468   valid's RMSPE: 0.468891\n[556]   train's rmse: 0.000539264   train's RMSPE: 0.37479  valid's rmse: 0.000687083   valid's RMSPE: 0.467948\n[557]   train's rmse: 0.000538075   train's RMSPE: 0.373964 valid's rmse: 0.000693006   valid's RMSPE: 0.471981\n[558]   train's rmse: 0.000536736   train's RMSPE: 0.373034 valid's rmse: 0.000695931   valid's RMSPE: 0.473974\n[559]   train's rmse: 0.000537419   train's RMSPE: 0.373508 valid's rmse: 0.000694911   valid's RMSPE: 0.473279\n[560]   train's rmse: 0.000535944   train's RMSPE: 0.372483 valid's rmse: 0.000694258   valid's RMSPE: 0.472834\n[561]   train's rmse: 0.000536533   train's RMSPE: 0.372892 valid's rmse: 0.000693223   valid's RMSPE: 0.472129\n[562]   train's rmse: 0.000537178   train's RMSPE: 0.373341 valid's rmse: 0.000692365   valid's RMSPE: 0.471545\n[563]   train's rmse: 0.00053566    train's RMSPE: 0.372286 valid's rmse: 0.00069576    valid's RMSPE: 0.473857\n[564]   train's rmse: 0.000536355   train's RMSPE: 0.372768 valid's rmse: 0.000693722   valid's RMSPE: 0.472469\n[565]   train's rmse: 0.000535158   train's RMSPE: 0.371936 valid's rmse: 0.000693664   valid's RMSPE: 0.472429\n[566]   train's rmse: 0.000535774   train's RMSPE: 0.372365 valid's rmse: 0.000692932   valid's RMSPE: 0.471931\n[567]   train's rmse: 0.000536373   train's RMSPE: 0.372781 valid's rmse: 0.000692163   valid's RMSPE: 0.471407\n[568]   train's rmse: 0.000534784   train's RMSPE: 0.371677 valid's rmse: 0.000694242   valid's RMSPE: 0.472824\n[569]   train's rmse: 0.000535305   train's RMSPE: 0.372039 valid's rmse: 0.000693543   valid's RMSPE: 0.472347\n[570]   train's rmse: 0.000535772   train's RMSPE: 0.372363 valid's rmse: 0.000692685   valid's RMSPE: 0.471763\n[571]   train's rmse: 0.000536564   train's RMSPE: 0.372914 valid's rmse: 0.000692095   valid's RMSPE: 0.471361\n[572]   train's rmse: 0.000537167   train's RMSPE: 0.373333 valid's rmse: 0.00069134    valid's RMSPE: 0.470847\n[573]   train's rmse: 0.000537889   train's RMSPE: 0.373835 valid's rmse: 0.000690496   valid's RMSPE: 0.470272\n[574]   train's rmse: 0.000536552   train's RMSPE: 0.372906 valid's rmse: 0.000694413   valid's RMSPE: 0.47294\n[575]   train's rmse: 0.000537168   train's RMSPE: 0.373334 valid's rmse: 0.00069342    valid's RMSPE: 0.472263\n[576]   train's rmse: 0.000537937   train's RMSPE: 0.373868 valid's rmse: 0.000692576   valid's RMSPE: 0.471689\n[577]   train's rmse: 0.000538685   train's RMSPE: 0.374388 valid's rmse: 0.000691649   valid's RMSPE: 0.471057\n[578]   train's rmse: 0.000536897   train's RMSPE: 0.373145 valid's rmse: 0.000691538   valid's RMSPE: 0.470981\n[579]   train's rmse: 0.000535143   train's RMSPE: 0.371926 valid's rmse: 0.00069182    valid's RMSPE: 0.471174\n[580]   train's rmse: 0.000535809   train's RMSPE: 0.372389 valid's rmse: 0.000691281   valid's RMSPE: 0.470807\n[581]   train's rmse: 0.00053454    train's RMSPE: 0.371507 valid's rmse: 0.000692205   valid's RMSPE: 0.471436\n[582]   train's rmse: 0.000535106   train's RMSPE: 0.371901 valid's rmse: 0.000691818   valid's RMSPE: 0.471172\n[583]   train's rmse: 0.000535679   train's RMSPE: 0.372299 valid's rmse: 0.000691077   valid's RMSPE: 0.470668\n[584]   train's rmse: 0.000534717   train's RMSPE: 0.37163  valid's rmse: 0.000698098   valid's RMSPE: 0.475449\n[585]   train's rmse: 0.000535337   train's RMSPE: 0.372061 valid's rmse: 0.000697312   valid's RMSPE: 0.474914\n[586]   train's rmse: 0.00053368    train's RMSPE: 0.37091  valid's rmse: 0.000696895   valid's RMSPE: 0.47463\n[587]   train's rmse: 0.000532479   train's RMSPE: 0.370075 valid's rmse: 0.000699666   valid's RMSPE: 0.476517\n[588]   train's rmse: 0.000531338   train's RMSPE: 0.369282 valid's rmse: 0.000706338   valid's RMSPE: 0.481061\n[589]   train's rmse: 0.000532041   train's RMSPE: 0.36977  valid's rmse: 0.000705649   valid's RMSPE: 0.480592\n[590]   train's rmse: 0.000530435   train's RMSPE: 0.368654 valid's rmse: 0.000705526   valid's RMSPE: 0.480508\n[591]   train's rmse: 0.000531137   train's RMSPE: 0.369142 valid's rmse: 0.000703669   valid's RMSPE: 0.479244\n[592]   train's rmse: 0.000530335   train's RMSPE: 0.368585 valid's rmse: 0.000703675   valid's RMSPE: 0.479248\n[593]   train's rmse: 0.000530814   train's RMSPE: 0.368917 valid's rmse: 0.00070278    valid's RMSPE: 0.478638\n[594]   train's rmse: 0.000531414   train's RMSPE: 0.369335 valid's rmse: 0.000702028   valid's RMSPE: 0.478126\n[595]   train's rmse: 0.000530414   train's RMSPE: 0.36864  valid's rmse: 0.000703966   valid's RMSPE: 0.479446\n[596]   train's rmse: 0.000531112   train's RMSPE: 0.369125 valid's rmse: 0.000703123   valid's RMSPE: 0.478871\n[597]   train's rmse: 0.0005319 train's RMSPE: 0.369673 valid's rmse: 0.000701872   valid's RMSPE: 0.47802\n[598]   train's rmse: 0.00053154    train's RMSPE: 0.369422 valid's rmse: 0.000703136   valid's RMSPE: 0.47888\n[599]   train's rmse: 0.000530683   train's RMSPE: 0.368827 valid's rmse: 0.000707797   valid's RMSPE: 0.482055\n[600]   train's rmse: 0.000529343   train's RMSPE: 0.367895 valid's rmse: 0.000712996   valid's RMSPE: 0.485596\n[601]   train's rmse: 0.00052875    train's RMSPE: 0.367483 valid's rmse: 0.000715932   valid's RMSPE: 0.487596\n[602]   train's rmse: 0.00052747    train's RMSPE: 0.366593 valid's rmse: 0.0007175 valid's RMSPE: 0.488663\n[603]   train's rmse: 0.000528023   train's RMSPE: 0.366977 valid's rmse: 0.000716761   valid's RMSPE: 0.48816\n[604]   train's rmse: 0.000526749   train's RMSPE: 0.366093 valid's rmse: 0.000716035   valid's RMSPE: 0.487666\n[605]   train's rmse: 0.000526046   train's RMSPE: 0.365604 valid's rmse: 0.000719954   valid's RMSPE: 0.490335\n[606]   train's rmse: 0.000524857   train's RMSPE: 0.364778 valid's rmse: 0.000718603   valid's RMSPE: 0.489415\n[607]   train's rmse: 0.000525089   train's RMSPE: 0.364939 valid's rmse: 0.000718012   valid's RMSPE: 0.489012\n[608]   train's rmse: 0.000524356   train's RMSPE: 0.364429 valid's rmse: 0.00072098    valid's RMSPE: 0.491034\n[609]   train's rmse: 0.000524779   train's RMSPE: 0.364724 valid's rmse: 0.000720105   valid's RMSPE: 0.490438\n[610]   train's rmse: 0.000523764   train's RMSPE: 0.364018 valid's rmse: 0.000723266   valid's RMSPE: 0.492591\n[611]   train's rmse: 0.000523469   train's RMSPE: 0.363812 valid's rmse: 0.000723671   valid's RMSPE: 0.492867\n[612]   train's rmse: 0.000522396   train's RMSPE: 0.363067 valid's rmse: 0.000723496   valid's RMSPE: 0.492747\n[613]   train's rmse: 0.000521724   train's RMSPE: 0.3626   valid's rmse: 0.000726845   valid's RMSPE: 0.495028\n[614]   train's rmse: 0.000522272   train's RMSPE: 0.362981 valid's rmse: 0.000725671   valid's RMSPE: 0.494228\n[615]   train's rmse: 0.00052133    train's RMSPE: 0.362326 valid's rmse: 0.000727724   valid's RMSPE: 0.495627\n[616]   train's rmse: 0.000521881   train's RMSPE: 0.362709 valid's rmse: 0.00072672    valid's RMSPE: 0.494943\n[617]   train's rmse: 0.000520603   train's RMSPE: 0.361821 valid's rmse: 0.000729597   valid's RMSPE: 0.496902\n[618]   train's rmse: 0.000519691   train's RMSPE: 0.361187 valid's rmse: 0.000731391   valid's RMSPE: 0.498124\n[619]   train's rmse: 0.000520113   train's RMSPE: 0.36148  valid's rmse: 0.000730512   valid's RMSPE: 0.497525\n[620]   train's rmse: 0.00052048    train's RMSPE: 0.361736 valid's rmse: 0.000729632   valid's RMSPE: 0.496926\n[621]   train's rmse: 0.000520966   train's RMSPE: 0.362073 valid's rmse: 0.000728561   valid's RMSPE: 0.496197\n[622]   train's rmse: 0.000521491   train's RMSPE: 0.362438 valid's rmse: 0.000725984   valid's RMSPE: 0.494442\n[623]   train's rmse: 0.000521943   train's RMSPE: 0.362753 valid's rmse: 0.000725041   valid's RMSPE: 0.4938\n[624]   train's rmse: 0.000521699   train's RMSPE: 0.362582 valid's rmse: 0.000724155   valid's RMSPE: 0.493196\n[625]   train's rmse: 0.000520639   train's RMSPE: 0.361846 valid's rmse: 0.000724839   valid's RMSPE: 0.493662\n[626]   train's rmse: 0.000519576   train's RMSPE: 0.361107 valid's rmse: 0.000722677   valid's RMSPE: 0.49219\n[627]   train's rmse: 0.000519956   train's RMSPE: 0.361371 valid's rmse: 0.000721921   valid's RMSPE: 0.491674\n[628]   train's rmse: 0.000520504   train's RMSPE: 0.361752 valid's rmse: 0.00072092    valid's RMSPE: 0.490993\n[629]   train's rmse: 0.000521052   train's RMSPE: 0.362133 valid's rmse: 0.000718849   valid's RMSPE: 0.489582\n[630]   train's rmse: 0.000520828   train's RMSPE: 0.361977 valid's rmse: 0.000718671   valid's RMSPE: 0.489461\n[631]   train's rmse: 0.000521319   train's RMSPE: 0.362319 valid's rmse: 0.000717464   valid's RMSPE: 0.488639\n[632]   train's rmse: 0.000520183   train's RMSPE: 0.361529 valid's rmse: 0.000717076   valid's RMSPE: 0.488375\n[633]   train's rmse: 0.000520705   train's RMSPE: 0.361892 valid's rmse: 0.000716114   valid's RMSPE: 0.48772\n[634]   train's rmse: 0.000520028   train's RMSPE: 0.361421 valid's rmse: 0.000719308   valid's RMSPE: 0.489895\n[635]   train's rmse: 0.000520501   train's RMSPE: 0.36175  valid's rmse: 0.000717199   valid's RMSPE: 0.488458\n[636]   train's rmse: 0.000519577   train's RMSPE: 0.361107 valid's rmse: 0.000715754   valid's RMSPE: 0.487474\n[637]   train's rmse: 0.00051821    train's RMSPE: 0.360158 valid's rmse: 0.000717046   valid's RMSPE: 0.488354\n[638]   train's rmse: 0.000517713   train's RMSPE: 0.359813 valid's rmse: 0.000719515   valid's RMSPE: 0.490036\n[639]   train's rmse: 0.000517001   train's RMSPE: 0.359318 valid's rmse: 0.0007222 valid's RMSPE: 0.491864\n[640]   train's rmse: 0.000516498   train's RMSPE: 0.358968 valid's rmse: 0.000721698   valid's RMSPE: 0.491523\n[641]   train's rmse: 0.00051701    train's RMSPE: 0.359324 valid's rmse: 0.000720243   valid's RMSPE: 0.490531\n[642]   train's rmse: 0.000517315   train's RMSPE: 0.359536 valid's rmse: 0.00071815    valid's RMSPE: 0.489106\n[643]   train's rmse: 0.000516257   train's RMSPE: 0.358801 valid's rmse: 0.000718493   valid's RMSPE: 0.48934\n[644]   train's rmse: 0.000515659   train's RMSPE: 0.358385 valid's rmse: 0.000718216   valid's RMSPE: 0.489151\n[645]   train's rmse: 0.00051597    train's RMSPE: 0.358601 valid's rmse: 0.00071723    valid's RMSPE: 0.48848\n[646]   train's rmse: 0.000516092   train's RMSPE: 0.358686 valid's rmse: 0.000718096   valid's RMSPE: 0.489069\n[647]   train's rmse: 0.000515147   train's RMSPE: 0.358029 valid's rmse: 0.000718923   valid's RMSPE: 0.489632\n[648]   train's rmse: 0.000513988   train's RMSPE: 0.357224 valid's rmse: 0.000724521   valid's RMSPE: 0.493445\n[649]   train's rmse: 0.000514403   train's RMSPE: 0.357512 valid's rmse: 0.000723228   valid's RMSPE: 0.492565\n[650]   train's rmse: 0.000514867   train's RMSPE: 0.357834 valid's rmse: 0.000721977   valid's RMSPE: 0.491713\n[651]   train's rmse: 0.000515201   train's RMSPE: 0.358066 valid's rmse: 0.000720959   valid's RMSPE: 0.491019\n[652]   train's rmse: 0.000514606   train's RMSPE: 0.357653 valid's rmse: 0.000721089   valid's RMSPE: 0.491107\n[653]   train's rmse: 0.00051506    train's RMSPE: 0.357969 valid's rmse: 0.000720449   valid's RMSPE: 0.490672\n[654]   train's rmse: 0.000514855   train's RMSPE: 0.357826 valid's rmse: 0.000724307   valid's RMSPE: 0.493299\n[655]   train's rmse: 0.000515298   train's RMSPE: 0.358134 valid's rmse: 0.000723397   valid's RMSPE: 0.49268\n[656]   train's rmse: 0.000514158   train's RMSPE: 0.357341 valid's rmse: 0.000717484   valid's RMSPE: 0.488653\n[657]   train's rmse: 0.000512933   train's RMSPE: 0.35649  valid's rmse: 0.00071569    valid's RMSPE: 0.487431\n[658]   train's rmse: 0.000512575   train's RMSPE: 0.356241 valid's rmse: 0.000717767   valid's RMSPE: 0.488846\n[659]   train's rmse: 0.000512038   train's RMSPE: 0.355868 valid's rmse: 0.00071797    valid's RMSPE: 0.488984\n[660]   train's rmse: 0.000512439   train's RMSPE: 0.356147 valid's rmse: 0.000716823   valid's RMSPE: 0.488202\n[661]   train's rmse: 0.000511392   train's RMSPE: 0.355419 valid's rmse: 0.000717251   valid's RMSPE: 0.488494\n[662]   train's rmse: 0.000511209   train's RMSPE: 0.355292 valid's rmse: 0.000721325   valid's RMSPE: 0.491269\n[663]   train's rmse: 0.000511615   train's RMSPE: 0.355574 valid's rmse: 0.000720156   valid's RMSPE: 0.490472\n[664]   train's rmse: 0.000512004   train's RMSPE: 0.355844 valid's rmse: 0.000719384   valid's RMSPE: 0.489946\n[665]   train's rmse: 0.00051239    train's RMSPE: 0.356113 valid's rmse: 0.000718421   valid's RMSPE: 0.489291\n[666]   train's rmse: 0.000511427   train's RMSPE: 0.355443 valid's rmse: 0.000722543   valid's RMSPE: 0.492098\n[667]   train's rmse: 0.000511862   train's RMSPE: 0.355746 valid's rmse: 0.000721734   valid's RMSPE: 0.491547\n[668]   train's rmse: 0.000512091   train's RMSPE: 0.355905 valid's rmse: 0.000721024   valid's RMSPE: 0.491064\n[669]   train's rmse: 0.000512473   train's RMSPE: 0.356171 valid's rmse: 0.000719945   valid's RMSPE: 0.490328\n[670]   train's rmse: 0.000512159   train's RMSPE: 0.355952 valid's rmse: 0.000721065   valid's RMSPE: 0.491091\n[671]   train's rmse: 0.000511336   train's RMSPE: 0.35538  valid's rmse: 0.000723578   valid's RMSPE: 0.492803\n[672]   train's rmse: 0.000511837   train's RMSPE: 0.355729 valid's rmse: 0.000722283   valid's RMSPE: 0.491921\n[673]   train's rmse: 0.000512331   train's RMSPE: 0.356072 valid's rmse: 0.000720877   valid's RMSPE: 0.490963\n[674]   train's rmse: 0.000512804   train's RMSPE: 0.356401 valid's rmse: 0.000719838   valid's RMSPE: 0.490256\n[675]   train's rmse: 0.000513107   train's RMSPE: 0.356611 valid's rmse: 0.000726872   valid's RMSPE: 0.495046\n[676]   train's rmse: 0.000513562   train's RMSPE: 0.356927 valid's rmse: 0.000725566   valid's RMSPE: 0.494157\n[677]   train's rmse: 0.00051274    train's RMSPE: 0.356356 valid's rmse: 0.000730535   valid's RMSPE: 0.497541\n[678]   train's rmse: 0.000512519   train's RMSPE: 0.356203 valid's rmse: 0.000731853   valid's RMSPE: 0.498438\n[679]   train's rmse: 0.000511469   train's RMSPE: 0.355473 valid's rmse: 0.00073026    valid's RMSPE: 0.497354\n[680]   train's rmse: 0.000511835   train's RMSPE: 0.355727 valid's rmse: 0.00072928    valid's RMSPE: 0.496686\n[681]   train's rmse: 0.000512327   train's RMSPE: 0.356069 valid's rmse: 0.000728269   valid's RMSPE: 0.495998\n[682]   train's rmse: 0.000512776   train's RMSPE: 0.356381 valid's rmse: 0.000727288   valid's RMSPE: 0.49533\n[683]   train's rmse: 0.000513083   train's RMSPE: 0.356594 valid's rmse: 0.000726144   valid's RMSPE: 0.494551\n[684]   train's rmse: 0.000511735   train's RMSPE: 0.355658 valid's rmse: 0.000723999   valid's RMSPE: 0.493089\n[685]   train's rmse: 0.00051065    train's RMSPE: 0.354904 valid's rmse: 0.000729421   valid's RMSPE: 0.496783\n[686]   train's rmse: 0.000511118   train's RMSPE: 0.355229 valid's rmse: 0.000728647   valid's RMSPE: 0.496255\n[687]   train's rmse: 0.000509974   train's RMSPE: 0.354434 valid's rmse: 0.000729934   valid's RMSPE: 0.497132\n[688]   train's rmse: 0.000510479   train's RMSPE: 0.354785 valid's rmse: 0.000727575   valid's RMSPE: 0.495525\n[689]   train's rmse: 0.000510628   train's RMSPE: 0.354888 valid's rmse: 0.000735084   valid's RMSPE: 0.500639\n[690]   train's rmse: 0.000510993   train's RMSPE: 0.355142 valid's rmse: 0.000734575   valid's RMSPE: 0.500292\n[691]   train's rmse: 0.000511536   train's RMSPE: 0.355519 valid's rmse: 0.000735121   valid's RMSPE: 0.500665\n[692]   train's rmse: 0.00051029    train's RMSPE: 0.354653 valid's rmse: 0.000736724   valid's RMSPE: 0.501756\n[693]   train's rmse: 0.000509577   train's RMSPE: 0.354158 valid's rmse: 0.000737354   valid's RMSPE: 0.502185\n[694]   train's rmse: 0.000509997   train's RMSPE: 0.35445  valid's rmse: 0.000736239   valid's RMSPE: 0.501426\n[695]   train's rmse: 0.000510266   train's RMSPE: 0.354637 valid's rmse: 0.000738029   valid's RMSPE: 0.502645\n[696]   train's rmse: 0.000510761   train's RMSPE: 0.35498  valid's rmse: 0.00073716    valid's RMSPE: 0.502053\n[697]   train's rmse: 0.000509693   train's RMSPE: 0.354238 valid's rmse: 0.000740731   valid's RMSPE: 0.504485\n[698]   train's rmse: 0.000510148   train's RMSPE: 0.354554 valid's rmse: 0.000739695   valid's RMSPE: 0.50378\n[699]   train's rmse: 0.000508352   train's RMSPE: 0.353306 valid's rmse: 0.000740696   valid's RMSPE: 0.504462\n[700]   train's rmse: 0.00050875    train's RMSPE: 0.353583 valid's rmse: 0.00073969    valid's RMSPE: 0.503776\n[701]   train's rmse: 0.00050917    train's RMSPE: 0.353875 valid's rmse: 0.000738463   valid's RMSPE: 0.502941\n[702]   train's rmse: 0.000508615   train's RMSPE: 0.353489 valid's rmse: 0.000739115   valid's RMSPE: 0.503384\n[703]   train's rmse: 0.000508951   train's RMSPE: 0.353723 valid's rmse: 0.000736578   valid's RMSPE: 0.501657\n[704]   train's rmse: 0.000509394   train's RMSPE: 0.354031 valid's rmse: 0.000735541   valid's RMSPE: 0.50095\n[705]   train's rmse: 0.000508914   train's RMSPE: 0.353697 valid's rmse: 0.000734719   valid's RMSPE: 0.500391\n[706]   train's rmse: 0.000507816   train's RMSPE: 0.352934 valid's rmse: 0.000736294   valid's RMSPE: 0.501464\n[707]   train's rmse: 0.000508164   train's RMSPE: 0.353176 valid's rmse: 0.000735515   valid's RMSPE: 0.500933\n[708]   train's rmse: 0.000507719   train's RMSPE: 0.352866 valid's rmse: 0.000739746   valid's RMSPE: 0.503814\n[709]   train's rmse: 0.000507281   train's RMSPE: 0.352562 valid's rmse: 0.000745809   valid's RMSPE: 0.507944\n[710]   train's rmse: 0.000506708   train's RMSPE: 0.352164 valid's rmse: 0.000744356   valid's RMSPE: 0.506954\n[711]   train's rmse: 0.000507236   train's RMSPE: 0.352531 valid's rmse: 0.000743343   valid's RMSPE: 0.506264\n[712]   train's rmse: 0.000507056   train's RMSPE: 0.352406 valid's rmse: 0.00074318    valid's RMSPE: 0.506153\n[713]   train's rmse: 0.000506512   train's RMSPE: 0.352027 valid's rmse: 0.000745638   valid's RMSPE: 0.507827\n[714]   train's rmse: 0.000506693   train's RMSPE: 0.352154 valid's rmse: 0.000747586   valid's RMSPE: 0.509154\n[715]   train's rmse: 0.000507028   train's RMSPE: 0.352386 valid's rmse: 0.000746518   valid's RMSPE: 0.508427\n[716]   train's rmse: 0.00050688    train's RMSPE: 0.352283 valid's rmse: 0.000749767   valid's RMSPE: 0.510639\n[717]   train's rmse: 0.000505799   train's RMSPE: 0.351532 valid's rmse: 0.0007498 valid's RMSPE: 0.510662\n[718]   train's rmse: 0.000505729   train's RMSPE: 0.351484 valid's rmse: 0.000749654   valid's RMSPE: 0.510563\n[719]   train's rmse: 0.000505705   train's RMSPE: 0.351467 valid's rmse: 0.000750423   valid's RMSPE: 0.511086\n[720]   train's rmse: 0.000504831   train's RMSPE: 0.350859 valid's rmse: 0.00075429    valid's RMSPE: 0.51372\n[721]   train's rmse: 0.00050367    train's RMSPE: 0.350052 valid's rmse: 0.000755289   valid's RMSPE: 0.5144\n[722]   train's rmse: 0.000504041   train's RMSPE: 0.350311 valid's rmse: 0.000754037   valid's RMSPE: 0.513547\n[723]   train's rmse: 0.000503678   train's RMSPE: 0.350058 valid's rmse: 0.000757503   valid's RMSPE: 0.515908\n[724]   train's rmse: 0.000503081   train's RMSPE: 0.349643 valid's rmse: 0.000760346   valid's RMSPE: 0.517845\n[725]   train's rmse: 0.000503437   train's RMSPE: 0.34989  valid's rmse: 0.000758889   valid's RMSPE: 0.516852\n[726]   train's rmse: 0.000502569   train's RMSPE: 0.349287 valid's rmse: 0.000761732   valid's RMSPE: 0.518789\n[727]   train's rmse: 0.00050282    train's RMSPE: 0.349462 valid's rmse: 0.000763302   valid's RMSPE: 0.519857\n[728]   train's rmse: 0.000501988   train's RMSPE: 0.348883 valid's rmse: 0.000765846   valid's RMSPE: 0.52159\n[729]   train's rmse: 0.000501839   train's RMSPE: 0.34878  valid's rmse: 0.000765938   valid's RMSPE: 0.521653\n[730]   train's rmse: 0.000502172   train's RMSPE: 0.349011 valid's rmse: 0.00076476    valid's RMSPE: 0.52085\n[731]   train's rmse: 0.000502565   train's RMSPE: 0.349285 valid's rmse: 0.00076363    valid's RMSPE: 0.520081\n[732]   train's rmse: 0.00050295    train's RMSPE: 0.349552 valid's rmse: 0.000762373   valid's RMSPE: 0.519225\n[733]   train's rmse: 0.000503263   train's RMSPE: 0.349769 valid's rmse: 0.000761422   valid's RMSPE: 0.518577\n[734]   train's rmse: 0.00050369    train's RMSPE: 0.350066 valid's rmse: 0.000760299   valid's RMSPE: 0.517812\n[735]   train's rmse: 0.000504055   train's RMSPE: 0.35032  valid's rmse: 0.000759116   valid's RMSPE: 0.517007\n[736]   train's rmse: 0.000504419   train's RMSPE: 0.350573 valid's rmse: 0.000757731   valid's RMSPE: 0.516063\n[737]   train's rmse: 0.000503822   train's RMSPE: 0.350158 valid's rmse: 0.000764646   valid's RMSPE: 0.520773\n[738]   train's rmse: 0.000504203   train's RMSPE: 0.350423 valid's rmse: 0.000763539   valid's RMSPE: 0.520019\n[739]   train's rmse: 0.000503274   train's RMSPE: 0.349777 valid's rmse: 0.000768269   valid's RMSPE: 0.52324\n[740]   train's rmse: 0.000503484   train's RMSPE: 0.349923 valid's rmse: 0.000767475   valid's RMSPE: 0.522699\n[741]   train's rmse: 0.000503787   train's RMSPE: 0.350134 valid's rmse: 0.000766356   valid's RMSPE: 0.521937\n[742]   train's rmse: 0.000502844   train's RMSPE: 0.349478 valid's rmse: 0.000769973   valid's RMSPE: 0.524401\n[743]   train's rmse: 0.000503039   train's RMSPE: 0.349614 valid's rmse: 0.000773858   valid's RMSPE: 0.527047\n[744]   train's rmse: 0.000503496   train's RMSPE: 0.349931 valid's rmse: 0.000772772   valid's RMSPE: 0.526307\n[745]   train's rmse: 0.000503775   train's RMSPE: 0.350126 valid's rmse: 0.000771445   valid's RMSPE: 0.525404\n[746]   train's rmse: 0.000503235   train's RMSPE: 0.34975  valid's rmse: 0.000772429   valid's RMSPE: 0.526074\n[747]   train's rmse: 0.000503579   train's RMSPE: 0.349989 valid's rmse: 0.000771558   valid's RMSPE: 0.52548\n[748]   train's rmse: 0.000502933   train's RMSPE: 0.34954  valid's rmse: 0.000773249   valid's RMSPE: 0.526632\n[749]   train's rmse: 0.000502223   train's RMSPE: 0.349047 valid's rmse: 0.000778155   valid's RMSPE: 0.529973\n[750]   train's rmse: 0.000502345   train's RMSPE: 0.349132 valid's rmse: 0.000778354   valid's RMSPE: 0.530109\n[751]   train's rmse: 0.000502775   train's RMSPE: 0.34943  valid's rmse: 0.000777079   valid's RMSPE: 0.52924\n[752]   train's rmse: 0.000501916   train's RMSPE: 0.348833 valid's rmse: 0.00077606    valid's RMSPE: 0.528547\n[753]   train's rmse: 0.000502297   train's RMSPE: 0.349098 valid's rmse: 0.000774885   valid's RMSPE: 0.527747\n[754]   train's rmse: 0.000502689   train's RMSPE: 0.349371 valid's rmse: 0.000773596   valid's RMSPE: 0.526869\n[755]   train's rmse: 0.00050176    train's RMSPE: 0.348725 valid's rmse: 0.00077291    valid's RMSPE: 0.526401\nEarly stopping, best iteration is:\n[356]   0.44411014835577256\n355\nOur out of folds RMSPE is 0.9967\nOur cv fold scores are [0.435, 0.673, 0.446, 0.468, 0.444]\nhttps://app.neptune.ai/chrisrichardmiles/optiver/e/OP-130\nRemember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\nShutting down background jobs, please wait a moment...\nDone!\n\n\nWaiting for the remaining 13718 operations to synchronize with Neptune. Do not kill this process.\n\n\nAll 13718 operations synced, thanks for waiting!\nretraining model with all data for [576, 22, 269, 189, 355] iterations\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nm = lgb.Booster(model_file='./lgb_fold_0.txt')"
  },
  {
    "objectID": "projects/optiver/notebooks/opt-train-one-at-a-time.html",
    "href": "projects/optiver/notebooks/opt-train-one-at-a-time.html",
    "title": "chrisrichardmiles",
    "section": "",
    "text": "def rdf(train): \n    train['spe'] = ((train['target'] - train['pred']) / train['target']) ** 2\n    return np.sqrt((train['spe'].sum()) / train.shape[0])\n\n\nwith open('../input/nepop76/cfg.json') as f: \n    cfg = json.load(f)\n\n\nstocks = defaultdict(dict)\n\n\nall_train = pd.read_pickle('../input/nepop76/enc_p8_train.pkl')\ncols = [c for c in all_train.columns if not c.startswith('stock_id_')]\nall_train = all_train[cols]\n# all_train.columns.tolist()\nall_preds = all_train[['stock_id', 'target']]\nall_preds['pred'] = 0\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n\n\n\n\n\n\n\n\n\n  \n    \n      \n      stock_id\n      target\n      pred\n    \n  \n  \n    \n      0\n      0\n      0.004136\n      0\n    \n    \n      1\n      0\n      0.001445\n      0\n    \n    \n      2\n      0\n      0.002168\n      0\n    \n    \n      3\n      0\n      0.002195\n      0\n    \n    \n      4\n      0\n      0.001747\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      428927\n      126\n      0.003461\n      0\n    \n    \n      428928\n      126\n      0.003113\n      0\n    \n    \n      428929\n      126\n      0.004070\n      0\n    \n    \n      428930\n      126\n      0.003357\n      0\n    \n    \n      428931\n      126\n      0.002090\n      0\n    \n  \n\n428932 rows × 3 columns\n\n\n\n\nold_preds = all_train[['stock_id', 'target']]\nold_preds['pred'] = np.load('../input/nepop76/oof_predictions.npy')\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n\n\n\nsdf = pd.DataFrame(columns=['old', 'new'])\n\n\ndef main(stock_id): \n#     train = pd.read_pickle(cfg['path_features'])\n#     train = encode_cols(train, cfg[\"encode_time_cols\"], funcs=cfg['encode_funcs'], on='time_id')\n    \n    # Saving encoded stock columns\n#     feat_file = 'enc_' + os.path.split(cfg['path_features'])[1]\n#     tmp = encode_cols(train, cfg[\"encode_stock_cols\"], funcs=cfg['encode_funcs'], on='stock_id')\n#     tmp.to_pickle(os.path.join(cfg['path_models'], feat_file))\n     \n    train = all_train[all_train.stock_id == stock_id]\n    drop_cols = [c for c in cfg['drop_cols'] if c in train.columns and c != 'stock_id' and c not in cfg['encode_stock_cols']]\n    x = train.drop(drop_cols, axis = 1)\n    y = train['target']\n    \n    oof_predictions = np.zeros(x.shape[0]) # Create out of folds array\n    scores = [] # Keep track of scores for each fold and all oof at the end\n    best_iterations = []\n    training_best_scores = []\n    valid_best_scores = [] # Same as scores in this script, but would be different with nested cv\n    best_score_diffs = []\n    dict_eval_logs = [] # For experimentation tracking\n    booster_summaries = [] # For experimentation tracking\n    dumb_features = []\n    top_features = []\n    \n    for fold in range(5):\n        trn_ind = x.fold != fold\n        val_ind = x.fold == fold\n        \n        print(f'Training fold {fold}')\n        x_train, x_val = x[trn_ind].drop('fold', axis=1), x[val_ind].drop('fold', axis=1)\n        y_train, y_val = y[trn_ind], y[val_ind]\n        \n        x_train = encode_cols(x_train, \n                              cfg['encode_stock_cols'], \n                              funcs=cfg['encode_funcs'], \n                              shake=cfg['shake'], \n                              shake_std=cfg['shake_std']).drop('stock_id', axis=1)\n        n_train_cols = x_train.shape[1]\n        \n        x_val = encode_cols(x_val, \n                            cfg['encode_stock_cols'], \n                            funcs=cfg['encode_funcs']).drop('stock_id', axis=1)\n        \n        train_weights = 1 / np.square(y_train) # Root mean squared percentage error weights\n        val_weights = 1 / np.square(y_val)\n        train_dataset = lgb.Dataset(x_train, y_train, weight=train_weights)\n        val_dataset = lgb.Dataset(x_val, y_val, weight=val_weights, reference=train_dataset)\n        \n        dict_eval_log = {}\n        model = lgb.train(params = cfg['lgb_params'], \n                          train_set = train_dataset, \n                          valid_sets = [val_dataset, train_dataset], \n                          valid_names = ['valid', 'train'], \n                          feval = feval_rmspe,\n                          callbacks=[record_evaluation(dict_eval_log)],\n                          verbose_eval = 50)\n        \n#         model.save_model(os.path.join(cfg['path_models'], f'{cfg[\"prefix\"]}lgb_fold_{fold}.txt'))\n        y_pred = model.predict(x_val)\n        oof_predictions[val_ind] = y_pred\n        scores.append(round(rmspe(y_val, y_pred), 3))\n        \n#         dumb_features.append(get_dumb_features(model))\n#         top_features.append(get_top_features(model))\n        \n#         booster_summary = create_booster_summary(\n#             booster=model,\n#             log_importances=True,\n#             max_num_features=25,\n#             log_trees_as_dataframe=False, \n#             log_pickled_booster=True, \n#             y_true=y_val, \n#             y_pred=y_pred, \n#         )\n#         train_score = model.best_score['train']['RMSPE']\n#         valid_score = model.best_score['valid']['RMSPE']\n#         best_iterations.append(model.best_iteration)\n#         training_best_scores.append(round(train_score, 3))\n#         valid_best_scores.append(round(valid_score, 3))\n#         best_score_diffs.append(round(valid_score - train_score, 3))\n        \n#         booster_summaries.append(booster_summary)\n#         dict_eval_logs.append(dict_eval_log)\n#         del booster_summary, dict_eval_log\n    \n    \n    rmspe_score = round(rmspe(y, oof_predictions), 3)\n    old = rdf(old_preds[old_preds.stock_id == stock_id])\n    sc = [old, rmspe_score]\n    sdf.loc[stock_id] = sc\n    all_preds.loc[all_preds.stock_id == stock_id, 'pred'] = oof_predictions\n    print(f'Our out of folds RMSPE is {rmspe_score}, compared to {old}, giving gain {rmspe_score - old}')\n    print(f'Our cv fold scores are {scores}')\n#     np.save('oof_predictions', oof_predictions)\n    \n#     run = neptune.init(\n#             project=cfg['neptune_project'],\n#             api_token=NEPTUNE_API_TOKEN,\n#             name=cfg['neptune_run_name'],    \n#             description=cfg['neptune_description'],\n#             tags=[cfg['path_features'], cfg['prefix']],\n#             source_files=['cfg.json'],\n#     )\n#     run = stocks[stock_id]\n# #     run['feat_id'] = feat_file\n#     run['old_score'] = \n#     run['cfg'] = cfg\n#     run['RMSPE'] = rmspe_score\n#     run['RMSPE_oof_scores'] = scores\n#     run['RMSPE_cv_std'] = np.std(scores)\n    \n#     run['best_iterations'] = best_iterations\n#     best_iterations_mean = int(np.mean(best_iterations))\n#     run['best_iterations_mean'] = best_iterations_mean\n#     run['training_best_scores'] = training_best_scores\n#     run['valid_best_scores'] = valid_best_scores\n#     run['best_score_diffs'] = best_score_diffs\n#     run['best_score_diffs_mean'] = round(np.mean(best_score_diffs), 3)\n#     run['dumb_features'] = list(reduce(lambda a, b: set(a).intersection(set(b)), dumb_features))\n#     run['top_features'] = list(reduce(lambda a, b: set(a).intersection(set(b)), top_features))\n    \n#     run[f'fold_{fold}'] = booster_summaries[fold]\n#     run[f'dumb_features_{fold}'] = list(dumb_features[fold])\n#     run[f'top_features_{fold}'] = list(top_features[fold])\n    \n    # Logs for each folds model\n#     for fold in range(5):\n#         run[f'lgbm_summaries/fold_{fold}'] = booster_summaries[fold]\n#         run[f'lgbm_summaries/dumb_features_{fold}'] = list(dumb_features[fold])\n#         run[f'lgbm_summaries/top_features_{fold}'] = list(top_features[fold])\n#         dict_eval_log = dict_eval_logs[fold]\n#         for valid_set, odict in dict_eval_log.items():\n#             for metric, log in odict.items():\n#                 for val in log:\n#                     run[f'eval_logs/{fold}_{valid_set}_{metric}'].log(val)\n#     run.stop()\n    \n#     if cfg['rerun']: \n#         print(f'retraining model with all data for {best_iterations} iterations')\n#         params = cfg['lgb_params'].copy()\n#         params['early_stopping_rounds'] = 0 # No valid set to stop with\n        \n#         x_train = x.drop(['fold'], axis=1)\n#         x_train = encode_cols(x_train, \n#                               cfg['encode_stock_cols'], \n#                               funcs=cfg['encode_funcs'], \n#                               shake=cfg['shake'], \n#                               shake_std=cfg['shake_std']).drop('stock_id', axis=1)\n#         y_train = y\n        \n#         assert(n_train_cols == x_train.shape[1])\n        \n#         train_weights = 1 / np.square(y_train) # Root mean squared percentage error weights\n#         train_dataset = lgb.Dataset(x_train, y_train, weight=train_weights)\n        \n#         for fold, best_iter in enumerate(best_iterations): \n#             params['n_estimators'] = int(best_iter) # lgbm needs int here\n#             model = lgb.train(params = params, \n#                               train_set = train_dataset)\n#             model.save_model(os.path.join(cfg['path_models'], f'{cfg[\"prefix\"]}rerun_lgb_{fold}.txt'))\n    \n# if __name__ == '__main__': \n#     main()\n\n\nmain(31)\n\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000613071   train's RMSPE: 0.440295 valid's rmse: 0.000770026   valid's RMSPE: 0.444244\n[100]   train's rmse: 0.000542566   train's RMSPE: 0.38966  valid's rmse: 0.000754667   valid's RMSPE: 0.435383\nEarly stopping, best iteration is:\n[88]    train's rmse: 0.00055269    train's RMSPE: 0.396931 valid's rmse: 0.000751319   valid's RMSPE: 0.433451\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000601588   train's RMSPE: 0.419415 valid's rmse: 0.00116532    valid's RMSPE: 0.783223\nEarly stopping, best iteration is:\n[16]    train's rmse: 0.000776851   train's RMSPE: 0.541605 valid's rmse: 0.0010316 valid's RMSPE: 0.693344\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000644589   train's RMSPE: 0.445608 valid's rmse: 0.000662557   valid's RMSPE: 0.461107\n[100]   train's rmse: 0.000567772   train's RMSPE: 0.392504 valid's rmse: 0.000656094   valid's RMSPE: 0.456609\nEarly stopping, best iteration is:\n[94]    train's rmse: 0.000574504   train's RMSPE: 0.397159 valid's rmse: 0.000650131   valid's RMSPE: 0.452459\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000668864   train's RMSPE: 0.440228 valid's rmse: 0.000588563   valid's RMSPE: 0.479311\n[100]   train's rmse: 0.000600592   train's RMSPE: 0.395293 valid's rmse: 0.000617043   valid's RMSPE: 0.502504\nEarly stopping, best iteration is:\n[57]    train's rmse: 0.000652315   train's RMSPE: 0.429336 valid's rmse: 0.000576923   valid's RMSPE: 0.469831\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000645764   train's RMSPE: 0.448808 valid's rmse: 0.000658246   valid's RMSPE: 0.448308\n[100]   train's rmse: 0.000564414   train's RMSPE: 0.39227  valid's rmse: 0.000672598   valid's RMSPE: 0.458083\nEarly stopping, best iteration is:\n[57]    train's rmse: 0.0006261 train's RMSPE: 0.435142 valid's rmse: 0.000649591   valid's RMSPE: 0.442413\nOur out of folds RMSPE is 0.508, compared to 0.5555796745804047, giving gain -0.047579674580404685\nOur cv fold scores are [0.433, 0.693, 0.452, 0.47, 0.442]\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n\n\n\nfor stock_id in all_preds.stock_id.unique(): \n    main(stock_id)\n\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000708746   train's RMSPE: 0.275569 valid's rmse: 0.00077724    valid's RMSPE: 0.296384\n[100]   train's rmse: 0.000678066   train's RMSPE: 0.26364  valid's rmse: 0.000767171   valid's RMSPE: 0.292545\n[150]   train's rmse: 0.000661326   train's RMSPE: 0.257131 valid's rmse: 0.000765755   valid's RMSPE: 0.292005\n[200]   train's rmse: 0.00064754    train's RMSPE: 0.251771 valid's rmse: 0.000763377   valid's RMSPE: 0.291098\n[250]   train's rmse: 0.00063573    train's RMSPE: 0.247179 valid's rmse: 0.000760109   valid's RMSPE: 0.289852\n[300]   train's rmse: 0.000625967   train's RMSPE: 0.243383 valid's rmse: 0.000758097   valid's RMSPE: 0.289085\n[350]   train's rmse: 0.000615999   train's RMSPE: 0.239507 valid's rmse: 0.000757436   valid's RMSPE: 0.288833\n[400]   train's rmse: 0.00060813    train's RMSPE: 0.236448 valid's rmse: 0.000755773   valid's RMSPE: 0.288198\n[450]   train's rmse: 0.000601009   train's RMSPE: 0.233679 valid's rmse: 0.000753786   valid's RMSPE: 0.287441\n[500]   train's rmse: 0.000594125   train's RMSPE: 0.231003 valid's rmse: 0.000754027   valid's RMSPE: 0.287533\nEarly stopping, best iteration is:\n[470]   train's rmse: 0.000597956   train's RMSPE: 0.232492 valid's rmse: 0.000752422   valid's RMSPE: 0.286921\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000717123   train's RMSPE: 0.277548 valid's rmse: 0.000735287   valid's RMSPE: 0.285668\n[100]   train's rmse: 0.000687241   train's RMSPE: 0.265983 valid's rmse: 0.000723043   valid's RMSPE: 0.280911\n[150]   train's rmse: 0.000670054   train's RMSPE: 0.259331 valid's rmse: 0.000721038   valid's RMSPE: 0.280132\n[200]   train's rmse: 0.00065537    train's RMSPE: 0.253647 valid's rmse: 0.000720285   valid's RMSPE: 0.27984\n[250]   train's rmse: 0.000643291   train's RMSPE: 0.248973 valid's rmse: 0.000723496   valid's RMSPE: 0.281087\nEarly stopping, best iteration is:\n[204]   train's rmse: 0.000653848   train's RMSPE: 0.253058 valid's rmse: 0.000719287   valid's RMSPE: 0.279452\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000721856   train's RMSPE: 0.2783   valid's rmse: 0.000716356   valid's RMSPE: 0.282543\n[100]   train's rmse: 0.000690661   train's RMSPE: 0.266273 valid's rmse: 0.000703217   valid's RMSPE: 0.277361\n[150]   train's rmse: 0.000671458   train's RMSPE: 0.258869 valid's rmse: 0.000702197   valid's RMSPE: 0.276959\nEarly stopping, best iteration is:\n[141]   train's rmse: 0.000674685   train's RMSPE: 0.260114 valid's rmse: 0.000700929   valid's RMSPE: 0.276459\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000716965   train's RMSPE: 0.277472 valid's rmse: 0.000739081   valid's RMSPE: 0.287201\n[100]   train's rmse: 0.000685413   train's RMSPE: 0.265261 valid's rmse: 0.000731112   valid's RMSPE: 0.284104\n[150]   train's rmse: 0.000667796   train's RMSPE: 0.258443 valid's rmse: 0.000726732   valid's RMSPE: 0.282402\n[200]   train's rmse: 0.00065308    train's RMSPE: 0.252748 valid's rmse: 0.000726079   valid's RMSPE: 0.282149\n[250]   train's rmse: 0.000642084   train's RMSPE: 0.248492 valid's rmse: 0.00072531    valid's RMSPE: 0.28185\nEarly stopping, best iteration is:\n[243]   train's rmse: 0.000643344   train's RMSPE: 0.24898  valid's rmse: 0.000723453   valid's RMSPE: 0.281128\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000721276   train's RMSPE: 0.280029 valid's rmse: 0.000723078   valid's RMSPE: 0.277408\n[100]   train's rmse: 0.000691166   train's RMSPE: 0.268339 valid's rmse: 0.000703881   valid's RMSPE: 0.270043\n[150]   train's rmse: 0.000674363   train's RMSPE: 0.261815 valid's rmse: 0.000702649   valid's RMSPE: 0.26957\n[200]   train's rmse: 0.000661207   train's RMSPE: 0.256707 valid's rmse: 0.000700385   valid's RMSPE: 0.268701\n[250]   train's rmse: 0.000649103   train's RMSPE: 0.252008 valid's rmse: 0.000697772   valid's RMSPE: 0.267699\nEarly stopping, best iteration is:\n[241]   train's rmse: 0.000651073   train's RMSPE: 0.252773 valid's rmse: 0.000697554   valid's RMSPE: 0.267615\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.278, compared to 0.24694968849387877, giving gain 0.031050311506121253\nOur cv fold scores are [0.287, 0.279, 0.276, 0.281, 0.268]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000663015   train's RMSPE: 0.218782 valid's rmse: 0.000694527   valid's RMSPE: 0.230997\n[100]   train's rmse: 0.000626827   train's RMSPE: 0.206841 valid's rmse: 0.000664777   valid's RMSPE: 0.221102\n[150]   train's rmse: 0.000611527   train's RMSPE: 0.201792 valid's rmse: 0.000657947   valid's RMSPE: 0.21883\n[200]   train's rmse: 0.000598256   train's RMSPE: 0.197413 valid's rmse: 0.000653201   valid's RMSPE: 0.217252\n[250]   train's rmse: 0.000586653   train's RMSPE: 0.193584 valid's rmse: 0.00065099    valid's RMSPE: 0.216516\n[300]   train's rmse: 0.000577668   train's RMSPE: 0.19062  valid's rmse: 0.00064818    valid's RMSPE: 0.215582\n[350]   train's rmse: 0.000569594   train's RMSPE: 0.187955 valid's rmse: 0.000646962   valid's RMSPE: 0.215177\n[400]   train's rmse: 0.000562173   train's RMSPE: 0.185506 valid's rmse: 0.000646283   valid's RMSPE: 0.214951\nEarly stopping, best iteration is:\n[365]   train's rmse: 0.000567366   train's RMSPE: 0.18722  valid's rmse: 0.000646171   valid's RMSPE: 0.214914\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00067065    train's RMSPE: 0.221116 valid's rmse: 0.000668631   valid's RMSPE: 0.223119\n[100]   train's rmse: 0.000634159   train's RMSPE: 0.209084 valid's rmse: 0.000643784   valid's RMSPE: 0.214828\n[150]   train's rmse: 0.000616275   train's RMSPE: 0.203188 valid's rmse: 0.000638892   valid's RMSPE: 0.213196\n[200]   train's rmse: 0.00060468    train's RMSPE: 0.199365 valid's rmse: 0.000638823   valid's RMSPE: 0.213173\nEarly stopping, best iteration is:\n[162]   train's rmse: 0.000612928   train's RMSPE: 0.202084 valid's rmse: 0.000637516   valid's RMSPE: 0.212737\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000661398   train's RMSPE: 0.218809 valid's rmse: 0.00068514    valid's RMSPE: 0.225556\n[100]   train's rmse: 0.000624917   train's RMSPE: 0.20674  valid's rmse: 0.000668918   valid's RMSPE: 0.220215\n[150]   train's rmse: 0.000609733   train's RMSPE: 0.201717 valid's rmse: 0.000666552   valid's RMSPE: 0.219437\nEarly stopping, best iteration is:\n[129]   train's rmse: 0.000614757   train's RMSPE: 0.203379 valid's rmse: 0.000665544   valid's RMSPE: 0.219105\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000664549   train's RMSPE: 0.21977  valid's rmse: 0.000684257   valid's RMSPE: 0.225604\n[100]   train's rmse: 0.000628342   train's RMSPE: 0.207796 valid's rmse: 0.000656102   valid's RMSPE: 0.216321\n[150]   train's rmse: 0.000611617   train's RMSPE: 0.202265 valid's rmse: 0.00065246    valid's RMSPE: 0.21512\n[200]   train's rmse: 0.00059894    train's RMSPE: 0.198072 valid's rmse: 0.00064975    valid's RMSPE: 0.214227\n[250]   train's rmse: 0.00058807    train's RMSPE: 0.194478 valid's rmse: 0.000646565   valid's RMSPE: 0.213177\n[300]   train's rmse: 0.000579363   train's RMSPE: 0.191598 valid's rmse: 0.000645649   valid's RMSPE: 0.212875\n[350]   train's rmse: 0.000570791   train's RMSPE: 0.188763 valid's rmse: 0.000643303   valid's RMSPE: 0.212101\n[400]   train's rmse: 0.000562965   train's RMSPE: 0.186175 valid's rmse: 0.000644943   valid's RMSPE: 0.212642\nEarly stopping, best iteration is:\n[350]   train's rmse: 0.000570791   train's RMSPE: 0.188763 valid's rmse: 0.000643303   valid's RMSPE: 0.212101\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000663843   train's RMSPE: 0.219936 valid's rmse: 0.000673262   valid's RMSPE: 0.220343\n[100]   train's rmse: 0.000629131   train's RMSPE: 0.208436 valid's rmse: 0.000656543   valid's RMSPE: 0.214872\n[150]   train's rmse: 0.000614006   train's RMSPE: 0.203425 valid's rmse: 0.000652618   valid's RMSPE: 0.213587\n[200]   train's rmse: 0.000602411   train's RMSPE: 0.199583 valid's rmse: 0.000649536   valid's RMSPE: 0.212578\n[250]   train's rmse: 0.000591933   train's RMSPE: 0.196112 valid's rmse: 0.000648082   valid's RMSPE: 0.212102\n[300]   train's rmse: 0.000582249   train's RMSPE: 0.192904 valid's rmse: 0.000644267   valid's RMSPE: 0.210854\n[350]   train's rmse: 0.000574861   train's RMSPE: 0.190456 valid's rmse: 0.000643239   valid's RMSPE: 0.210517\n[400]   train's rmse: 0.000567273   train's RMSPE: 0.187942 valid's rmse: 0.000641481   valid's RMSPE: 0.209942\n[450]   train's rmse: 0.000560119   train's RMSPE: 0.185572 valid's rmse: 0.000641056   valid's RMSPE: 0.209803\n[500]   train's rmse: 0.000554047   train's RMSPE: 0.18356  valid's rmse: 0.000641136   valid's RMSPE: 0.209829\nEarly stopping, best iteration is:\n[473]   train's rmse: 0.000557142   train's RMSPE: 0.184585 valid's rmse: 0.000640663   valid's RMSPE: 0.209674\nOur out of folds RMSPE is 0.214, compared to 0.19164992013891172, giving gain 0.02235007986108828\nOur cv fold scores are [0.215, 0.213, 0.219, 0.212, 0.21]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000385367   train's RMSPE: 0.254042 valid's rmse: 0.0004076 valid's RMSPE: 0.26942\n[100]   train's rmse: 0.000370853   train's RMSPE: 0.244474 valid's rmse: 0.000395757   valid's RMSPE: 0.261591\n[150]   train's rmse: 0.000363434   train's RMSPE: 0.239583 valid's rmse: 0.000392467   valid's RMSPE: 0.259417\n[200]   train's rmse: 0.000357173   train's RMSPE: 0.235456 valid's rmse: 0.000390607   valid's RMSPE: 0.258188\n[250]   train's rmse: 0.000352057   train's RMSPE: 0.232084 valid's rmse: 0.000389412   valid's RMSPE: 0.257398\n[300]   train's rmse: 0.00034762    train's RMSPE: 0.229158 valid's rmse: 0.000387807   valid's RMSPE: 0.256337\n[350]   train's rmse: 0.000343856   train's RMSPE: 0.226677 valid's rmse: 0.000387619   valid's RMSPE: 0.256212\n[400]   train's rmse: 0.000340726   train's RMSPE: 0.224614 valid's rmse: 0.000386394   valid's RMSPE: 0.255403\n[450]   train's rmse: 0.000337471   train's RMSPE: 0.222468 valid's rmse: 0.000385527   valid's RMSPE: 0.25483\n[500]   train's rmse: 0.000333853   train's RMSPE: 0.220083 valid's rmse: 0.000384959   valid's RMSPE: 0.254455\n[550]   train's rmse: 0.000330805   train's RMSPE: 0.218073 valid's rmse: 0.000383802   valid's RMSPE: 0.25369\n[600]   train's rmse: 0.000327949   train's RMSPE: 0.216191 valid's rmse: 0.00038304    valid's RMSPE: 0.253186\n[650]   train's rmse: 0.000325399   train's RMSPE: 0.21451  valid's rmse: 0.0003822 valid's RMSPE: 0.25263\n[700]   train's rmse: 0.000322875   train's RMSPE: 0.212846 valid's rmse: 0.000381819   valid's RMSPE: 0.252379\n[750]   train's rmse: 0.00032028    train's RMSPE: 0.211136 valid's rmse: 0.00038167    valid's RMSPE: 0.25228\n[800]   train's rmse: 0.000318113   train's RMSPE: 0.209707 valid's rmse: 0.000381441   valid's RMSPE: 0.252129\n[850]   train's rmse: 0.000316257   train's RMSPE: 0.208483 valid's rmse: 0.000381708   valid's RMSPE: 0.252306\nEarly stopping, best iteration is:\n[811]   train's rmse: 0.00031767    train's RMSPE: 0.209415 valid's rmse: 0.000381174   valid's RMSPE: 0.251952\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000382807   train's RMSPE: 0.252032 valid's rmse: 0.000410493   valid's RMSPE: 0.272706\n[100]   train's rmse: 0.000368068   train's RMSPE: 0.242329 valid's rmse: 0.000398842   valid's RMSPE: 0.264966\n[150]   train's rmse: 0.000360027   train's RMSPE: 0.237035 valid's rmse: 0.000394982   valid's RMSPE: 0.262401\n[200]   train's rmse: 0.000353969   train's RMSPE: 0.233046 valid's rmse: 0.000392758   valid's RMSPE: 0.260924\n[250]   train's rmse: 0.000348929   train's RMSPE: 0.229728 valid's rmse: 0.000391607   valid's RMSPE: 0.26016\n[300]   train's rmse: 0.000344562   train's RMSPE: 0.226853 valid's rmse: 0.000390124   valid's RMSPE: 0.259174\n[350]   train's rmse: 0.000340462   train's RMSPE: 0.224153 valid's rmse: 0.000389361   valid's RMSPE: 0.258667\n[400]   train's rmse: 0.000337143   train's RMSPE: 0.221968 valid's rmse: 0.000388813   valid's RMSPE: 0.258303\n[450]   train's rmse: 0.000333724   train's RMSPE: 0.219717 valid's rmse: 0.000388467   valid's RMSPE: 0.258073\n[500]   train's rmse: 0.000330729   train's RMSPE: 0.217745 valid's rmse: 0.000388054   valid's RMSPE: 0.257799\n[550]   train's rmse: 0.000328077   train's RMSPE: 0.215999 valid's rmse: 0.000387804   valid's RMSPE: 0.257633\n[600]   train's rmse: 0.000325312   train's RMSPE: 0.214179 valid's rmse: 0.00038713    valid's RMSPE: 0.257185\n[650]   train's rmse: 0.000323051   train's RMSPE: 0.21269  valid's rmse: 0.000387104   valid's RMSPE: 0.257168\nEarly stopping, best iteration is:\n[624]   train's rmse: 0.000324124   train's RMSPE: 0.213397 valid's rmse: 0.000386491   valid's RMSPE: 0.256761\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000386336   train's RMSPE: 0.254397 valid's rmse: 0.000386773   valid's RMSPE: 0.256781\n[100]   train's rmse: 0.000370459   train's RMSPE: 0.243943 valid's rmse: 0.000380171   valid's RMSPE: 0.252398\n[150]   train's rmse: 0.000363626   train's RMSPE: 0.239444 valid's rmse: 0.000379187   valid's RMSPE: 0.251745\n[200]   train's rmse: 0.000358025   train's RMSPE: 0.235755 valid's rmse: 0.000378275   valid's RMSPE: 0.251139\n[250]   train's rmse: 0.000352804   train's RMSPE: 0.232317 valid's rmse: 0.000377376   valid's RMSPE: 0.250542\n[300]   train's rmse: 0.000348202   train's RMSPE: 0.229287 valid's rmse: 0.000377415   valid's RMSPE: 0.250569\nEarly stopping, best iteration is:\n[292]   train's rmse: 0.0003488 train's RMSPE: 0.229681 valid's rmse: 0.000377049   valid's RMSPE: 0.250326\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000393114   train's RMSPE: 0.259607 valid's rmse: 0.000367642   valid's RMSPE: 0.241292\n[100]   train's rmse: 0.000377236   train's RMSPE: 0.249121 valid's rmse: 0.0003591 valid's RMSPE: 0.235685\n[150]   train's rmse: 0.000370072   train's RMSPE: 0.244391 valid's rmse: 0.000356556   valid's RMSPE: 0.234016\n[200]   train's rmse: 0.000364154   train's RMSPE: 0.240482 valid's rmse: 0.000354155   valid's RMSPE: 0.23244\n[250]   train's rmse: 0.00035922    train's RMSPE: 0.237224 valid's rmse: 0.000352567   valid's RMSPE: 0.231398\n[300]   train's rmse: 0.000354725   train's RMSPE: 0.234255 valid's rmse: 0.000350734   valid's RMSPE: 0.230194\n[350]   train's rmse: 0.000351167   train's RMSPE: 0.231906 valid's rmse: 0.000349603   valid's RMSPE: 0.229452\n[400]   train's rmse: 0.000347746   train's RMSPE: 0.229647 valid's rmse: 0.000348669   valid's RMSPE: 0.228839\n[450]   train's rmse: 0.000344824   train's RMSPE: 0.227717 valid's rmse: 0.000348059   valid's RMSPE: 0.228439\n[500]   train's rmse: 0.000341999   train's RMSPE: 0.225851 valid's rmse: 0.000347595   valid's RMSPE: 0.228134\n[550]   train's rmse: 0.000339051   train's RMSPE: 0.223904 valid's rmse: 0.000347563   valid's RMSPE: 0.228114\nEarly stopping, best iteration is:\n[509]   train's rmse: 0.000341371   train's RMSPE: 0.225436 valid's rmse: 0.000347164   valid's RMSPE: 0.227851\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000386987   train's RMSPE: 0.255952 valid's rmse: 0.000393253   valid's RMSPE: 0.256494\n[100]   train's rmse: 0.000371233   train's RMSPE: 0.245532 valid's rmse: 0.000382655   valid's RMSPE: 0.249582\n[150]   train's rmse: 0.000363756   train's RMSPE: 0.240587 valid's rmse: 0.00037907    valid's RMSPE: 0.247244\n[200]   train's rmse: 0.000357675   train's RMSPE: 0.236565 valid's rmse: 0.000377367   valid's RMSPE: 0.246133\n[250]   train's rmse: 0.000352391   train's RMSPE: 0.233071 valid's rmse: 0.000375788   valid's RMSPE: 0.245103\n[300]   train's rmse: 0.000347854   train's RMSPE: 0.23007  valid's rmse: 0.000374972   valid's RMSPE: 0.244571\n[350]   train's rmse: 0.000344208   train's RMSPE: 0.227658 valid's rmse: 0.000374364   valid's RMSPE: 0.244174\n[400]   train's rmse: 0.000340407   train's RMSPE: 0.225144 valid's rmse: 0.000373648   valid's RMSPE: 0.243707\n[450]   train's rmse: 0.00033703    train's RMSPE: 0.222911 valid's rmse: 0.000372698   valid's RMSPE: 0.243087\n[500]   train's rmse: 0.000334398   train's RMSPE: 0.22117  valid's rmse: 0.000372722   valid's RMSPE: 0.243104\n[550]   train's rmse: 0.000331644   train's RMSPE: 0.219348 valid's rmse: 0.000371867   valid's RMSPE: 0.242546\n[600]   train's rmse: 0.000329187   train's RMSPE: 0.217723 valid's rmse: 0.000371062   valid's RMSPE: 0.24202\nEarly stopping, best iteration is:\n[598]   train's rmse: 0.000329246   train's RMSPE: 0.217762 valid's rmse: 0.000371011   valid's RMSPE: 0.241987\nOur out of folds RMSPE is 0.246, compared to 0.18952182769614576, giving gain 0.05647817230385424\nOur cv fold scores are [0.252, 0.257, 0.25, 0.228, 0.242]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000973236   train's RMSPE: 0.229739 valid's rmse: 0.00102394    valid's RMSPE: 0.237663\n[100]   train's rmse: 0.00091764    train's RMSPE: 0.216615 valid's rmse: 0.000997012   valid's RMSPE: 0.231413\n[150]   train's rmse: 0.000890674   train's RMSPE: 0.21025  valid's rmse: 0.000994557   valid's RMSPE: 0.230843\n[200]   train's rmse: 0.000868401   train's RMSPE: 0.204992 valid's rmse: 0.000993257   valid's RMSPE: 0.230542\nEarly stopping, best iteration is:\n[187]   train's rmse: 0.000873797   train's RMSPE: 0.206266 valid's rmse: 0.00099259    valid's RMSPE: 0.230387\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000971754   train's RMSPE: 0.227947 valid's rmse: 0.000998896   valid's RMSPE: 0.237787\n[100]   train's rmse: 0.000915413   train's RMSPE: 0.214731 valid's rmse: 0.00098596    valid's RMSPE: 0.234707\n[150]   train's rmse: 0.000888289   train's RMSPE: 0.208368 valid's rmse: 0.000988451   valid's RMSPE: 0.2353\nEarly stopping, best iteration is:\n[106]   train's rmse: 0.000911646   train's RMSPE: 0.213847 valid's rmse: 0.000984962   valid's RMSPE: 0.23447\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000982139   train's RMSPE: 0.229925 valid's rmse: 0.00101126    valid's RMSPE: 0.242577\n[100]   train's rmse: 0.000925828   train's RMSPE: 0.216742 valid's rmse: 0.000970109   valid's RMSPE: 0.232706\n[150]   train's rmse: 0.000900234   train's RMSPE: 0.210751 valid's rmse: 0.000968805   valid's RMSPE: 0.232394\nEarly stopping, best iteration is:\n[141]   train's rmse: 0.000904525   train's RMSPE: 0.211755 valid's rmse: 0.000966091   valid's RMSPE: 0.231743\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000970443   train's RMSPE: 0.230288 valid's rmse: 0.00101834    valid's RMSPE: 0.231133\n[100]   train's rmse: 0.000918926   train's RMSPE: 0.218063 valid's rmse: 0.000995422   valid's RMSPE: 0.225932\n[150]   train's rmse: 0.000892506   train's RMSPE: 0.211793 valid's rmse: 0.000989623   valid's RMSPE: 0.224616\n[200]   train's rmse: 0.000874237   train's RMSPE: 0.207458 valid's rmse: 0.000990818   valid's RMSPE: 0.224887\nEarly stopping, best iteration is:\n[167]   train's rmse: 0.00088598    train's RMSPE: 0.210245 valid's rmse: 0.000988675   valid's RMSPE: 0.224401\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000980881   train's RMSPE: 0.229827 valid's rmse: 0.00101017    valid's RMSPE: 0.241528\n[100]   train's rmse: 0.000926154   train's RMSPE: 0.217004 valid's rmse: 0.00097133    valid's RMSPE: 0.232241\n[150]   train's rmse: 0.000899878   train's RMSPE: 0.210847 valid's rmse: 0.000968824   valid's RMSPE: 0.231641\n[200]   train's rmse: 0.000879691   train's RMSPE: 0.206117 valid's rmse: 0.000970801   valid's RMSPE: 0.232114\nEarly stopping, best iteration is:\n[159]   train's rmse: 0.000895304   train's RMSPE: 0.209775 valid's rmse: 0.000967081   valid's RMSPE: 0.231225\nOur out of folds RMSPE is 0.23, compared to 0.21766147454252618, giving gain 0.012338525457473826\nOur cv fold scores are [0.23, 0.234, 0.232, 0.224, 0.231]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000755692   train's RMSPE: 0.273927 valid's rmse: 0.000811946   valid's RMSPE: 0.289188\n[100]   train's rmse: 0.000723597   train's RMSPE: 0.262293 valid's rmse: 0.000795207   valid's RMSPE: 0.283226\n[150]   train's rmse: 0.000707182   train's RMSPE: 0.256343 valid's rmse: 0.000791371   valid's RMSPE: 0.28186\n[200]   train's rmse: 0.000692183   train's RMSPE: 0.250906 valid's rmse: 0.000789591   valid's RMSPE: 0.281226\n[250]   train's rmse: 0.00068035    train's RMSPE: 0.246617 valid's rmse: 0.000790391   valid's RMSPE: 0.281511\nEarly stopping, best iteration is:\n[207]   train's rmse: 0.000690418   train's RMSPE: 0.250266 valid's rmse: 0.000789476   valid's RMSPE: 0.281185\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00076311    train's RMSPE: 0.275074 valid's rmse: 0.000782888   valid's RMSPE: 0.285189\n[100]   train's rmse: 0.000730568   train's RMSPE: 0.263344 valid's rmse: 0.000762068   valid's RMSPE: 0.277605\n[150]   train's rmse: 0.000712568   train's RMSPE: 0.256855 valid's rmse: 0.000758832   valid's RMSPE: 0.276426\n[200]   train's rmse: 0.000698341   train's RMSPE: 0.251727 valid's rmse: 0.000759107   valid's RMSPE: 0.276526\nEarly stopping, best iteration is:\n[181]   train's rmse: 0.000703557   train's RMSPE: 0.253607 valid's rmse: 0.000757376   valid's RMSPE: 0.275896\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000761674   train's RMSPE: 0.274614 valid's rmse: 0.000770253   valid's RMSPE: 0.280354\n[100]   train's rmse: 0.000729076   train's RMSPE: 0.262861 valid's rmse: 0.000757299   valid's RMSPE: 0.275639\n[150]   train's rmse: 0.000712713   train's RMSPE: 0.256962 valid's rmse: 0.000754344   valid's RMSPE: 0.274563\n[200]   train's rmse: 0.00069845    train's RMSPE: 0.251819 valid's rmse: 0.000750683   valid's RMSPE: 0.273231\n[250]   train's rmse: 0.000686699   train's RMSPE: 0.247583 valid's rmse: 0.00074819    valid's RMSPE: 0.272323\n[300]   train's rmse: 0.000676821   train's RMSPE: 0.244021 valid's rmse: 0.000748485   valid's RMSPE: 0.272431\n[350]   train's rmse: 0.000666601   train's RMSPE: 0.240336 valid's rmse: 0.000746721   valid's RMSPE: 0.271789\n[400]   train's rmse: 0.00065758    train's RMSPE: 0.237084 valid's rmse: 0.000743606   valid's RMSPE: 0.270655\n[450]   train's rmse: 0.000649884   train's RMSPE: 0.234309 valid's rmse: 0.000742612   valid's RMSPE: 0.270293\nEarly stopping, best iteration is:\n[441]   train's rmse: 0.000651319   train's RMSPE: 0.234827 valid's rmse: 0.00074219    valid's RMSPE: 0.27014\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000767367   train's RMSPE: 0.277162 valid's rmse: 0.00076626    valid's RMSPE: 0.276933\n[100]   train's rmse: 0.00073468    train's RMSPE: 0.265356 valid's rmse: 0.0007553 valid's RMSPE: 0.272972\n[150]   train's rmse: 0.000718498   train's RMSPE: 0.259511 valid's rmse: 0.000750146   valid's RMSPE: 0.271109\n[200]   train's rmse: 0.00070432    train's RMSPE: 0.25439  valid's rmse: 0.000747318   valid's RMSPE: 0.270087\n[250]   train's rmse: 0.000690451   train's RMSPE: 0.249381 valid's rmse: 0.000747016   valid's RMSPE: 0.269978\n[300]   train's rmse: 0.000679839   train's RMSPE: 0.245548 valid's rmse: 0.000743633   valid's RMSPE: 0.268755\n[350]   train's rmse: 0.000669133   train's RMSPE: 0.241681 valid's rmse: 0.000741087   valid's RMSPE: 0.267835\n[400]   train's rmse: 0.00065996    train's RMSPE: 0.238368 valid's rmse: 0.000741565   valid's RMSPE: 0.268008\nEarly stopping, best iteration is:\n[354]   train's rmse: 0.00066817    train's RMSPE: 0.241333 valid's rmse: 0.00074056    valid's RMSPE: 0.267645\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00076205    train's RMSPE: 0.27546  valid's rmse: 0.000771792   valid's RMSPE: 0.278047\n[100]   train's rmse: 0.000731108   train's RMSPE: 0.264275 valid's rmse: 0.000762482   valid's RMSPE: 0.274693\n[150]   train's rmse: 0.000713089   train's RMSPE: 0.257762 valid's rmse: 0.000762368   valid's RMSPE: 0.274652\nEarly stopping, best iteration is:\n[130]   train's rmse: 0.000720001   train's RMSPE: 0.26026  valid's rmse: 0.000759827   valid's RMSPE: 0.273736\nOur out of folds RMSPE is 0.274, compared to 0.23933832319605133, giving gain 0.03466167680394869\nOur cv fold scores are [0.281, 0.276, 0.27, 0.268, 0.274]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000944656   train's RMSPE: 0.266426 valid's rmse: 0.00097543    valid's RMSPE: 0.269382\n[100]   train's rmse: 0.000899396   train's RMSPE: 0.253661 valid's rmse: 0.000957845   valid's RMSPE: 0.264525\n[150]   train's rmse: 0.000872786   train's RMSPE: 0.246156 valid's rmse: 0.000953427   valid's RMSPE: 0.263305\n[200]   train's rmse: 0.000852248   train's RMSPE: 0.240363 valid's rmse: 0.000946795   valid's RMSPE: 0.261474\n[250]   train's rmse: 0.000834292   train's RMSPE: 0.235299 valid's rmse: 0.000943103   valid's RMSPE: 0.260454\n[300]   train's rmse: 0.000819513   train's RMSPE: 0.231131 valid's rmse: 0.000939008   valid's RMSPE: 0.259323\n[350]   train's rmse: 0.000806426   train's RMSPE: 0.22744  valid's rmse: 0.000942704   valid's RMSPE: 0.260344\nEarly stopping, best iteration is:\n[305]   train's rmse: 0.000818266   train's RMSPE: 0.230779 valid's rmse: 0.000937696   valid's RMSPE: 0.258961\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000927945   train's RMSPE: 0.258831 valid's rmse: 0.00104221    valid's RMSPE: 0.300684\n[100]   train's rmse: 0.000883927   train's RMSPE: 0.246553 valid's rmse: 0.00101045    valid's RMSPE: 0.29152\n[150]   train's rmse: 0.00086138    train's RMSPE: 0.240264 valid's rmse: 0.00100192    valid's RMSPE: 0.28906\n[200]   train's rmse: 0.000842614   train's RMSPE: 0.23503  valid's rmse: 0.00100184    valid's RMSPE: 0.289036\nEarly stopping, best iteration is:\n[193]   train's rmse: 0.000845355   train's RMSPE: 0.235794 valid's rmse: 0.00100067    valid's RMSPE: 0.288698\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000942966   train's RMSPE: 0.265835 valid's rmse: 0.000955974   valid's RMSPE: 0.26448\n[100]   train's rmse: 0.000895375   train's RMSPE: 0.252418 valid's rmse: 0.000941904   valid's RMSPE: 0.260587\n[150]   train's rmse: 0.000869753   train's RMSPE: 0.245195 valid's rmse: 0.000938302   valid's RMSPE: 0.259591\nEarly stopping, best iteration is:\n[135]   train's rmse: 0.000876947   train's RMSPE: 0.247223 valid's rmse: 0.000937079   valid's RMSPE: 0.259252\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000955162   train's RMSPE: 0.268909 valid's rmse: 0.00093659    valid's RMSPE: 0.260568\n[100]   train's rmse: 0.000906527   train's RMSPE: 0.255217 valid's rmse: 0.00092687    valid's RMSPE: 0.257864\n[150]   train's rmse: 0.000878069   train's RMSPE: 0.247205 valid's rmse: 0.00091908    valid's RMSPE: 0.255696\n[200]   train's rmse: 0.000858229   train's RMSPE: 0.241619 valid's rmse: 0.000914347   valid's RMSPE: 0.254379\n[250]   train's rmse: 0.000840302   train's RMSPE: 0.236572 valid's rmse: 0.000910522   valid's RMSPE: 0.253315\n[300]   train's rmse: 0.000824868   train's RMSPE: 0.232227 valid's rmse: 0.000909547   valid's RMSPE: 0.253044\n[350]   train's rmse: 0.000810734   train's RMSPE: 0.228248 valid's rmse: 0.00090975    valid's RMSPE: 0.2531\n[400]   train's rmse: 0.00079829    train's RMSPE: 0.224744 valid's rmse: 0.000908251   valid's RMSPE: 0.252683\n[450]   train's rmse: 0.000786947   train's RMSPE: 0.221551 valid's rmse: 0.000908615   valid's RMSPE: 0.252785\nEarly stopping, best iteration is:\n[436]   train's rmse: 0.000790367   train's RMSPE: 0.222514 valid's rmse: 0.000907673   valid's RMSPE: 0.252523\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00095325    train's RMSPE: 0.266844 valid's rmse: 0.000951162   valid's RMSPE: 0.270701\n[100]   train's rmse: 0.00090717    train's RMSPE: 0.253945 valid's rmse: 0.000919809   valid's RMSPE: 0.261778\n[150]   train's rmse: 0.000882432   train's RMSPE: 0.24702  valid's rmse: 0.000911042   valid's RMSPE: 0.259283\n[200]   train's rmse: 0.000861238   train's RMSPE: 0.241087 valid's rmse: 0.000906354   valid's RMSPE: 0.257949\n[250]   train's rmse: 0.0008438 train's RMSPE: 0.236206 valid's rmse: 0.000906677   valid's RMSPE: 0.258041\nEarly stopping, best iteration is:\n[237]   train's rmse: 0.000848025   train's RMSPE: 0.237388 valid's rmse: 0.000905404   valid's RMSPE: 0.257678\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.264, compared to 0.23908992165115264, giving gain 0.02491007834884737\nOur cv fold scores are [0.259, 0.289, 0.259, 0.253, 0.258]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00108865    train's RMSPE: 0.212352 valid's rmse: 0.00115337    valid's RMSPE: 0.222546\n[100]   train's rmse: 0.00102362    train's RMSPE: 0.199666 valid's rmse: 0.00111319    valid's RMSPE: 0.214792\n[150]   train's rmse: 0.000990082   train's RMSPE: 0.193124 valid's rmse: 0.00110163    valid's RMSPE: 0.212562\n[200]   train's rmse: 0.000965683   train's RMSPE: 0.188365 valid's rmse: 0.00109864    valid's RMSPE: 0.211984\n[250]   train's rmse: 0.000946053   train's RMSPE: 0.184536 valid's rmse: 0.00109835    valid's RMSPE: 0.211929\nEarly stopping, best iteration is:\n[211]   train's rmse: 0.00096107    train's RMSPE: 0.187466 valid's rmse: 0.00109718    valid's RMSPE: 0.211704\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00110252    train's RMSPE: 0.213866 valid's rmse: 0.00110269    valid's RMSPE: 0.217515\n[100]   train's rmse: 0.0010343 train's RMSPE: 0.200634 valid's rmse: 0.00108394    valid's RMSPE: 0.213816\nEarly stopping, best iteration is:\n[94]    train's rmse: 0.00103997    train's RMSPE: 0.201733 valid's rmse: 0.00107817    valid's RMSPE: 0.212678\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.00109839    train's RMSPE: 0.212804 valid's rmse: 0.00110527    valid's RMSPE: 0.219052\n[100]   train's rmse: 0.00103216    train's RMSPE: 0.199973 valid's rmse: 0.00107956    valid's RMSPE: 0.213956\n[150]   train's rmse: 0.000997546   train's RMSPE: 0.193267 valid's rmse: 0.00107626    valid's RMSPE: 0.213301\n[200]   train's rmse: 0.00096799    train's RMSPE: 0.187541 valid's rmse: 0.00107638    valid's RMSPE: 0.213326\nEarly stopping, best iteration is:\n[184]   train's rmse: 0.000976383   train's RMSPE: 0.189167 valid's rmse: 0.00107376    valid's RMSPE: 0.212806\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00109017    train's RMSPE: 0.21377  valid's rmse: 0.00112714    valid's RMSPE: 0.212723\n[100]   train's rmse: 0.00102221    train's RMSPE: 0.200445 valid's rmse: 0.00110785    valid's RMSPE: 0.209082\n[150]   train's rmse: 0.000989757   train's RMSPE: 0.194081 valid's rmse: 0.00110981    valid's RMSPE: 0.209453\nEarly stopping, best iteration is:\n[115]   train's rmse: 0.00101086    train's RMSPE: 0.19822  valid's rmse: 0.00110717    valid's RMSPE: 0.208954\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00108622    train's RMSPE: 0.211072 valid's rmse: 0.00119314    valid's RMSPE: 0.233762\n[100]   train's rmse: 0.00102504    train's RMSPE: 0.199185 valid's rmse: 0.00113577    valid's RMSPE: 0.22252\nEarly stopping, best iteration is:\n[89]    train's rmse: 0.00103343    train's RMSPE: 0.200815 valid's rmse: 0.00113289    valid's RMSPE: 0.221956\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.214, compared to 0.20317871450499694, giving gain 0.010821285495003052\nOur cv fold scores are [0.212, 0.213, 0.213, 0.209, 0.222]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000573645   train's RMSPE: 0.254149 valid's rmse: 0.000620383   valid's RMSPE: 0.270708\n[100]   train's rmse: 0.000547103   train's RMSPE: 0.242389 valid's rmse: 0.000605305   valid's RMSPE: 0.264128\n[150]   train's rmse: 0.000533209   train's RMSPE: 0.236234 valid's rmse: 0.000602481   valid's RMSPE: 0.262896\n[200]   train's rmse: 0.000522978   train's RMSPE: 0.231701 valid's rmse: 0.000601763   valid's RMSPE: 0.262583\n[250]   train's rmse: 0.000512558   train's RMSPE: 0.227084 valid's rmse: 0.00059995    valid's RMSPE: 0.261792\n[300]   train's rmse: 0.000503239   train's RMSPE: 0.222956 valid's rmse: 0.000600425   valid's RMSPE: 0.261999\nEarly stopping, best iteration is:\n[256]   train's rmse: 0.000511293   train's RMSPE: 0.226524 valid's rmse: 0.000599902   valid's RMSPE: 0.261771\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000575339   train's RMSPE: 0.253678 valid's rmse: 0.0005984 valid's RMSPE: 0.26621\n[100]   train's rmse: 0.000548005   train's RMSPE: 0.241626 valid's rmse: 0.000590675   valid's RMSPE: 0.262773\n[150]   train's rmse: 0.000534878   train's RMSPE: 0.235838 valid's rmse: 0.000589252   valid's RMSPE: 0.26214\n[200]   train's rmse: 0.000523637   train's RMSPE: 0.230882 valid's rmse: 0.000589124   valid's RMSPE: 0.262083\nEarly stopping, best iteration is:\n[179]   train's rmse: 0.000527766   train's RMSPE: 0.232703 valid's rmse: 0.000588614   valid's RMSPE: 0.261856\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000577926   train's RMSPE: 0.255238 valid's rmse: 0.000591157   valid's RMSPE: 0.261282\n[100]   train's rmse: 0.000551468   train's RMSPE: 0.243553 valid's rmse: 0.000580355   valid's RMSPE: 0.256507\n[150]   train's rmse: 0.000537292   train's RMSPE: 0.237292 valid's rmse: 0.000579173   valid's RMSPE: 0.255985\nEarly stopping, best iteration is:\n[148]   train's rmse: 0.000537834   train's RMSPE: 0.237531 valid's rmse: 0.000578989   valid's RMSPE: 0.255903\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000586955   train's RMSPE: 0.257438 valid's rmse: 0.000579631   valid's RMSPE: 0.263125\n[100]   train's rmse: 0.00055955    train's RMSPE: 0.245418 valid's rmse: 0.000569319   valid's RMSPE: 0.258444\nEarly stopping, best iteration is:\n[89]    train's rmse: 0.000563266   train's RMSPE: 0.247048 valid's rmse: 0.000565388   valid's RMSPE: 0.256659\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000576876   train's RMSPE: 0.256327 valid's rmse: 0.00059276    valid's RMSPE: 0.255515\n[100]   train's rmse: 0.000550507   train's RMSPE: 0.24461  valid's rmse: 0.000577949   valid's RMSPE: 0.24913\n[150]   train's rmse: 0.00053607    train's RMSPE: 0.238195 valid's rmse: 0.000577356   valid's RMSPE: 0.248875\n[200]   train's rmse: 0.000525622   train's RMSPE: 0.233553 valid's rmse: 0.000576717   valid's RMSPE: 0.248599\nEarly stopping, best iteration is:\n[176]   train's rmse: 0.00053042    train's RMSPE: 0.235685 valid's rmse: 0.000575464   valid's RMSPE: 0.248059\nOur out of folds RMSPE is 0.257, compared to 0.2273039636391359, giving gain 0.029696036360864098\nOur cv fold scores are [0.262, 0.262, 0.256, 0.257, 0.248]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000683591   train's RMSPE: 0.238078 valid's rmse: 0.000716843   valid's RMSPE: 0.248204\n[100]   train's rmse: 0.000647358   train's RMSPE: 0.225459 valid's rmse: 0.000690402   valid's RMSPE: 0.239049\n[150]   train's rmse: 0.000630882   train's RMSPE: 0.21972  valid's rmse: 0.000687774   valid's RMSPE: 0.238139\n[200]   train's rmse: 0.000616818   train's RMSPE: 0.214822 valid's rmse: 0.00068629    valid's RMSPE: 0.237625\nEarly stopping, best iteration is:\n[197]   train's rmse: 0.000617311   train's RMSPE: 0.214994 valid's rmse: 0.000685929   valid's RMSPE: 0.2375\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000686234   train's RMSPE: 0.239009 valid's rmse: 0.000708663   valid's RMSPE: 0.245325\n[100]   train's rmse: 0.000650577   train's RMSPE: 0.22659  valid's rmse: 0.00068683    valid's RMSPE: 0.237767\n[150]   train's rmse: 0.000633236   train's RMSPE: 0.22055  valid's rmse: 0.000682944   valid's RMSPE: 0.236421\n[200]   train's rmse: 0.000620042   train's RMSPE: 0.215955 valid's rmse: 0.000678422   valid's RMSPE: 0.234856\n[250]   train's rmse: 0.000608512   train's RMSPE: 0.211939 valid's rmse: 0.000677182   valid's RMSPE: 0.234427\n[300]   train's rmse: 0.000597369   train's RMSPE: 0.208058 valid's rmse: 0.000674325   valid's RMSPE: 0.233438\nEarly stopping, best iteration is:\n[276]   train's rmse: 0.000602036   train's RMSPE: 0.209684 valid's rmse: 0.000673706   valid's RMSPE: 0.233224\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000682659   train's RMSPE: 0.236975 valid's rmse: 0.000722046   valid's RMSPE: 0.25329\n[100]   train's rmse: 0.000645468   train's RMSPE: 0.224064 valid's rmse: 0.000702473   valid's RMSPE: 0.246424\n[150]   train's rmse: 0.000629283   train's RMSPE: 0.218446 valid's rmse: 0.000698327   valid's RMSPE: 0.244969\n[200]   train's rmse: 0.000614941   train's RMSPE: 0.213467 valid's rmse: 0.000695825   valid's RMSPE: 0.244092\n[250]   train's rmse: 0.000602504   train's RMSPE: 0.20915  valid's rmse: 0.000694437   valid's RMSPE: 0.243604\n[300]   train's rmse: 0.000592626   train's RMSPE: 0.205721 valid's rmse: 0.000693096   valid's RMSPE: 0.243134\n[350]   train's rmse: 0.000582644   train's RMSPE: 0.202256 valid's rmse: 0.000691468   valid's RMSPE: 0.242563\n[400]   train's rmse: 0.000575027   train's RMSPE: 0.199612 valid's rmse: 0.000689889   valid's RMSPE: 0.242009\n[450]   train's rmse: 0.000567723   train's RMSPE: 0.197076 valid's rmse: 0.000690564   valid's RMSPE: 0.242246\n[500]   train's rmse: 0.000560671   train's RMSPE: 0.194629 valid's rmse: 0.000688332   valid's RMSPE: 0.241463\nEarly stopping, best iteration is:\n[499]   train's rmse: 0.000560799   train's RMSPE: 0.194673 valid's rmse: 0.000688069   valid's RMSPE: 0.241371\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000692809   train's RMSPE: 0.240536 valid's rmse: 0.00068023    valid's RMSPE: 0.238474\n[100]   train's rmse: 0.000654228   train's RMSPE: 0.227141 valid's rmse: 0.000662673   valid's RMSPE: 0.232319\n[150]   train's rmse: 0.000635342   train's RMSPE: 0.220584 valid's rmse: 0.000658331   valid's RMSPE: 0.230797\n[200]   train's rmse: 0.000621143   train's RMSPE: 0.215654 valid's rmse: 0.0006549 valid's RMSPE: 0.229594\n[250]   train's rmse: 0.000609981   train's RMSPE: 0.211779 valid's rmse: 0.000654351   valid's RMSPE: 0.229401\n[300]   train's rmse: 0.000598974   train's RMSPE: 0.207957 valid's rmse: 0.000652797   valid's RMSPE: 0.228857\n[350]   train's rmse: 0.000589405   train's RMSPE: 0.204635 valid's rmse: 0.0006517 valid's RMSPE: 0.228472\n[400]   train's rmse: 0.000581362   train's RMSPE: 0.201843 valid's rmse: 0.000650069   valid's RMSPE: 0.2279\nEarly stopping, best iteration is:\n[388]   train's rmse: 0.000583179   train's RMSPE: 0.202474 valid's rmse: 0.00064992    valid's RMSPE: 0.227848\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000688292   train's RMSPE: 0.23984  valid's rmse: 0.000687628   valid's RMSPE: 0.237584\n[100]   train's rmse: 0.000650501   train's RMSPE: 0.226672 valid's rmse: 0.000665065   valid's RMSPE: 0.229788\n[150]   train's rmse: 0.000632791   train's RMSPE: 0.2205   valid's rmse: 0.000659404   valid's RMSPE: 0.227832\n[200]   train's rmse: 0.000620417   train's RMSPE: 0.216188 valid's rmse: 0.000655457   valid's RMSPE: 0.226468\n[250]   train's rmse: 0.000609194   train's RMSPE: 0.212278 valid's rmse: 0.000653756   valid's RMSPE: 0.225881\n[300]   train's rmse: 0.000599015   train's RMSPE: 0.208731 valid's rmse: 0.000651064   valid's RMSPE: 0.224951\n[350]   train's rmse: 0.000590011   train's RMSPE: 0.205593 valid's rmse: 0.000651666   valid's RMSPE: 0.225159\nEarly stopping, best iteration is:\n[307]   train's rmse: 0.000597671   train's RMSPE: 0.208263 valid's rmse: 0.000650092   valid's RMSPE: 0.224615\nOur out of folds RMSPE is 0.233, compared to 0.21572974617592797, giving gain 0.017270253824072046\nOur cv fold scores are [0.237, 0.233, 0.241, 0.228, 0.225]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000996248   train's RMSPE: 0.256754 valid's rmse: 0.00104637    valid's RMSPE: 0.274374\n[100]   train's rmse: 0.000948884   train's RMSPE: 0.244547 valid's rmse: 0.00102038    valid's RMSPE: 0.267559\n[150]   train's rmse: 0.000922486   train's RMSPE: 0.237744 valid's rmse: 0.00101386    valid's RMSPE: 0.265849\n[200]   train's rmse: 0.000900638   train's RMSPE: 0.232113 valid's rmse: 0.00101384    valid's RMSPE: 0.265843\n[250]   train's rmse: 0.000883149   train's RMSPE: 0.227606 valid's rmse: 0.00101541    valid's RMSPE: 0.266255\nEarly stopping, best iteration is:\n[212]   train's rmse: 0.000896171   train's RMSPE: 0.230962 valid's rmse: 0.0010127 valid's RMSPE: 0.265545\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000971785   train's RMSPE: 0.251525 valid's rmse: 0.00114474    valid's RMSPE: 0.295129\n[100]   train's rmse: 0.000928191   train's RMSPE: 0.240242 valid's rmse: 0.00113156    valid's RMSPE: 0.291731\n[150]   train's rmse: 0.000902794   train's RMSPE: 0.233669 valid's rmse: 0.00112029    valid's RMSPE: 0.288824\n[200]   train's rmse: 0.000883852   train's RMSPE: 0.228766 valid's rmse: 0.00111993    valid's RMSPE: 0.288731\nEarly stopping, best iteration is:\n[178]   train's rmse: 0.000892396   train's RMSPE: 0.230977 valid's rmse: 0.00111871    valid's RMSPE: 0.288418\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.0010086 train's RMSPE: 0.260273 valid's rmse: 0.000986853   valid's RMSPE: 0.257465\n[100]   train's rmse: 0.000961924   train's RMSPE: 0.248229 valid's rmse: 0.000966244   valid's RMSPE: 0.252089\n[150]   train's rmse: 0.000935374   train's RMSPE: 0.241378 valid's rmse: 0.000961685   valid's RMSPE: 0.250899\n[200]   train's rmse: 0.000911655   train's RMSPE: 0.235257 valid's rmse: 0.000953509   valid's RMSPE: 0.248766\n[250]   train's rmse: 0.00089265    train's RMSPE: 0.230353 valid's rmse: 0.000952645   valid's RMSPE: 0.248541\nEarly stopping, best iteration is:\n[243]   train's rmse: 0.000895242   train's RMSPE: 0.231022 valid's rmse: 0.000951661   valid's RMSPE: 0.248284\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.0010081 train's RMSPE: 0.261386 valid's rmse: 0.000967497   valid's RMSPE: 0.247646\n[100]   train's rmse: 0.000961959   train's RMSPE: 0.249423 valid's rmse: 0.000945814   valid's RMSPE: 0.242096\nEarly stopping, best iteration is:\n[89]    train's rmse: 0.000968588   train's RMSPE: 0.251142 valid's rmse: 0.000944815   valid's RMSPE: 0.24184\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00100379    train's RMSPE: 0.260216 valid's rmse: 0.00101585    valid's RMSPE: 0.260238\n[100]   train's rmse: 0.00095478    train's RMSPE: 0.247511 valid's rmse: 0.000998499   valid's RMSPE: 0.255794\n[150]   train's rmse: 0.000926798   train's RMSPE: 0.240257 valid's rmse: 0.00099781    valid's RMSPE: 0.255618\nEarly stopping, best iteration is:\n[134]   train's rmse: 0.000933631   train's RMSPE: 0.242029 valid's rmse: 0.00099449    valid's RMSPE: 0.254767\nOur out of folds RMSPE is 0.26, compared to 0.24636791823616067, giving gain 0.013632081763839343\nOur cv fold scores are [0.266, 0.288, 0.248, 0.242, 0.255]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000502889   train's RMSPE: 0.216962 valid's rmse: 0.000535229   valid's RMSPE: 0.233057\n[100]   train's rmse: 0.00047541    train's RMSPE: 0.205107 valid's rmse: 0.0005074 valid's RMSPE: 0.220939\n[150]   train's rmse: 0.000465857   train's RMSPE: 0.200985 valid's rmse: 0.000504205   valid's RMSPE: 0.219548\n[200]   train's rmse: 0.000457891   train's RMSPE: 0.197548 valid's rmse: 0.000501479   valid's RMSPE: 0.21836\nEarly stopping, best iteration is:\n[194]   train's rmse: 0.000458492   train's RMSPE: 0.197807 valid's rmse: 0.000501248   valid's RMSPE: 0.21826\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000499855   train's RMSPE: 0.216876 valid's rmse: 0.000537696   valid's RMSPE: 0.228844\n[100]   train's rmse: 0.000472025   train's RMSPE: 0.204801 valid's rmse: 0.000520909   valid's RMSPE: 0.221699\n[150]   train's rmse: 0.000462356   train's RMSPE: 0.200606 valid's rmse: 0.000518513   valid's RMSPE: 0.220679\n[200]   train's rmse: 0.000454856   train's RMSPE: 0.197351 valid's rmse: 0.000516055   valid's RMSPE: 0.219633\n[250]   train's rmse: 0.000447781   train's RMSPE: 0.194282 valid's rmse: 0.000514675   valid's RMSPE: 0.219046\n[300]   train's rmse: 0.000441385   train's RMSPE: 0.191507 valid's rmse: 0.000513542   valid's RMSPE: 0.218563\n[350]   train's rmse: 0.000436165   train's RMSPE: 0.189242 valid's rmse: 0.000512305   valid's RMSPE: 0.218037\n[400]   train's rmse: 0.000431183   train's RMSPE: 0.18708  valid's rmse: 0.000512007   valid's RMSPE: 0.21791\n[450]   train's rmse: 0.000426894   train's RMSPE: 0.185219 valid's rmse: 0.000511126   valid's RMSPE: 0.217535\n[500]   train's rmse: 0.000423103   train's RMSPE: 0.183575 valid's rmse: 0.000509688   valid's RMSPE: 0.216923\nEarly stopping, best iteration is:\n[499]   train's rmse: 0.000423155   train's RMSPE: 0.183597 valid's rmse: 0.000509656   valid's RMSPE: 0.216909\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000510056   train's RMSPE: 0.219812 valid's rmse: 0.000478071   valid's RMSPE: 0.209066\n[100]   train's rmse: 0.000483929   train's RMSPE: 0.208552 valid's rmse: 0.000453579   valid's RMSPE: 0.198355\n[150]   train's rmse: 0.000474046   train's RMSPE: 0.204293 valid's rmse: 0.000450015   valid's RMSPE: 0.196796\n[200]   train's rmse: 0.000465815   train's RMSPE: 0.200746 valid's rmse: 0.000448373   valid's RMSPE: 0.196078\n[250]   train's rmse: 0.000459622   train's RMSPE: 0.198077 valid's rmse: 0.000447051   valid's RMSPE: 0.1955\n[300]   train's rmse: 0.000453199   train's RMSPE: 0.195308 valid's rmse: 0.000444225   valid's RMSPE: 0.194264\nEarly stopping, best iteration is:\n[299]   train's rmse: 0.000453294   train's RMSPE: 0.19535  valid's rmse: 0.00044418    valid's RMSPE: 0.194245\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000502998   train's RMSPE: 0.217518 valid's rmse: 0.000518909   valid's RMSPE: 0.223856\n[100]   train's rmse: 0.000475193   train's RMSPE: 0.205494 valid's rmse: 0.000503684   valid's RMSPE: 0.217288\n[150]   train's rmse: 0.000465766   train's RMSPE: 0.201417 valid's rmse: 0.00050207    valid's RMSPE: 0.216592\n[200]   train's rmse: 0.00045832    train's RMSPE: 0.198197 valid's rmse: 0.000501178   valid's RMSPE: 0.216207\n[250]   train's rmse: 0.000451999   train's RMSPE: 0.195464 valid's rmse: 0.000500343   valid's RMSPE: 0.215847\n[300]   train's rmse: 0.000446455   train's RMSPE: 0.193066 valid's rmse: 0.000499361   valid's RMSPE: 0.215423\nEarly stopping, best iteration is:\n[299]   train's rmse: 0.000446518   train's RMSPE: 0.193094 valid's rmse: 0.000499305   valid's RMSPE: 0.215399\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000504604   train's RMSPE: 0.21822  valid's rmse: 0.000506495   valid's RMSPE: 0.218469\n[100]   train's rmse: 0.000478129   train's RMSPE: 0.206771 valid's rmse: 0.000490917   valid's RMSPE: 0.21175\n[150]   train's rmse: 0.000468267   train's RMSPE: 0.202506 valid's rmse: 0.000488406   valid's RMSPE: 0.210666\n[200]   train's rmse: 0.000460701   train's RMSPE: 0.199234 valid's rmse: 0.000487159   valid's RMSPE: 0.210129\n[250]   train's rmse: 0.000453743   train's RMSPE: 0.196225 valid's rmse: 0.000486436   valid's RMSPE: 0.209817\n[300]   train's rmse: 0.000447505   train's RMSPE: 0.193527 valid's rmse: 0.000485776   valid's RMSPE: 0.209532\nEarly stopping, best iteration is:\n[285]   train's rmse: 0.000449415   train's RMSPE: 0.194353 valid's rmse: 0.000485267   valid's RMSPE: 0.209312\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.211, compared to 0.1731892288214724, giving gain 0.0378107711785276\nOur cv fold scores are [0.218, 0.217, 0.194, 0.215, 0.209]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000736734   train's RMSPE: 0.249597 valid's rmse: 0.000776814   valid's RMSPE: 0.265348\n[100]   train's rmse: 0.00070234    train's RMSPE: 0.237945 valid's rmse: 0.000752108   valid's RMSPE: 0.256909\n[150]   train's rmse: 0.000685514   train's RMSPE: 0.232244 valid's rmse: 0.000750291   valid's RMSPE: 0.256288\n[200]   train's rmse: 0.000672003   train's RMSPE: 0.227667 valid's rmse: 0.000748589   valid's RMSPE: 0.255707\n[250]   train's rmse: 0.000659487   train's RMSPE: 0.223427 valid's rmse: 0.000750149   valid's RMSPE: 0.25624\nEarly stopping, best iteration is:\n[209]   train's rmse: 0.000669683   train's RMSPE: 0.226881 valid's rmse: 0.00074801    valid's RMSPE: 0.255509\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000734301   train's RMSPE: 0.248285 valid's rmse: 0.000788026   valid's RMSPE: 0.271245\n[100]   train's rmse: 0.000700522   train's RMSPE: 0.236864 valid's rmse: 0.000771452   valid's RMSPE: 0.26554\n[150]   train's rmse: 0.000683773   train's RMSPE: 0.231201 valid's rmse: 0.000773926   valid's RMSPE: 0.266391\nEarly stopping, best iteration is:\n[112]   train's rmse: 0.000696452   train's RMSPE: 0.235488 valid's rmse: 0.000771045   valid's RMSPE: 0.2654\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000742552   train's RMSPE: 0.252735 valid's rmse: 0.00074144    valid's RMSPE: 0.248589\n[100]   train's rmse: 0.000709467   train's RMSPE: 0.241474 valid's rmse: 0.000725967   valid's RMSPE: 0.243402\n[150]   train's rmse: 0.000692258   train's RMSPE: 0.235617 valid's rmse: 0.000721985   valid's RMSPE: 0.242067\n[200]   train's rmse: 0.000678488   train's RMSPE: 0.23093  valid's rmse: 0.000719907   valid's RMSPE: 0.24137\n[250]   train's rmse: 0.00066776    train's RMSPE: 0.227279 valid's rmse: 0.000719298   valid's RMSPE: 0.241166\n[300]   train's rmse: 0.000657032   train's RMSPE: 0.223628 valid's rmse: 0.000718317   valid's RMSPE: 0.240837\n[350]   train's rmse: 0.000648486   train's RMSPE: 0.220719 valid's rmse: 0.00071866    valid's RMSPE: 0.240952\nEarly stopping, best iteration is:\n[320]   train's rmse: 0.000653656   train's RMSPE: 0.222478 valid's rmse: 0.000718023   valid's RMSPE: 0.240738\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000746463   train's RMSPE: 0.253615 valid's rmse: 0.000746741   valid's RMSPE: 0.252193\n[100]   train's rmse: 0.000710827   train's RMSPE: 0.241507 valid's rmse: 0.000734354   valid's RMSPE: 0.24801\n[150]   train's rmse: 0.000693849   train's RMSPE: 0.235739 valid's rmse: 0.000732339   valid's RMSPE: 0.247329\nEarly stopping, best iteration is:\n[119]   train's rmse: 0.000703754   train's RMSPE: 0.239104 valid's rmse: 0.000731626   valid's RMSPE: 0.247088\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000747071   train's RMSPE: 0.253792 valid's rmse: 0.000752757   valid's RMSPE: 0.254341\n[100]   train's rmse: 0.000713948   train's RMSPE: 0.24254  valid's rmse: 0.000733785   valid's RMSPE: 0.247931\n[150]   train's rmse: 0.000697031   train's RMSPE: 0.236793 valid's rmse: 0.000728828   valid's RMSPE: 0.246256\n[200]   train's rmse: 0.000683624   train's RMSPE: 0.232238 valid's rmse: 0.000728172   valid's RMSPE: 0.246034\n[250]   train's rmse: 0.000672446   train's RMSPE: 0.228441 valid's rmse: 0.000727523   valid's RMSPE: 0.245815\n[300]   train's rmse: 0.000662311   train's RMSPE: 0.224998 valid's rmse: 0.000726069   valid's RMSPE: 0.245324\n[350]   train's rmse: 0.000653165   train's RMSPE: 0.221891 valid's rmse: 0.000725237   valid's RMSPE: 0.245042\n[400]   train's rmse: 0.000644602   train's RMSPE: 0.218982 valid's rmse: 0.000724066   valid's RMSPE: 0.244647\nEarly stopping, best iteration is:\n[388]   train's rmse: 0.000646679   train's RMSPE: 0.219688 valid's rmse: 0.000722934   valid's RMSPE: 0.244264\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.251, compared to 0.22177076465868406, giving gain 0.02922923534131594\nOur cv fold scores are [0.256, 0.265, 0.241, 0.247, 0.244]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000381483   train's RMSPE: 0.238166 valid's rmse: 0.000426127   valid's RMSPE: 0.268764\n[100]   train's rmse: 0.000360635   train's RMSPE: 0.22515  valid's rmse: 0.000409895   valid's RMSPE: 0.258526\n[150]   train's rmse: 0.000351648   train's RMSPE: 0.219539 valid's rmse: 0.000405578   valid's RMSPE: 0.255803\n[200]   train's rmse: 0.000344365   train's RMSPE: 0.214992 valid's rmse: 0.000405641   valid's RMSPE: 0.255843\n[250]   train's rmse: 0.000338058   train's RMSPE: 0.211055 valid's rmse: 0.000405558   valid's RMSPE: 0.255791\nEarly stopping, best iteration is:\n[219]   train's rmse: 0.000341802   train's RMSPE: 0.213392 valid's rmse: 0.000404283   valid's RMSPE: 0.254986\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000386419   train's RMSPE: 0.241393 valid's rmse: 0.000397816   valid's RMSPE: 0.250316\n[100]   train's rmse: 0.000363913   train's RMSPE: 0.227334 valid's rmse: 0.000385238   valid's RMSPE: 0.242401\n[150]   train's rmse: 0.000354043   train's RMSPE: 0.221168 valid's rmse: 0.00038238    valid's RMSPE: 0.240603\n[200]   train's rmse: 0.000346513   train's RMSPE: 0.216464 valid's rmse: 0.000380247   valid's RMSPE: 0.239261\n[250]   train's rmse: 0.000340254   train's RMSPE: 0.212554 valid's rmse: 0.000379501   valid's RMSPE: 0.238791\n[300]   train's rmse: 0.000334169   train's RMSPE: 0.208753 valid's rmse: 0.000377718   valid's RMSPE: 0.23767\n[350]   train's rmse: 0.000329556   train's RMSPE: 0.205871 valid's rmse: 0.00037714    valid's RMSPE: 0.237306\n[400]   train's rmse: 0.000325274   train's RMSPE: 0.203196 valid's rmse: 0.000377477   valid's RMSPE: 0.237518\n[450]   train's rmse: 0.000320997   train's RMSPE: 0.200524 valid's rmse: 0.000376427   valid's RMSPE: 0.236857\n[500]   train's rmse: 0.000317178   train's RMSPE: 0.198139 valid's rmse: 0.000376007   valid's RMSPE: 0.236593\n[550]   train's rmse: 0.00031384    train's RMSPE: 0.196053 valid's rmse: 0.000375351   valid's RMSPE: 0.23618\n[600]   train's rmse: 0.000310546   train's RMSPE: 0.193996 valid's rmse: 0.000374953   valid's RMSPE: 0.23593\nEarly stopping, best iteration is:\n[564]   train's rmse: 0.00031286    train's RMSPE: 0.195441 valid's rmse: 0.000374756   valid's RMSPE: 0.235806\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00038804    train's RMSPE: 0.242562 valid's rmse: 0.000385378   valid's RMSPE: 0.24187\n[100]   train's rmse: 0.000367607   train's RMSPE: 0.229789 valid's rmse: 0.000371898   valid's RMSPE: 0.23341\n[150]   train's rmse: 0.000357901   train's RMSPE: 0.223722 valid's rmse: 0.000369786   valid's RMSPE: 0.232084\n[200]   train's rmse: 0.000349973   train's RMSPE: 0.218766 valid's rmse: 0.000368117   valid's RMSPE: 0.231037\n[250]   train's rmse: 0.000343611   train's RMSPE: 0.214789 valid's rmse: 0.00036674    valid's RMSPE: 0.230172\n[300]   train's rmse: 0.000338379   train's RMSPE: 0.211519 valid's rmse: 0.000366292   valid's RMSPE: 0.229891\n[350]   train's rmse: 0.00033375    train's RMSPE: 0.208625 valid's rmse: 0.000365041   valid's RMSPE: 0.229106\n[400]   train's rmse: 0.000329134   train's RMSPE: 0.20574  valid's rmse: 0.000363405   valid's RMSPE: 0.228079\n[450]   train's rmse: 0.000325105   train's RMSPE: 0.203222 valid's rmse: 0.000362715   valid's RMSPE: 0.227646\n[500]   train's rmse: 0.000321571   train's RMSPE: 0.201012 valid's rmse: 0.000362525   valid's RMSPE: 0.227527\n[550]   train's rmse: 0.000317821   train's RMSPE: 0.198668 valid's rmse: 0.00036232    valid's RMSPE: 0.227398\nEarly stopping, best iteration is:\n[521]   train's rmse: 0.000319792   train's RMSPE: 0.1999   valid's rmse: 0.00036192    valid's RMSPE: 0.227148\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000391112   train's RMSPE: 0.245045 valid's rmse: 0.000369371   valid's RMSPE: 0.229695\n[100]   train's rmse: 0.000370136   train's RMSPE: 0.231902 valid's rmse: 0.000358857   valid's RMSPE: 0.223157\n[150]   train's rmse: 0.000360863   train's RMSPE: 0.226093 valid's rmse: 0.000354215   valid's RMSPE: 0.22027\n[200]   train's rmse: 0.000353379   train's RMSPE: 0.221404 valid's rmse: 0.000351162   valid's RMSPE: 0.218372\n[250]   train's rmse: 0.000347449   train's RMSPE: 0.217689 valid's rmse: 0.000348718   valid's RMSPE: 0.216851\n[300]   train's rmse: 0.00034225    train's RMSPE: 0.214431 valid's rmse: 0.00034885    valid's RMSPE: 0.216933\nEarly stopping, best iteration is:\n[265]   train's rmse: 0.000345665   train's RMSPE: 0.216571 valid's rmse: 0.000348148   valid's RMSPE: 0.216497\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000386732   train's RMSPE: 0.24262  valid's rmse: 0.000398143   valid's RMSPE: 0.246256\n[100]   train's rmse: 0.00036442    train's RMSPE: 0.228623 valid's rmse: 0.000387388   valid's RMSPE: 0.239604\n[150]   train's rmse: 0.0003553 train's RMSPE: 0.222901 valid's rmse: 0.000385318   valid's RMSPE: 0.238323\n[200]   train's rmse: 0.000348516   train's RMSPE: 0.218645 valid's rmse: 0.000384357   valid's RMSPE: 0.237729\n[250]   train's rmse: 0.000342379   train's RMSPE: 0.214795 valid's rmse: 0.000383352   valid's RMSPE: 0.237108\n[300]   train's rmse: 0.000337021   train's RMSPE: 0.211434 valid's rmse: 0.000382638   valid's RMSPE: 0.236666\n[350]   train's rmse: 0.000332485   train's RMSPE: 0.208588 valid's rmse: 0.000381909   valid's RMSPE: 0.236215\n[400]   train's rmse: 0.000328051   train's RMSPE: 0.205807 valid's rmse: 0.000381067   valid's RMSPE: 0.235694\nEarly stopping, best iteration is:\n[386]   train's rmse: 0.000329215   train's RMSPE: 0.206537 valid's rmse: 0.00038052    valid's RMSPE: 0.235356\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.234, compared to 0.1930378405336289, giving gain 0.040962159466371106\nOur cv fold scores are [0.255, 0.236, 0.227, 0.216, 0.235]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000384782   train's RMSPE: 0.216141 valid's rmse: 0.00041617    valid's RMSPE: 0.233972\n[100]   train's rmse: 0.000360969   train's RMSPE: 0.202765 valid's rmse: 0.000395374   valid's RMSPE: 0.222281\n[150]   train's rmse: 0.000352712   train's RMSPE: 0.198126 valid's rmse: 0.000390744   valid's RMSPE: 0.219678\n[200]   train's rmse: 0.000344949   train's RMSPE: 0.193766 valid's rmse: 0.00038726    valid's RMSPE: 0.217719\n[250]   train's rmse: 0.000339541   train's RMSPE: 0.190728 valid's rmse: 0.000385985   valid's RMSPE: 0.217003\n[300]   train's rmse: 0.000335158   train's RMSPE: 0.188266 valid's rmse: 0.000384433   valid's RMSPE: 0.21613\n[350]   train's rmse: 0.000330883   train's RMSPE: 0.185865 valid's rmse: 0.000383497   valid's RMSPE: 0.215604\n[400]   train's rmse: 0.000326963   train's RMSPE: 0.183663 valid's rmse: 0.000382281   valid's RMSPE: 0.21492\n[450]   train's rmse: 0.000322706   train's RMSPE: 0.181272 valid's rmse: 0.000382544   valid's RMSPE: 0.215068\nEarly stopping, best iteration is:\n[403]   train's rmse: 0.000326348   train's RMSPE: 0.183317 valid's rmse: 0.000381603   valid's RMSPE: 0.214539\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000380577   train's RMSPE: 0.21289  valid's rmse: 0.000418214   valid's RMSPE: 0.238986\n[100]   train's rmse: 0.00035824    train's RMSPE: 0.200395 valid's rmse: 0.00039854    valid's RMSPE: 0.227744\n[150]   train's rmse: 0.00034969    train's RMSPE: 0.195612 valid's rmse: 0.000393661   valid's RMSPE: 0.224956\n[200]   train's rmse: 0.000343398   train's RMSPE: 0.192093 valid's rmse: 0.000389981   valid's RMSPE: 0.222853\n[250]   train's rmse: 0.000338058   train's RMSPE: 0.189105 valid's rmse: 0.000387312   valid's RMSPE: 0.221327\n[300]   train's rmse: 0.00033245    train's RMSPE: 0.185969 valid's rmse: 0.000384984   valid's RMSPE: 0.219997\n[350]   train's rmse: 0.000328569   train's RMSPE: 0.183798 valid's rmse: 0.000383814   valid's RMSPE: 0.219328\n[400]   train's rmse: 0.000324602   train's RMSPE: 0.181578 valid's rmse: 0.00038238    valid's RMSPE: 0.218509\n[450]   train's rmse: 0.000321023   train's RMSPE: 0.179576 valid's rmse: 0.000381534   valid's RMSPE: 0.218026\n[500]   train's rmse: 0.000318089   train's RMSPE: 0.177935 valid's rmse: 0.000381131   valid's RMSPE: 0.217795\n[550]   train's rmse: 0.000315386   train's RMSPE: 0.176423 valid's rmse: 0.000380522   valid's RMSPE: 0.217447\n[600]   train's rmse: 0.00031261    train's RMSPE: 0.17487  valid's rmse: 0.000380056   valid's RMSPE: 0.217181\n[650]   train's rmse: 0.000309752   train's RMSPE: 0.173272 valid's rmse: 0.0003795 valid's RMSPE: 0.216863\n[700]   train's rmse: 0.000307186   train's RMSPE: 0.171836 valid's rmse: 0.000379806   valid's RMSPE: 0.217038\n[750]   train's rmse: 0.000304376   train's RMSPE: 0.170264 valid's rmse: 0.000378732   valid's RMSPE: 0.216424\nEarly stopping, best iteration is:\n[744]   train's rmse: 0.000304642   train's RMSPE: 0.170413 valid's rmse: 0.00037858    valid's RMSPE: 0.216338\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000389079   train's RMSPE: 0.218222 valid's rmse: 0.000365458   valid's RMSPE: 0.206706\n[100]   train's rmse: 0.000365529   train's RMSPE: 0.205014 valid's rmse: 0.000350951   valid's RMSPE: 0.198501\n[150]   train's rmse: 0.000356609   train's RMSPE: 0.200011 valid's rmse: 0.000348343   valid's RMSPE: 0.197026\n[200]   train's rmse: 0.000349578   train's RMSPE: 0.196068 valid's rmse: 0.000346755   valid's RMSPE: 0.196127\n[250]   train's rmse: 0.000344077   train's RMSPE: 0.192982 valid's rmse: 0.000345076   valid's RMSPE: 0.195177\n[300]   train's rmse: 0.00033944    train's RMSPE: 0.190381 valid's rmse: 0.000345725   valid's RMSPE: 0.195545\nEarly stopping, best iteration is:\n[251]   train's rmse: 0.000344019   train's RMSPE: 0.192949 valid's rmse: 0.00034503    valid's RMSPE: 0.195152\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000390033   train's RMSPE: 0.219327 valid's rmse: 0.000372524   valid's RMSPE: 0.208528\n[100]   train's rmse: 0.000366111   train's RMSPE: 0.205875 valid's rmse: 0.000358462   valid's RMSPE: 0.200657\n[150]   train's rmse: 0.000357868   train's RMSPE: 0.20124  valid's rmse: 0.000356217   valid's RMSPE: 0.199401\n[200]   train's rmse: 0.000351282   train's RMSPE: 0.197536 valid's rmse: 0.000354192   valid's RMSPE: 0.198267\n[250]   train's rmse: 0.000345907   train's RMSPE: 0.194514 valid's rmse: 0.000352985   valid's RMSPE: 0.197591\n[300]   train's rmse: 0.000341495   train's RMSPE: 0.192033 valid's rmse: 0.000351283   valid's RMSPE: 0.196639\nEarly stopping, best iteration is:\n[293]   train's rmse: 0.000342072   train's RMSPE: 0.192357 valid's rmse: 0.000350955   valid's RMSPE: 0.196455\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000386639   train's RMSPE: 0.218364 valid's rmse: 0.000402552   valid's RMSPE: 0.221341\n[100]   train's rmse: 0.000363112   train's RMSPE: 0.205076 valid's rmse: 0.000384095   valid's RMSPE: 0.211192\n[150]   train's rmse: 0.000353671   train's RMSPE: 0.199744 valid's rmse: 0.000380119   valid's RMSPE: 0.209006\n[200]   train's rmse: 0.00034643    train's RMSPE: 0.195655 valid's rmse: 0.000378692   valid's RMSPE: 0.208221\n[250]   train's rmse: 0.000340689   train's RMSPE: 0.192412 valid's rmse: 0.000376218   valid's RMSPE: 0.206861\n[300]   train's rmse: 0.000335999   train's RMSPE: 0.189764 valid's rmse: 0.000375025   valid's RMSPE: 0.206205\n[350]   train's rmse: 0.000331875   train's RMSPE: 0.187434 valid's rmse: 0.000375051   valid's RMSPE: 0.206219\n[400]   train's rmse: 0.000327678   train's RMSPE: 0.185064 valid's rmse: 0.000373807   valid's RMSPE: 0.205536\n[450]   train's rmse: 0.00032427    train's RMSPE: 0.183139 valid's rmse: 0.000374149   valid's RMSPE: 0.205724\nEarly stopping, best iteration is:\n[446]   train's rmse: 0.000324529   train's RMSPE: 0.183286 valid's rmse: 0.000373668   valid's RMSPE: 0.205459\nOur out of folds RMSPE is 0.206, compared to 0.1686554230321588, giving gain 0.037344576967841187\nOur cv fold scores are [0.215, 0.216, 0.195, 0.196, 0.205]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000575982   train's RMSPE: 0.233616 valid's rmse: 0.000610009   valid's RMSPE: 0.2464\n[100]   train's rmse: 0.000547459   train's RMSPE: 0.222047 valid's rmse: 0.000591339   valid's RMSPE: 0.238859\n[150]   train's rmse: 0.000534472   train's RMSPE: 0.216779 valid's rmse: 0.000587469   valid's RMSPE: 0.237296\n[200]   train's rmse: 0.00052523    train's RMSPE: 0.213031 valid's rmse: 0.000587013   valid's RMSPE: 0.237111\n[250]   train's rmse: 0.000516824   train's RMSPE: 0.209621 valid's rmse: 0.000586106   valid's RMSPE: 0.236745\n[300]   train's rmse: 0.000509715   train's RMSPE: 0.206738 valid's rmse: 0.00058524    valid's RMSPE: 0.236395\nEarly stopping, best iteration is:\n[289]   train's rmse: 0.000511099   train's RMSPE: 0.207299 valid's rmse: 0.000584212   valid's RMSPE: 0.23598\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000575489   train's RMSPE: 0.232763 valid's rmse: 0.000604577   valid's RMSPE: 0.246941\n[100]   train's rmse: 0.000546889   train's RMSPE: 0.221195 valid's rmse: 0.000586229   valid's RMSPE: 0.239447\n[150]   train's rmse: 0.000533618   train's RMSPE: 0.215828 valid's rmse: 0.000581886   valid's RMSPE: 0.237673\n[200]   train's rmse: 0.000524077   train's RMSPE: 0.211969 valid's rmse: 0.00057857    valid's RMSPE: 0.236318\n[250]   train's rmse: 0.000515961   train's RMSPE: 0.208686 valid's rmse: 0.000576071   valid's RMSPE: 0.235298\n[300]   train's rmse: 0.000507557   train's RMSPE: 0.205287 valid's rmse: 0.00057412    valid's RMSPE: 0.234501\n[350]   train's rmse: 0.000500767   train's RMSPE: 0.202541 valid's rmse: 0.00057323    valid's RMSPE: 0.234137\nEarly stopping, best iteration is:\n[334]   train's rmse: 0.000502837   train's RMSPE: 0.203378 valid's rmse: 0.000572651   valid's RMSPE: 0.233901\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000580629   train's RMSPE: 0.235061 valid's rmse: 0.000578487   valid's RMSPE: 0.235418\n[100]   train's rmse: 0.000553119   train's RMSPE: 0.223924 valid's rmse: 0.000556155   valid's RMSPE: 0.22633\n[150]   train's rmse: 0.000540631   train's RMSPE: 0.218868 valid's rmse: 0.000552012   valid's RMSPE: 0.224644\n[200]   train's rmse: 0.000529465   train's RMSPE: 0.214348 valid's rmse: 0.000548324   valid's RMSPE: 0.223143\n[250]   train's rmse: 0.000521872   train's RMSPE: 0.211274 valid's rmse: 0.000546144   valid's RMSPE: 0.222256\n[300]   train's rmse: 0.000514498   train's RMSPE: 0.208288 valid's rmse: 0.000544662   valid's RMSPE: 0.221653\n[350]   train's rmse: 0.00050858    train's RMSPE: 0.205893 valid's rmse: 0.000544609   valid's RMSPE: 0.221631\nEarly stopping, best iteration is:\n[307]   train's rmse: 0.000513812   train's RMSPE: 0.208011 valid's rmse: 0.000544195   valid's RMSPE: 0.221463\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000582283   train's RMSPE: 0.235814 valid's rmse: 0.000575235   valid's RMSPE: 0.233765\n[100]   train's rmse: 0.000551679   train's RMSPE: 0.22342  valid's rmse: 0.000556892   valid's RMSPE: 0.226311\n[150]   train's rmse: 0.000538868   train's RMSPE: 0.218232 valid's rmse: 0.000555158   valid's RMSPE: 0.225606\n[200]   train's rmse: 0.00052871    train's RMSPE: 0.214118 valid's rmse: 0.000552035   valid's RMSPE: 0.224337\n[250]   train's rmse: 0.000519738   train's RMSPE: 0.210485 valid's rmse: 0.000547457   valid's RMSPE: 0.222477\n[300]   train's rmse: 0.000512577   train's RMSPE: 0.207585 valid's rmse: 0.000545923   valid's RMSPE: 0.221853\n[350]   train's rmse: 0.000505555   train's RMSPE: 0.204741 valid's rmse: 0.000543915   valid's RMSPE: 0.221037\n[400]   train's rmse: 0.000499733   train's RMSPE: 0.202383 valid's rmse: 0.000542997   valid's RMSPE: 0.220664\n[450]   train's rmse: 0.00049474    train's RMSPE: 0.200361 valid's rmse: 0.00054145    valid's RMSPE: 0.220036\n[500]   train's rmse: 0.000489338   train's RMSPE: 0.198173 valid's rmse: 0.000539899   valid's RMSPE: 0.219405\n[550]   train's rmse: 0.000484276   train's RMSPE: 0.196123 valid's rmse: 0.000539289   valid's RMSPE: 0.219157\n[600]   train's rmse: 0.000479866   train's RMSPE: 0.194337 valid's rmse: 0.000538044   valid's RMSPE: 0.218651\n[650]   train's rmse: 0.000475214   train's RMSPE: 0.192453 valid's rmse: 0.000537727   valid's RMSPE: 0.218523\nEarly stopping, best iteration is:\n[610]   train's rmse: 0.000478767   train's RMSPE: 0.193892 valid's rmse: 0.000537542   valid's RMSPE: 0.218447\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000576429   train's RMSPE: 0.23428  valid's rmse: 0.000593098   valid's RMSPE: 0.237564\n[100]   train's rmse: 0.000546956   train's RMSPE: 0.222301 valid's rmse: 0.000578114   valid's RMSPE: 0.231562\n[150]   train's rmse: 0.000534339   train's RMSPE: 0.217173 valid's rmse: 0.000573977   valid's RMSPE: 0.229905\n[200]   train's rmse: 0.00052516    train's RMSPE: 0.213442 valid's rmse: 0.000571255   valid's RMSPE: 0.228815\n[250]   train's rmse: 0.000516511   train's RMSPE: 0.209927 valid's rmse: 0.000569413   valid's RMSPE: 0.228077\n[300]   train's rmse: 0.000509189   train's RMSPE: 0.206951 valid's rmse: 0.000567924   valid's RMSPE: 0.22748\n[350]   train's rmse: 0.000501732   train's RMSPE: 0.20392  valid's rmse: 0.000566379   valid's RMSPE: 0.226862\nEarly stopping, best iteration is:\n[337]   train's rmse: 0.000503596   train's RMSPE: 0.204678 valid's rmse: 0.000566109   valid's RMSPE: 0.226754\nOur out of folds RMSPE is 0.227, compared to 0.191652955156558, giving gain 0.035347044843442005\nOur cv fold scores are [0.236, 0.234, 0.221, 0.218, 0.227]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000711837   train's RMSPE: 0.280035 valid's rmse: 0.000771399   valid's RMSPE: 0.305334\n[100]   train's rmse: 0.000676695   train's RMSPE: 0.26621  valid's rmse: 0.000757647   valid's RMSPE: 0.299891\n[150]   train's rmse: 0.000658101   train's RMSPE: 0.258895 valid's rmse: 0.000754218   valid's RMSPE: 0.298534\n[200]   train's rmse: 0.00064415    train's RMSPE: 0.253407 valid's rmse: 0.000752087   valid's RMSPE: 0.29769\n[250]   train's rmse: 0.000631555   train's RMSPE: 0.248452 valid's rmse: 0.000751979   valid's RMSPE: 0.297647\nEarly stopping, best iteration is:\n[204]   train's rmse: 0.00064322    train's RMSPE: 0.253041 valid's rmse: 0.000751441   valid's RMSPE: 0.297434\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000718611   train's RMSPE: 0.280959 valid's rmse: 0.000763813   valid's RMSPE: 0.309579\n[100]   train's rmse: 0.000686064   train's RMSPE: 0.268234 valid's rmse: 0.000733588   valid's RMSPE: 0.297328\n[150]   train's rmse: 0.000669262   train's RMSPE: 0.261665 valid's rmse: 0.000731339   valid's RMSPE: 0.296417\nEarly stopping, best iteration is:\n[124]   train's rmse: 0.000677614   train's RMSPE: 0.26493  valid's rmse: 0.000729048   valid's RMSPE: 0.295488\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000729827   train's RMSPE: 0.286404 valid's rmse: 0.000695522   valid's RMSPE: 0.277967\n[100]   train's rmse: 0.000692909   train's RMSPE: 0.271916 valid's rmse: 0.000684463   valid's RMSPE: 0.273547\n[150]   train's rmse: 0.000674148   train's RMSPE: 0.264554 valid's rmse: 0.000686471   valid's RMSPE: 0.27435\nEarly stopping, best iteration is:\n[106]   train's rmse: 0.000690399   train's RMSPE: 0.270931 valid's rmse: 0.000682954   valid's RMSPE: 0.272944\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000722212   train's RMSPE: 0.286414 valid's rmse: 0.000745011   valid's RMSPE: 0.285272\n[100]   train's rmse: 0.000685207   train's RMSPE: 0.271739 valid's rmse: 0.000736635   valid's RMSPE: 0.282065\n[150]   train's rmse: 0.000665343   train's RMSPE: 0.263861 valid's rmse: 0.000730966   valid's RMSPE: 0.279894\n[200]   train's rmse: 0.000650377   train's RMSPE: 0.257926 valid's rmse: 0.000731671   valid's RMSPE: 0.280164\nEarly stopping, best iteration is:\n[175]   train's rmse: 0.000658039   train's RMSPE: 0.260964 valid's rmse: 0.000729852   valid's RMSPE: 0.279468\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000718978   train's RMSPE: 0.284721 valid's rmse: 0.000728316   valid's RMSPE: 0.280596\n[100]   train's rmse: 0.00068428    train's RMSPE: 0.27098  valid's rmse: 0.000712443   valid's RMSPE: 0.274481\n[150]   train's rmse: 0.000666736   train's RMSPE: 0.264033 valid's rmse: 0.000710709   valid's RMSPE: 0.273813\n[200]   train's rmse: 0.000653682   train's RMSPE: 0.258863 valid's rmse: 0.000708121   valid's RMSPE: 0.272815\n[250]   train's rmse: 0.000641891   train's RMSPE: 0.254194 valid's rmse: 0.000707535   valid's RMSPE: 0.27259\n[300]   train's rmse: 0.000631877   train's RMSPE: 0.250228 valid's rmse: 0.000708484   valid's RMSPE: 0.272955\n[350]   train's rmse: 0.00062199    train's RMSPE: 0.246313 valid's rmse: 0.00070626    valid's RMSPE: 0.272099\n[400]   train's rmse: 0.000614042   train's RMSPE: 0.243165 valid's rmse: 0.00070629    valid's RMSPE: 0.27211\nEarly stopping, best iteration is:\n[377]   train's rmse: 0.000617611   train's RMSPE: 0.244578 valid's rmse: 0.000705118   valid's RMSPE: 0.271659\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.284, compared to 0.25713568883373233, giving gain 0.02686431116626764\nOur cv fold scores are [0.297, 0.295, 0.273, 0.279, 0.272]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000635952   train's RMSPE: 0.233423 valid's rmse: 0.000677687   valid's RMSPE: 0.253069\n[100]   train's rmse: 0.000605958   train's RMSPE: 0.222414 valid's rmse: 0.000651236   valid's RMSPE: 0.243192\n[150]   train's rmse: 0.000591471   train's RMSPE: 0.217097 valid's rmse: 0.000647573   valid's RMSPE: 0.241824\n[200]   train's rmse: 0.000579884   train's RMSPE: 0.212843 valid's rmse: 0.000645845   valid's RMSPE: 0.241178\n[250]   train's rmse: 0.00057113    train's RMSPE: 0.20963  valid's rmse: 0.000643455   valid's RMSPE: 0.240286\n[300]   train's rmse: 0.000562645   train's RMSPE: 0.206516 valid's rmse: 0.000643038   valid's RMSPE: 0.24013\n[350]   train's rmse: 0.000554556   train's RMSPE: 0.203547 valid's rmse: 0.000639853   valid's RMSPE: 0.238941\nEarly stopping, best iteration is:\n[347]   train's rmse: 0.000554992   train's RMSPE: 0.203707 valid's rmse: 0.000639367   valid's RMSPE: 0.238759\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000631052   train's RMSPE: 0.23118  valid's rmse: 0.000689904   valid's RMSPE: 0.259534\n[100]   train's rmse: 0.000599598   train's RMSPE: 0.219657 valid's rmse: 0.000666121   valid's RMSPE: 0.250587\n[150]   train's rmse: 0.000585679   train's RMSPE: 0.214558 valid's rmse: 0.000659903   valid's RMSPE: 0.248247\n[200]   train's rmse: 0.000574978   train's RMSPE: 0.210638 valid's rmse: 0.000655928   valid's RMSPE: 0.246752\n[250]   train's rmse: 0.000566921   train's RMSPE: 0.207686 valid's rmse: 0.00065328    valid's RMSPE: 0.245756\n[300]   train's rmse: 0.000558922   train's RMSPE: 0.204756 valid's rmse: 0.000649415   valid's RMSPE: 0.244302\n[350]   train's rmse: 0.000551769   train's RMSPE: 0.202135 valid's rmse: 0.000646548   valid's RMSPE: 0.243223\n[400]   train's rmse: 0.000545268   train's RMSPE: 0.199754 valid's rmse: 0.000645924   valid's RMSPE: 0.242989\n[450]   train's rmse: 0.00053964    train's RMSPE: 0.197692 valid's rmse: 0.000643798   valid's RMSPE: 0.242189\n[500]   train's rmse: 0.000533583   train's RMSPE: 0.195473 valid's rmse: 0.000641323   valid's RMSPE: 0.241258\n[550]   train's rmse: 0.000528085   train's RMSPE: 0.193459 valid's rmse: 0.000640522   valid's RMSPE: 0.240956\n[600]   train's rmse: 0.000523455   train's RMSPE: 0.191763 valid's rmse: 0.000639716   valid's RMSPE: 0.240653\n[650]   train's rmse: 0.000518661   train's RMSPE: 0.190006 valid's rmse: 0.000638226   valid's RMSPE: 0.240093\n[700]   train's rmse: 0.000513731   train's RMSPE: 0.188201 valid's rmse: 0.000638467   valid's RMSPE: 0.240184\nEarly stopping, best iteration is:\n[664]   train's rmse: 0.000517075   train's RMSPE: 0.189425 valid's rmse: 0.000637786   valid's RMSPE: 0.239927\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000642865   train's RMSPE: 0.236321 valid's rmse: 0.000631448   valid's RMSPE: 0.234404\n[100]   train's rmse: 0.000608943   train's RMSPE: 0.223851 valid's rmse: 0.000613907   valid's RMSPE: 0.227893\n[150]   train's rmse: 0.000594986   train's RMSPE: 0.21872  valid's rmse: 0.000610803   valid's RMSPE: 0.22674\n[200]   train's rmse: 0.000582996   train's RMSPE: 0.214313 valid's rmse: 0.000607715   valid's RMSPE: 0.225594\n[250]   train's rmse: 0.000573542   train's RMSPE: 0.210838 valid's rmse: 0.000606709   valid's RMSPE: 0.225221\n[300]   train's rmse: 0.000566387   train's RMSPE: 0.208207 valid's rmse: 0.000605567   valid's RMSPE: 0.224797\n[350]   train's rmse: 0.000559827   train's RMSPE: 0.205796 valid's rmse: 0.000606535   valid's RMSPE: 0.225156\nEarly stopping, best iteration is:\n[310]   train's rmse: 0.000565079   train's RMSPE: 0.207726 valid's rmse: 0.000605026   valid's RMSPE: 0.224596\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000648115   train's RMSPE: 0.239664 valid's rmse: 0.000605241   valid's RMSPE: 0.219369\n[100]   train's rmse: 0.000615741   train's RMSPE: 0.227693 valid's rmse: 0.000594228   valid's RMSPE: 0.215378\n[150]   train's rmse: 0.000602537   train's RMSPE: 0.22281  valid's rmse: 0.000592018   valid's RMSPE: 0.214577\n[200]   train's rmse: 0.000591016   train's RMSPE: 0.21855  valid's rmse: 0.0005892 valid's RMSPE: 0.213555\n[250]   train's rmse: 0.000581653   train's RMSPE: 0.215087 valid's rmse: 0.00058716    valid's RMSPE: 0.212816\n[300]   train's rmse: 0.000571873   train's RMSPE: 0.211471 valid's rmse: 0.000586105   valid's RMSPE: 0.212434\n[350]   train's rmse: 0.000563975   train's RMSPE: 0.208551 valid's rmse: 0.000584527   valid's RMSPE: 0.211862\n[400]   train's rmse: 0.000556879   train's RMSPE: 0.205926 valid's rmse: 0.000583707   valid's RMSPE: 0.211564\nEarly stopping, best iteration is:\n[385]   train's rmse: 0.000558868   train's RMSPE: 0.206662 valid's rmse: 0.000583442   valid's RMSPE: 0.211468\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000641123   train's RMSPE: 0.237765 valid's rmse: 0.000657114   valid's RMSPE: 0.235278\n[100]   train's rmse: 0.000607932   train's RMSPE: 0.225456 valid's rmse: 0.000637019   valid's RMSPE: 0.228083\n[150]   train's rmse: 0.000593093   train's RMSPE: 0.219953 valid's rmse: 0.000631381   valid's RMSPE: 0.226065\n[200]   train's rmse: 0.000581679   train's RMSPE: 0.21572  valid's rmse: 0.000629575   valid's RMSPE: 0.225418\n[250]   train's rmse: 0.000572791   train's RMSPE: 0.212424 valid's rmse: 0.000628712   valid's RMSPE: 0.225109\n[300]   train's rmse: 0.000564822   train's RMSPE: 0.209468 valid's rmse: 0.00062704    valid's RMSPE: 0.22451\n[350]   train's rmse: 0.00055659    train's RMSPE: 0.206416 valid's rmse: 0.000624631   valid's RMSPE: 0.223648\n[400]   train's rmse: 0.000549678   train's RMSPE: 0.203852 valid's rmse: 0.000624158   valid's RMSPE: 0.223479\n[450]   train's rmse: 0.000543746   train's RMSPE: 0.201652 valid's rmse: 0.000623013   valid's RMSPE: 0.223069\n[500]   train's rmse: 0.000538405   train's RMSPE: 0.199671 valid's rmse: 0.000623647   valid's RMSPE: 0.223296\nEarly stopping, best iteration is:\n[451]   train's rmse: 0.000543692   train's RMSPE: 0.201632 valid's rmse: 0.000622932   valid's RMSPE: 0.223039\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.228, compared to 0.19072875458746932, giving gain 0.037271245412530685\nOur cv fold scores are [0.239, 0.24, 0.225, 0.211, 0.223]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00167119    train's RMSPE: 0.286459 valid's rmse: 0.00184806    valid's RMSPE: 0.311681\n[100]   train's rmse: 0.00159208    train's RMSPE: 0.272899 valid's rmse: 0.00181748    valid's RMSPE: 0.306523\n[150]   train's rmse: 0.00154664    train's RMSPE: 0.26511  valid's rmse: 0.00180777    valid's RMSPE: 0.304885\n[200]   train's rmse: 0.00151132    train's RMSPE: 0.259056 valid's rmse: 0.00180815    valid's RMSPE: 0.304949\nEarly stopping, best iteration is:\n[170]   train's rmse: 0.00153185    train's RMSPE: 0.262575 valid's rmse: 0.00180459    valid's RMSPE: 0.304348\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00168635    train's RMSPE: 0.28763  valid's rmse: 0.0017807 valid's RMSPE: 0.306375\n[100]   train's rmse: 0.00160457    train's RMSPE: 0.273682 valid's rmse: 0.00174622    valid's RMSPE: 0.300443\n[150]   train's rmse: 0.00156184    train's RMSPE: 0.266392 valid's rmse: 0.00174482    valid's RMSPE: 0.300201\nEarly stopping, best iteration is:\n[125]   train's rmse: 0.00158212    train's RMSPE: 0.269851 valid's rmse: 0.00173887    valid's RMSPE: 0.299178\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00172558    train's RMSPE: 0.293414 valid's rmse: 0.00161225    valid's RMSPE: 0.280729\n[100]   train's rmse: 0.00164543    train's RMSPE: 0.279785 valid's rmse: 0.00157121    valid's RMSPE: 0.273583\n[150]   train's rmse: 0.00160099    train's RMSPE: 0.272228 valid's rmse: 0.00155786    valid's RMSPE: 0.271259\n[200]   train's rmse: 0.0015686 train's RMSPE: 0.26672  valid's rmse: 0.00155391    valid's RMSPE: 0.270572\nEarly stopping, best iteration is:\n[181]   train's rmse: 0.00157996    train's RMSPE: 0.268652 valid's rmse: 0.00155247    valid's RMSPE: 0.270321\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00167584    train's RMSPE: 0.285722 valid's rmse: 0.00180791    valid's RMSPE: 0.311545\n[100]   train's rmse: 0.0015899 train's RMSPE: 0.271071 valid's rmse: 0.00178703    valid's RMSPE: 0.307947\n[150]   train's rmse: 0.00154124    train's RMSPE: 0.262775 valid's rmse: 0.0017884 valid's RMSPE: 0.308183\nEarly stopping, best iteration is:\n[102]   train's rmse: 0.00158667    train's RMSPE: 0.27052  valid's rmse: 0.00178602    valid's RMSPE: 0.307774\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.0016907 train's RMSPE: 0.290461 valid's rmse: 0.00177341    valid's RMSPE: 0.296269\n[100]   train's rmse: 0.00161115    train's RMSPE: 0.276794 valid's rmse: 0.00174614    valid's RMSPE: 0.291713\n[150]   train's rmse: 0.00156436    train's RMSPE: 0.268757 valid's rmse: 0.00174247    valid's RMSPE: 0.2911\nEarly stopping, best iteration is:\n[146]   train's rmse: 0.00156782    train's RMSPE: 0.269351 valid's rmse: 0.00173899    valid's RMSPE: 0.290518\nOur out of folds RMSPE is 0.295, compared to 0.2889225845421511, giving gain 0.0060774154578489\nOur cv fold scores are [0.304, 0.299, 0.27, 0.308, 0.291]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000490788   train's RMSPE: 0.263215 valid's rmse: 0.000531108   valid's RMSPE: 0.283377\n[100]   train's rmse: 0.000466599   train's RMSPE: 0.250242 valid's rmse: 0.000518328   valid's RMSPE: 0.276558\n[150]   train's rmse: 0.000454113   train's RMSPE: 0.243546 valid's rmse: 0.000516021   valid's RMSPE: 0.275328\n[200]   train's rmse: 0.000445361   train's RMSPE: 0.238851 valid's rmse: 0.00051365    valid's RMSPE: 0.274062\n[250]   train's rmse: 0.000437869   train's RMSPE: 0.234833 valid's rmse: 0.000511702   valid's RMSPE: 0.273023\n[300]   train's rmse: 0.000431259   train's RMSPE: 0.231289 valid's rmse: 0.000509312   valid's RMSPE: 0.271748\n[350]   train's rmse: 0.000425126   train's RMSPE: 0.228    valid's rmse: 0.000508052   valid's RMSPE: 0.271076\n[400]   train's rmse: 0.000419583   train's RMSPE: 0.225027 valid's rmse: 0.000508063   valid's RMSPE: 0.271082\nEarly stopping, best iteration is:\n[354]   train's rmse: 0.000424598   train's RMSPE: 0.227716 valid's rmse: 0.000507699   valid's RMSPE: 0.270887\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000491334   train's RMSPE: 0.262405 valid's rmse: 0.000533633   valid's RMSPE: 0.289489\n[100]   train's rmse: 0.000466528   train's RMSPE: 0.249157 valid's rmse: 0.000520872   valid's RMSPE: 0.282566\n[150]   train's rmse: 0.000454126   train's RMSPE: 0.242533 valid's rmse: 0.000517467   valid's RMSPE: 0.280719\n[200]   train's rmse: 0.000443623   train's RMSPE: 0.236924 valid's rmse: 0.00051588    valid's RMSPE: 0.279858\n[250]   train's rmse: 0.000435741   train's RMSPE: 0.232714 valid's rmse: 0.000515847   valid's RMSPE: 0.27984\nEarly stopping, best iteration is:\n[212]   train's rmse: 0.000441752   train's RMSPE: 0.235925 valid's rmse: 0.000515403   valid's RMSPE: 0.279599\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000503659   train's RMSPE: 0.269387 valid's rmse: 0.000481946   valid's RMSPE: 0.259938\n[100]   train's rmse: 0.000478298   train's RMSPE: 0.255822 valid's rmse: 0.000466311   valid's RMSPE: 0.251505\n[150]   train's rmse: 0.000464998   train's RMSPE: 0.248709 valid's rmse: 0.000466505   valid's RMSPE: 0.25161\nEarly stopping, best iteration is:\n[111]   train's rmse: 0.000474784   train's RMSPE: 0.253943 valid's rmse: 0.000465048   valid's RMSPE: 0.250824\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000498307   train's RMSPE: 0.266603 valid's rmse: 0.000509034   valid's RMSPE: 0.274229\n[100]   train's rmse: 0.000473999   train's RMSPE: 0.253598 valid's rmse: 0.000494233   valid's RMSPE: 0.266256\n[150]   train's rmse: 0.000462714   train's RMSPE: 0.24756  valid's rmse: 0.000492027   valid's RMSPE: 0.265067\n[200]   train's rmse: 0.000453425   train's RMSPE: 0.24259  valid's rmse: 0.000490754   valid's RMSPE: 0.264381\n[250]   train's rmse: 0.000445749   train's RMSPE: 0.238484 valid's rmse: 0.000488495   valid's RMSPE: 0.263164\nEarly stopping, best iteration is:\n[231]   train's rmse: 0.000448377   train's RMSPE: 0.239889 valid's rmse: 0.000487196   valid's RMSPE: 0.262465\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000501141   train's RMSPE: 0.269884 valid's rmse: 0.000492624   valid's RMSPE: 0.258381\n[100]   train's rmse: 0.000476804   train's RMSPE: 0.256778 valid's rmse: 0.000478897   valid's RMSPE: 0.251181\n[150]   train's rmse: 0.000463476   train's RMSPE: 0.2496   valid's rmse: 0.000476099   valid's RMSPE: 0.249714\n[200]   train's rmse: 0.000452939   train's RMSPE: 0.243925 valid's rmse: 0.000474241   valid's RMSPE: 0.248739\nEarly stopping, best iteration is:\n[187]   train's rmse: 0.000455319   train's RMSPE: 0.245207 valid's rmse: 0.000474061   valid's RMSPE: 0.248645\nOur out of folds RMSPE is 0.263, compared to 0.22601895323506935, giving gain 0.036981046764930664\nOur cv fold scores are [0.271, 0.28, 0.251, 0.262, 0.249]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000444933   train's RMSPE: 0.226682 valid's rmse: 0.000475867   valid's RMSPE: 0.241866\n[100]   train's rmse: 0.000425009   train's RMSPE: 0.216532 valid's rmse: 0.000459049   valid's RMSPE: 0.233317\n[150]   train's rmse: 0.000415276   train's RMSPE: 0.211573 valid's rmse: 0.000453479   valid's RMSPE: 0.230486\n[200]   train's rmse: 0.000407785   train's RMSPE: 0.207756 valid's rmse: 0.000451113   valid's RMSPE: 0.229284\n[250]   train's rmse: 0.000401481   train's RMSPE: 0.204544 valid's rmse: 0.000450142   valid's RMSPE: 0.228791\n[300]   train's rmse: 0.00039584    train's RMSPE: 0.201671 valid's rmse: 0.00044851    valid's RMSPE: 0.227961\n[350]   train's rmse: 0.000390753   train's RMSPE: 0.199079 valid's rmse: 0.00044793    valid's RMSPE: 0.227666\nEarly stopping, best iteration is:\n[324]   train's rmse: 0.000393145   train's RMSPE: 0.200298 valid's rmse: 0.000447624   valid's RMSPE: 0.227511\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000440434   train's RMSPE: 0.224109 valid's rmse: 0.000482282   valid's RMSPE: 0.246356\n[100]   train's rmse: 0.000419707   train's RMSPE: 0.213563 valid's rmse: 0.000469944   valid's RMSPE: 0.240053\n[150]   train's rmse: 0.000410704   train's RMSPE: 0.208982 valid's rmse: 0.000468145   valid's RMSPE: 0.239135\n[200]   train's rmse: 0.00040319    train's RMSPE: 0.205158 valid's rmse: 0.000465055   valid's RMSPE: 0.237556\n[250]   train's rmse: 0.000397336   train's RMSPE: 0.202179 valid's rmse: 0.00046447    valid's RMSPE: 0.237257\nEarly stopping, best iteration is:\n[243]   train's rmse: 0.000398031   train's RMSPE: 0.202533 valid's rmse: 0.000464112   valid's RMSPE: 0.237074\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00045182    train's RMSPE: 0.229304 valid's rmse: 0.000431247   valid's RMSPE: 0.222549\n[100]   train's rmse: 0.000431161   train's RMSPE: 0.218819 valid's rmse: 0.000419763   valid's RMSPE: 0.216622\n[150]   train's rmse: 0.000421159   train's RMSPE: 0.213743 valid's rmse: 0.000416146   valid's RMSPE: 0.214755\n[200]   train's rmse: 0.000413843   train's RMSPE: 0.21003  valid's rmse: 0.000414329   valid's RMSPE: 0.213818\n[250]   train's rmse: 0.000407864   train's RMSPE: 0.206996 valid's rmse: 0.000414628   valid's RMSPE: 0.213972\nEarly stopping, best iteration is:\n[245]   train's rmse: 0.000408311   train's RMSPE: 0.207223 valid's rmse: 0.000414143   valid's RMSPE: 0.213722\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000456671   train's RMSPE: 0.232649 valid's rmse: 0.000420007   valid's RMSPE: 0.213522\n[100]   train's rmse: 0.000435785   train's RMSPE: 0.222009 valid's rmse: 0.000408954   valid's RMSPE: 0.207903\n[150]   train's rmse: 0.00042709    train's RMSPE: 0.217579 valid's rmse: 0.000407944   valid's RMSPE: 0.20739\n[200]   train's rmse: 0.000419061   train's RMSPE: 0.213489 valid's rmse: 0.000408294   valid's RMSPE: 0.207568\nEarly stopping, best iteration is:\n[174]   train's rmse: 0.000422751   train's RMSPE: 0.215369 valid's rmse: 0.000407498   valid's RMSPE: 0.207163\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000445781   train's RMSPE: 0.227744 valid's rmse: 0.000472346   valid's RMSPE: 0.237381\n[100]   train's rmse: 0.000424741   train's RMSPE: 0.216995 valid's rmse: 0.000458404   valid's RMSPE: 0.230375\n[150]   train's rmse: 0.000415616   train's RMSPE: 0.212333 valid's rmse: 0.000455008   valid's RMSPE: 0.228668\n[200]   train's rmse: 0.000408374   train's RMSPE: 0.208634 valid's rmse: 0.000452808   valid's RMSPE: 0.227562\n[250]   train's rmse: 0.000401722   train's RMSPE: 0.205235 valid's rmse: 0.000452202   valid's RMSPE: 0.227258\nEarly stopping, best iteration is:\n[226]   train's rmse: 0.000404502   train's RMSPE: 0.206655 valid's rmse: 0.0004517 valid's RMSPE: 0.227005\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.223, compared to 0.17900678157963607, giving gain 0.04399321842036394\nOur cv fold scores are [0.228, 0.237, 0.214, 0.207, 0.227]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000435184   train's RMSPE: 0.256744 valid's rmse: 0.000465168   valid's RMSPE: 0.276192\n[100]   train's rmse: 0.00041287    train's RMSPE: 0.24358  valid's rmse: 0.000449542   valid's RMSPE: 0.266914\n[150]   train's rmse: 0.000401982   train's RMSPE: 0.237156 valid's rmse: 0.000446324   valid's RMSPE: 0.265003\n[200]   train's rmse: 0.000392722   train's RMSPE: 0.231693 valid's rmse: 0.000446187   valid's RMSPE: 0.264922\n[250]   train's rmse: 0.000385982   train's RMSPE: 0.227717 valid's rmse: 0.000444877   valid's RMSPE: 0.264145\n[300]   train's rmse: 0.000379589   train's RMSPE: 0.223945 valid's rmse: 0.000443365   valid's RMSPE: 0.263247\n[350]   train's rmse: 0.000373994   train's RMSPE: 0.220644 valid's rmse: 0.000443324   valid's RMSPE: 0.263222\nEarly stopping, best iteration is:\n[324]   train's rmse: 0.000376925   train's RMSPE: 0.222374 valid's rmse: 0.000442732   valid's RMSPE: 0.262871\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00043093    train's RMSPE: 0.255392 valid's rmse: 0.000471853   valid's RMSPE: 0.275065\n[100]   train's rmse: 0.000407579   train's RMSPE: 0.241553 valid's rmse: 0.000458794   valid's RMSPE: 0.267453\n[150]   train's rmse: 0.000396335   train's RMSPE: 0.23489  valid's rmse: 0.000455669   valid's RMSPE: 0.265631\n[200]   train's rmse: 0.000387339   train's RMSPE: 0.229558 valid's rmse: 0.00045417    valid's RMSPE: 0.264757\n[250]   train's rmse: 0.000379866   train's RMSPE: 0.225129 valid's rmse: 0.000452687   valid's RMSPE: 0.263893\n[300]   train's rmse: 0.000373394   train's RMSPE: 0.221293 valid's rmse: 0.000452377   valid's RMSPE: 0.263712\nEarly stopping, best iteration is:\n[269]   train's rmse: 0.000377272   train's RMSPE: 0.223592 valid's rmse: 0.000452205   valid's RMSPE: 0.263612\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000434788   train's RMSPE: 0.257213 valid's rmse: 0.000435545   valid's RMSPE: 0.255788\n[100]   train's rmse: 0.000411495   train's RMSPE: 0.243434 valid's rmse: 0.000430635   valid's RMSPE: 0.252904\n[150]   train's rmse: 0.00039988    train's RMSPE: 0.236562 valid's rmse: 0.00042907    valid's RMSPE: 0.251985\nEarly stopping, best iteration is:\n[144]   train's rmse: 0.000400852   train's RMSPE: 0.237137 valid's rmse: 0.000428938   valid's RMSPE: 0.251908\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000435917   train's RMSPE: 0.25793  valid's rmse: 0.000453489   valid's RMSPE: 0.26612\n[100]   train's rmse: 0.000412679   train's RMSPE: 0.244181 valid's rmse: 0.000441486   valid's RMSPE: 0.259076\n[150]   train's rmse: 0.000401228   train's RMSPE: 0.237405 valid's rmse: 0.000441829   valid's RMSPE: 0.259277\nEarly stopping, best iteration is:\n[114]   train's rmse: 0.000409088   train's RMSPE: 0.242055 valid's rmse: 0.000440896   valid's RMSPE: 0.25873\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000444483   train's RMSPE: 0.261228 valid's rmse: 0.000417535   valid's RMSPE: 0.251615\n[100]   train's rmse: 0.000422477   train's RMSPE: 0.248295 valid's rmse: 0.000401623   valid's RMSPE: 0.242026\n[150]   train's rmse: 0.000411233   train's RMSPE: 0.241687 valid's rmse: 0.000398365   valid's RMSPE: 0.240063\n[200]   train's rmse: 0.000401979   train's RMSPE: 0.236249 valid's rmse: 0.000396598   valid's RMSPE: 0.238998\n[250]   train's rmse: 0.000394447   train's RMSPE: 0.231822 valid's rmse: 0.000397063   valid's RMSPE: 0.239278\nEarly stopping, best iteration is:\n[222]   train's rmse: 0.000398575   train's RMSPE: 0.234248 valid's rmse: 0.000396023   valid's RMSPE: 0.238651\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.255, compared to 0.22612054446229005, giving gain 0.028879455537709958\nOur cv fold scores are [0.263, 0.264, 0.252, 0.259, 0.239]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000728622   train's RMSPE: 0.227569 valid's rmse: 0.000785335   valid's RMSPE: 0.240509\n[100]   train's rmse: 0.000687906   train's RMSPE: 0.214853 valid's rmse: 0.000763836   valid's RMSPE: 0.233925\n[150]   train's rmse: 0.000670188   train's RMSPE: 0.209319 valid's rmse: 0.000759741   valid's RMSPE: 0.232671\n[200]   train's rmse: 0.00065475    train's RMSPE: 0.204497 valid's rmse: 0.000757188   valid's RMSPE: 0.231889\nEarly stopping, best iteration is:\n[194]   train's rmse: 0.000656324   train's RMSPE: 0.204988 valid's rmse: 0.000755931   valid's RMSPE: 0.231504\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000728531   train's RMSPE: 0.225462 valid's rmse: 0.000777148   valid's RMSPE: 0.246844\n[100]   train's rmse: 0.000687393   train's RMSPE: 0.21273  valid's rmse: 0.000758287   valid's RMSPE: 0.240853\n[150]   train's rmse: 0.000669455   train's RMSPE: 0.207179 valid's rmse: 0.000755781   valid's RMSPE: 0.240057\n[200]   train's rmse: 0.000654868   train's RMSPE: 0.202665 valid's rmse: 0.000754434   valid's RMSPE: 0.239629\n[250]   train's rmse: 0.000641682   train's RMSPE: 0.198584 valid's rmse: 0.000754077   valid's RMSPE: 0.239516\nEarly stopping, best iteration is:\n[205]   train's rmse: 0.000653458   train's RMSPE: 0.202229 valid's rmse: 0.000753145   valid's RMSPE: 0.23922\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000739777   train's RMSPE: 0.230105 valid's rmse: 0.000714744   valid's RMSPE: 0.222589\n[100]   train's rmse: 0.000697432   train's RMSPE: 0.216934 valid's rmse: 0.000695711   valid's RMSPE: 0.216662\n[150]   train's rmse: 0.000677796   train's RMSPE: 0.210826 valid's rmse: 0.00069396    valid's RMSPE: 0.216117\nEarly stopping, best iteration is:\n[148]   train's rmse: 0.000678279   train's RMSPE: 0.210976 valid's rmse: 0.000693469   valid's RMSPE: 0.215964\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00072916    train's RMSPE: 0.22703  valid's rmse: 0.000773565   valid's RMSPE: 0.239941\n[100]   train's rmse: 0.000686764   train's RMSPE: 0.21383  valid's rmse: 0.000763724   valid's RMSPE: 0.236888\nEarly stopping, best iteration is:\n[76]    train's rmse: 0.000700067   train's RMSPE: 0.217972 valid's rmse: 0.000761842   valid's RMSPE: 0.236305\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000739768   train's RMSPE: 0.230361 valid's rmse: 0.000744123   valid's RMSPE: 0.230695\n[100]   train's rmse: 0.000700814   train's RMSPE: 0.218231 valid's rmse: 0.000714484   valid's RMSPE: 0.221506\n[150]   train's rmse: 0.000682654   train's RMSPE: 0.212576 valid's rmse: 0.000711031   valid's RMSPE: 0.220436\n[200]   train's rmse: 0.00066642    train's RMSPE: 0.207521 valid's rmse: 0.000708605   valid's RMSPE: 0.219684\nEarly stopping, best iteration is:\n[180]   train's rmse: 0.00067252    train's RMSPE: 0.20942  valid's rmse: 0.000707721   valid's RMSPE: 0.21941\nOur out of folds RMSPE is 0.229, compared to 0.20676157404809947, giving gain 0.022238425951900537\nOur cv fold scores are [0.232, 0.239, 0.216, 0.236, 0.219]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000694247   train's RMSPE: 0.236973 valid's rmse: 0.000743298   valid's RMSPE: 0.257054\n[100]   train's rmse: 0.000657039   train's RMSPE: 0.224273 valid's rmse: 0.000722694   valid's RMSPE: 0.249928\n[150]   train's rmse: 0.00063937    train's RMSPE: 0.218242 valid's rmse: 0.000719903   valid's RMSPE: 0.248963\n[200]   train's rmse: 0.000625594   train's RMSPE: 0.213539 valid's rmse: 0.000719468   valid's RMSPE: 0.248813\n[250]   train's rmse: 0.000613638   train's RMSPE: 0.209458 valid's rmse: 0.000718563   valid's RMSPE: 0.2485\n[300]   train's rmse: 0.000604656   train's RMSPE: 0.206392 valid's rmse: 0.000718666   valid's RMSPE: 0.248535\nEarly stopping, best iteration is:\n[267]   train's rmse: 0.000610311   train's RMSPE: 0.208323 valid's rmse: 0.00071782    valid's RMSPE: 0.248243\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000697113   train's RMSPE: 0.237124 valid's rmse: 0.000741569   valid's RMSPE: 0.259902\n[100]   train's rmse: 0.000663173   train's RMSPE: 0.225579 valid's rmse: 0.000716087   valid's RMSPE: 0.250971\n[150]   train's rmse: 0.000648547   train's RMSPE: 0.220604 valid's rmse: 0.000710754   valid's RMSPE: 0.249102\n[200]   train's rmse: 0.000635601   train's RMSPE: 0.2162   valid's rmse: 0.00070875    valid's RMSPE: 0.2484\n[250]   train's rmse: 0.000625343   train's RMSPE: 0.212711 valid's rmse: 0.000705913   valid's RMSPE: 0.247406\n[300]   train's rmse: 0.000615569   train's RMSPE: 0.209387 valid's rmse: 0.000703559   valid's RMSPE: 0.246581\n[350]   train's rmse: 0.000606403   train's RMSPE: 0.206269 valid's rmse: 0.000699992   valid's RMSPE: 0.245331\n[400]   train's rmse: 0.000598168   train's RMSPE: 0.203468 valid's rmse: 0.000701231   valid's RMSPE: 0.245765\nEarly stopping, best iteration is:\n[379]   train's rmse: 0.000600909   train's RMSPE: 0.2044   valid's rmse: 0.000699261   valid's RMSPE: 0.245074\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000708932   train's RMSPE: 0.242677 valid's rmse: 0.000674426   valid's RMSPE: 0.230621\n[100]   train's rmse: 0.000672407   train's RMSPE: 0.230174 valid's rmse: 0.000656306   valid's RMSPE: 0.224425\n[150]   train's rmse: 0.000655856   train's RMSPE: 0.224509 valid's rmse: 0.000654705   valid's RMSPE: 0.223877\n[200]   train's rmse: 0.000643032   train's RMSPE: 0.220119 valid's rmse: 0.000653878   valid's RMSPE: 0.223594\n[250]   train's rmse: 0.000631498   train's RMSPE: 0.21617  valid's rmse: 0.000651153   valid's RMSPE: 0.222663\nEarly stopping, best iteration is:\n[245]   train's rmse: 0.000632475   train's RMSPE: 0.216505 valid's rmse: 0.000650815   valid's RMSPE: 0.222547\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000710283   train's RMSPE: 0.243296 valid's rmse: 0.000693382   valid's RMSPE: 0.236489\n[100]   train's rmse: 0.000672329   train's RMSPE: 0.230296 valid's rmse: 0.000672201   valid's RMSPE: 0.229265\n[150]   train's rmse: 0.000657181   train's RMSPE: 0.225107 valid's rmse: 0.000669294   valid's RMSPE: 0.228274\n[200]   train's rmse: 0.000643908   train's RMSPE: 0.22056  valid's rmse: 0.000665188   valid's RMSPE: 0.226873\n[250]   train's rmse: 0.000633346   train's RMSPE: 0.216943 valid's rmse: 0.000661013   valid's RMSPE: 0.22545\n[300]   train's rmse: 0.000623373   train's RMSPE: 0.213527 valid's rmse: 0.00065929    valid's RMSPE: 0.224862\n[350]   train's rmse: 0.000614738   train's RMSPE: 0.210569 valid's rmse: 0.000659222   valid's RMSPE: 0.224839\n[400]   train's rmse: 0.000606861   train's RMSPE: 0.207871 valid's rmse: 0.000660092   valid's RMSPE: 0.225135\nEarly stopping, best iteration is:\n[352]   train's rmse: 0.000614449   train's RMSPE: 0.21047  valid's rmse: 0.000658829   valid's RMSPE: 0.224705\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000699256   train's RMSPE: 0.241139 valid's rmse: 0.000733697   valid's RMSPE: 0.243292\n[100]   train's rmse: 0.000665507   train's RMSPE: 0.2295   valid's rmse: 0.000712454   valid's RMSPE: 0.236248\n[150]   train's rmse: 0.000649241   train's RMSPE: 0.223891 valid's rmse: 0.000707823   valid's RMSPE: 0.234712\n[200]   train's rmse: 0.000635673   train's RMSPE: 0.219212 valid's rmse: 0.000704086   valid's RMSPE: 0.233473\n[250]   train's rmse: 0.000623882   train's RMSPE: 0.215146 valid's rmse: 0.000704128   valid's RMSPE: 0.233487\nEarly stopping, best iteration is:\n[224]   train's rmse: 0.000629302   train's RMSPE: 0.217015 valid's rmse: 0.000702665   valid's RMSPE: 0.233002\nOur out of folds RMSPE is 0.235, compared to 0.19946161370414217, giving gain 0.035538386295857816\nOur cv fold scores are [0.248, 0.245, 0.223, 0.225, 0.233]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000514385   train's RMSPE: 0.238296 valid's rmse: 0.000540053   valid's RMSPE: 0.247204\n[100]   train's rmse: 0.000488623   train's RMSPE: 0.226361 valid's rmse: 0.000519593   valid's RMSPE: 0.237839\n[150]   train's rmse: 0.000475888   train's RMSPE: 0.220461 valid's rmse: 0.000514632   valid's RMSPE: 0.235568\n[200]   train's rmse: 0.00046544    train's RMSPE: 0.215621 valid's rmse: 0.000511899   valid's RMSPE: 0.234317\n[250]   train's rmse: 0.000456955   train's RMSPE: 0.211691 valid's rmse: 0.000510592   valid's RMSPE: 0.233719\n[300]   train's rmse: 0.000450052   train's RMSPE: 0.208493 valid's rmse: 0.000508884   valid's RMSPE: 0.232937\n[350]   train's rmse: 0.000443583   train's RMSPE: 0.205496 valid's rmse: 0.000507774   valid's RMSPE: 0.232429\n[400]   train's rmse: 0.000437796   train's RMSPE: 0.202815 valid's rmse: 0.000507792   valid's RMSPE: 0.232437\n[450]   train's rmse: 0.000432336   train's RMSPE: 0.200285 valid's rmse: 0.000507046   valid's RMSPE: 0.232096\n[500]   train's rmse: 0.000427492   train's RMSPE: 0.198041 valid's rmse: 0.000506456   valid's RMSPE: 0.231826\n[550]   train's rmse: 0.000423445   train's RMSPE: 0.196166 valid's rmse: 0.000506216   valid's RMSPE: 0.231716\n[600]   train's rmse: 0.000419621   train's RMSPE: 0.194395 valid's rmse: 0.000506205   valid's RMSPE: 0.231711\nEarly stopping, best iteration is:\n[562]   train's rmse: 0.000422477   train's RMSPE: 0.195718 valid's rmse: 0.000505774   valid's RMSPE: 0.231514\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000506689   train's RMSPE: 0.233591 valid's rmse: 0.000568943   valid's RMSPE: 0.265546\n[100]   train's rmse: 0.000482446   train's RMSPE: 0.222414 valid's rmse: 0.000552225   valid's RMSPE: 0.257743\n[150]   train's rmse: 0.000472033   train's RMSPE: 0.217614 valid's rmse: 0.00054693    valid's RMSPE: 0.255272\n[200]   train's rmse: 0.000463314   train's RMSPE: 0.213594 valid's rmse: 0.000541185   valid's RMSPE: 0.252591\n[250]   train's rmse: 0.000455685   train's RMSPE: 0.210077 valid's rmse: 0.00053853    valid's RMSPE: 0.251351\n[300]   train's rmse: 0.000449416   train's RMSPE: 0.207187 valid's rmse: 0.000536121   valid's RMSPE: 0.250227\n[350]   train's rmse: 0.000443756   train's RMSPE: 0.204578 valid's rmse: 0.00053323    valid's RMSPE: 0.248878\n[400]   train's rmse: 0.0004386 train's RMSPE: 0.202201 valid's rmse: 0.0005298 valid's RMSPE: 0.247277\n[450]   train's rmse: 0.00043416    train's RMSPE: 0.200154 valid's rmse: 0.000530067   valid's RMSPE: 0.247402\n[500]   train's rmse: 0.000429181   train's RMSPE: 0.197858 valid's rmse: 0.000529186   valid's RMSPE: 0.24699\n[550]   train's rmse: 0.000424933   train's RMSPE: 0.1959   valid's rmse: 0.000527102   valid's RMSPE: 0.246018\n[600]   train's rmse: 0.000420958   train's RMSPE: 0.194067 valid's rmse: 0.000525788   valid's RMSPE: 0.245404\n[650]   train's rmse: 0.000417588   train's RMSPE: 0.192514 valid's rmse: 0.000524409   valid's RMSPE: 0.244761\n[700]   train's rmse: 0.000414353   train's RMSPE: 0.191023 valid's rmse: 0.00052378    valid's RMSPE: 0.244467\n[750]   train's rmse: 0.000411174   train's RMSPE: 0.189557 valid's rmse: 0.000522802   valid's RMSPE: 0.244011\n[800]   train's rmse: 0.000407793   train's RMSPE: 0.187998 valid's rmse: 0.000521815   valid's RMSPE: 0.24355\n[850]   train's rmse: 0.000404801   train's RMSPE: 0.186619 valid's rmse: 0.000521591   valid's RMSPE: 0.243446\n[900]   train's rmse: 0.000401799   train's RMSPE: 0.185235 valid's rmse: 0.00051995    valid's RMSPE: 0.24268\n[950]   train's rmse: 0.000398998   train's RMSPE: 0.183944 valid's rmse: 0.000519095   valid's RMSPE: 0.24228\n[1000]  train's rmse: 0.000396138   train's RMSPE: 0.182625 valid's rmse: 0.000519466   valid's RMSPE: 0.242454\nEarly stopping, best iteration is:\n[955]   train's rmse: 0.000398694   train's RMSPE: 0.183804 valid's rmse: 0.000518858   valid's RMSPE: 0.24217\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000522691   train's RMSPE: 0.241194 valid's rmse: 0.000500253   valid's RMSPE: 0.232629\n[100]   train's rmse: 0.000496872   train's RMSPE: 0.22928  valid's rmse: 0.000479474   valid's RMSPE: 0.222966\n[150]   train's rmse: 0.000483818   train's RMSPE: 0.223256 valid's rmse: 0.000473498   valid's RMSPE: 0.220188\n[200]   train's rmse: 0.000473663   train's RMSPE: 0.21857  valid's rmse: 0.000470943   valid's RMSPE: 0.218999\n[250]   train's rmse: 0.000465423   train's RMSPE: 0.214768 valid's rmse: 0.000469391   valid's RMSPE: 0.218278\n[300]   train's rmse: 0.000458505   train's RMSPE: 0.211576 valid's rmse: 0.000469731   valid's RMSPE: 0.218436\nEarly stopping, best iteration is:\n[272]   train's rmse: 0.000462177   train's RMSPE: 0.21327  valid's rmse: 0.000468464   valid's RMSPE: 0.217847\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000521042   train's RMSPE: 0.241032 valid's rmse: 0.000518277   valid's RMSPE: 0.238633\n[100]   train's rmse: 0.000493491   train's RMSPE: 0.228286 valid's rmse: 0.000507818   valid's RMSPE: 0.233818\n[150]   train's rmse: 0.000481685   train's RMSPE: 0.222825 valid's rmse: 0.000506517   valid's RMSPE: 0.233219\n[200]   train's rmse: 0.000471486   train's RMSPE: 0.218107 valid's rmse: 0.000506149   valid's RMSPE: 0.233049\n[250]   train's rmse: 0.000463572   train's RMSPE: 0.214446 valid's rmse: 0.000504795   valid's RMSPE: 0.232426\n[300]   train's rmse: 0.000456354   train's RMSPE: 0.211107 valid's rmse: 0.000503055   valid's RMSPE: 0.231625\nEarly stopping, best iteration is:\n[289]   train's rmse: 0.0004576 train's RMSPE: 0.211684 valid's rmse: 0.000502711   valid's RMSPE: 0.231466\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000522361   train's RMSPE: 0.241591 valid's rmse: 0.000513421   valid's RMSPE: 0.236598\n[100]   train's rmse: 0.00049628    train's RMSPE: 0.229528 valid's rmse: 0.000496745   valid's RMSPE: 0.228913\n[150]   train's rmse: 0.000482765   train's RMSPE: 0.223278 valid's rmse: 0.000490285   valid's RMSPE: 0.225936\n[200]   train's rmse: 0.000472864   train's RMSPE: 0.218699 valid's rmse: 0.000488412   valid's RMSPE: 0.225073\n[250]   train's rmse: 0.000464073   train's RMSPE: 0.214633 valid's rmse: 0.000487121   valid's RMSPE: 0.224478\n[300]   train's rmse: 0.000456863   train's RMSPE: 0.211298 valid's rmse: 0.000485217   valid's RMSPE: 0.223601\n[350]   train's rmse: 0.000450551   train's RMSPE: 0.208379 valid's rmse: 0.000482647   valid's RMSPE: 0.222416\n[400]   train's rmse: 0.000444283   train's RMSPE: 0.20548  valid's rmse: 0.00048138    valid's RMSPE: 0.221832\n[450]   train's rmse: 0.000438156   train's RMSPE: 0.202646 valid's rmse: 0.000480165   valid's RMSPE: 0.221273\n[500]   train's rmse: 0.000433464   train's RMSPE: 0.200476 valid's rmse: 0.000479613   valid's RMSPE: 0.221018\nEarly stopping, best iteration is:\n[477]   train's rmse: 0.000435858   train's RMSPE: 0.201583 valid's rmse: 0.000479369   valid's RMSPE: 0.220906\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.229, compared to 0.1941653502859443, giving gain 0.0348346497140557\nOur cv fold scores are [0.232, 0.242, 0.218, 0.231, 0.221]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00121212    train's RMSPE: 0.27341  valid's rmse: 0.0014175 valid's RMSPE: 0.31535\n[100]   train's rmse: 0.00116106    train's RMSPE: 0.261892 valid's rmse: 0.00139045    valid's RMSPE: 0.309334\n[150]   train's rmse: 0.0011327 train's RMSPE: 0.255494 valid's rmse: 0.00139183    valid's RMSPE: 0.309641\nEarly stopping, best iteration is:\n[109]   train's rmse: 0.001156  train's RMSPE: 0.26075  valid's rmse: 0.00138726    valid's RMSPE: 0.308624\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00123601    train's RMSPE: 0.277175 valid's rmse: 0.00127804    valid's RMSPE: 0.29103\n[100]   train's rmse: 0.00117894    train's RMSPE: 0.264377 valid's rmse: 0.00125846    valid's RMSPE: 0.286571\n[150]   train's rmse: 0.00114875    train's RMSPE: 0.257607 valid's rmse: 0.0012541 valid's RMSPE: 0.28558\n[200]   train's rmse: 0.0011247 train's RMSPE: 0.252213 valid's rmse: 0.00125131    valid's RMSPE: 0.284944\n[250]   train's rmse: 0.0011016 train's RMSPE: 0.247034 valid's rmse: 0.00124068    valid's RMSPE: 0.282523\n[300]   train's rmse: 0.00108238    train's RMSPE: 0.242725 valid's rmse: 0.00123539    valid's RMSPE: 0.281319\n[350]   train's rmse: 0.00106562    train's RMSPE: 0.238966 valid's rmse: 0.00123244    valid's RMSPE: 0.280647\nEarly stopping, best iteration is:\n[332]   train's rmse: 0.00107157    train's RMSPE: 0.2403   valid's rmse: 0.00123023    valid's RMSPE: 0.280143\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00124766    train's RMSPE: 0.280951 valid's rmse: 0.00120655    valid's RMSPE: 0.270269\n[100]   train's rmse: 0.00119283    train's RMSPE: 0.268605 valid's rmse: 0.00118769    valid's RMSPE: 0.266046\n[150]   train's rmse: 0.00115673    train's RMSPE: 0.260475 valid's rmse: 0.00117915    valid's RMSPE: 0.264133\nEarly stopping, best iteration is:\n[148]   train's rmse: 0.00115815    train's RMSPE: 0.260797 valid's rmse: 0.00117827    valid's RMSPE: 0.263936\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00124413    train's RMSPE: 0.279006 valid's rmse: 0.00127038    valid's RMSPE: 0.289246\n[100]   train's rmse: 0.00118884    train's RMSPE: 0.266608 valid's rmse: 0.00125107    valid's RMSPE: 0.28485\n[150]   train's rmse: 0.00115573    train's RMSPE: 0.259181 valid's rmse: 0.00124254    valid's RMSPE: 0.282908\n[200]   train's rmse: 0.0011287 train's RMSPE: 0.253121 valid's rmse: 0.00123722    valid's RMSPE: 0.281696\n[250]   train's rmse: 0.00110761    train's RMSPE: 0.248391 valid's rmse: 0.00122969    valid's RMSPE: 0.279981\nEarly stopping, best iteration is:\n[234]   train's rmse: 0.00111411    train's RMSPE: 0.249848 valid's rmse: 0.00122877    valid's RMSPE: 0.279774\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00123855    train's RMSPE: 0.279269 valid's rmse: 0.00124188    valid's RMSPE: 0.276698\n[100]   train's rmse: 0.00117726    train's RMSPE: 0.265449 valid's rmse: 0.00123112    valid's RMSPE: 0.2743\n[150]   train's rmse: 0.0011406 train's RMSPE: 0.257183 valid's rmse: 0.00123193    valid's RMSPE: 0.27448\nEarly stopping, best iteration is:\n[126]   train's rmse: 0.0011578 train's RMSPE: 0.261062 valid's rmse: 0.00122925    valid's RMSPE: 0.273883\nOur out of folds RMSPE is 0.282, compared to 0.2661141171323659, giving gain 0.015885882867634094\nOur cv fold scores are [0.309, 0.28, 0.264, 0.28, 0.274]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000473624   train's RMSPE: 0.248436 valid's rmse: 0.000490458   valid's RMSPE: 0.256469\n[100]   train's rmse: 0.000450868   train's RMSPE: 0.2365   valid's rmse: 0.000473001   valid's RMSPE: 0.24734\n[150]   train's rmse: 0.000441001   train's RMSPE: 0.231325 valid's rmse: 0.000468413   valid's RMSPE: 0.244941\n[200]   train's rmse: 0.0004322 train's RMSPE: 0.226708 valid's rmse: 0.000465933   valid's RMSPE: 0.243644\nEarly stopping, best iteration is:\n[195]   train's rmse: 0.000432779   train's RMSPE: 0.227012 valid's rmse: 0.000465682   valid's RMSPE: 0.243513\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000471483   train's RMSPE: 0.247971 valid's rmse: 0.000512537   valid's RMSPE: 0.265128\n[100]   train's rmse: 0.0004481 train's RMSPE: 0.235673 valid's rmse: 0.000501623   valid's RMSPE: 0.259483\n[150]   train's rmse: 0.000437621   train's RMSPE: 0.230161 valid's rmse: 0.000496677   valid's RMSPE: 0.256924\n[200]   train's rmse: 0.000428756   train's RMSPE: 0.225499 valid's rmse: 0.000493929   valid's RMSPE: 0.255502\n[250]   train's rmse: 0.00042233    train's RMSPE: 0.222119 valid's rmse: 0.000493317   valid's RMSPE: 0.255186\n[300]   train's rmse: 0.000415843   train's RMSPE: 0.218707 valid's rmse: 0.000491041   valid's RMSPE: 0.254009\n[350]   train's rmse: 0.000410075   train's RMSPE: 0.215674 valid's rmse: 0.000490252   valid's RMSPE: 0.253601\n[400]   train's rmse: 0.000405327   train's RMSPE: 0.213177 valid's rmse: 0.000489291   valid's RMSPE: 0.253103\n[450]   train's rmse: 0.000401137   train's RMSPE: 0.210973 valid's rmse: 0.000490256   valid's RMSPE: 0.253603\nEarly stopping, best iteration is:\n[407]   train's rmse: 0.000404733   train's RMSPE: 0.212864 valid's rmse: 0.000489178   valid's RMSPE: 0.253045\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000479807   train's RMSPE: 0.250903 valid's rmse: 0.000466318   valid's RMSPE: 0.246852\n[100]   train's rmse: 0.000455484   train's RMSPE: 0.238184 valid's rmse: 0.00045884    valid's RMSPE: 0.242893\n[150]   train's rmse: 0.000443775   train's RMSPE: 0.232061 valid's rmse: 0.000456692   valid's RMSPE: 0.241756\n[200]   train's rmse: 0.000434865   train's RMSPE: 0.227402 valid's rmse: 0.000457387   valid's RMSPE: 0.242124\nEarly stopping, best iteration is:\n[167]   train's rmse: 0.000439945   train's RMSPE: 0.230058 valid's rmse: 0.000455344   valid's RMSPE: 0.241043\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00047802    train's RMSPE: 0.249662 valid's rmse: 0.000487006   valid's RMSPE: 0.25903\n[100]   train's rmse: 0.000453355   train's RMSPE: 0.23678  valid's rmse: 0.000467893   valid's RMSPE: 0.248865\n[150]   train's rmse: 0.00044361    train's RMSPE: 0.231691 valid's rmse: 0.000465544   valid's RMSPE: 0.247615\n[200]   train's rmse: 0.000435754   train's RMSPE: 0.227588 valid's rmse: 0.000464494   valid's RMSPE: 0.247057\n[250]   train's rmse: 0.000428603   train's RMSPE: 0.223853 valid's rmse: 0.000462918   valid's RMSPE: 0.246219\n[300]   train's rmse: 0.000422096   train's RMSPE: 0.220454 valid's rmse: 0.000461172   valid's RMSPE: 0.24529\n[350]   train's rmse: 0.000416235   train's RMSPE: 0.217393 valid's rmse: 0.000459158   valid's RMSPE: 0.244219\n[400]   train's rmse: 0.000411506   train's RMSPE: 0.214923 valid's rmse: 0.000459324   valid's RMSPE: 0.244307\n[450]   train's rmse: 0.000407049   train's RMSPE: 0.212596 valid's rmse: 0.000458507   valid's RMSPE: 0.243872\nEarly stopping, best iteration is:\n[433]   train's rmse: 0.000408708   train's RMSPE: 0.213462 valid's rmse: 0.000458174   valid's RMSPE: 0.243695\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000478852   train's RMSPE: 0.251586 valid's rmse: 0.000485159   valid's RMSPE: 0.252038\n[100]   train's rmse: 0.000456377   train's RMSPE: 0.239777 valid's rmse: 0.000471884   valid's RMSPE: 0.245141\n[150]   train's rmse: 0.000444948   train's RMSPE: 0.233772 valid's rmse: 0.000469155   valid's RMSPE: 0.243724\n[200]   train's rmse: 0.000435719   train's RMSPE: 0.228924 valid's rmse: 0.000465971   valid's RMSPE: 0.242069\n[250]   train's rmse: 0.00042888    train's RMSPE: 0.225331 valid's rmse: 0.000465388   valid's RMSPE: 0.241767\n[300]   train's rmse: 0.000422325   train's RMSPE: 0.221887 valid's rmse: 0.000464272   valid's RMSPE: 0.241187\n[350]   train's rmse: 0.00041678    train's RMSPE: 0.218973 valid's rmse: 0.000465631   valid's RMSPE: 0.241893\nEarly stopping, best iteration is:\n[318]   train's rmse: 0.000420318   train's RMSPE: 0.220832 valid's rmse: 0.000464113   valid's RMSPE: 0.241104\nOur out of folds RMSPE is 0.245, compared to 0.2057642320364516, giving gain 0.039235767963548385\nOur cv fold scores are [0.244, 0.253, 0.241, 0.244, 0.241]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000248786   train's RMSPE: 0.215369 valid's rmse: 0.000271734   valid's RMSPE: 0.238568\n[100]   train's rmse: 0.000232294   train's RMSPE: 0.201092 valid's rmse: 0.000257682   valid's RMSPE: 0.226231\n[150]   train's rmse: 0.000225665   train's RMSPE: 0.195353 valid's rmse: 0.000252378   valid's RMSPE: 0.221574\n[200]   train's rmse: 0.000221167   train's RMSPE: 0.191459 valid's rmse: 0.000250959   valid's RMSPE: 0.220329\n[250]   train's rmse: 0.000217874   train's RMSPE: 0.188609 valid's rmse: 0.000249193   valid's RMSPE: 0.218778\n[300]   train's rmse: 0.000214876   train's RMSPE: 0.186014 valid's rmse: 0.000247871   valid's RMSPE: 0.217617\n[350]   train's rmse: 0.000212475   train's RMSPE: 0.183935 valid's rmse: 0.000247221   valid's RMSPE: 0.217047\n[400]   train's rmse: 0.000210441   train's RMSPE: 0.182174 valid's rmse: 0.000246752   valid's RMSPE: 0.216634\n[450]   train's rmse: 0.000208473   train's RMSPE: 0.18047  valid's rmse: 0.00024672    valid's RMSPE: 0.216606\n[500]   train's rmse: 0.000206312   train's RMSPE: 0.1786   valid's rmse: 0.000246064   valid's RMSPE: 0.216031\n[550]   train's rmse: 0.000204213   train's RMSPE: 0.176783 valid's rmse: 0.000245143   valid's RMSPE: 0.215222\n[600]   train's rmse: 0.000202111   train's RMSPE: 0.174964 valid's rmse: 0.000244718   valid's RMSPE: 0.214849\n[650]   train's rmse: 0.000200457   train's RMSPE: 0.173531 valid's rmse: 0.000244197   valid's RMSPE: 0.214391\n[700]   train's rmse: 0.000198929   train's RMSPE: 0.172209 valid's rmse: 0.00024366    valid's RMSPE: 0.213921\n[750]   train's rmse: 0.000197442   train's RMSPE: 0.170921 valid's rmse: 0.000243314   valid's RMSPE: 0.213617\n[800]   train's rmse: 0.00019593    train's RMSPE: 0.169612 valid's rmse: 0.000243098   valid's RMSPE: 0.213427\n[850]   train's rmse: 0.000194457   train's RMSPE: 0.168337 valid's rmse: 0.000243259   valid's RMSPE: 0.213568\nEarly stopping, best iteration is:\n[821]   train's rmse: 0.000195292   train's RMSPE: 0.16906  valid's rmse: 0.000242992   valid's RMSPE: 0.213333\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000248691   train's RMSPE: 0.2143   valid's rmse: 0.000266124   valid's RMSPE: 0.237757\n[100]   train's rmse: 0.000231472   train's RMSPE: 0.199463 valid's rmse: 0.000251885   valid's RMSPE: 0.225036\n[150]   train's rmse: 0.0002254 train's RMSPE: 0.194231 valid's rmse: 0.00024812    valid's RMSPE: 0.221673\n[200]   train's rmse: 0.000220963   train's RMSPE: 0.190407 valid's rmse: 0.000246166   valid's RMSPE: 0.219926\n[250]   train's rmse: 0.000217696   train's RMSPE: 0.187592 valid's rmse: 0.000244828   valid's RMSPE: 0.218731\n[300]   train's rmse: 0.000214631   train's RMSPE: 0.18495  valid's rmse: 0.000243399   valid's RMSPE: 0.217454\n[350]   train's rmse: 0.000212025   train's RMSPE: 0.182705 valid's rmse: 0.000243081   valid's RMSPE: 0.21717\n[400]   train's rmse: 0.000209786   train's RMSPE: 0.180775 valid's rmse: 0.000242672   valid's RMSPE: 0.216805\n[450]   train's rmse: 0.000207477   train's RMSPE: 0.178786 valid's rmse: 0.000242039   valid's RMSPE: 0.216239\nEarly stopping, best iteration is:\n[425]   train's rmse: 0.000208511   train's RMSPE: 0.179677 valid's rmse: 0.000241778   valid's RMSPE: 0.216006\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000254411   train's RMSPE: 0.221016 valid's rmse: 0.00024132    valid's RMSPE: 0.208932\n[100]   train's rmse: 0.000236131   train's RMSPE: 0.205135 valid's rmse: 0.000228149   valid's RMSPE: 0.197528\n[150]   train's rmse: 0.000230733   train's RMSPE: 0.200445 valid's rmse: 0.00022641    valid's RMSPE: 0.196022\n[200]   train's rmse: 0.000226901   train's RMSPE: 0.197116 valid's rmse: 0.00022519    valid's RMSPE: 0.194967\n[250]   train's rmse: 0.000223782   train's RMSPE: 0.194407 valid's rmse: 0.000224741   valid's RMSPE: 0.194577\n[300]   train's rmse: 0.000221129   train's RMSPE: 0.192102 valid's rmse: 0.000224573   valid's RMSPE: 0.194432\n[350]   train's rmse: 0.000218603   train's RMSPE: 0.189908 valid's rmse: 0.000223615   valid's RMSPE: 0.193603\n[400]   train's rmse: 0.000216427   train's RMSPE: 0.188018 valid's rmse: 0.000223729   valid's RMSPE: 0.193701\n[450]   train's rmse: 0.000214145   train's RMSPE: 0.186035 valid's rmse: 0.000223391   valid's RMSPE: 0.193409\n[500]   train's rmse: 0.000212182   train's RMSPE: 0.184329 valid's rmse: 0.000223059   valid's RMSPE: 0.193122\n[550]   train's rmse: 0.000210149   train's RMSPE: 0.182564 valid's rmse: 0.000222775   valid's RMSPE: 0.192876\n[600]   train's rmse: 0.000208179   train's RMSPE: 0.180852 valid's rmse: 0.000222323   valid's RMSPE: 0.192484\n[650]   train's rmse: 0.00020648    train's RMSPE: 0.179376 valid's rmse: 0.000221952   valid's RMSPE: 0.192163\nEarly stopping, best iteration is:\n[612]   train's rmse: 0.00020781    train's RMSPE: 0.180532 valid's rmse: 0.000221835   valid's RMSPE: 0.192061\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000252984   train's RMSPE: 0.220628 valid's rmse: 0.000248828   valid's RMSPE: 0.212035\n[100]   train's rmse: 0.000235304   train's RMSPE: 0.205209 valid's rmse: 0.000233904   valid's RMSPE: 0.199318\n[150]   train's rmse: 0.000229846   train's RMSPE: 0.200449 valid's rmse: 0.000230084   valid's RMSPE: 0.196062\n[200]   train's rmse: 0.000225897   train's RMSPE: 0.197006 valid's rmse: 0.00022711    valid's RMSPE: 0.193528\n[250]   train's rmse: 0.000222964   train's RMSPE: 0.194447 valid's rmse: 0.000226232   valid's RMSPE: 0.19278\n[300]   train's rmse: 0.000220052   train's RMSPE: 0.191908 valid's rmse: 0.000224616   valid's RMSPE: 0.191403\n[350]   train's rmse: 0.000217186   train's RMSPE: 0.189409 valid's rmse: 0.000223813   valid's RMSPE: 0.190718\n[400]   train's rmse: 0.000214813   train's RMSPE: 0.187339 valid's rmse: 0.000223123   valid's RMSPE: 0.19013\n[450]   train's rmse: 0.000212588   train's RMSPE: 0.185399 valid's rmse: 0.000222855   valid's RMSPE: 0.189902\n[500]   train's rmse: 0.000210425   train's RMSPE: 0.183512 valid's rmse: 0.000222627   valid's RMSPE: 0.189708\n[550]   train's rmse: 0.000208609   train's RMSPE: 0.181928 valid's rmse: 0.000222421   valid's RMSPE: 0.189532\n[600]   train's rmse: 0.000206814   train's RMSPE: 0.180363 valid's rmse: 0.00022215    valid's RMSPE: 0.189302\n[650]   train's rmse: 0.000205171   train's RMSPE: 0.17893  valid's rmse: 0.000221987   valid's RMSPE: 0.189163\nEarly stopping, best iteration is:\n[632]   train's rmse: 0.000205779   train's RMSPE: 0.17946  valid's rmse: 0.000221852   valid's RMSPE: 0.189048\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000253122   train's RMSPE: 0.220836 valid's rmse: 0.000255566   valid's RMSPE: 0.217411\n[100]   train's rmse: 0.000235659   train's RMSPE: 0.205601 valid's rmse: 0.000242469   valid's RMSPE: 0.206269\n[150]   train's rmse: 0.000229598   train's RMSPE: 0.200313 valid's rmse: 0.000240242   valid's RMSPE: 0.204375\n[200]   train's rmse: 0.000225233   train's RMSPE: 0.196505 valid's rmse: 0.000239054   valid's RMSPE: 0.203365\n[250]   train's rmse: 0.00022147    train's RMSPE: 0.193222 valid's rmse: 0.000237821   valid's RMSPE: 0.202316\n[300]   train's rmse: 0.000218541   train's RMSPE: 0.190666 valid's rmse: 0.000237553   valid's RMSPE: 0.202088\nEarly stopping, best iteration is:\n[271]   train's rmse: 0.000220211   train's RMSPE: 0.192123 valid's rmse: 0.000237456   valid's RMSPE: 0.202005\nOur out of folds RMSPE is 0.203, compared to 0.17478725390050795, giving gain 0.028212746099492064\nOur cv fold scores are [0.213, 0.216, 0.192, 0.189, 0.202]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000690832   train's RMSPE: 0.289989 valid's rmse: 0.000763569   valid's RMSPE: 0.322017\n[100]   train's rmse: 0.000663163   train's RMSPE: 0.278375 valid's rmse: 0.000746924   valid's RMSPE: 0.314997\n[150]   train's rmse: 0.000647834   train's RMSPE: 0.27194  valid's rmse: 0.000743378   valid's RMSPE: 0.313502\n[200]   train's rmse: 0.000635305   train's RMSPE: 0.266681 valid's rmse: 0.000737699   valid's RMSPE: 0.311107\n[250]   train's rmse: 0.000625332   train's RMSPE: 0.262495 valid's rmse: 0.000737708   valid's RMSPE: 0.311111\n[300]   train's rmse: 0.000615935   train's RMSPE: 0.25855  valid's rmse: 0.000736753   valid's RMSPE: 0.310708\nEarly stopping, best iteration is:\n[278]   train's rmse: 0.000619826   train's RMSPE: 0.260183 valid's rmse: 0.000736159   valid's RMSPE: 0.310458\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000688508   train's RMSPE: 0.288444 valid's rmse: 0.000759902   valid's RMSPE: 0.322964\n[100]   train's rmse: 0.000659715   train's RMSPE: 0.276381 valid's rmse: 0.000749398   valid's RMSPE: 0.3185\nEarly stopping, best iteration is:\n[86]    train's rmse: 0.000664955   train's RMSPE: 0.278577 valid's rmse: 0.000749094   valid's RMSPE: 0.318371\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000706965   train's RMSPE: 0.295707 valid's rmse: 0.000684289   valid's RMSPE: 0.292612\n[100]   train's rmse: 0.000675875   train's RMSPE: 0.282703 valid's rmse: 0.000671272   valid's RMSPE: 0.287046\n[150]   train's rmse: 0.000660329   train's RMSPE: 0.2762   valid's rmse: 0.000668144   valid's RMSPE: 0.285709\n[200]   train's rmse: 0.000647167   train's RMSPE: 0.270695 valid's rmse: 0.000667939   valid's RMSPE: 0.285621\n[250]   train's rmse: 0.000635613   train's RMSPE: 0.265862 valid's rmse: 0.000667132   valid's RMSPE: 0.285276\n[300]   train's rmse: 0.000624982   train's RMSPE: 0.261415 valid's rmse: 0.000666077   valid's RMSPE: 0.284825\nEarly stopping, best iteration is:\n[273]   train's rmse: 0.000630414   train's RMSPE: 0.263687 valid's rmse: 0.000665048   valid's RMSPE: 0.284385\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000711571   train's RMSPE: 0.299744 valid's rmse: 0.000667515   valid's RMSPE: 0.277557\n[100]   train's rmse: 0.000681277   train's RMSPE: 0.286983 valid's rmse: 0.000658838   valid's RMSPE: 0.273949\n[150]   train's rmse: 0.000664825   train's RMSPE: 0.280052 valid's rmse: 0.000655814   valid's RMSPE: 0.272692\n[200]   train's rmse: 0.000652344   train's RMSPE: 0.274795 valid's rmse: 0.000652173   valid's RMSPE: 0.271178\n[250]   train's rmse: 0.000640346   train's RMSPE: 0.269741 valid's rmse: 0.000652518   valid's RMSPE: 0.271321\nEarly stopping, best iteration is:\n[205]   train's rmse: 0.000650817   train's RMSPE: 0.274152 valid's rmse: 0.000651393   valid's RMSPE: 0.270853\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000703194   train's RMSPE: 0.297143 valid's rmse: 0.000721825   valid's RMSPE: 0.296248\n[100]   train's rmse: 0.000674124   train's RMSPE: 0.284859 valid's rmse: 0.000707837   valid's RMSPE: 0.290507\n[150]   train's rmse: 0.000658236   train's RMSPE: 0.278145 valid's rmse: 0.000707051   valid's RMSPE: 0.290185\n[200]   train's rmse: 0.000645686   train's RMSPE: 0.272842 valid's rmse: 0.000706569   valid's RMSPE: 0.289987\nEarly stopping, best iteration is:\n[171]   train's rmse: 0.000652471   train's RMSPE: 0.275709 valid's rmse: 0.000705291   valid's RMSPE: 0.289462\nOur out of folds RMSPE is 0.295, compared to 0.25716377936657236, giving gain 0.03783622063342762\nOur cv fold scores are [0.31, 0.318, 0.284, 0.271, 0.289]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000614869   train's RMSPE: 0.441586 valid's rmse: 0.000764693   valid's RMSPE: 0.441167\n[100]   train's rmse: 0.000546937   train's RMSPE: 0.392799 valid's rmse: 0.000757734   valid's RMSPE: 0.437152\n[150]   train's rmse: 0.00051293    train's RMSPE: 0.368376 valid's rmse: 0.000750625   valid's RMSPE: 0.433051\nEarly stopping, best iteration is:\n[145]   train's rmse: 0.000514909   train's RMSPE: 0.369797 valid's rmse: 0.000749825   valid's RMSPE: 0.43259\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000601515   train's RMSPE: 0.419364 valid's rmse: 0.00116479    valid's RMSPE: 0.782863\nEarly stopping, best iteration is:\n[16]    train's rmse: 0.000776851   train's RMSPE: 0.541605 valid's rmse: 0.0010316 valid's RMSPE: 0.693344\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000647022   train's RMSPE: 0.447291 valid's rmse: 0.000658346   valid's RMSPE: 0.458176\n[100]   train's rmse: 0.000571828   train's RMSPE: 0.395309 valid's rmse: 0.0006871 valid's RMSPE: 0.478187\nEarly stopping, best iteration is:\n[53]    train's rmse: 0.000638903   train's RMSPE: 0.441678 valid's rmse: 0.000655376   valid's RMSPE: 0.456109\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000666162   train's RMSPE: 0.438449 valid's rmse: 0.000576003   valid's RMSPE: 0.469082\n[100]   train's rmse: 0.000594935   train's RMSPE: 0.391569 valid's rmse: 0.000554784   valid's RMSPE: 0.451802\nEarly stopping, best iteration is:\n[94]    train's rmse: 0.000603128   train's RMSPE: 0.396962 valid's rmse: 0.000547952   valid's RMSPE: 0.446238\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000658642   train's RMSPE: 0.457759 valid's rmse: 0.000670324   valid's RMSPE: 0.456534\nEarly stopping, best iteration is:\n[43]    train's rmse: 0.000670946   train's RMSPE: 0.46631  valid's rmse: 0.000666708   valid's RMSPE: 0.454071\nOur out of folds RMSPE is 0.506, compared to 0.5555796745804047, giving gain -0.04957967458040469\nOur cv fold scores are [0.433, 0.693, 0.456, 0.446, 0.454]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00039723    train's RMSPE: 0.226417 valid's rmse: 0.000439767   valid's RMSPE: 0.249683\n[100]   train's rmse: 0.000369055   train's RMSPE: 0.210358 valid's rmse: 0.000418914   valid's RMSPE: 0.237844\n[150]   train's rmse: 0.000359385   train's RMSPE: 0.204846 valid's rmse: 0.000414815   valid's RMSPE: 0.235516\n[200]   train's rmse: 0.000351331   train's RMSPE: 0.200255 valid's rmse: 0.00041314    valid's RMSPE: 0.234565\n[250]   train's rmse: 0.000344951   train's RMSPE: 0.196618 valid's rmse: 0.000411162   valid's RMSPE: 0.233442\n[300]   train's rmse: 0.000339402   train's RMSPE: 0.193455 valid's rmse: 0.00040962    valid's RMSPE: 0.232566\n[350]   train's rmse: 0.000334466   train's RMSPE: 0.190642 valid's rmse: 0.000409882   valid's RMSPE: 0.232716\nEarly stopping, best iteration is:\n[328]   train's rmse: 0.000336732   train's RMSPE: 0.191934 valid's rmse: 0.000409114   valid's RMSPE: 0.23228\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000402896   train's RMSPE: 0.228173 valid's rmse: 0.000423411   valid's RMSPE: 0.246517\n[100]   train's rmse: 0.000374615   train's RMSPE: 0.212157 valid's rmse: 0.00039617    valid's RMSPE: 0.230657\n[150]   train's rmse: 0.000363968   train's RMSPE: 0.206127 valid's rmse: 0.000390854   valid's RMSPE: 0.227562\n[200]   train's rmse: 0.000355846   train's RMSPE: 0.201527 valid's rmse: 0.000387348   valid's RMSPE: 0.22552\n[250]   train's rmse: 0.000349067   train's RMSPE: 0.197688 valid's rmse: 0.000384118   valid's RMSPE: 0.22364\n[300]   train's rmse: 0.000343017   train's RMSPE: 0.194262 valid's rmse: 0.000383293   valid's RMSPE: 0.223159\n[350]   train's rmse: 0.000337753   train's RMSPE: 0.191281 valid's rmse: 0.000381529   valid's RMSPE: 0.222132\n[400]   train's rmse: 0.000333333   train's RMSPE: 0.188778 valid's rmse: 0.000380727   valid's RMSPE: 0.221665\n[450]   train's rmse: 0.000329207   train's RMSPE: 0.186441 valid's rmse: 0.000379729   valid's RMSPE: 0.221084\n[500]   train's rmse: 0.000325146   train's RMSPE: 0.184141 valid's rmse: 0.000378746   valid's RMSPE: 0.220512\n[550]   train's rmse: 0.000321359   train's RMSPE: 0.181996 valid's rmse: 0.000379008   valid's RMSPE: 0.220664\nEarly stopping, best iteration is:\n[530]   train's rmse: 0.000323102   train's RMSPE: 0.182983 valid's rmse: 0.000378465   valid's RMSPE: 0.220348\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000405455   train's RMSPE: 0.230161 valid's rmse: 0.000386934   valid's RMSPE: 0.223268\n[100]   train's rmse: 0.00037835    train's RMSPE: 0.214774 valid's rmse: 0.000366542   valid's RMSPE: 0.211501\n[150]   train's rmse: 0.000367153   train's RMSPE: 0.208419 valid's rmse: 0.000362319   valid's RMSPE: 0.209065\n[200]   train's rmse: 0.000359099   train's RMSPE: 0.203847 valid's rmse: 0.000359321   valid's RMSPE: 0.207334\n[250]   train's rmse: 0.000352645   train's RMSPE: 0.200183 valid's rmse: 0.000358424   valid's RMSPE: 0.206817\n[300]   train's rmse: 0.000347163   train's RMSPE: 0.197071 valid's rmse: 0.000357344   valid's RMSPE: 0.206194\n[350]   train's rmse: 0.000341992   train's RMSPE: 0.194136 valid's rmse: 0.000356144   valid's RMSPE: 0.205502\n[400]   train's rmse: 0.00033734    train's RMSPE: 0.191495 valid's rmse: 0.000356351   valid's RMSPE: 0.205621\nEarly stopping, best iteration is:\n[355]   train's rmse: 0.000341555   train's RMSPE: 0.193887 valid's rmse: 0.000355747   valid's RMSPE: 0.205273\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000399879   train's RMSPE: 0.228842 valid's rmse: 0.000405203   valid's RMSPE: 0.226295\n[100]   train's rmse: 0.000370735   train's RMSPE: 0.212164 valid's rmse: 0.000392929   valid's RMSPE: 0.21944\n[150]   train's rmse: 0.000360031   train's RMSPE: 0.206038 valid's rmse: 0.000391477   valid's RMSPE: 0.218629\n[200]   train's rmse: 0.000351761   train's RMSPE: 0.201306 valid's rmse: 0.000388342   valid's RMSPE: 0.216878\n[250]   train's rmse: 0.000345449   train's RMSPE: 0.197693 valid's rmse: 0.000387485   valid's RMSPE: 0.216399\n[300]   train's rmse: 0.000339815   train's RMSPE: 0.194469 valid's rmse: 0.000385555   valid's RMSPE: 0.215322\n[350]   train's rmse: 0.000334853   train's RMSPE: 0.191629 valid's rmse: 0.000384336   valid's RMSPE: 0.214641\n[400]   train's rmse: 0.000330034   train's RMSPE: 0.188872 valid's rmse: 0.000383217   valid's RMSPE: 0.214016\n[450]   train's rmse: 0.000326632   train's RMSPE: 0.186925 valid's rmse: 0.000382196   valid's RMSPE: 0.213446\nEarly stopping, best iteration is:\n[446]   train's rmse: 0.00032685    train's RMSPE: 0.18705  valid's rmse: 0.000382023   valid's RMSPE: 0.213349\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000402398   train's RMSPE: 0.229946 valid's rmse: 0.000406105   valid's RMSPE: 0.228192\n[100]   train's rmse: 0.000375333   train's RMSPE: 0.21448  valid's rmse: 0.000385549   valid's RMSPE: 0.216642\n[150]   train's rmse: 0.000364505   train's RMSPE: 0.208293 valid's rmse: 0.000383036   valid's RMSPE: 0.21523\n[200]   train's rmse: 0.00035633    train's RMSPE: 0.203621 valid's rmse: 0.00038178    valid's RMSPE: 0.214524\n[250]   train's rmse: 0.00034964    train's RMSPE: 0.199798 valid's rmse: 0.000380764   valid's RMSPE: 0.213953\n[300]   train's rmse: 0.000343263   train's RMSPE: 0.196154 valid's rmse: 0.000378777   valid's RMSPE: 0.212836\n[350]   train's rmse: 0.000337913   train's RMSPE: 0.193097 valid's rmse: 0.000376702   valid's RMSPE: 0.21167\n[400]   train's rmse: 0.000333583   train's RMSPE: 0.190622 valid's rmse: 0.000375854   valid's RMSPE: 0.211194\nEarly stopping, best iteration is:\n[398]   train's rmse: 0.00033375    train's RMSPE: 0.190718 valid's rmse: 0.000375718   valid's RMSPE: 0.211117\nOur out of folds RMSPE is 0.217, compared to 0.1923845378320642, giving gain 0.02461546216793581\nOur cv fold scores are [0.232, 0.22, 0.205, 0.213, 0.211]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.0011175 train's RMSPE: 0.304442 valid's rmse: 0.00117706    valid's RMSPE: 0.311014\n[100]   train's rmse: 0.00106958    train's RMSPE: 0.291388 valid's rmse: 0.00115566    valid's RMSPE: 0.305359\n[150]   train's rmse: 0.0010402 train's RMSPE: 0.283383 valid's rmse: 0.00114694    valid's RMSPE: 0.303054\n[200]   train's rmse: 0.00101648    train's RMSPE: 0.276922 valid's rmse: 0.0011412 valid's RMSPE: 0.301537\n[250]   train's rmse: 0.000995729   train's RMSPE: 0.271268 valid's rmse: 0.00113983    valid's RMSPE: 0.301176\nEarly stopping, best iteration is:\n[242]   train's rmse: 0.000998485   train's RMSPE: 0.272019 valid's rmse: 0.0011387 valid's RMSPE: 0.300876\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.00111123    train's RMSPE: 0.299647 valid's rmse: 0.00116845    valid's RMSPE: 0.321783\n[100]   train's rmse: 0.00106458    train's RMSPE: 0.287067 valid's rmse: 0.00114916    valid's RMSPE: 0.316471\nEarly stopping, best iteration is:\n[90]    train's rmse: 0.00107092    train's RMSPE: 0.288776 valid's rmse: 0.00114808    valid's RMSPE: 0.316172\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00111825    train's RMSPE: 0.301841 valid's rmse: 0.00117597    valid's RMSPE: 0.322609\n[100]   train's rmse: 0.00107019    train's RMSPE: 0.288869 valid's rmse: 0.00116224    valid's RMSPE: 0.318843\n[150]   train's rmse: 0.00104097    train's RMSPE: 0.28098  valid's rmse: 0.00115831    valid's RMSPE: 0.317766\n[200]   train's rmse: 0.00101926    train's RMSPE: 0.275121 valid's rmse: 0.0011551 valid's RMSPE: 0.316884\n[250]   train's rmse: 0.000998883   train's RMSPE: 0.269621 valid's rmse: 0.00115509    valid's RMSPE: 0.316881\nEarly stopping, best iteration is:\n[223]   train's rmse: 0.00100991    train's RMSPE: 0.272597 valid's rmse: 0.00115152    valid's RMSPE: 0.315901\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00112694    train's RMSPE: 0.304311 valid's rmse: 0.0011462 valid's RMSPE: 0.313946\n[100]   train's rmse: 0.00107574    train's RMSPE: 0.290483 valid's rmse: 0.00113937    valid's RMSPE: 0.312078\nEarly stopping, best iteration is:\n[95]    train's rmse: 0.00107892    train's RMSPE: 0.291342 valid's rmse: 0.00113781    valid's RMSPE: 0.311648\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.00112118    train's RMSPE: 0.304964 valid's rmse: 0.00114648    valid's RMSPE: 0.304953\n[100]   train's rmse: 0.00107201    train's RMSPE: 0.291589 valid's rmse: 0.001127  valid's RMSPE: 0.299773\n[150]   train's rmse: 0.00104226    train's RMSPE: 0.283497 valid's rmse: 0.00112456    valid's RMSPE: 0.299123\n[200]   train's rmse: 0.00102055    train's RMSPE: 0.277591 valid's rmse: 0.00112023    valid's RMSPE: 0.297972\n[250]   train's rmse: 0.00100086    train's RMSPE: 0.272235 valid's rmse: 0.00112191    valid's RMSPE: 0.298418\n[300]   train's rmse: 0.000985378   train's RMSPE: 0.268025 valid's rmse: 0.00111947    valid's RMSPE: 0.297769\nEarly stopping, best iteration is:\n[281]   train's rmse: 0.000990801   train's RMSPE: 0.2695   valid's rmse: 0.00111786    valid's RMSPE: 0.297341\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.308, compared to 0.2867198191034136, giving gain 0.021280180896586398\nOur cv fold scores are [0.301, 0.316, 0.316, 0.312, 0.297]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000417942   train's RMSPE: 0.242059 valid's rmse: 0.000445869   valid's RMSPE: 0.257241\n[100]   train's rmse: 0.00040016    train's RMSPE: 0.23176  valid's rmse: 0.000431344   valid's RMSPE: 0.248861\n[150]   train's rmse: 0.000391543   train's RMSPE: 0.226769 valid's rmse: 0.000427086   valid's RMSPE: 0.246405\n[200]   train's rmse: 0.000384166   train's RMSPE: 0.222497 valid's rmse: 0.000424822   valid's RMSPE: 0.245099\n[250]   train's rmse: 0.000377458   train's RMSPE: 0.218612 valid's rmse: 0.000422495   valid's RMSPE: 0.243756\n[300]   train's rmse: 0.000372235   train's RMSPE: 0.215587 valid's rmse: 0.00042037    valid's RMSPE: 0.24253\n[350]   train's rmse: 0.00036736    train's RMSPE: 0.212763 valid's rmse: 0.000418507   valid's RMSPE: 0.241455\n[400]   train's rmse: 0.000363575   train's RMSPE: 0.210571 valid's rmse: 0.000417663   valid's RMSPE: 0.240968\n[450]   train's rmse: 0.000358973   train's RMSPE: 0.207906 valid's rmse: 0.000416549   valid's RMSPE: 0.240325\n[500]   train's rmse: 0.000354936   train's RMSPE: 0.205568 valid's rmse: 0.00041519    valid's RMSPE: 0.239541\n[550]   train's rmse: 0.000351251   train's RMSPE: 0.203434 valid's rmse: 0.000414363   valid's RMSPE: 0.239064\n[600]   train's rmse: 0.000347262   train's RMSPE: 0.201123 valid's rmse: 0.000413474   valid's RMSPE: 0.238551\n[650]   train's rmse: 0.000343936   train's RMSPE: 0.199197 valid's rmse: 0.000412601   valid's RMSPE: 0.238047\n[700]   train's rmse: 0.000340524   train's RMSPE: 0.197221 valid's rmse: 0.000412269   valid's RMSPE: 0.237856\n[750]   train's rmse: 0.00033753    train's RMSPE: 0.195487 valid's rmse: 0.000411725   valid's RMSPE: 0.237542\n[800]   train's rmse: 0.00033443    train's RMSPE: 0.193692 valid's rmse: 0.000411257   valid's RMSPE: 0.237272\nEarly stopping, best iteration is:\n[799]   train's rmse: 0.000334482   train's RMSPE: 0.193722 valid's rmse: 0.000411179   valid's RMSPE: 0.237227\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000416788   train's RMSPE: 0.241073 valid's rmse: 0.000445878   valid's RMSPE: 0.258606\n[100]   train's rmse: 0.000398077   train's RMSPE: 0.230251 valid's rmse: 0.000434007   valid's RMSPE: 0.251721\n[150]   train's rmse: 0.000388474   train's RMSPE: 0.224696 valid's rmse: 0.000430368   valid's RMSPE: 0.24961\n[200]   train's rmse: 0.000381385   train's RMSPE: 0.220596 valid's rmse: 0.000428261   valid's RMSPE: 0.248388\n[250]   train's rmse: 0.000375034   train's RMSPE: 0.216922 valid's rmse: 0.000426926   valid's RMSPE: 0.247614\n[300]   train's rmse: 0.00036994    train's RMSPE: 0.213976 valid's rmse: 0.000426173   valid's RMSPE: 0.247177\n[350]   train's rmse: 0.000364936   train's RMSPE: 0.211081 valid's rmse: 0.000424211   valid's RMSPE: 0.246039\n[400]   train's rmse: 0.000360471   train's RMSPE: 0.208499 valid's rmse: 0.000423409   valid's RMSPE: 0.245574\n[450]   train's rmse: 0.00035672    train's RMSPE: 0.20633  valid's rmse: 0.000422035   valid's RMSPE: 0.244777\n[500]   train's rmse: 0.000352741   train's RMSPE: 0.204028 valid's rmse: 0.000421127   valid's RMSPE: 0.24425\n[550]   train's rmse: 0.000348868   train's RMSPE: 0.201788 valid's rmse: 0.000420472   valid's RMSPE: 0.243871\n[600]   train's rmse: 0.000345328   train's RMSPE: 0.19974  valid's rmse: 0.000420137   valid's RMSPE: 0.243676\n[650]   train's rmse: 0.000341883   train's RMSPE: 0.197747 valid's rmse: 0.000418918   valid's RMSPE: 0.24297\n[700]   train's rmse: 0.000338069   train's RMSPE: 0.195541 valid's rmse: 0.000417985   valid's RMSPE: 0.242428\n[750]   train's rmse: 0.000335019   train's RMSPE: 0.193777 valid's rmse: 0.000417463   valid's RMSPE: 0.242125\n[800]   train's rmse: 0.000332661   train's RMSPE: 0.192413 valid's rmse: 0.000416665   valid's RMSPE: 0.241663\n[850]   train's rmse: 0.00033022    train's RMSPE: 0.191002 valid's rmse: 0.000415868   valid's RMSPE: 0.241201\n[900]   train's rmse: 0.000327855   train's RMSPE: 0.189634 valid's rmse: 0.000415387   valid's RMSPE: 0.240921\nEarly stopping, best iteration is:\n[886]   train's rmse: 0.000328412   train's RMSPE: 0.189956 valid's rmse: 0.000415224   valid's RMSPE: 0.240827\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00042349    train's RMSPE: 0.244181 valid's rmse: 0.000411397   valid's RMSPE: 0.241563\n[100]   train's rmse: 0.000404399   train's RMSPE: 0.233173 valid's rmse: 0.000399507   valid's RMSPE: 0.234582\n[150]   train's rmse: 0.00039646    train's RMSPE: 0.228596 valid's rmse: 0.000399502   valid's RMSPE: 0.234579\n[200]   train's rmse: 0.000388574   train's RMSPE: 0.224049 valid's rmse: 0.000398456   valid's RMSPE: 0.233964\n[250]   train's rmse: 0.00038214    train's RMSPE: 0.220339 valid's rmse: 0.000399302   valid's RMSPE: 0.234461\nEarly stopping, best iteration is:\n[236]   train's rmse: 0.000383407   train's RMSPE: 0.221069 valid's rmse: 0.000397808   valid's RMSPE: 0.233584\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000426107   train's RMSPE: 0.246845 valid's rmse: 0.000406535   valid's RMSPE: 0.234329\n[100]   train's rmse: 0.000407051   train's RMSPE: 0.235806 valid's rmse: 0.000396857   valid's RMSPE: 0.228751\n[150]   train's rmse: 0.000397979   train's RMSPE: 0.23055  valid's rmse: 0.000396006   valid's RMSPE: 0.228261\n[200]   train's rmse: 0.000390013   train's RMSPE: 0.225936 valid's rmse: 0.000393931   valid's RMSPE: 0.227065\n[250]   train's rmse: 0.000383496   train's RMSPE: 0.22216  valid's rmse: 0.000392614   valid's RMSPE: 0.226305\n[300]   train's rmse: 0.000377878   train's RMSPE: 0.218906 valid's rmse: 0.000392372   valid's RMSPE: 0.226166\n[350]   train's rmse: 0.000373446   train's RMSPE: 0.216338 valid's rmse: 0.000392922   valid's RMSPE: 0.226483\nEarly stopping, best iteration is:\n[303]   train's rmse: 0.000377604   train's RMSPE: 0.218747 valid's rmse: 0.000392058   valid's RMSPE: 0.225985\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00042068    train's RMSPE: 0.244056 valid's rmse: 0.000433792   valid's RMSPE: 0.248564\n[100]   train's rmse: 0.000402341   train's RMSPE: 0.233417 valid's rmse: 0.000421603   valid's RMSPE: 0.24158\n[150]   train's rmse: 0.000394481   train's RMSPE: 0.228856 valid's rmse: 0.000419888   valid's RMSPE: 0.240597\n[200]   train's rmse: 0.000386905   train's RMSPE: 0.224461 valid's rmse: 0.000417157   valid's RMSPE: 0.239032\n[250]   train's rmse: 0.000381181   train's RMSPE: 0.221141 valid's rmse: 0.000415899   valid's RMSPE: 0.238312\n[300]   train's rmse: 0.000375316   train's RMSPE: 0.217738 valid's rmse: 0.000414409   valid's RMSPE: 0.237458\n[350]   train's rmse: 0.00037034    train's RMSPE: 0.214851 valid's rmse: 0.000412873   valid's RMSPE: 0.236578\n[400]   train's rmse: 0.000365805   train's RMSPE: 0.21222  valid's rmse: 0.000411412   valid's RMSPE: 0.23574\n[450]   train's rmse: 0.000361803   train's RMSPE: 0.209899 valid's rmse: 0.000412677   valid's RMSPE: 0.236465\nEarly stopping, best iteration is:\n[409]   train's rmse: 0.000364936   train's RMSPE: 0.211716 valid's rmse: 0.000410972   valid's RMSPE: 0.235488\nOur out of folds RMSPE is 0.235, compared to 0.18658038014822179, giving gain 0.0484196198517782\nOur cv fold scores are [0.237, 0.241, 0.234, 0.226, 0.235]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000446344   train's RMSPE: 0.218843 valid's rmse: 0.000476402   valid's RMSPE: 0.234381\n[100]   train's rmse: 0.000417835   train's RMSPE: 0.204865 valid's rmse: 0.000453947   valid's RMSPE: 0.223334\n[150]   train's rmse: 0.000406005   train's RMSPE: 0.199065 valid's rmse: 0.000447468   valid's RMSPE: 0.220146\n[200]   train's rmse: 0.000396539   train's RMSPE: 0.194424 valid's rmse: 0.000443771   valid's RMSPE: 0.218327\n[250]   train's rmse: 0.000389794   train's RMSPE: 0.191117 valid's rmse: 0.000441542   valid's RMSPE: 0.217231\n[300]   train's rmse: 0.000383058   train's RMSPE: 0.187814 valid's rmse: 0.000439806   valid's RMSPE: 0.216376\n[350]   train's rmse: 0.000376519   train's RMSPE: 0.184608 valid's rmse: 0.000436031   valid's RMSPE: 0.214519\n[400]   train's rmse: 0.000371895   train's RMSPE: 0.182341 valid's rmse: 0.000433654   valid's RMSPE: 0.213349\n[450]   train's rmse: 0.000366016   train's RMSPE: 0.179458 valid's rmse: 0.000433619   valid's RMSPE: 0.213333\n[500]   train's rmse: 0.000361721   train's RMSPE: 0.177352 valid's rmse: 0.000431966   valid's RMSPE: 0.21252\n[550]   train's rmse: 0.000357701   train's RMSPE: 0.175381 valid's rmse: 0.000430264   valid's RMSPE: 0.211682\n[600]   train's rmse: 0.00035355    train's RMSPE: 0.173346 valid's rmse: 0.000428168   valid's RMSPE: 0.210651\n[650]   train's rmse: 0.000349589   train's RMSPE: 0.171404 valid's rmse: 0.000427023   valid's RMSPE: 0.210088\n[700]   train's rmse: 0.000346183   train's RMSPE: 0.169734 valid's rmse: 0.000425777   valid's RMSPE: 0.209475\n[750]   train's rmse: 0.000342831   train's RMSPE: 0.16809  valid's rmse: 0.000425205   valid's RMSPE: 0.209193\n[800]   train's rmse: 0.000339932   train's RMSPE: 0.166669 valid's rmse: 0.000424385   valid's RMSPE: 0.208789\n[850]   train's rmse: 0.000336988   train's RMSPE: 0.165226 valid's rmse: 0.000424013   valid's RMSPE: 0.208606\n[900]   train's rmse: 0.000334425   train's RMSPE: 0.163969 valid's rmse: 0.000424357   valid's RMSPE: 0.208776\nEarly stopping, best iteration is:\n[873]   train's rmse: 0.000335731   train's RMSPE: 0.16461  valid's rmse: 0.000423619   valid's RMSPE: 0.208413\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000442589   train's RMSPE: 0.216954 valid's rmse: 0.000481789   valid's RMSPE: 0.237241\n[100]   train's rmse: 0.000414509   train's RMSPE: 0.203189 valid's rmse: 0.000463327   valid's RMSPE: 0.228151\n[150]   train's rmse: 0.000403039   train's RMSPE: 0.197567 valid's rmse: 0.000456519   valid's RMSPE: 0.224798\n[200]   train's rmse: 0.000394344   train's RMSPE: 0.193304 valid's rmse: 0.000451963   valid's RMSPE: 0.222554\n[250]   train's rmse: 0.00038743    train's RMSPE: 0.189915 valid's rmse: 0.000449032   valid's RMSPE: 0.221111\n[300]   train's rmse: 0.0003807 train's RMSPE: 0.186616 valid's rmse: 0.000445178   valid's RMSPE: 0.219213\n[350]   train's rmse: 0.000374966   train's RMSPE: 0.183806 valid's rmse: 0.000443249   valid's RMSPE: 0.218263\n[400]   train's rmse: 0.000369799   train's RMSPE: 0.181273 valid's rmse: 0.000441243   valid's RMSPE: 0.217276\n[450]   train's rmse: 0.000365105   train's RMSPE: 0.178971 valid's rmse: 0.000439255   valid's RMSPE: 0.216297\n[500]   train's rmse: 0.000360607   train's RMSPE: 0.176767 valid's rmse: 0.000437633   valid's RMSPE: 0.215498\n[550]   train's rmse: 0.000356986   train's RMSPE: 0.174992 valid's rmse: 0.000436627   valid's RMSPE: 0.215003\n[600]   train's rmse: 0.000352849   train's RMSPE: 0.172964 valid's rmse: 0.000434361   valid's RMSPE: 0.213887\n[650]   train's rmse: 0.000349375   train's RMSPE: 0.171261 valid's rmse: 0.000433866   valid's RMSPE: 0.213643\n[700]   train's rmse: 0.000346109   train's RMSPE: 0.16966  valid's rmse: 0.000433359   valid's RMSPE: 0.213394\n[750]   train's rmse: 0.000342729   train's RMSPE: 0.168003 valid's rmse: 0.000431179   valid's RMSPE: 0.21232\n[800]   train's rmse: 0.000339584   train's RMSPE: 0.166462 valid's rmse: 0.000430392   valid's RMSPE: 0.211933\nEarly stopping, best iteration is:\n[778]   train's rmse: 0.000340892   train's RMSPE: 0.167102 valid's rmse: 0.00043006    valid's RMSPE: 0.211769\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000451291   train's RMSPE: 0.221319 valid's rmse: 0.000435711   valid's RMSPE: 0.214168\n[100]   train's rmse: 0.000421945   train's RMSPE: 0.206927 valid's rmse: 0.00041421    valid's RMSPE: 0.203599\n[150]   train's rmse: 0.00040955    train's RMSPE: 0.200849 valid's rmse: 0.000408239   valid's RMSPE: 0.200664\n[200]   train's rmse: 0.000399516   train's RMSPE: 0.195928 valid's rmse: 0.00040293    valid's RMSPE: 0.198055\n[250]   train's rmse: 0.000391941   train's RMSPE: 0.192213 valid's rmse: 0.000400605   valid's RMSPE: 0.196912\n[300]   train's rmse: 0.000385581   train's RMSPE: 0.189094 valid's rmse: 0.000399063   valid's RMSPE: 0.196154\n[350]   train's rmse: 0.000380271   train's RMSPE: 0.18649  valid's rmse: 0.000398977   valid's RMSPE: 0.196112\n[400]   train's rmse: 0.000374882   train's RMSPE: 0.183847 valid's rmse: 0.000398129   valid's RMSPE: 0.195695\n[450]   train's rmse: 0.000369822   train's RMSPE: 0.181366 valid's rmse: 0.000397197   valid's RMSPE: 0.195237\n[500]   train's rmse: 0.000365765   train's RMSPE: 0.179376 valid's rmse: 0.000396422   valid's RMSPE: 0.194856\n[550]   train's rmse: 0.000361797   train's RMSPE: 0.17743  valid's rmse: 0.000396363   valid's RMSPE: 0.194827\nEarly stopping, best iteration is:\n[508]   train's rmse: 0.000365096   train's RMSPE: 0.179048 valid's rmse: 0.00039628    valid's RMSPE: 0.194786\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000455365   train's RMSPE: 0.223326 valid's rmse: 0.000433018   valid's RMSPE: 0.21281\n[100]   train's rmse: 0.000426077   train's RMSPE: 0.208962 valid's rmse: 0.000410157   valid's RMSPE: 0.201575\n[150]   train's rmse: 0.000413755   train's RMSPE: 0.202919 valid's rmse: 0.000403949   valid's RMSPE: 0.198524\n[200]   train's rmse: 0.000405443   train's RMSPE: 0.198843 valid's rmse: 0.000401512   valid's RMSPE: 0.197327\n[250]   train's rmse: 0.000398068   train's RMSPE: 0.195226 valid's rmse: 0.000398827   valid's RMSPE: 0.196007\n[300]   train's rmse: 0.000391417   train's RMSPE: 0.191964 valid's rmse: 0.00039782    valid's RMSPE: 0.195512\n[350]   train's rmse: 0.000386055   train's RMSPE: 0.189334 valid's rmse: 0.000396077   valid's RMSPE: 0.194656\n[400]   train's rmse: 0.000380402   train's RMSPE: 0.186561 valid's rmse: 0.000392823   valid's RMSPE: 0.193057\n[450]   train's rmse: 0.000375122   train's RMSPE: 0.183972 valid's rmse: 0.000391623   valid's RMSPE: 0.192467\n[500]   train's rmse: 0.000371157   train's RMSPE: 0.182028 valid's rmse: 0.000391563   valid's RMSPE: 0.192437\nEarly stopping, best iteration is:\n[490]   train's rmse: 0.000371854   train's RMSPE: 0.182369 valid's rmse: 0.000391245   valid's RMSPE: 0.192281\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000450345   train's RMSPE: 0.221502 valid's rmse: 0.000466906   valid's RMSPE: 0.226806\n[100]   train's rmse: 0.000422108   train's RMSPE: 0.207613 valid's rmse: 0.000442206   valid's RMSPE: 0.214808\n[150]   train's rmse: 0.000410842   train's RMSPE: 0.202072 valid's rmse: 0.00043617    valid's RMSPE: 0.211876\n[200]   train's rmse: 0.00040189    train's RMSPE: 0.197669 valid's rmse: 0.000431385   valid's RMSPE: 0.209552\n[250]   train's rmse: 0.00039435    train's RMSPE: 0.193961 valid's rmse: 0.000428592   valid's RMSPE: 0.208195\n[300]   train's rmse: 0.000388214   train's RMSPE: 0.190942 valid's rmse: 0.000427098   valid's RMSPE: 0.207469\n[350]   train's rmse: 0.000382148   train's RMSPE: 0.187959 valid's rmse: 0.000425249   valid's RMSPE: 0.206571\n[400]   train's rmse: 0.000377317   train's RMSPE: 0.185583 valid's rmse: 0.000424829   valid's RMSPE: 0.206367\n[450]   train's rmse: 0.000372493   train's RMSPE: 0.18321  valid's rmse: 0.000424056   valid's RMSPE: 0.205991\n[500]   train's rmse: 0.00036765    train's RMSPE: 0.180828 valid's rmse: 0.000422307   valid's RMSPE: 0.205141\n[550]   train's rmse: 0.000363568   train's RMSPE: 0.178821 valid's rmse: 0.000421682   valid's RMSPE: 0.204838\n[600]   train's rmse: 0.000359786   train's RMSPE: 0.17696  valid's rmse: 0.00042086    valid's RMSPE: 0.204439\nEarly stopping, best iteration is:\n[585]   train's rmse: 0.000360964   train's RMSPE: 0.177539 valid's rmse: 0.000420713   valid's RMSPE: 0.204367\nOur out of folds RMSPE is 0.202, compared to 0.16995311675322403, giving gain 0.03204688324677599\nOur cv fold scores are [0.208, 0.212, 0.195, 0.192, 0.204]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000510245   train's RMSPE: 0.208969 valid's rmse: 0.000554907   valid's RMSPE: 0.226135\n[100]   train's rmse: 0.000485833   train's RMSPE: 0.198971 valid's rmse: 0.000533288   valid's RMSPE: 0.217325\n[150]   train's rmse: 0.000474737   train's RMSPE: 0.194427 valid's rmse: 0.000529576   valid's RMSPE: 0.215813\n[200]   train's rmse: 0.000465351   train's RMSPE: 0.190583 valid's rmse: 0.000526653   valid's RMSPE: 0.214621\n[250]   train's rmse: 0.000457885   train's RMSPE: 0.187525 valid's rmse: 0.000524208   valid's RMSPE: 0.213625\n[300]   train's rmse: 0.000450833   train's RMSPE: 0.184637 valid's rmse: 0.000524202   valid's RMSPE: 0.213622\n[350]   train's rmse: 0.000444406   train's RMSPE: 0.182005 valid's rmse: 0.000524495   valid's RMSPE: 0.213742\nEarly stopping, best iteration is:\n[306]   train's rmse: 0.000449979   train's RMSPE: 0.184287 valid's rmse: 0.000523719   valid's RMSPE: 0.213425\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000509038   train's RMSPE: 0.207649 valid's rmse: 0.000551159   valid's RMSPE: 0.228167\n[100]   train's rmse: 0.00048366    train's RMSPE: 0.197296 valid's rmse: 0.000527558   valid's RMSPE: 0.218397\n[150]   train's rmse: 0.000472599   train's RMSPE: 0.192784 valid's rmse: 0.000522067   valid's RMSPE: 0.216124\n[200]   train's rmse: 0.000463758   train's RMSPE: 0.189178 valid's rmse: 0.000520127   valid's RMSPE: 0.21532\n[250]   train's rmse: 0.000456442   train's RMSPE: 0.186193 valid's rmse: 0.000518663   valid's RMSPE: 0.214715\n[300]   train's rmse: 0.000449743   train's RMSPE: 0.183461 valid's rmse: 0.000517252   valid's RMSPE: 0.21413\n[350]   train's rmse: 0.000443263   train's RMSPE: 0.180817 valid's rmse: 0.000516569   valid's RMSPE: 0.213848\n[400]   train's rmse: 0.000438167   train's RMSPE: 0.178738 valid's rmse: 0.000515116   valid's RMSPE: 0.213246\n[450]   train's rmse: 0.000433207   train's RMSPE: 0.176715 valid's rmse: 0.000515223   valid's RMSPE: 0.21329\n[500]   train's rmse: 0.000428689   train's RMSPE: 0.174872 valid's rmse: 0.000514596   valid's RMSPE: 0.213031\nEarly stopping, best iteration is:\n[492]   train's rmse: 0.000429376   train's RMSPE: 0.175153 valid's rmse: 0.000514194   valid's RMSPE: 0.212864\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000517757   train's RMSPE: 0.21227  valid's rmse: 0.000497619   valid's RMSPE: 0.201919\n[100]   train's rmse: 0.000490622   train's RMSPE: 0.201145 valid's rmse: 0.000482214   valid's RMSPE: 0.195668\n[150]   train's rmse: 0.000479304   train's RMSPE: 0.196505 valid's rmse: 0.000480532   valid's RMSPE: 0.194986\n[200]   train's rmse: 0.000470325   train's RMSPE: 0.192824 valid's rmse: 0.000480268   valid's RMSPE: 0.194879\n[250]   train's rmse: 0.00046261    train's RMSPE: 0.189661 valid's rmse: 0.000480065   valid's RMSPE: 0.194796\n[300]   train's rmse: 0.000455978   train's RMSPE: 0.186942 valid's rmse: 0.00047842    valid's RMSPE: 0.194129\n[350]   train's rmse: 0.000450297   train's RMSPE: 0.184613 valid's rmse: 0.00047778    valid's RMSPE: 0.193869\nEarly stopping, best iteration is:\n[347]   train's rmse: 0.000450675   train's RMSPE: 0.184768 valid's rmse: 0.000477496   valid's RMSPE: 0.193754\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000517935   train's RMSPE: 0.211657 valid's rmse: 0.000500252   valid's RMSPE: 0.205644\n[100]   train's rmse: 0.000491913   train's RMSPE: 0.201023 valid's rmse: 0.000487488   valid's RMSPE: 0.200397\n[150]   train's rmse: 0.000481308   train's RMSPE: 0.196689 valid's rmse: 0.000485263   valid's RMSPE: 0.199482\n[200]   train's rmse: 0.000471858   train's RMSPE: 0.192827 valid's rmse: 0.000484973   valid's RMSPE: 0.199363\nEarly stopping, best iteration is:\n[169]   train's rmse: 0.000477301   train's RMSPE: 0.195052 valid's rmse: 0.000484481   valid's RMSPE: 0.199161\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000513214   train's RMSPE: 0.210212 valid's rmse: 0.000524501   valid's RMSPE: 0.213632\n[100]   train's rmse: 0.000485449   train's RMSPE: 0.198839 valid's rmse: 0.000516254   valid's RMSPE: 0.210273\n[150]   train's rmse: 0.000473543   train's RMSPE: 0.193963 valid's rmse: 0.0005196 valid's RMSPE: 0.211636\nEarly stopping, best iteration is:\n[120]   train's rmse: 0.000480258   train's RMSPE: 0.196713 valid's rmse: 0.0005154 valid's RMSPE: 0.209926\nOur out of folds RMSPE is 0.206, compared to 0.18527433835243848, giving gain 0.02072566164756151\nOur cv fold scores are [0.213, 0.213, 0.194, 0.199, 0.21]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00132234    train's RMSPE: 0.303079 valid's rmse: 0.00136657    valid's RMSPE: 0.320983\n[100]   train's rmse: 0.00126374    train's RMSPE: 0.289647 valid's rmse: 0.00135468    valid's RMSPE: 0.318192\n[150]   train's rmse: 0.0012242 train's RMSPE: 0.280585 valid's rmse: 0.00134842    valid's RMSPE: 0.316719\nEarly stopping, best iteration is:\n[129]   train's rmse: 0.00124003    train's RMSPE: 0.284213 valid's rmse: 0.00134588    valid's RMSPE: 0.316123\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00131211    train's RMSPE: 0.301431 valid's rmse: 0.00144151    valid's RMSPE: 0.335587\n[100]   train's rmse: 0.00125864    train's RMSPE: 0.289145 valid's rmse: 0.00141549    valid's RMSPE: 0.329529\n[150]   train's rmse: 0.00122255    train's RMSPE: 0.280854 valid's rmse: 0.00140551    valid's RMSPE: 0.327206\n[200]   train's rmse: 0.00119214    train's RMSPE: 0.273869 valid's rmse: 0.00140189    valid's RMSPE: 0.326364\n[250]   train's rmse: 0.0011656 train's RMSPE: 0.267772 valid's rmse: 0.0014019 valid's RMSPE: 0.326366\nEarly stopping, best iteration is:\n[205]   train's rmse: 0.0011893 train's RMSPE: 0.273216 valid's rmse: 0.00139994    valid's RMSPE: 0.325908\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00131533    train's RMSPE: 0.303011 valid's rmse: 0.00137633    valid's RMSPE: 0.316911\n[100]   train's rmse: 0.00125301    train's RMSPE: 0.288655 valid's rmse: 0.00136538    valid's RMSPE: 0.31439\n[150]   train's rmse: 0.00121009    train's RMSPE: 0.278767 valid's rmse: 0.00137057    valid's RMSPE: 0.315584\nEarly stopping, best iteration is:\n[105]   train's rmse: 0.00124759    train's RMSPE: 0.287406 valid's rmse: 0.00136383    valid's RMSPE: 0.314034\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.0013307 train's RMSPE: 0.305694 valid's rmse: 0.00134207    valid's RMSPE: 0.31246\n[100]   train's rmse: 0.00127379    train's RMSPE: 0.292622 valid's rmse: 0.00131196    valid's RMSPE: 0.305451\n[150]   train's rmse: 0.00123701    train's RMSPE: 0.284171 valid's rmse: 0.0013074 valid's RMSPE: 0.304389\n[200]   train's rmse: 0.00120723    train's RMSPE: 0.27733  valid's rmse: 0.00131055    valid's RMSPE: 0.305122\nEarly stopping, best iteration is:\n[162]   train's rmse: 0.00122894    train's RMSPE: 0.282318 valid's rmse: 0.00130525    valid's RMSPE: 0.303888\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00132626    train's RMSPE: 0.308617 valid's rmse: 0.00134424    valid's RMSPE: 0.296673\n[100]   train's rmse: 0.00126559    train's RMSPE: 0.294498 valid's rmse: 0.00134179    valid's RMSPE: 0.296131\nEarly stopping, best iteration is:\n[71]    train's rmse: 0.00129631    train's RMSPE: 0.301647 valid's rmse: 0.00133786    valid's RMSPE: 0.295264\nOur out of folds RMSPE is 0.311, compared to 0.29956908631074286, giving gain 0.011430913689257138\nOur cv fold scores are [0.316, 0.326, 0.314, 0.304, 0.295]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000827845   train's RMSPE: 0.263586 valid's rmse: 0.000876612   valid's RMSPE: 0.279166\n[100]   train's rmse: 0.000788547   train's RMSPE: 0.251073 valid's rmse: 0.000859402   valid's RMSPE: 0.273686\n[150]   train's rmse: 0.000766807   train's RMSPE: 0.244151 valid's rmse: 0.00085265    valid's RMSPE: 0.271535\n[200]   train's rmse: 0.0007509 train's RMSPE: 0.239086 valid's rmse: 0.000851763   valid's RMSPE: 0.271253\n[250]   train's rmse: 0.000736839   train's RMSPE: 0.234609 valid's rmse: 0.000851255   valid's RMSPE: 0.271091\n[300]   train's rmse: 0.000723966   train's RMSPE: 0.23051  valid's rmse: 0.000849551   valid's RMSPE: 0.270549\n[350]   train's rmse: 0.000712837   train's RMSPE: 0.226967 valid's rmse: 0.000849703   valid's RMSPE: 0.270597\nEarly stopping, best iteration is:\n[314]   train's rmse: 0.00072093    train's RMSPE: 0.229544 valid's rmse: 0.00084856    valid's RMSPE: 0.270233\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000832168   train's RMSPE: 0.264929 valid's rmse: 0.000870116   valid's RMSPE: 0.277235\n[100]   train's rmse: 0.000793867   train's RMSPE: 0.252736 valid's rmse: 0.00084072    valid's RMSPE: 0.267869\n[150]   train's rmse: 0.000773728   train's RMSPE: 0.246324 valid's rmse: 0.000833545   valid's RMSPE: 0.265583\n[200]   train's rmse: 0.000757768   train's RMSPE: 0.241243 valid's rmse: 0.000833455   valid's RMSPE: 0.265554\nEarly stopping, best iteration is:\n[155]   train's rmse: 0.000772052   train's RMSPE: 0.24579  valid's rmse: 0.00083201    valid's RMSPE: 0.265094\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000831619   train's RMSPE: 0.264806 valid's rmse: 0.00086984    valid's RMSPE: 0.276931\n[100]   train's rmse: 0.000794497   train's RMSPE: 0.252986 valid's rmse: 0.00085114    valid's RMSPE: 0.270977\n[150]   train's rmse: 0.000773853   train's RMSPE: 0.246412 valid's rmse: 0.000844718   valid's RMSPE: 0.268933\n[200]   train's rmse: 0.000759539   train's RMSPE: 0.241854 valid's rmse: 0.000844053   valid's RMSPE: 0.268721\nEarly stopping, best iteration is:\n[158]   train's rmse: 0.000771377   train's RMSPE: 0.245624 valid's rmse: 0.000842612   valid's RMSPE: 0.268262\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000845721   train's RMSPE: 0.269481 valid's rmse: 0.000811102   valid's RMSPE: 0.257523\n[100]   train's rmse: 0.000808158   train's RMSPE: 0.257512 valid's rmse: 0.000789324   valid's RMSPE: 0.250608\n[150]   train's rmse: 0.000787964   train's RMSPE: 0.251077 valid's rmse: 0.000783138   valid's RMSPE: 0.248644\n[200]   train's rmse: 0.000771519   train's RMSPE: 0.245837 valid's rmse: 0.000782716   valid's RMSPE: 0.24851\n[250]   train's rmse: 0.000758956   train's RMSPE: 0.241834 valid's rmse: 0.000779229   valid's RMSPE: 0.247403\n[300]   train's rmse: 0.000746787   train's RMSPE: 0.237956 valid's rmse: 0.00077704    valid's RMSPE: 0.246708\n[350]   train's rmse: 0.000736501   train's RMSPE: 0.234679 valid's rmse: 0.000776995   valid's RMSPE: 0.246693\n[400]   train's rmse: 0.000725673   train's RMSPE: 0.231229 valid's rmse: 0.000773691   valid's RMSPE: 0.245645\n[450]   train's rmse: 0.00071665    train's RMSPE: 0.228353 valid's rmse: 0.000772458   valid's RMSPE: 0.245253\n[500]   train's rmse: 0.00070696    train's RMSPE: 0.225266 valid's rmse: 0.000771267   valid's RMSPE: 0.244875\n[550]   train's rmse: 0.000699386   train's RMSPE: 0.222852 valid's rmse: 0.000772531   valid's RMSPE: 0.245276\nEarly stopping, best iteration is:\n[540]   train's rmse: 0.000700813   train's RMSPE: 0.223307 valid's rmse: 0.000771021   valid's RMSPE: 0.244797\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000834304   train's RMSPE: 0.265506 valid's rmse: 0.000854708   valid's RMSPE: 0.272747\n[100]   train's rmse: 0.000795167   train's RMSPE: 0.253051 valid's rmse: 0.000838232   valid's RMSPE: 0.26749\n[150]   train's rmse: 0.000775309   train's RMSPE: 0.246732 valid's rmse: 0.000831368   valid's RMSPE: 0.265299\n[200]   train's rmse: 0.000760209   train's RMSPE: 0.241927 valid's rmse: 0.000825205   valid's RMSPE: 0.263332\nEarly stopping, best iteration is:\n[195]   train's rmse: 0.000761323   train's RMSPE: 0.242281 valid's rmse: 0.000824975   valid's RMSPE: 0.263259\nOur out of folds RMSPE is 0.262, compared to 0.22961166109765224, giving gain 0.03238833890234777\nOur cv fold scores are [0.27, 0.265, 0.268, 0.245, 0.263]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000445318   train's RMSPE: 0.254122 valid's rmse: 0.000474526   valid's RMSPE: 0.26794\n[100]   train's rmse: 0.00042452    train's RMSPE: 0.242254 valid's rmse: 0.000457837   valid's RMSPE: 0.258517\n[150]   train's rmse: 0.000414165   train's RMSPE: 0.236345 valid's rmse: 0.000453177   valid's RMSPE: 0.255885\n[200]   train's rmse: 0.000406225   train's RMSPE: 0.231814 valid's rmse: 0.000450738   valid's RMSPE: 0.254508\n[250]   train's rmse: 0.000399319   train's RMSPE: 0.227873 valid's rmse: 0.000448452   valid's RMSPE: 0.253218\n[300]   train's rmse: 0.000393581   train's RMSPE: 0.224598 valid's rmse: 0.000447552   valid's RMSPE: 0.252709\n[350]   train's rmse: 0.000387729   train's RMSPE: 0.221259 valid's rmse: 0.000446529   valid's RMSPE: 0.252132\n[400]   train's rmse: 0.000382469   train's RMSPE: 0.218257 valid's rmse: 0.000445165   valid's RMSPE: 0.251362\n[450]   train's rmse: 0.000378311   train's RMSPE: 0.215885 valid's rmse: 0.000444213   valid's RMSPE: 0.250824\n[500]   train's rmse: 0.000374862   train's RMSPE: 0.213916 valid's rmse: 0.00044391    valid's RMSPE: 0.250653\n[550]   train's rmse: 0.000371347   train's RMSPE: 0.211911 valid's rmse: 0.000444085   valid's RMSPE: 0.250752\nEarly stopping, best iteration is:\n[524]   train's rmse: 0.000373035   train's RMSPE: 0.212874 valid's rmse: 0.000443615   valid's RMSPE: 0.250487\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000440059   train's RMSPE: 0.251215 valid's rmse: 0.00049702    valid's RMSPE: 0.280215\n[100]   train's rmse: 0.000418972   train's RMSPE: 0.239177 valid's rmse: 0.000481284   valid's RMSPE: 0.271343\n[150]   train's rmse: 0.000409427   train's RMSPE: 0.233728 valid's rmse: 0.000477581   valid's RMSPE: 0.269255\n[200]   train's rmse: 0.00040184    train's RMSPE: 0.229397 valid's rmse: 0.000473508   valid's RMSPE: 0.266959\n[250]   train's rmse: 0.000395786   train's RMSPE: 0.225941 valid's rmse: 0.000471367   valid's RMSPE: 0.265752\n[300]   train's rmse: 0.00038991    train's RMSPE: 0.222586 valid's rmse: 0.000468859   valid's RMSPE: 0.264338\n[350]   train's rmse: 0.000384979   train's RMSPE: 0.219772 valid's rmse: 0.000466715   valid's RMSPE: 0.263129\n[400]   train's rmse: 0.000380609   train's RMSPE: 0.217277 valid's rmse: 0.000466011   valid's RMSPE: 0.262733\n[450]   train's rmse: 0.000376364   train's RMSPE: 0.214854 valid's rmse: 0.000464658   valid's RMSPE: 0.26197\n[500]   train's rmse: 0.000372561   train's RMSPE: 0.212682 valid's rmse: 0.000464072   valid's RMSPE: 0.261639\n[550]   train's rmse: 0.00036923    train's RMSPE: 0.210781 valid's rmse: 0.000463387   valid's RMSPE: 0.261253\n[600]   train's rmse: 0.000366032   train's RMSPE: 0.208955 valid's rmse: 0.000462787   valid's RMSPE: 0.260915\n[650]   train's rmse: 0.000363053   train's RMSPE: 0.207255 valid's rmse: 0.000462628   valid's RMSPE: 0.260825\nEarly stopping, best iteration is:\n[647]   train's rmse: 0.000363219   train's RMSPE: 0.207349 valid's rmse: 0.000462533   valid's RMSPE: 0.260771\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000455239   train's RMSPE: 0.258592 valid's rmse: 0.000431958   valid's RMSPE: 0.248422\n[100]   train's rmse: 0.000433125   train's RMSPE: 0.246031 valid's rmse: 0.000416842   valid's RMSPE: 0.239729\n[150]   train's rmse: 0.00042274    train's RMSPE: 0.240132 valid's rmse: 0.000413246   valid's RMSPE: 0.23766\n[200]   train's rmse: 0.000415304   train's RMSPE: 0.235908 valid's rmse: 0.000411767   valid's RMSPE: 0.23681\n[250]   train's rmse: 0.000408692   train's RMSPE: 0.232152 valid's rmse: 0.000410179   valid's RMSPE: 0.235897\n[300]   train's rmse: 0.000403591   train's RMSPE: 0.229255 valid's rmse: 0.000410619   valid's RMSPE: 0.23615\nEarly stopping, best iteration is:\n[270]   train's rmse: 0.000406552   train's RMSPE: 0.230936 valid's rmse: 0.000409589   valid's RMSPE: 0.235557\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000454973   train's RMSPE: 0.258381 valid's rmse: 0.00042869    valid's RMSPE: 0.246766\n[100]   train's rmse: 0.000433664   train's RMSPE: 0.24628  valid's rmse: 0.00041544    valid's RMSPE: 0.239139\n[150]   train's rmse: 0.000422919   train's RMSPE: 0.240178 valid's rmse: 0.00041149    valid's RMSPE: 0.236865\n[200]   train's rmse: 0.000414858   train's RMSPE: 0.2356   valid's rmse: 0.000409728   valid's RMSPE: 0.23585\n[250]   train's rmse: 0.000408481   train's RMSPE: 0.231978 valid's rmse: 0.000408087   valid's RMSPE: 0.234906\n[300]   train's rmse: 0.000402323   train's RMSPE: 0.228481 valid's rmse: 0.000406253   valid's RMSPE: 0.233851\n[350]   train's rmse: 0.000396528   train's RMSPE: 0.22519  valid's rmse: 0.00040588    valid's RMSPE: 0.233635\n[400]   train's rmse: 0.000391941   train's RMSPE: 0.222585 valid's rmse: 0.00040514    valid's RMSPE: 0.23321\n[450]   train's rmse: 0.000387435   train's RMSPE: 0.220026 valid's rmse: 0.000404976   valid's RMSPE: 0.233115\n[500]   train's rmse: 0.000383757   train's RMSPE: 0.217937 valid's rmse: 0.000404198   valid's RMSPE: 0.232668\n[550]   train's rmse: 0.000379997   train's RMSPE: 0.215802 valid's rmse: 0.000403736   valid's RMSPE: 0.232402\n[600]   train's rmse: 0.00037609    train's RMSPE: 0.213583 valid's rmse: 0.000403634   valid's RMSPE: 0.232343\nEarly stopping, best iteration is:\n[594]   train's rmse: 0.000376526   train's RMSPE: 0.213831 valid's rmse: 0.000403421   valid's RMSPE: 0.23222\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00044848    train's RMSPE: 0.255553 valid's rmse: 0.000458319   valid's RMSPE: 0.260327\n[100]   train's rmse: 0.000427756   train's RMSPE: 0.243744 valid's rmse: 0.000445529   valid's RMSPE: 0.253062\n[150]   train's rmse: 0.000417468   train's RMSPE: 0.237882 valid's rmse: 0.000440054   valid's RMSPE: 0.249952\n[200]   train's rmse: 0.000409979   train's RMSPE: 0.233614 valid's rmse: 0.000436806   valid's RMSPE: 0.248108\n[250]   train's rmse: 0.000403363   train's RMSPE: 0.229844 valid's rmse: 0.00043526    valid's RMSPE: 0.247229\n[300]   train's rmse: 0.000397797   train's RMSPE: 0.226673 valid's rmse: 0.000434675   valid's RMSPE: 0.246897\n[350]   train's rmse: 0.000392743   train's RMSPE: 0.223793 valid's rmse: 0.000432361   valid's RMSPE: 0.245583\n[400]   train's rmse: 0.000388726   train's RMSPE: 0.221504 valid's rmse: 0.000432577   valid's RMSPE: 0.245706\nEarly stopping, best iteration is:\n[376]   train's rmse: 0.000390759   train's RMSPE: 0.222662 valid's rmse: 0.000431648   valid's RMSPE: 0.245178\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.245, compared to 0.19686216926245892, giving gain 0.048137830737541076\nOur cv fold scores are [0.25, 0.261, 0.236, 0.232, 0.245]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00101107    train's RMSPE: 0.250236 valid's rmse: 0.00107613    valid's RMSPE: 0.268845\n[100]   train's rmse: 0.000966506   train's RMSPE: 0.239207 valid's rmse: 0.00104335    valid's RMSPE: 0.260654\n[150]   train's rmse: 0.000942252   train's RMSPE: 0.233204 valid's rmse: 0.00104109    valid's RMSPE: 0.26009\n[200]   train's rmse: 0.000922865   train's RMSPE: 0.228406 valid's rmse: 0.00104024    valid's RMSPE: 0.259878\n[250]   train's rmse: 0.000904178   train's RMSPE: 0.223781 valid's rmse: 0.00103993    valid's RMSPE: 0.259801\nEarly stopping, best iteration is:\n[207]   train's rmse: 0.000919993   train's RMSPE: 0.227695 valid's rmse: 0.00103967    valid's RMSPE: 0.259736\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00100147    train's RMSPE: 0.248071 valid's rmse: 0.00110652    valid's RMSPE: 0.275515\n[100]   train's rmse: 0.000957784   train's RMSPE: 0.237249 valid's rmse: 0.00109035    valid's RMSPE: 0.27149\n[150]   train's rmse: 0.000934431   train's RMSPE: 0.231464 valid's rmse: 0.00108571    valid's RMSPE: 0.270334\n[200]   train's rmse: 0.000914579   train's RMSPE: 0.226547 valid's rmse: 0.0010807 valid's RMSPE: 0.269086\n[250]   train's rmse: 0.000898498   train's RMSPE: 0.222563 valid's rmse: 0.0010783 valid's RMSPE: 0.268487\n[300]   train's rmse: 0.000884614   train's RMSPE: 0.219124 valid's rmse: 0.00107654    valid's RMSPE: 0.268051\n[350]   train's rmse: 0.000872229   train's RMSPE: 0.216056 valid's rmse: 0.00107571    valid's RMSPE: 0.267844\n[400]   train's rmse: 0.000859814   train's RMSPE: 0.212981 valid's rmse: 0.00107581    valid's RMSPE: 0.267868\nEarly stopping, best iteration is:\n[387]   train's rmse: 0.00086329    train's RMSPE: 0.213842 valid's rmse: 0.00107444    valid's RMSPE: 0.267526\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.00102391    train's RMSPE: 0.253814 valid's rmse: 0.00100884    valid's RMSPE: 0.250467\n[100]   train's rmse: 0.000978457   train's RMSPE: 0.242546 valid's rmse: 0.000985337   valid's RMSPE: 0.244631\n[150]   train's rmse: 0.00095459    train's RMSPE: 0.23663  valid's rmse: 0.000984817   valid's RMSPE: 0.244502\nEarly stopping, best iteration is:\n[119]   train's rmse: 0.000968235   train's RMSPE: 0.240013 valid's rmse: 0.000983361   valid's RMSPE: 0.244141\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.00101828    train's RMSPE: 0.252819 valid's rmse: 0.00104528    valid's RMSPE: 0.257867\n[100]   train's rmse: 0.000975984   train's RMSPE: 0.242317 valid's rmse: 0.00103286    valid's RMSPE: 0.254804\n[150]   train's rmse: 0.000952175   train's RMSPE: 0.236405 valid's rmse: 0.00102694    valid's RMSPE: 0.253343\n[200]   train's rmse: 0.000933601   train's RMSPE: 0.231794 valid's rmse: 0.00102596    valid's RMSPE: 0.253101\n[250]   train's rmse: 0.000916656   train's RMSPE: 0.227587 valid's rmse: 0.00102167    valid's RMSPE: 0.252042\n[300]   train's rmse: 0.000902172   train's RMSPE: 0.223991 valid's rmse: 0.00102092    valid's RMSPE: 0.251857\n[350]   train's rmse: 0.000888484   train's RMSPE: 0.220592 valid's rmse: 0.00101872    valid's RMSPE: 0.251315\n[400]   train's rmse: 0.00087517    train's RMSPE: 0.217287 valid's rmse: 0.00101795    valid's RMSPE: 0.251125\nEarly stopping, best iteration is:\n[372]   train's rmse: 0.000882191   train's RMSPE: 0.21903  valid's rmse: 0.0010165 valid's RMSPE: 0.250768\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00102898    train's RMSPE: 0.25565  valid's rmse: 0.00100078    valid's RMSPE: 0.246204\n[100]   train's rmse: 0.000986292   train's RMSPE: 0.245043 valid's rmse: 0.000984709   valid's RMSPE: 0.242251\n[150]   train's rmse: 0.000962004   train's RMSPE: 0.239009 valid's rmse: 0.000986939   valid's RMSPE: 0.2428\nEarly stopping, best iteration is:\n[108]   train's rmse: 0.000981779   train's RMSPE: 0.243922 valid's rmse: 0.000984386   valid's RMSPE: 0.242171\nOur out of folds RMSPE is 0.253, compared to 0.23432519394342552, giving gain 0.018674806056574483\nOur cv fold scores are [0.26, 0.268, 0.244, 0.251, 0.242]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000357238   train's RMSPE: 0.254097 valid's rmse: 0.000384688   valid's RMSPE: 0.273498\n[100]   train's rmse: 0.000337361   train's RMSPE: 0.239959 valid's rmse: 0.000369382   valid's RMSPE: 0.262617\n[150]   train's rmse: 0.000327938   train's RMSPE: 0.233256 valid's rmse: 0.000365195   valid's RMSPE: 0.25964\n[200]   train's rmse: 0.000319582   train's RMSPE: 0.227313 valid's rmse: 0.00036185    valid's RMSPE: 0.257262\n[250]   train's rmse: 0.000313052   train's RMSPE: 0.222668 valid's rmse: 0.000360033   valid's RMSPE: 0.25597\n[300]   train's rmse: 0.000307643   train's RMSPE: 0.218821 valid's rmse: 0.000359535   valid's RMSPE: 0.255616\nEarly stopping, best iteration is:\n[280]   train's rmse: 0.00030954    train's RMSPE: 0.220171 valid's rmse: 0.00035903    valid's RMSPE: 0.255257\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00035321    train's RMSPE: 0.251435 valid's rmse: 0.000392498   valid's RMSPE: 0.278148\n[100]   train's rmse: 0.000334016   train's RMSPE: 0.237771 valid's rmse: 0.000379872   valid's RMSPE: 0.2692\n[150]   train's rmse: 0.000324559   train's RMSPE: 0.23104  valid's rmse: 0.000375806   valid's RMSPE: 0.266319\n[200]   train's rmse: 0.000317186   train's RMSPE: 0.225791 valid's rmse: 0.000373094   valid's RMSPE: 0.264397\n[250]   train's rmse: 0.000310625   train's RMSPE: 0.22112  valid's rmse: 0.000370354   valid's RMSPE: 0.262455\n[300]   train's rmse: 0.000304505   train's RMSPE: 0.216764 valid's rmse: 0.000368869   valid's RMSPE: 0.261403\n[350]   train's rmse: 0.000299483   train's RMSPE: 0.213189 valid's rmse: 0.000367303   valid's RMSPE: 0.260293\n[400]   train's rmse: 0.000295337   train's RMSPE: 0.210237 valid's rmse: 0.000366037   valid's RMSPE: 0.259396\n[450]   train's rmse: 0.000291547   train's RMSPE: 0.207539 valid's rmse: 0.000365553   valid's RMSPE: 0.259053\n[500]   train's rmse: 0.000287886   train's RMSPE: 0.204933 valid's rmse: 0.00036559    valid's RMSPE: 0.259079\n[550]   train's rmse: 0.000284667   train's RMSPE: 0.202642 valid's rmse: 0.000364225   valid's RMSPE: 0.258111\n[600]   train's rmse: 0.000281504   train's RMSPE: 0.20039  valid's rmse: 0.000363407   valid's RMSPE: 0.257532\n[650]   train's rmse: 0.000278511   train's RMSPE: 0.19826  valid's rmse: 0.00036249    valid's RMSPE: 0.256882\n[700]   train's rmse: 0.000276046   train's RMSPE: 0.196505 valid's rmse: 0.00036357    valid's RMSPE: 0.257648\nEarly stopping, best iteration is:\n[657]   train's rmse: 0.000278202   train's RMSPE: 0.19804  valid's rmse: 0.000362269   valid's RMSPE: 0.256726\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000363584   train's RMSPE: 0.258912 valid's rmse: 0.000349481   valid's RMSPE: 0.247303\n[100]   train's rmse: 0.000345215   train's RMSPE: 0.245832 valid's rmse: 0.000338054   valid's RMSPE: 0.239217\n[150]   train's rmse: 0.00033506    train's RMSPE: 0.2386   valid's rmse: 0.000333135   valid's RMSPE: 0.235736\n[200]   train's rmse: 0.000326276   train's RMSPE: 0.232345 valid's rmse: 0.000330098   valid's RMSPE: 0.233587\n[250]   train's rmse: 0.000319797   train's RMSPE: 0.227731 valid's rmse: 0.000329029   valid's RMSPE: 0.232831\n[300]   train's rmse: 0.000313914   train's RMSPE: 0.223542 valid's rmse: 0.000327633   valid's RMSPE: 0.231843\n[350]   train's rmse: 0.000309422   train's RMSPE: 0.220343 valid's rmse: 0.000326564   valid's RMSPE: 0.231086\n[400]   train's rmse: 0.000305009   train's RMSPE: 0.2172   valid's rmse: 0.000325949   valid's RMSPE: 0.230651\n[450]   train's rmse: 0.000300934   train's RMSPE: 0.214299 valid's rmse: 0.000325575   valid's RMSPE: 0.230386\n[500]   train's rmse: 0.000297533   train's RMSPE: 0.211877 valid's rmse: 0.000325337   valid's RMSPE: 0.230218\n[550]   train's rmse: 0.000294102   train's RMSPE: 0.209433 valid's rmse: 0.000324481   valid's RMSPE: 0.229612\n[600]   train's rmse: 0.000290955   train's RMSPE: 0.207193 valid's rmse: 0.000324077   valid's RMSPE: 0.229326\nEarly stopping, best iteration is:\n[595]   train's rmse: 0.000291319   train's RMSPE: 0.207452 valid's rmse: 0.000323826   valid's RMSPE: 0.229149\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00036526    train's RMSPE: 0.258029 valid's rmse: 0.000355526   valid's RMSPE: 0.259558\n[100]   train's rmse: 0.000345908   train's RMSPE: 0.244359 valid's rmse: 0.000342721   valid's RMSPE: 0.25021\n[150]   train's rmse: 0.000336162   train's RMSPE: 0.237474 valid's rmse: 0.000339554   valid's RMSPE: 0.247898\n[200]   train's rmse: 0.000327581   train's RMSPE: 0.231412 valid's rmse: 0.000335932   valid's RMSPE: 0.245254\n[250]   train's rmse: 0.000321555   train's RMSPE: 0.227155 valid's rmse: 0.000333887   valid's RMSPE: 0.24376\n[300]   train's rmse: 0.000316458   train's RMSPE: 0.223554 valid's rmse: 0.000333168   valid's RMSPE: 0.243236\n[350]   train's rmse: 0.000311846   train's RMSPE: 0.220297 valid's rmse: 0.000332817   valid's RMSPE: 0.242979\nEarly stopping, best iteration is:\n[317]   train's rmse: 0.000314898   train's RMSPE: 0.222453 valid's rmse: 0.000332285   valid's RMSPE: 0.242591\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000360087   train's RMSPE: 0.257242 valid's rmse: 0.000362287   valid's RMSPE: 0.253018\n[100]   train's rmse: 0.000340509   train's RMSPE: 0.243256 valid's rmse: 0.000354536   valid's RMSPE: 0.247605\n[150]   train's rmse: 0.000330642   train's RMSPE: 0.236207 valid's rmse: 0.000351794   valid's RMSPE: 0.245689\n[200]   train's rmse: 0.000322808   train's RMSPE: 0.230611 valid's rmse: 0.000349359   valid's RMSPE: 0.243989\n[250]   train's rmse: 0.000315747   train's RMSPE: 0.225566 valid's rmse: 0.000347542   valid's RMSPE: 0.24272\n[300]   train's rmse: 0.000310269   train's RMSPE: 0.221653 valid's rmse: 0.000346377   valid's RMSPE: 0.241906\n[350]   train's rmse: 0.000305358   train's RMSPE: 0.218144 valid's rmse: 0.000345788   valid's RMSPE: 0.241495\n[400]   train's rmse: 0.000300882   train's RMSPE: 0.214947 valid's rmse: 0.000345217   valid's RMSPE: 0.241096\n[450]   train's rmse: 0.00029697    train's RMSPE: 0.212152 valid's rmse: 0.000345328   valid's RMSPE: 0.241174\nEarly stopping, best iteration is:\n[417]   train's rmse: 0.000299258   train's RMSPE: 0.213787 valid's rmse: 0.000344867   valid's RMSPE: 0.240852\nOur out of folds RMSPE is 0.245, compared to 0.21141539873479068, giving gain 0.03358460126520932\nOur cv fold scores are [0.255, 0.257, 0.229, 0.243, 0.241]\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000528673   train's RMSPE: 0.247051 valid's rmse: 0.000575775   valid's RMSPE: 0.267044\n[100]   train's rmse: 0.000502562   train's RMSPE: 0.23485  valid's rmse: 0.000561608   valid's RMSPE: 0.260474\n[150]   train's rmse: 0.000490681   train's RMSPE: 0.229298 valid's rmse: 0.000558188   valid's RMSPE: 0.258888\n[200]   train's rmse: 0.000479732   train's RMSPE: 0.224181 valid's rmse: 0.000555477   valid's RMSPE: 0.25763\n[250]   train's rmse: 0.000471442   train's RMSPE: 0.220307 valid's rmse: 0.000555481   valid's RMSPE: 0.257632\n[300]   train's rmse: 0.000463977   train's RMSPE: 0.216819 valid's rmse: 0.000554474   valid's RMSPE: 0.257165\n[350]   train's rmse: 0.000457563   train's RMSPE: 0.213821 valid's rmse: 0.000556091   valid's RMSPE: 0.257915\nEarly stopping, best iteration is:\n[311]   train's rmse: 0.000462471   train's RMSPE: 0.216115 valid's rmse: 0.00055348    valid's RMSPE: 0.256704\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000529195   train's RMSPE: 0.246414 valid's rmse: 0.000561202   valid's RMSPE: 0.264021\n[100]   train's rmse: 0.000503151   train's RMSPE: 0.234286 valid's rmse: 0.000542479   valid's RMSPE: 0.255213\n[150]   train's rmse: 0.000490372   train's RMSPE: 0.228336 valid's rmse: 0.00053968    valid's RMSPE: 0.253896\n[200]   train's rmse: 0.000480185   train's RMSPE: 0.223593 valid's rmse: 0.000537065   valid's RMSPE: 0.252665\n[250]   train's rmse: 0.000471456   train's RMSPE: 0.219528 valid's rmse: 0.000535621   valid's RMSPE: 0.251986\n[300]   train's rmse: 0.000464925   train's RMSPE: 0.216487 valid's rmse: 0.000534693   valid's RMSPE: 0.25155\n[350]   train's rmse: 0.00045862    train's RMSPE: 0.213551 valid's rmse: 0.000533267   valid's RMSPE: 0.250879\n[400]   train's rmse: 0.000452665   train's RMSPE: 0.210778 valid's rmse: 0.000531345   valid's RMSPE: 0.249975\n[450]   train's rmse: 0.000446723   train's RMSPE: 0.208011 valid's rmse: 0.000531415   valid's RMSPE: 0.250007\nEarly stopping, best iteration is:\n[411]   train's rmse: 0.000450935   train's RMSPE: 0.209973 valid's rmse: 0.000530846   valid's RMSPE: 0.24974\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000536132   train's RMSPE: 0.249863 valid's rmse: 0.000522643   valid's RMSPE: 0.24503\n[100]   train's rmse: 0.000507821   train's RMSPE: 0.236669 valid's rmse: 0.000507766   valid's RMSPE: 0.238056\n[150]   train's rmse: 0.000496047   train's RMSPE: 0.231182 valid's rmse: 0.000506372   valid's RMSPE: 0.237402\nEarly stopping, best iteration is:\n[137]   train's rmse: 0.000498826   train's RMSPE: 0.232477 valid's rmse: 0.000505791   valid's RMSPE: 0.23713\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00053751    train's RMSPE: 0.250463 valid's rmse: 0.000529292   valid's RMSPE: 0.248314\n[100]   train's rmse: 0.000510597   train's RMSPE: 0.237923 valid's rmse: 0.000513893   valid's RMSPE: 0.24109\n[150]   train's rmse: 0.000498514   train's RMSPE: 0.232292 valid's rmse: 0.000511303   valid's RMSPE: 0.239875\n[200]   train's rmse: 0.000488599   train's RMSPE: 0.227672 valid's rmse: 0.000507853   valid's RMSPE: 0.238257\n[250]   train's rmse: 0.000480904   train's RMSPE: 0.224086 valid's rmse: 0.000508522   valid's RMSPE: 0.23857\nEarly stopping, best iteration is:\n[222]   train's rmse: 0.000485196   train's RMSPE: 0.226086 valid's rmse: 0.000507136   valid's RMSPE: 0.23792\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000532208   train's RMSPE: 0.249107 valid's rmse: 0.000542083   valid's RMSPE: 0.249752\n[100]   train's rmse: 0.000505832   train's RMSPE: 0.236762 valid's rmse: 0.000531399   valid's RMSPE: 0.244829\n[150]   train's rmse: 0.000494768   train's RMSPE: 0.231583 valid's rmse: 0.000529038   valid's RMSPE: 0.243741\n[200]   train's rmse: 0.00048465    train's RMSPE: 0.226848 valid's rmse: 0.00052727    valid's RMSPE: 0.242927\nEarly stopping, best iteration is:\n[195]   train's rmse: 0.000485445   train's RMSPE: 0.227219 valid's rmse: 0.000526979   valid's RMSPE: 0.242793\nOur out of folds RMSPE is 0.245, compared to 0.21009390571045697, giving gain 0.03490609428954303\nOur cv fold scores are [0.257, 0.25, 0.237, 0.238, 0.243]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000207856   train's RMSPE: 0.249234 valid's rmse: 0.000226576   valid's RMSPE: 0.275623\n[100]   train's rmse: 0.000196259   train's RMSPE: 0.235329 valid's rmse: 0.000216983   valid's RMSPE: 0.263954\n[150]   train's rmse: 0.000191205   train's RMSPE: 0.229268 valid's rmse: 0.000212909   valid's RMSPE: 0.258998\n[200]   train's rmse: 0.00018783    train's RMSPE: 0.225221 valid's rmse: 0.000211122   valid's RMSPE: 0.256825\n[250]   train's rmse: 0.000185138   train's RMSPE: 0.221993 valid's rmse: 0.000210381   valid's RMSPE: 0.255923\n[300]   train's rmse: 0.00018286    train's RMSPE: 0.219263 valid's rmse: 0.000209388   valid's RMSPE: 0.254715\n[350]   train's rmse: 0.000180207   train's RMSPE: 0.216081 valid's rmse: 0.000208446   valid's RMSPE: 0.253568\n[400]   train's rmse: 0.000178237   train's RMSPE: 0.213719 valid's rmse: 0.000208019   valid's RMSPE: 0.253049\n[450]   train's rmse: 0.000176425   train's RMSPE: 0.211546 valid's rmse: 0.000207339   valid's RMSPE: 0.252222\n[500]   train's rmse: 0.000174746   train's RMSPE: 0.209533 valid's rmse: 0.000207387   valid's RMSPE: 0.25228\n[550]   train's rmse: 0.000172926   train's RMSPE: 0.207351 valid's rmse: 0.000206668   valid's RMSPE: 0.251407\n[600]   train's rmse: 0.000171358   train's RMSPE: 0.20547  valid's rmse: 0.000205817   valid's RMSPE: 0.250371\n[650]   train's rmse: 0.000169943   train's RMSPE: 0.203774 valid's rmse: 0.000205312   valid's RMSPE: 0.249756\n[700]   train's rmse: 0.000168507   train's RMSPE: 0.202052 valid's rmse: 0.000204852   valid's RMSPE: 0.249197\n[750]   train's rmse: 0.000167085   train's RMSPE: 0.200347 valid's rmse: 0.000204797   valid's RMSPE: 0.24913\nEarly stopping, best iteration is:\n[722]   train's rmse: 0.000167823   train's RMSPE: 0.201232 valid's rmse: 0.000204636   valid's RMSPE: 0.248935\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000206558   train's RMSPE: 0.248581 valid's rmse: 0.000224257   valid's RMSPE: 0.268901\n[100]   train's rmse: 0.00019425    train's RMSPE: 0.233769 valid's rmse: 0.00021552    valid's RMSPE: 0.258424\n[150]   train's rmse: 0.00018957    train's RMSPE: 0.228137 valid's rmse: 0.000213084   valid's RMSPE: 0.255503\n[200]   train's rmse: 0.000186133   train's RMSPE: 0.224001 valid's rmse: 0.000211647   valid's RMSPE: 0.25378\n[250]   train's rmse: 0.000183135   train's RMSPE: 0.220393 valid's rmse: 0.000210559   valid's RMSPE: 0.252475\n[300]   train's rmse: 0.000180573   train's RMSPE: 0.217309 valid's rmse: 0.000209737   valid's RMSPE: 0.25149\n[350]   train's rmse: 0.000178382   train's RMSPE: 0.214673 valid's rmse: 0.000209248   valid's RMSPE: 0.250904\n[400]   train's rmse: 0.000176236   train's RMSPE: 0.21209  valid's rmse: 0.000208851   valid's RMSPE: 0.250427\n[450]   train's rmse: 0.000174278   train's RMSPE: 0.209734 valid's rmse: 0.000208275   valid's RMSPE: 0.249737\n[500]   train's rmse: 0.000172301   train's RMSPE: 0.207355 valid's rmse: 0.000208147   valid's RMSPE: 0.249584\n[550]   train's rmse: 0.000170595   train's RMSPE: 0.205302 valid's rmse: 0.000208261   valid's RMSPE: 0.24972\nEarly stopping, best iteration is:\n[517]   train's rmse: 0.000171752   train's RMSPE: 0.206694 valid's rmse: 0.00020794    valid's RMSPE: 0.249335\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000212087   train's RMSPE: 0.255342 valid's rmse: 0.000203957   valid's RMSPE: 0.244146\n[100]   train's rmse: 0.000199873   train's RMSPE: 0.240637 valid's rmse: 0.000194753   valid's RMSPE: 0.233128\n[150]   train's rmse: 0.000194983   train's RMSPE: 0.23475  valid's rmse: 0.000192682   valid's RMSPE: 0.230649\n[200]   train's rmse: 0.000191384   train's RMSPE: 0.230417 valid's rmse: 0.000191504   valid's RMSPE: 0.229239\n[250]   train's rmse: 0.000188445   train's RMSPE: 0.226879 valid's rmse: 0.000191163   valid's RMSPE: 0.228831\n[300]   train's rmse: 0.000186049   train's RMSPE: 0.223993 valid's rmse: 0.000190781   valid's RMSPE: 0.228374\n[350]   train's rmse: 0.000183909   train's RMSPE: 0.221417 valid's rmse: 0.000190512   valid's RMSPE: 0.228051\n[400]   train's rmse: 0.000181896   train's RMSPE: 0.218994 valid's rmse: 0.000190133   valid's RMSPE: 0.227599\n[450]   train's rmse: 0.000179614   train's RMSPE: 0.216246 valid's rmse: 0.000189613   valid's RMSPE: 0.226975\nEarly stopping, best iteration is:\n[447]   train's rmse: 0.00017973    train's RMSPE: 0.216386 valid's rmse: 0.000189597   valid's RMSPE: 0.226956\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000212571   train's RMSPE: 0.255494 valid's rmse: 0.000203092   valid's RMSPE: 0.244759\n[100]   train's rmse: 0.000200116   train's RMSPE: 0.240524 valid's rmse: 0.000194825   valid's RMSPE: 0.234796\n[150]   train's rmse: 0.000195126   train's RMSPE: 0.234526 valid's rmse: 0.000191687   valid's RMSPE: 0.231014\n[200]   train's rmse: 0.000192053   train's RMSPE: 0.230833 valid's rmse: 0.000190212   valid's RMSPE: 0.229236\n[250]   train's rmse: 0.000189438   train's RMSPE: 0.22769  valid's rmse: 0.000189839   valid's RMSPE: 0.228786\n[300]   train's rmse: 0.000186582   train's RMSPE: 0.224257 valid's rmse: 0.000188701   valid's RMSPE: 0.227415\n[350]   train's rmse: 0.000184331   train's RMSPE: 0.221552 valid's rmse: 0.000188493   valid's RMSPE: 0.227165\n[400]   train's rmse: 0.00018249    train's RMSPE: 0.21934  valid's rmse: 0.000188142   valid's RMSPE: 0.226741\n[450]   train's rmse: 0.00018092    train's RMSPE: 0.217452 valid's rmse: 0.000187794   valid's RMSPE: 0.226322\n[500]   train's rmse: 0.000179214   train's RMSPE: 0.215401 valid's rmse: 0.000187496   valid's RMSPE: 0.225962\n[550]   train's rmse: 0.000177454   train's RMSPE: 0.213286 valid's rmse: 0.000186942   valid's RMSPE: 0.225296\n[600]   train's rmse: 0.000175711   train's RMSPE: 0.211191 valid's rmse: 0.000186878   valid's RMSPE: 0.225218\nEarly stopping, best iteration is:\n[593]   train's rmse: 0.000175956   train's RMSPE: 0.211486 valid's rmse: 0.000186767   valid's RMSPE: 0.225084\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000211984   train's RMSPE: 0.255327 valid's rmse: 0.000214151   valid's RMSPE: 0.255907\n[100]   train's rmse: 0.000199611   train's RMSPE: 0.240424 valid's rmse: 0.000204682   valid's RMSPE: 0.244592\n[150]   train's rmse: 0.000194992   train's RMSPE: 0.234861 valid's rmse: 0.000202769   valid's RMSPE: 0.242305\n[200]   train's rmse: 0.000191808   train's RMSPE: 0.231026 valid's rmse: 0.0002025 valid's RMSPE: 0.241984\n[250]   train's rmse: 0.000189207   train's RMSPE: 0.227893 valid's rmse: 0.000201831   valid's RMSPE: 0.241185\n[300]   train's rmse: 0.000186913   train's RMSPE: 0.22513  valid's rmse: 0.000201447   valid's RMSPE: 0.240726\nEarly stopping, best iteration is:\n[298]   train's rmse: 0.000186986   train's RMSPE: 0.225218 valid's rmse: 0.000201428   valid's RMSPE: 0.240703\nOur out of folds RMSPE is 0.238, compared to 0.19746750811566835, giving gain 0.04053249188433164\nOur cv fold scores are [0.249, 0.249, 0.227, 0.225, 0.241]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000487826   train's RMSPE: 0.210579 valid's rmse: 0.000513017   valid's RMSPE: 0.223738\n[100]   train's rmse: 0.000457666   train's RMSPE: 0.19756  valid's rmse: 0.000492531   valid's RMSPE: 0.214804\n[150]   train's rmse: 0.000446484   train's RMSPE: 0.192733 valid's rmse: 0.000491333   valid's RMSPE: 0.214281\n[200]   train's rmse: 0.000437977   train's RMSPE: 0.189061 valid's rmse: 0.000489263   valid's RMSPE: 0.213378\n[250]   train's rmse: 0.00043041    train's RMSPE: 0.185794 valid's rmse: 0.000487646   valid's RMSPE: 0.212673\n[300]   train's rmse: 0.000423437   train's RMSPE: 0.182785 valid's rmse: 0.000486085   valid's RMSPE: 0.211992\nEarly stopping, best iteration is:\n[298]   train's rmse: 0.000423683   train's RMSPE: 0.182891 valid's rmse: 0.000485906   valid's RMSPE: 0.211914\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000484335   train's RMSPE: 0.209958 valid's rmse: 0.000519667   valid's RMSPE: 0.222838\n[100]   train's rmse: 0.000457423   train's RMSPE: 0.198291 valid's rmse: 0.000502326   valid's RMSPE: 0.215402\n[150]   train's rmse: 0.000445395   train's RMSPE: 0.193077 valid's rmse: 0.000496559   valid's RMSPE: 0.212929\n[200]   train's rmse: 0.000436642   train's RMSPE: 0.189283 valid's rmse: 0.000493628   valid's RMSPE: 0.211672\n[250]   train's rmse: 0.00042952    train's RMSPE: 0.186195 valid's rmse: 0.000491101   valid's RMSPE: 0.210588\n[300]   train's rmse: 0.000423284   train's RMSPE: 0.183492 valid's rmse: 0.000489907   valid's RMSPE: 0.210076\n[350]   train's rmse: 0.000417306   train's RMSPE: 0.180901 valid's rmse: 0.000488921   valid's RMSPE: 0.209653\n[400]   train's rmse: 0.000412608   train's RMSPE: 0.178864 valid's rmse: 0.000488176   valid's RMSPE: 0.209334\n[450]   train's rmse: 0.000407552   train's RMSPE: 0.176673 valid's rmse: 0.000486736   valid's RMSPE: 0.208716\n[500]   train's rmse: 0.00040296    train's RMSPE: 0.174682 valid's rmse: 0.000486316   valid's RMSPE: 0.208536\n[550]   train's rmse: 0.000398449   train's RMSPE: 0.172726 valid's rmse: 0.000486232   valid's RMSPE: 0.2085\nEarly stopping, best iteration is:\n[539]   train's rmse: 0.00039947    train's RMSPE: 0.173169 valid's rmse: 0.000485647   valid's RMSPE: 0.20825\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000495218   train's RMSPE: 0.213962 valid's rmse: 0.000477298   valid's RMSPE: 0.207426\n[100]   train's rmse: 0.000468042   train's RMSPE: 0.202221 valid's rmse: 0.000455117   valid's RMSPE: 0.197786\n[150]   train's rmse: 0.00045695    train's RMSPE: 0.197428 valid's rmse: 0.00045118    valid's RMSPE: 0.196075\n[200]   train's rmse: 0.000447797   train's RMSPE: 0.193473 valid's rmse: 0.0004486 valid's RMSPE: 0.194954\n[250]   train's rmse: 0.000440307   train's RMSPE: 0.190238 valid's rmse: 0.000447741   valid's RMSPE: 0.194581\n[300]   train's rmse: 0.000433915   train's RMSPE: 0.187476 valid's rmse: 0.000448023   valid's RMSPE: 0.194703\nEarly stopping, best iteration is:\n[263]   train's rmse: 0.000438415   train's RMSPE: 0.18942  valid's rmse: 0.000447324   valid's RMSPE: 0.194399\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000492713   train's RMSPE: 0.213112 valid's rmse: 0.00048918    valid's RMSPE: 0.211671\n[100]   train's rmse: 0.000464528   train's RMSPE: 0.200921 valid's rmse: 0.000470561   valid's RMSPE: 0.203615\n[150]   train's rmse: 0.000453428   train's RMSPE: 0.19612  valid's rmse: 0.000467062   valid's RMSPE: 0.202101\n[200]   train's rmse: 0.000444643   train's RMSPE: 0.19232  valid's rmse: 0.000466716   valid's RMSPE: 0.201951\n[250]   train's rmse: 0.000437644   train's RMSPE: 0.189293 valid's rmse: 0.000465663   valid's RMSPE: 0.201495\n[300]   train's rmse: 0.000430873   train's RMSPE: 0.186364 valid's rmse: 0.000464515   valid's RMSPE: 0.200999\nEarly stopping, best iteration is:\n[297]   train's rmse: 0.00043122    train's RMSPE: 0.186514 valid's rmse: 0.000464207   valid's RMSPE: 0.200865\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000487819   train's RMSPE: 0.211257 valid's rmse: 0.000499965   valid's RMSPE: 0.215262\n[100]   train's rmse: 0.000460513   train's RMSPE: 0.199432 valid's rmse: 0.000481653   valid's RMSPE: 0.207378\n[150]   train's rmse: 0.000449961   train's RMSPE: 0.194862 valid's rmse: 0.000479238   valid's RMSPE: 0.206338\n[200]   train's rmse: 0.000441545   train's RMSPE: 0.191217 valid's rmse: 0.000478122   valid's RMSPE: 0.205858\n[250]   train's rmse: 0.000433334   train's RMSPE: 0.187661 valid's rmse: 0.00047918    valid's RMSPE: 0.206313\nEarly stopping, best iteration is:\n[224]   train's rmse: 0.000437733   train's RMSPE: 0.189566 valid's rmse: 0.000478094   valid's RMSPE: 0.205845\nOur out of folds RMSPE is 0.204, compared to 0.17670245970948012, giving gain 0.027297540290519867\nOur cv fold scores are [0.212, 0.208, 0.194, 0.201, 0.206]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000311052   train's RMSPE: 0.245669 valid's rmse: 0.000343938   valid's RMSPE: 0.279705\n[100]   train's rmse: 0.000293155   train's RMSPE: 0.231533 valid's rmse: 0.000330066   valid's RMSPE: 0.268424\n[150]   train's rmse: 0.000285595   train's RMSPE: 0.225562 valid's rmse: 0.000327164   valid's RMSPE: 0.266064\n[200]   train's rmse: 0.000279848   train's RMSPE: 0.221024 valid's rmse: 0.000324661   valid's RMSPE: 0.264028\n[250]   train's rmse: 0.000274633   train's RMSPE: 0.216905 valid's rmse: 0.000323892   valid's RMSPE: 0.263403\n[300]   train's rmse: 0.000270234   train's RMSPE: 0.21343  valid's rmse: 0.000323294   valid's RMSPE: 0.262917\n[350]   train's rmse: 0.000266457   train's RMSPE: 0.210447 valid's rmse: 0.000324046   valid's RMSPE: 0.263528\nEarly stopping, best iteration is:\n[305]   train's rmse: 0.000269835   train's RMSPE: 0.213115 valid's rmse: 0.000323  valid's RMSPE: 0.262678\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.0003101 train's RMSPE: 0.246224 valid's rmse: 0.000344949   valid's RMSPE: 0.274806\n[100]   train's rmse: 0.000291655   train's RMSPE: 0.231578 valid's rmse: 0.00033136    valid's RMSPE: 0.26398\n[150]   train's rmse: 0.000283954   train's RMSPE: 0.225463 valid's rmse: 0.000328797   valid's RMSPE: 0.261938\n[200]   train's rmse: 0.000277788   train's RMSPE: 0.220567 valid's rmse: 0.000327206   valid's RMSPE: 0.260671\n[250]   train's rmse: 0.000272774   train's RMSPE: 0.216587 valid's rmse: 0.000325341   valid's RMSPE: 0.259185\n[300]   train's rmse: 0.000268413   train's RMSPE: 0.213124 valid's rmse: 0.000324024   valid's RMSPE: 0.258136\n[350]   train's rmse: 0.000264394   train's RMSPE: 0.209932 valid's rmse: 0.000323247   valid's RMSPE: 0.257517\n[400]   train's rmse: 0.00026098    train's RMSPE: 0.207222 valid's rmse: 0.000322175   valid's RMSPE: 0.256662\n[450]   train's rmse: 0.000257669   train's RMSPE: 0.204593 valid's rmse: 0.000320736   valid's RMSPE: 0.255516\n[500]   train's rmse: 0.000254957   train's RMSPE: 0.202439 valid's rmse: 0.00031975    valid's RMSPE: 0.254731\n[550]   train's rmse: 0.000252178   train's RMSPE: 0.200233 valid's rmse: 0.000319254   valid's RMSPE: 0.254336\n[600]   train's rmse: 0.000249494   train's RMSPE: 0.198102 valid's rmse: 0.000318825   valid's RMSPE: 0.253993\n[650]   train's rmse: 0.000247003   train's RMSPE: 0.196124 valid's rmse: 0.000319142   valid's RMSPE: 0.254246\nEarly stopping, best iteration is:\n[617]   train's rmse: 0.000248694   train's RMSPE: 0.197467 valid's rmse: 0.000318521   valid's RMSPE: 0.253752\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000319108   train's RMSPE: 0.254332 valid's rmse: 0.000301476   valid's RMSPE: 0.236541\n[100]   train's rmse: 0.000301055   train's RMSPE: 0.239943 valid's rmse: 0.000291706   valid's RMSPE: 0.228875\n[150]   train's rmse: 0.000293015   train's RMSPE: 0.233535 valid's rmse: 0.000289897   valid's RMSPE: 0.227456\n[200]   train's rmse: 0.000286795   train's RMSPE: 0.228578 valid's rmse: 0.00028804    valid's RMSPE: 0.225999\n[250]   train's rmse: 0.000281336   train's RMSPE: 0.224226 valid's rmse: 0.000286724   valid's RMSPE: 0.224967\n[300]   train's rmse: 0.000276778   train's RMSPE: 0.220594 valid's rmse: 0.000286299   valid's RMSPE: 0.224633\n[350]   train's rmse: 0.000272845   train's RMSPE: 0.217459 valid's rmse: 0.000285775   valid's RMSPE: 0.224222\n[400]   train's rmse: 0.000269137   train's RMSPE: 0.214504 valid's rmse: 0.00028505    valid's RMSPE: 0.223653\n[450]   train's rmse: 0.000265774   train's RMSPE: 0.211824 valid's rmse: 0.00028411    valid's RMSPE: 0.222915\n[500]   train's rmse: 0.000263211   train's RMSPE: 0.209781 valid's rmse: 0.000283748   valid's RMSPE: 0.222631\n[550]   train's rmse: 0.000260092   train's RMSPE: 0.207295 valid's rmse: 0.000283167   valid's RMSPE: 0.222175\n[600]   train's rmse: 0.000257437   train's RMSPE: 0.205179 valid's rmse: 0.000283076   valid's RMSPE: 0.222104\nEarly stopping, best iteration is:\n[565]   train's rmse: 0.000259183   train's RMSPE: 0.20657  valid's rmse: 0.000282968   valid's RMSPE: 0.222019\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000319041   train's RMSPE: 0.254593 valid's rmse: 0.000309009   valid's RMSPE: 0.241206\n[100]   train's rmse: 0.000300518   train's RMSPE: 0.239812 valid's rmse: 0.000299949   valid's RMSPE: 0.234133\n[150]   train's rmse: 0.000292576   train's RMSPE: 0.233475 valid's rmse: 0.000297006   valid's RMSPE: 0.231836\n[200]   train's rmse: 0.000286591   train's RMSPE: 0.228698 valid's rmse: 0.00029499    valid's RMSPE: 0.230262\n[250]   train's rmse: 0.000281553   train's RMSPE: 0.224678 valid's rmse: 0.000293532   valid's RMSPE: 0.229124\n[300]   train's rmse: 0.000277274   train's RMSPE: 0.221263 valid's rmse: 0.00029363    valid's RMSPE: 0.229201\nEarly stopping, best iteration is:\n[265]   train's rmse: 0.00028027    train's RMSPE: 0.223655 valid's rmse: 0.000293216   valid's RMSPE: 0.228878\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000316654   train's RMSPE: 0.251383 valid's rmse: 0.000315892   valid's RMSPE: 0.251834\n[100]   train's rmse: 0.000299015   train's RMSPE: 0.23738  valid's rmse: 0.000303629   valid's RMSPE: 0.242058\n[150]   train's rmse: 0.000290875   train's RMSPE: 0.230918 valid's rmse: 0.000299872   valid's RMSPE: 0.239063\n[200]   train's rmse: 0.000284784   train's RMSPE: 0.226082 valid's rmse: 0.000298604   valid's RMSPE: 0.238052\n[250]   train's rmse: 0.000279846   train's RMSPE: 0.222162 valid's rmse: 0.000296943   valid's RMSPE: 0.236728\n[300]   train's rmse: 0.00027546    train's RMSPE: 0.218681 valid's rmse: 0.000296113   valid's RMSPE: 0.236066\n[350]   train's rmse: 0.00027145    train's RMSPE: 0.215497 valid's rmse: 0.000295307   valid's RMSPE: 0.235424\n[400]   train's rmse: 0.000267885   train's RMSPE: 0.212667 valid's rmse: 0.000294812   valid's RMSPE: 0.235029\nEarly stopping, best iteration is:\n[390]   train's rmse: 0.000268552   train's RMSPE: 0.213196 valid's rmse: 0.000294551   valid's RMSPE: 0.234821\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.241, compared to 0.20578409495577155, giving gain 0.035215905044228446\nOur cv fold scores are [0.263, 0.254, 0.222, 0.229, 0.235]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00036893    train's RMSPE: 0.250754 valid's rmse: 0.000413822   valid's RMSPE: 0.275053\n[100]   train's rmse: 0.000346207   train's RMSPE: 0.235309 valid's rmse: 0.000396428   valid's RMSPE: 0.263492\n[150]   train's rmse: 0.000335774   train's RMSPE: 0.228218 valid's rmse: 0.000392301   valid's RMSPE: 0.260749\n[200]   train's rmse: 0.000327032   train's RMSPE: 0.222277 valid's rmse: 0.000389626   valid's RMSPE: 0.258971\n[250]   train's rmse: 0.000320412   train's RMSPE: 0.217777 valid's rmse: 0.000387041   valid's RMSPE: 0.257253\n[300]   train's rmse: 0.000314604   train's RMSPE: 0.213829 valid's rmse: 0.000386047   valid's RMSPE: 0.256592\n[350]   train's rmse: 0.000309093   train's RMSPE: 0.210083 valid's rmse: 0.000384019   valid's RMSPE: 0.255244\n[400]   train's rmse: 0.000304119   train's RMSPE: 0.206703 valid's rmse: 0.000382534   valid's RMSPE: 0.254257\n[450]   train's rmse: 0.000300032   train's RMSPE: 0.203925 valid's rmse: 0.00038207    valid's RMSPE: 0.253949\n[500]   train's rmse: 0.000296556   train's RMSPE: 0.201562 valid's rmse: 0.000380845   valid's RMSPE: 0.253135\n[550]   train's rmse: 0.000293121   train's RMSPE: 0.199228 valid's rmse: 0.000379746   valid's RMSPE: 0.252404\nEarly stopping, best iteration is:\n[530]   train's rmse: 0.000294452   train's RMSPE: 0.200132 valid's rmse: 0.000379578   valid's RMSPE: 0.252293\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000367987   train's RMSPE: 0.248132 valid's rmse: 0.000409113   valid's RMSPE: 0.280749\n[100]   train's rmse: 0.000347729   train's RMSPE: 0.234473 valid's rmse: 0.000393478   valid's RMSPE: 0.27002\n[150]   train's rmse: 0.000337667   train's RMSPE: 0.227687 valid's rmse: 0.000387287   valid's RMSPE: 0.265772\n[200]   train's rmse: 0.00032986    train's RMSPE: 0.222423 valid's rmse: 0.00038334    valid's RMSPE: 0.263063\n[250]   train's rmse: 0.000323682   train's RMSPE: 0.218257 valid's rmse: 0.00037968    valid's RMSPE: 0.260551\n[300]   train's rmse: 0.000318076   train's RMSPE: 0.214478 valid's rmse: 0.000378511   valid's RMSPE: 0.259749\n[350]   train's rmse: 0.00031321    train's RMSPE: 0.211196 valid's rmse: 0.000377033   valid's RMSPE: 0.258735\n[400]   train's rmse: 0.000308648   train's RMSPE: 0.20812  valid's rmse: 0.000375108   valid's RMSPE: 0.257414\n[450]   train's rmse: 0.000304837   train's RMSPE: 0.205551 valid's rmse: 0.000374366   valid's RMSPE: 0.256905\n[500]   train's rmse: 0.00030154    train's RMSPE: 0.203328 valid's rmse: 0.000373061   valid's RMSPE: 0.256009\n[550]   train's rmse: 0.000298067   train's RMSPE: 0.200985 valid's rmse: 0.000372295   valid's RMSPE: 0.255484\n[600]   train's rmse: 0.000295169   train's RMSPE: 0.199031 valid's rmse: 0.00037132    valid's RMSPE: 0.254814\nEarly stopping, best iteration is:\n[594]   train's rmse: 0.000295592   train's RMSPE: 0.199317 valid's rmse: 0.000371119   valid's RMSPE: 0.254676\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000379817   train's RMSPE: 0.256542 valid's rmse: 0.000353676   valid's RMSPE: 0.241115\n[100]   train's rmse: 0.000357694   train's RMSPE: 0.2416   valid's rmse: 0.000340457   valid's RMSPE: 0.232102\n[150]   train's rmse: 0.000346926   train's RMSPE: 0.234327 valid's rmse: 0.000337557   valid's RMSPE: 0.230125\n[200]   train's rmse: 0.00033818    train's RMSPE: 0.228419 valid's rmse: 0.000336782   valid's RMSPE: 0.229597\n[250]   train's rmse: 0.000331294   train's RMSPE: 0.223768 valid's rmse: 0.000335524   valid's RMSPE: 0.22874\n[300]   train's rmse: 0.000324978   train's RMSPE: 0.219502 valid's rmse: 0.000335106   valid's RMSPE: 0.228455\nEarly stopping, best iteration is:\n[265]   train's rmse: 0.000329054   train's RMSPE: 0.222255 valid's rmse: 0.000334742   valid's RMSPE: 0.228207\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000379041   train's RMSPE: 0.25543  valid's rmse: 0.00036966    valid's RMSPE: 0.25427\n[100]   train's rmse: 0.000355171   train's RMSPE: 0.239345 valid's rmse: 0.000356939   valid's RMSPE: 0.245519\n[150]   train's rmse: 0.000343889   train's RMSPE: 0.231742 valid's rmse: 0.000355341   valid's RMSPE: 0.24442\n[200]   train's rmse: 0.00033528    train's RMSPE: 0.22594  valid's rmse: 0.000353375   valid's RMSPE: 0.243068\n[250]   train's rmse: 0.000328688   train's RMSPE: 0.221498 valid's rmse: 0.000352191   valid's RMSPE: 0.242253\n[300]   train's rmse: 0.000322819   train's RMSPE: 0.217543 valid's rmse: 0.000351935   valid's RMSPE: 0.242077\n[350]   train's rmse: 0.000317116   train's RMSPE: 0.2137   valid's rmse: 0.000350678   valid's RMSPE: 0.241213\n[400]   train's rmse: 0.000312358   train's RMSPE: 0.210494 valid's rmse: 0.000353542   valid's RMSPE: 0.243183\nEarly stopping, best iteration is:\n[357]   train's rmse: 0.000316294   train's RMSPE: 0.213147 valid's rmse: 0.000350625   valid's RMSPE: 0.241176\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000374489   train's RMSPE: 0.254722 valid's rmse: 0.000376241   valid's RMSPE: 0.249292\n[100]   train's rmse: 0.000351665   train's RMSPE: 0.239197 valid's rmse: 0.000368132   valid's RMSPE: 0.243919\n[150]   train's rmse: 0.000340192   train's RMSPE: 0.231393 valid's rmse: 0.000366087   valid's RMSPE: 0.242564\n[200]   train's rmse: 0.000331251   train's RMSPE: 0.225312 valid's rmse: 0.000366179   valid's RMSPE: 0.242625\nEarly stopping, best iteration is:\n[152]   train's rmse: 0.000339807   train's RMSPE: 0.231132 valid's rmse: 0.000365774   valid's RMSPE: 0.242356\nOur out of folds RMSPE is 0.244, compared to 0.21423163704470313, giving gain 0.029768362955296862\nOur cv fold scores are [0.252, 0.255, 0.228, 0.241, 0.242]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000518921   train's RMSPE: 0.228128 valid's rmse: 0.000553911   valid's RMSPE: 0.2421\n[100]   train's rmse: 0.000492685   train's RMSPE: 0.216595 valid's rmse: 0.000531333   valid's RMSPE: 0.232232\n[150]   train's rmse: 0.000482513   train's RMSPE: 0.212123 valid's rmse: 0.000528038   valid's RMSPE: 0.230792\n[200]   train's rmse: 0.000473695   train's RMSPE: 0.208246 valid's rmse: 0.000525256   valid's RMSPE: 0.229576\n[250]   train's rmse: 0.000464846   train's RMSPE: 0.204356 valid's rmse: 0.000524295   valid's RMSPE: 0.229156\n[300]   train's rmse: 0.000458344   train's RMSPE: 0.201498 valid's rmse: 0.000522757   valid's RMSPE: 0.228484\n[350]   train's rmse: 0.000452011   train's RMSPE: 0.198713 valid's rmse: 0.000520959   valid's RMSPE: 0.227698\nEarly stopping, best iteration is:\n[336]   train's rmse: 0.000453873   train's RMSPE: 0.199532 valid's rmse: 0.000520481   valid's RMSPE: 0.227489\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000518506   train's RMSPE: 0.226821 valid's rmse: 0.000549291   valid's RMSPE: 0.244817\n[100]   train's rmse: 0.000492229   train's RMSPE: 0.215326 valid's rmse: 0.000531408   valid's RMSPE: 0.236847\n[150]   train's rmse: 0.000480461   train's RMSPE: 0.210179 valid's rmse: 0.000529729   valid's RMSPE: 0.236099\n[200]   train's rmse: 0.000470785   train's RMSPE: 0.205945 valid's rmse: 0.000526797   valid's RMSPE: 0.234792\n[250]   train's rmse: 0.000463199   train's RMSPE: 0.202627 valid's rmse: 0.000527352   valid's RMSPE: 0.235039\nEarly stopping, best iteration is:\n[214]   train's rmse: 0.000468637   train's RMSPE: 0.205006 valid's rmse: 0.000526436   valid's RMSPE: 0.234631\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000524928   train's RMSPE: 0.229497 valid's rmse: 0.000512947   valid's RMSPE: 0.22913\n[100]   train's rmse: 0.000498676   train's RMSPE: 0.21802  valid's rmse: 0.000503047   valid's RMSPE: 0.224708\n[150]   train's rmse: 0.000487918   train's RMSPE: 0.213316 valid's rmse: 0.000500814   valid's RMSPE: 0.22371\nEarly stopping, best iteration is:\n[149]   train's rmse: 0.000488036   train's RMSPE: 0.213368 valid's rmse: 0.000500625   valid's RMSPE: 0.223626\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000525394   train's RMSPE: 0.230881 valid's rmse: 0.000530216   valid's RMSPE: 0.232122\n[100]   train's rmse: 0.000499654   train's RMSPE: 0.21957  valid's rmse: 0.000515259   valid's RMSPE: 0.225574\n[150]   train's rmse: 0.000487737   train's RMSPE: 0.214333 valid's rmse: 0.00051355    valid's RMSPE: 0.224826\n[200]   train's rmse: 0.000478557   train's RMSPE: 0.210299 valid's rmse: 0.000512954   valid's RMSPE: 0.224565\nEarly stopping, best iteration is:\n[185]   train's rmse: 0.00048105    train's RMSPE: 0.211394 valid's rmse: 0.000512226   valid's RMSPE: 0.224247\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000521727   train's RMSPE: 0.230517 valid's rmse: 0.000530557   valid's RMSPE: 0.227105\n[100]   train's rmse: 0.00049672    train's RMSPE: 0.219468 valid's rmse: 0.000518427   valid's RMSPE: 0.221913\n[150]   train's rmse: 0.000485823   train's RMSPE: 0.214653 valid's rmse: 0.0005161 valid's RMSPE: 0.220917\n[200]   train's rmse: 0.000476768   train's RMSPE: 0.210653 valid's rmse: 0.000514112   valid's RMSPE: 0.220066\n[250]   train's rmse: 0.000468212   train's RMSPE: 0.206872 valid's rmse: 0.000511887   valid's RMSPE: 0.219114\n[300]   train's rmse: 0.000461538   train's RMSPE: 0.203924 valid's rmse: 0.000511118   valid's RMSPE: 0.218785\n[350]   train's rmse: 0.000455047   train's RMSPE: 0.201055 valid's rmse: 0.000511768   valid's RMSPE: 0.219063\nEarly stopping, best iteration is:\n[316]   train's rmse: 0.000459405   train's RMSPE: 0.202981 valid's rmse: 0.000510663   valid's RMSPE: 0.21859\nOur out of folds RMSPE is 0.226, compared to 0.20040336277301074, giving gain 0.025596637226989266\nOur cv fold scores are [0.227, 0.235, 0.224, 0.224, 0.219]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000433189   train's RMSPE: 0.192845 valid's rmse: 0.000478944   valid's RMSPE: 0.214132\n[100]   train's rmse: 0.000407693   train's RMSPE: 0.181495 valid's rmse: 0.000461463   valid's RMSPE: 0.206317\n[150]   train's rmse: 0.000397858   train's RMSPE: 0.177117 valid's rmse: 0.000457334   valid's RMSPE: 0.204471\n[200]   train's rmse: 0.000389874   train's RMSPE: 0.173563 valid's rmse: 0.000456115   valid's RMSPE: 0.203926\n[250]   train's rmse: 0.000383429   train's RMSPE: 0.170693 valid's rmse: 0.000454218   valid's RMSPE: 0.203077\n[300]   train's rmse: 0.000377816   train's RMSPE: 0.168194 valid's rmse: 0.00045248    valid's RMSPE: 0.2023\n[350]   train's rmse: 0.000372742   train's RMSPE: 0.165936 valid's rmse: 0.000451808   valid's RMSPE: 0.202\n[400]   train's rmse: 0.000368173   train's RMSPE: 0.163902 valid's rmse: 0.00045178    valid's RMSPE: 0.201988\nEarly stopping, best iteration is:\n[379]   train's rmse: 0.000369885   train's RMSPE: 0.164664 valid's rmse: 0.000451161   valid's RMSPE: 0.201711\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000432943   train's RMSPE: 0.192394 valid's rmse: 0.00046348    valid's RMSPE: 0.208671\n[100]   train's rmse: 0.000407794   train's RMSPE: 0.181218 valid's rmse: 0.000450354   valid's RMSPE: 0.202761\n[150]   train's rmse: 0.000397779   train's RMSPE: 0.176767 valid's rmse: 0.000448407   valid's RMSPE: 0.201884\n[200]   train's rmse: 0.000389511   train's RMSPE: 0.173093 valid's rmse: 0.000446317   valid's RMSPE: 0.200943\n[250]   train's rmse: 0.000382848   train's RMSPE: 0.170132 valid's rmse: 0.000444879   valid's RMSPE: 0.200296\n[300]   train's rmse: 0.000377465   train's RMSPE: 0.16774  valid's rmse: 0.000442946   valid's RMSPE: 0.199426\n[350]   train's rmse: 0.000371738   train's RMSPE: 0.165195 valid's rmse: 0.000441549   valid's RMSPE: 0.198797\n[400]   train's rmse: 0.000367062   train's RMSPE: 0.163117 valid's rmse: 0.000440566   valid's RMSPE: 0.198354\n[450]   train's rmse: 0.000362614   train's RMSPE: 0.16114  valid's rmse: 0.000439655   valid's RMSPE: 0.197944\n[500]   train's rmse: 0.000358581   train's RMSPE: 0.159348 valid's rmse: 0.00043999    valid's RMSPE: 0.198095\nEarly stopping, best iteration is:\n[486]   train's rmse: 0.000359724   train's RMSPE: 0.159856 valid's rmse: 0.000439535   valid's RMSPE: 0.19789\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000444898   train's RMSPE: 0.19725  valid's rmse: 0.000413365   valid's RMSPE: 0.18777\n[100]   train's rmse: 0.000420029   train's RMSPE: 0.186225 valid's rmse: 0.000397322   valid's RMSPE: 0.180483\n[150]   train's rmse: 0.000409487   train's RMSPE: 0.181551 valid's rmse: 0.000396058   valid's RMSPE: 0.179909\n[200]   train's rmse: 0.000401497   train's RMSPE: 0.178008 valid's rmse: 0.000395737   valid's RMSPE: 0.179763\n[250]   train's rmse: 0.000394792   train's RMSPE: 0.175035 valid's rmse: 0.000393723   valid's RMSPE: 0.178848\n[300]   train's rmse: 0.000388874   train's RMSPE: 0.172411 valid's rmse: 0.000393443   valid's RMSPE: 0.178721\n[350]   train's rmse: 0.000383262   train's RMSPE: 0.169923 valid's rmse: 0.000393503   valid's RMSPE: 0.178748\nEarly stopping, best iteration is:\n[327]   train's rmse: 0.000385684   train's RMSPE: 0.170997 valid's rmse: 0.000392937   valid's RMSPE: 0.178491\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000441435   train's RMSPE: 0.197068 valid's rmse: 0.000444912   valid's RMSPE: 0.196685\n[100]   train's rmse: 0.000415582   train's RMSPE: 0.185527 valid's rmse: 0.000427652   valid's RMSPE: 0.189055\n[150]   train's rmse: 0.000405661   train's RMSPE: 0.181098 valid's rmse: 0.000425473   valid's RMSPE: 0.188091\n[200]   train's rmse: 0.00039786    train's RMSPE: 0.177615 valid's rmse: 0.000424109   valid's RMSPE: 0.187489\n[250]   train's rmse: 0.000391521   train's RMSPE: 0.174785 valid's rmse: 0.000422262   valid's RMSPE: 0.186672\n[300]   train's rmse: 0.000385754   train's RMSPE: 0.172211 valid's rmse: 0.000421269   valid's RMSPE: 0.186233\nEarly stopping, best iteration is:\n[288]   train's rmse: 0.000387177   train's RMSPE: 0.172846 valid's rmse: 0.000420809   valid's RMSPE: 0.18603\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00043869    train's RMSPE: 0.196723 valid's rmse: 0.000453379   valid's RMSPE: 0.196711\n[100]   train's rmse: 0.000413437   train's RMSPE: 0.185399 valid's rmse: 0.000434064   valid's RMSPE: 0.18833\n[150]   train's rmse: 0.000403443   train's RMSPE: 0.180917 valid's rmse: 0.000431563   valid's RMSPE: 0.187245\n[200]   train's rmse: 0.000395527   train's RMSPE: 0.177367 valid's rmse: 0.000429264   valid's RMSPE: 0.186248\n[250]   train's rmse: 0.000389031   train's RMSPE: 0.174454 valid's rmse: 0.000428326   valid's RMSPE: 0.185841\n[300]   train's rmse: 0.000383514   train's RMSPE: 0.17198  valid's rmse: 0.000427696   valid's RMSPE: 0.185568\n[350]   train's rmse: 0.000378363   train's RMSPE: 0.169671 valid's rmse: 0.00042843    valid's RMSPE: 0.185886\nEarly stopping, best iteration is:\n[304]   train's rmse: 0.000383086   train's RMSPE: 0.171788 valid's rmse: 0.000427423   valid's RMSPE: 0.185449\nOur out of folds RMSPE is 0.19, compared to 0.1716341490656949, giving gain 0.018365850934305095\nOur cv fold scores are [0.202, 0.198, 0.178, 0.186, 0.185]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000404051   train's RMSPE: 0.232355 valid's rmse: 0.000434802   valid's RMSPE: 0.247156\n[100]   train's rmse: 0.000382754   train's RMSPE: 0.220108 valid's rmse: 0.000415534   valid's RMSPE: 0.236203\n[150]   train's rmse: 0.000373717   train's RMSPE: 0.214911 valid's rmse: 0.000411464   valid's RMSPE: 0.233889\n[200]   train's rmse: 0.000365743   train's RMSPE: 0.210326 valid's rmse: 0.000407746   valid's RMSPE: 0.231776\n[250]   train's rmse: 0.000359713   train's RMSPE: 0.206858 valid's rmse: 0.000406331   valid's RMSPE: 0.230972\n[300]   train's rmse: 0.000354397   train's RMSPE: 0.203801 valid's rmse: 0.000404264   valid's RMSPE: 0.229797\n[350]   train's rmse: 0.000349901   train's RMSPE: 0.201216 valid's rmse: 0.000403529   valid's RMSPE: 0.229379\n[400]   train's rmse: 0.000345342   train's RMSPE: 0.198594 valid's rmse: 0.000402146   valid's RMSPE: 0.228593\n[450]   train's rmse: 0.000341279   train's RMSPE: 0.196257 valid's rmse: 0.000401563   valid's RMSPE: 0.228262\n[500]   train's rmse: 0.000337948   train's RMSPE: 0.194342 valid's rmse: 0.000401939   valid's RMSPE: 0.228475\nEarly stopping, best iteration is:\n[454]   train's rmse: 0.000340983   train's RMSPE: 0.196087 valid's rmse: 0.000401335   valid's RMSPE: 0.228132\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000405912   train's RMSPE: 0.232367 valid's rmse: 0.000427819   valid's RMSPE: 0.247649\n[100]   train's rmse: 0.00038456    train's RMSPE: 0.220144 valid's rmse: 0.000408604   valid's RMSPE: 0.236526\n[150]   train's rmse: 0.000375432   train's RMSPE: 0.214919 valid's rmse: 0.000403445   valid's RMSPE: 0.233539\n[200]   train's rmse: 0.000368753   train's RMSPE: 0.211095 valid's rmse: 0.000399153   valid's RMSPE: 0.231055\n[250]   train's rmse: 0.000363059   train's RMSPE: 0.207836 valid's rmse: 0.000396217   valid's RMSPE: 0.229355\n[300]   train's rmse: 0.000358084   train's RMSPE: 0.204988 valid's rmse: 0.000393707   valid's RMSPE: 0.227902\n[350]   train's rmse: 0.000354042   train's RMSPE: 0.202674 valid's rmse: 0.000391848   valid's RMSPE: 0.226827\n[400]   train's rmse: 0.000350475   train's RMSPE: 0.200632 valid's rmse: 0.000390511   valid's RMSPE: 0.226052\n[450]   train's rmse: 0.000347116   train's RMSPE: 0.198709 valid's rmse: 0.000389586   valid's RMSPE: 0.225517\n[500]   train's rmse: 0.000343917   train's RMSPE: 0.196878 valid's rmse: 0.000388703   valid's RMSPE: 0.225006\n[550]   train's rmse: 0.000340863   train's RMSPE: 0.19513  valid's rmse: 0.000388083   valid's RMSPE: 0.224647\n[600]   train's rmse: 0.000337905   train's RMSPE: 0.193436 valid's rmse: 0.000387192   valid's RMSPE: 0.224131\n[650]   train's rmse: 0.000335076   train's RMSPE: 0.191817 valid's rmse: 0.000386627   valid's RMSPE: 0.223804\n[700]   train's rmse: 0.000332262   train's RMSPE: 0.190206 valid's rmse: 0.00038645    valid's RMSPE: 0.223702\n[750]   train's rmse: 0.000329628   train's RMSPE: 0.188698 valid's rmse: 0.00038572    valid's RMSPE: 0.223279\n[800]   train's rmse: 0.000327232   train's RMSPE: 0.187326 valid's rmse: 0.000385353   valid's RMSPE: 0.223067\nEarly stopping, best iteration is:\n[781]   train's rmse: 0.000327971   train's RMSPE: 0.187749 valid's rmse: 0.0003852 valid's RMSPE: 0.222978\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000408327   train's RMSPE: 0.234056 valid's rmse: 0.000415989   valid's RMSPE: 0.239562\n[100]   train's rmse: 0.000386992   train's RMSPE: 0.221826 valid's rmse: 0.000401929   valid's RMSPE: 0.231465\n[150]   train's rmse: 0.000377042   train's RMSPE: 0.216123 valid's rmse: 0.000397917   valid's RMSPE: 0.229155\n[200]   train's rmse: 0.0003689 train's RMSPE: 0.211456 valid's rmse: 0.000395072   valid's RMSPE: 0.227517\n[250]   train's rmse: 0.000363144   train's RMSPE: 0.208157 valid's rmse: 0.000393398   valid's RMSPE: 0.226552\n[300]   train's rmse: 0.000358014   train's RMSPE: 0.205216 valid's rmse: 0.000391945   valid's RMSPE: 0.225716\n[350]   train's rmse: 0.000353009   train's RMSPE: 0.202347 valid's rmse: 0.000390648   valid's RMSPE: 0.224969\n[400]   train's rmse: 0.000349111   train's RMSPE: 0.200113 valid's rmse: 0.000391155   valid's RMSPE: 0.225261\nEarly stopping, best iteration is:\n[367]   train's rmse: 0.000351635   train's RMSPE: 0.20156  valid's rmse: 0.000390199   valid's RMSPE: 0.224711\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000411013   train's RMSPE: 0.235809 valid's rmse: 0.000399902   valid's RMSPE: 0.229468\n[100]   train's rmse: 0.000389888   train's RMSPE: 0.22369  valid's rmse: 0.000386833   valid's RMSPE: 0.221969\n[150]   train's rmse: 0.000380972   train's RMSPE: 0.218574 valid's rmse: 0.000382896   valid's RMSPE: 0.21971\n[200]   train's rmse: 0.000374245   train's RMSPE: 0.214715 valid's rmse: 0.000380018   valid's RMSPE: 0.218058\n[250]   train's rmse: 0.000368265   train's RMSPE: 0.211284 valid's rmse: 0.000377296   valid's RMSPE: 0.216496\n[300]   train's rmse: 0.000363414   train's RMSPE: 0.2085   valid's rmse: 0.000376207   valid's RMSPE: 0.215872\n[350]   train's rmse: 0.000358632   train's RMSPE: 0.205757 valid's rmse: 0.000375153   valid's RMSPE: 0.215267\n[400]   train's rmse: 0.00035442    train's RMSPE: 0.20334  valid's rmse: 0.000374973   valid's RMSPE: 0.215163\n[450]   train's rmse: 0.000350739   train's RMSPE: 0.201229 valid's rmse: 0.000374934   valid's RMSPE: 0.215141\n[500]   train's rmse: 0.000347392   train's RMSPE: 0.199308 valid's rmse: 0.000374268   valid's RMSPE: 0.214759\n[550]   train's rmse: 0.000344122   train's RMSPE: 0.197432 valid's rmse: 0.000374304   valid's RMSPE: 0.21478\nEarly stopping, best iteration is:\n[516]   train's rmse: 0.000346313   train's RMSPE: 0.198689 valid's rmse: 0.000374007   valid's RMSPE: 0.214609\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000412607   train's RMSPE: 0.236944 valid's rmse: 0.000402675   valid's RMSPE: 0.230198\n[100]   train's rmse: 0.000391933   train's RMSPE: 0.225072 valid's rmse: 0.000389888   valid's RMSPE: 0.222888\n[150]   train's rmse: 0.000382524   train's RMSPE: 0.219668 valid's rmse: 0.000385454   valid's RMSPE: 0.220353\n[200]   train's rmse: 0.000375209   train's RMSPE: 0.215468 valid's rmse: 0.000382009   valid's RMSPE: 0.218384\n[250]   train's rmse: 0.000369039   train's RMSPE: 0.211925 valid's rmse: 0.000380712   valid's RMSPE: 0.217642\n[300]   train's rmse: 0.000363679   train's RMSPE: 0.208846 valid's rmse: 0.000379597   valid's RMSPE: 0.217005\n[350]   train's rmse: 0.000359604   train's RMSPE: 0.206506 valid's rmse: 0.000378535   valid's RMSPE: 0.216398\n[400]   train's rmse: 0.000355003   train's RMSPE: 0.203865 valid's rmse: 0.000378447   valid's RMSPE: 0.216348\n[450]   train's rmse: 0.000351286   train's RMSPE: 0.20173  valid's rmse: 0.000377493   valid's RMSPE: 0.215802\n[500]   train's rmse: 0.000348219   train's RMSPE: 0.199969 valid's rmse: 0.00037743    valid's RMSPE: 0.215766\nEarly stopping, best iteration is:\n[472]   train's rmse: 0.000349937   train's RMSPE: 0.200955 valid's rmse: 0.000377105   valid's RMSPE: 0.21558\nOur out of folds RMSPE is 0.221, compared to 0.17552957994839127, giving gain 0.04547042005160873\nOur cv fold scores are [0.228, 0.223, 0.225, 0.215, 0.216]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000482897   train's RMSPE: 0.238967 valid's rmse: 0.000519933   valid's RMSPE: 0.255886\n[100]   train's rmse: 0.00045544    train's RMSPE: 0.22538  valid's rmse: 0.000498117   valid's RMSPE: 0.245149\n[150]   train's rmse: 0.000443839   train's RMSPE: 0.219639 valid's rmse: 0.000493753   valid's RMSPE: 0.243002\n[200]   train's rmse: 0.000435175   train's RMSPE: 0.215352 valid's rmse: 0.000491886   valid's RMSPE: 0.242083\n[250]   train's rmse: 0.00042811    train's RMSPE: 0.211855 valid's rmse: 0.000490361   valid's RMSPE: 0.241332\nEarly stopping, best iteration is:\n[241]   train's rmse: 0.000429225   train's RMSPE: 0.212407 valid's rmse: 0.000489946   valid's RMSPE: 0.241128\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000479038   train's RMSPE: 0.23643  valid's rmse: 0.000516401   valid's RMSPE: 0.256852\n[100]   train's rmse: 0.000454994   train's RMSPE: 0.224563 valid's rmse: 0.000499308   valid's RMSPE: 0.248349\n[150]   train's rmse: 0.000444677   train's RMSPE: 0.219471 valid's rmse: 0.000497334   valid's RMSPE: 0.247368\n[200]   train's rmse: 0.000436866   train's RMSPE: 0.215616 valid's rmse: 0.000496933   valid's RMSPE: 0.247168\n[250]   train's rmse: 0.000428719   train's RMSPE: 0.211595 valid's rmse: 0.00049422    valid's RMSPE: 0.245819\nEarly stopping, best iteration is:\n[246]   train's rmse: 0.000429248   train's RMSPE: 0.211856 valid's rmse: 0.000493708   valid's RMSPE: 0.245564\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.00048693    train's RMSPE: 0.240517 valid's rmse: 0.000493618   valid's RMSPE: 0.244745\n[100]   train's rmse: 0.000462006   train's RMSPE: 0.228206 valid's rmse: 0.000476138   valid's RMSPE: 0.236078\n[150]   train's rmse: 0.000450937   train's RMSPE: 0.222739 valid's rmse: 0.000471592   valid's RMSPE: 0.233824\n[200]   train's rmse: 0.000442292   train's RMSPE: 0.218468 valid's rmse: 0.000471026   valid's RMSPE: 0.233544\n[250]   train's rmse: 0.000435488   train's RMSPE: 0.215107 valid's rmse: 0.000470153   valid's RMSPE: 0.23311\n[300]   train's rmse: 0.000429508   train's RMSPE: 0.212154 valid's rmse: 0.000469168   valid's RMSPE: 0.232622\nEarly stopping, best iteration is:\n[293]   train's rmse: 0.000430163   train's RMSPE: 0.212477 valid's rmse: 0.000468832   valid's RMSPE: 0.232456\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000494743   train's RMSPE: 0.244663 valid's rmse: 0.000459296   valid's RMSPE: 0.226664\n[100]   train's rmse: 0.000469041   train's RMSPE: 0.231952 valid's rmse: 0.000443093   valid's RMSPE: 0.218668\n[150]   train's rmse: 0.000458311   train's RMSPE: 0.226646 valid's rmse: 0.000440706   valid's RMSPE: 0.21749\n[200]   train's rmse: 0.00044926    train's RMSPE: 0.222171 valid's rmse: 0.000439178   valid's RMSPE: 0.216736\n[250]   train's rmse: 0.000442394   train's RMSPE: 0.218775 valid's rmse: 0.000438838   valid's RMSPE: 0.216568\n[300]   train's rmse: 0.000435531   train's RMSPE: 0.215381 valid's rmse: 0.000437719   valid's RMSPE: 0.216016\nEarly stopping, best iteration is:\n[263]   train's rmse: 0.000440876   train's RMSPE: 0.218024 valid's rmse: 0.000437308   valid's RMSPE: 0.215813\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000484861   train's RMSPE: 0.23987  valid's rmse: 0.000493303   valid's RMSPE: 0.243062\n[100]   train's rmse: 0.000460185   train's RMSPE: 0.227663 valid's rmse: 0.000480031   valid's RMSPE: 0.236523\n[150]   train's rmse: 0.000448945   train's RMSPE: 0.222102 valid's rmse: 0.000476134   valid's RMSPE: 0.234602\n[200]   train's rmse: 0.000440498   train's RMSPE: 0.217923 valid's rmse: 0.000475142   valid's RMSPE: 0.234113\n[250]   train's rmse: 0.000433026   train's RMSPE: 0.214226 valid's rmse: 0.000474694   valid's RMSPE: 0.233893\nEarly stopping, best iteration is:\n[225]   train's rmse: 0.000436639   train's RMSPE: 0.216014 valid's rmse: 0.000474356   valid's RMSPE: 0.233726\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.234, compared to 0.19115105952198225, giving gain 0.042848940478017766\nOur cv fold scores are [0.241, 0.246, 0.232, 0.216, 0.234]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000457988   train's RMSPE: 0.2435   valid's rmse: 0.000493914   valid's RMSPE: 0.257165\n[100]   train's rmse: 0.000437976   train's RMSPE: 0.23286  valid's rmse: 0.000479809   valid's RMSPE: 0.249821\n[150]   train's rmse: 0.000428478   train's RMSPE: 0.227811 valid's rmse: 0.000476945   valid's RMSPE: 0.24833\n[200]   train's rmse: 0.000419562   train's RMSPE: 0.22307  valid's rmse: 0.000473035   valid's RMSPE: 0.246294\n[250]   train's rmse: 0.00041283    train's RMSPE: 0.219491 valid's rmse: 0.00047206    valid's RMSPE: 0.245787\n[300]   train's rmse: 0.000406502   train's RMSPE: 0.216126 valid's rmse: 0.000471996   valid's RMSPE: 0.245754\n[350]   train's rmse: 0.00040105    train's RMSPE: 0.213228 valid's rmse: 0.000469674   valid's RMSPE: 0.244545\n[400]   train's rmse: 0.00039595    train's RMSPE: 0.210516 valid's rmse: 0.000467856   valid's RMSPE: 0.243598\n[450]   train's rmse: 0.000390724   train's RMSPE: 0.207738 valid's rmse: 0.000466949   valid's RMSPE: 0.243125\n[500]   train's rmse: 0.000386568   train's RMSPE: 0.205528 valid's rmse: 0.000466829   valid's RMSPE: 0.243063\nEarly stopping, best iteration is:\n[464]   train's rmse: 0.000389597   train's RMSPE: 0.207139 valid's rmse: 0.000466048   valid's RMSPE: 0.242657\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000456083   train's RMSPE: 0.240487 valid's rmse: 0.000499657   valid's RMSPE: 0.268923\n[100]   train's rmse: 0.000434162   train's RMSPE: 0.228928 valid's rmse: 0.000485322   valid's RMSPE: 0.261208\n[150]   train's rmse: 0.000424924   train's RMSPE: 0.224057 valid's rmse: 0.000482623   valid's RMSPE: 0.259756\n[200]   train's rmse: 0.000417131   train's RMSPE: 0.219948 valid's rmse: 0.000479623   valid's RMSPE: 0.258141\n[250]   train's rmse: 0.000411123   train's RMSPE: 0.21678  valid's rmse: 0.00047793    valid's RMSPE: 0.25723\n[300]   train's rmse: 0.00040528    train's RMSPE: 0.213699 valid's rmse: 0.000477153   valid's RMSPE: 0.256811\n[350]   train's rmse: 0.000399708   train's RMSPE: 0.210761 valid's rmse: 0.000475235   valid's RMSPE: 0.255779\n[400]   train's rmse: 0.000395149   train's RMSPE: 0.208357 valid's rmse: 0.000474903   valid's RMSPE: 0.2556\n[450]   train's rmse: 0.000390486   train's RMSPE: 0.205899 valid's rmse: 0.000473561   valid's RMSPE: 0.254878\n[500]   train's rmse: 0.000386514   train's RMSPE: 0.203804 valid's rmse: 0.000473374   valid's RMSPE: 0.254777\nEarly stopping, best iteration is:\n[475]   train's rmse: 0.000388297   train's RMSPE: 0.204744 valid's rmse: 0.000472769   valid's RMSPE: 0.254452\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000469695   train's RMSPE: 0.247912 valid's rmse: 0.0004357 valid's RMSPE: 0.233597\n[100]   train's rmse: 0.000448543   train's RMSPE: 0.236748 valid's rmse: 0.000429  valid's RMSPE: 0.230005\nEarly stopping, best iteration is:\n[90]    train's rmse: 0.000451159   train's RMSPE: 0.238129 valid's rmse: 0.000428174   valid's RMSPE: 0.229562\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000466601   train's RMSPE: 0.246927 valid's rmse: 0.000460628   valid's RMSPE: 0.244428\n[100]   train's rmse: 0.000445622   train's RMSPE: 0.235825 valid's rmse: 0.000448304   valid's RMSPE: 0.237888\n[150]   train's rmse: 0.000436219   train's RMSPE: 0.230849 valid's rmse: 0.000445323   valid's RMSPE: 0.236306\n[200]   train's rmse: 0.000426812   train's RMSPE: 0.225871 valid's rmse: 0.000443304   valid's RMSPE: 0.235235\nEarly stopping, best iteration is:\n[199]   train's rmse: 0.000426915   train's RMSPE: 0.225925 valid's rmse: 0.000443244   valid's RMSPE: 0.235203\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000461482   train's RMSPE: 0.24526  valid's rmse: 0.000474622   valid's RMSPE: 0.247535\n[100]   train's rmse: 0.000441185   train's RMSPE: 0.234472 valid's rmse: 0.000466305   valid's RMSPE: 0.243198\n[150]   train's rmse: 0.00043124    train's RMSPE: 0.229187 valid's rmse: 0.000466249   valid's RMSPE: 0.243169\nEarly stopping, best iteration is:\n[132]   train's rmse: 0.000434167   train's RMSPE: 0.230743 valid's rmse: 0.000464804   valid's RMSPE: 0.242415\nOur out of folds RMSPE is 0.241, compared to 0.1976775402077671, giving gain 0.0433224597922329\nOur cv fold scores are [0.243, 0.254, 0.23, 0.235, 0.242]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000791794   train's RMSPE: 0.239436 valid's rmse: 0.000846052   valid's RMSPE: 0.250488\n[100]   train's rmse: 0.000744666   train's RMSPE: 0.225184 valid's rmse: 0.000822681   valid's RMSPE: 0.243569\n[150]   train's rmse: 0.000723299   train's RMSPE: 0.218723 valid's rmse: 0.000818577   valid's RMSPE: 0.242354\nEarly stopping, best iteration is:\n[145]   train's rmse: 0.000725098   train's RMSPE: 0.219267 valid's rmse: 0.000817545   valid's RMSPE: 0.242048\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00080158    train's RMSPE: 0.239645 valid's rmse: 0.000833736   valid's RMSPE: 0.258199\n[100]   train's rmse: 0.000754277   train's RMSPE: 0.225503 valid's rmse: 0.000799332   valid's RMSPE: 0.247544\n[150]   train's rmse: 0.00073459    train's RMSPE: 0.219617 valid's rmse: 0.000799653   valid's RMSPE: 0.247643\nEarly stopping, best iteration is:\n[124]   train's rmse: 0.000742947   train's RMSPE: 0.222116 valid's rmse: 0.000797544   valid's RMSPE: 0.24699\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000793593   train's RMSPE: 0.238448 valid's rmse: 0.000834368   valid's RMSPE: 0.253501\n[100]   train's rmse: 0.000748077   train's RMSPE: 0.224772 valid's rmse: 0.000817881   valid's RMSPE: 0.248492\n[150]   train's rmse: 0.000729303   train's RMSPE: 0.219131 valid's rmse: 0.000814916   valid's RMSPE: 0.247591\n[200]   train's rmse: 0.000714793   train's RMSPE: 0.214772 valid's rmse: 0.000814032   valid's RMSPE: 0.247323\n[250]   train's rmse: 0.000701329   train's RMSPE: 0.210726 valid's rmse: 0.000810996   valid's RMSPE: 0.2464\nEarly stopping, best iteration is:\n[245]   train's rmse: 0.000702554   train's RMSPE: 0.211094 valid's rmse: 0.000810648   valid's RMSPE: 0.246294\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000801343   train's RMSPE: 0.240706 valid's rmse: 0.000831118   valid's RMSPE: 0.252806\n[100]   train's rmse: 0.00075551    train's RMSPE: 0.226938 valid's rmse: 0.000787973   valid's RMSPE: 0.239682\n[150]   train's rmse: 0.000736424   train's RMSPE: 0.221205 valid's rmse: 0.000784355   valid's RMSPE: 0.238582\n[200]   train's rmse: 0.000721422   train's RMSPE: 0.216699 valid's rmse: 0.000783625   valid's RMSPE: 0.23836\n[250]   train's rmse: 0.000709516   train's RMSPE: 0.213123 valid's rmse: 0.000782045   valid's RMSPE: 0.237879\nEarly stopping, best iteration is:\n[243]   train's rmse: 0.000711039   train's RMSPE: 0.21358  valid's rmse: 0.000781064   valid's RMSPE: 0.237581\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000802203   train's RMSPE: 0.243451 valid's rmse: 0.000810728   valid's RMSPE: 0.236414\n[100]   train's rmse: 0.000756068   train's RMSPE: 0.22945  valid's rmse: 0.000799085   valid's RMSPE: 0.233019\n[150]   train's rmse: 0.000736431   train's RMSPE: 0.22349  valid's rmse: 0.000796241   valid's RMSPE: 0.23219\n[200]   train's rmse: 0.000720297   train's RMSPE: 0.218594 valid's rmse: 0.000799286   valid's RMSPE: 0.233078\nEarly stopping, best iteration is:\n[150]   train's rmse: 0.000736431   train's RMSPE: 0.22349  valid's rmse: 0.000796241   valid's RMSPE: 0.23219\nOur out of folds RMSPE is 0.241, compared to 0.21694871689478218, giving gain 0.024051283105217813\nOur cv fold scores are [0.242, 0.247, 0.246, 0.238, 0.232]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000615269   train's RMSPE: 0.186362 valid's rmse: 0.000641006   valid's RMSPE: 0.196004\n[100]   train's rmse: 0.000580305   train's RMSPE: 0.175771 valid's rmse: 0.0006102 valid's RMSPE: 0.186584\n[150]   train's rmse: 0.000566782   train's RMSPE: 0.171675 valid's rmse: 0.00060373    valid's RMSPE: 0.184606\n[200]   train's rmse: 0.00055788    train's RMSPE: 0.168979 valid's rmse: 0.000602189   valid's RMSPE: 0.184134\n[250]   train's rmse: 0.000549013   train's RMSPE: 0.166293 valid's rmse: 0.000598017   valid's RMSPE: 0.182859\n[300]   train's rmse: 0.000541119   train's RMSPE: 0.163902 valid's rmse: 0.000595226   valid's RMSPE: 0.182005\n[350]   train's rmse: 0.000534016   train's RMSPE: 0.161751 valid's rmse: 0.000594943   valid's RMSPE: 0.181919\nEarly stopping, best iteration is:\n[328]   train's rmse: 0.000536995   train's RMSPE: 0.162653 valid's rmse: 0.000593733   valid's RMSPE: 0.181549\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000606196   train's RMSPE: 0.183558 valid's rmse: 0.00064853    valid's RMSPE: 0.198542\n[100]   train's rmse: 0.000569989   train's RMSPE: 0.172594 valid's rmse: 0.000628047   valid's RMSPE: 0.192271\n[150]   train's rmse: 0.000557647   train's RMSPE: 0.168857 valid's rmse: 0.00062342    valid's RMSPE: 0.190854\n[200]   train's rmse: 0.000547873   train's RMSPE: 0.165898 valid's rmse: 0.00062116    valid's RMSPE: 0.190162\n[250]   train's rmse: 0.000539335   train's RMSPE: 0.163312 valid's rmse: 0.000618729   valid's RMSPE: 0.189418\n[300]   train's rmse: 0.000532515   train's RMSPE: 0.161247 valid's rmse: 0.000617852   valid's RMSPE: 0.18915\n[350]   train's rmse: 0.000525297   train's RMSPE: 0.159062 valid's rmse: 0.000616304   valid's RMSPE: 0.188676\n[400]   train's rmse: 0.00051941    train's RMSPE: 0.157279 valid's rmse: 0.000614427   valid's RMSPE: 0.188101\n[450]   train's rmse: 0.0005135 train's RMSPE: 0.155489 valid's rmse: 0.000612414   valid's RMSPE: 0.187485\n[500]   train's rmse: 0.000508403   train's RMSPE: 0.153946 valid's rmse: 0.000614133   valid's RMSPE: 0.188011\nEarly stopping, best iteration is:\n[460]   train's rmse: 0.000512414   train's RMSPE: 0.15516  valid's rmse: 0.00061223    valid's RMSPE: 0.187429\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000614314   train's RMSPE: 0.186293 valid's rmse: 0.000615201   valid's RMSPE: 0.187236\n[100]   train's rmse: 0.000578689   train's RMSPE: 0.17549  valid's rmse: 0.00059317    valid's RMSPE: 0.180531\n[150]   train's rmse: 0.000564913   train's RMSPE: 0.171312 valid's rmse: 0.000589397   valid's RMSPE: 0.179383\n[200]   train's rmse: 0.000554796   train's RMSPE: 0.168244 valid's rmse: 0.00058796    valid's RMSPE: 0.178945\n[250]   train's rmse: 0.000546414   train's RMSPE: 0.165702 valid's rmse: 0.000586651   valid's RMSPE: 0.178547\n[300]   train's rmse: 0.000538896   train's RMSPE: 0.163422 valid's rmse: 0.000585551   valid's RMSPE: 0.178212\n[350]   train's rmse: 0.000532578   train's RMSPE: 0.161506 valid's rmse: 0.000585597   valid's RMSPE: 0.178226\n[400]   train's rmse: 0.000525952   train's RMSPE: 0.159497 valid's rmse: 0.000584727   valid's RMSPE: 0.177961\n[450]   train's rmse: 0.000519912   train's RMSPE: 0.157665 valid's rmse: 0.000584623   valid's RMSPE: 0.17793\nEarly stopping, best iteration is:\n[434]   train's rmse: 0.000522265   train's RMSPE: 0.158379 valid's rmse: 0.000584008   valid's RMSPE: 0.177743\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000611281   train's RMSPE: 0.18588  valid's rmse: 0.000633623   valid's RMSPE: 0.190736\n[100]   train's rmse: 0.000573544   train's RMSPE: 0.174405 valid's rmse: 0.00061131    valid's RMSPE: 0.184019\n[150]   train's rmse: 0.000560159   train's RMSPE: 0.170335 valid's rmse: 0.00060869    valid's RMSPE: 0.18323\n[200]   train's rmse: 0.000549555   train's RMSPE: 0.16711  valid's rmse: 0.000608894   valid's RMSPE: 0.183292\nEarly stopping, best iteration is:\n[167]   train's rmse: 0.000556357   train's RMSPE: 0.169178 valid's rmse: 0.000608108   valid's RMSPE: 0.183055\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000618542   train's RMSPE: 0.188241 valid's rmse: 0.000601608   valid's RMSPE: 0.180498\n[100]   train's rmse: 0.000582901   train's RMSPE: 0.177394 valid's rmse: 0.000577334   valid's RMSPE: 0.173215\n[150]   train's rmse: 0.000569689   train's RMSPE: 0.173373 valid's rmse: 0.000574581   valid's RMSPE: 0.172389\n[200]   train's rmse: 0.000559663   train's RMSPE: 0.170322 valid's rmse: 0.000573911   valid's RMSPE: 0.172188\n[250]   train's rmse: 0.000552088   train's RMSPE: 0.168017 valid's rmse: 0.000573715   valid's RMSPE: 0.172129\nEarly stopping, best iteration is:\n[228]   train's rmse: 0.000555191   train's RMSPE: 0.168961 valid's rmse: 0.00057269    valid's RMSPE: 0.171821\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.18, compared to 0.1547566259930346, giving gain 0.025243374006965386\nOur cv fold scores are [0.182, 0.187, 0.178, 0.183, 0.172]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000653347   train's RMSPE: 0.284463 valid's rmse: 0.00067398    valid's RMSPE: 0.296359\n[100]   train's rmse: 0.000615357   train's RMSPE: 0.267922 valid's rmse: 0.000649711   valid's RMSPE: 0.285688\n[150]   train's rmse: 0.000596022   train's RMSPE: 0.259504 valid's rmse: 0.000644953   valid's RMSPE: 0.283596\n[200]   train's rmse: 0.000579897   train's RMSPE: 0.252483 valid's rmse: 0.000640869   valid's RMSPE: 0.2818\n[250]   train's rmse: 0.000568857   train's RMSPE: 0.247677 valid's rmse: 0.000639326   valid's RMSPE: 0.281121\n[300]   train's rmse: 0.000558628   train's RMSPE: 0.243223 valid's rmse: 0.000639336   valid's RMSPE: 0.281125\n[350]   train's rmse: 0.000548593   train's RMSPE: 0.238854 valid's rmse: 0.000637894   valid's RMSPE: 0.280491\n[400]   train's rmse: 0.000540247   train's RMSPE: 0.23522  valid's rmse: 0.000635785   valid's RMSPE: 0.279564\n[450]   train's rmse: 0.00053369    train's RMSPE: 0.232365 valid's rmse: 0.000634087   valid's RMSPE: 0.278818\n[500]   train's rmse: 0.000526832   train's RMSPE: 0.229379 valid's rmse: 0.000634704   valid's RMSPE: 0.279089\nEarly stopping, best iteration is:\n[454]   train's rmse: 0.000533049   train's RMSPE: 0.232086 valid's rmse: 0.00063376    valid's RMSPE: 0.278674\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000643142   train's RMSPE: 0.282491 valid's rmse: 0.00071781    valid's RMSPE: 0.304466\n[100]   train's rmse: 0.000603254   train's RMSPE: 0.26497  valid's rmse: 0.000710149   valid's RMSPE: 0.301216\n[150]   train's rmse: 0.00058535    train's RMSPE: 0.257106 valid's rmse: 0.000704136   valid's RMSPE: 0.298665\n[200]   train's rmse: 0.000570741   train's RMSPE: 0.250689 valid's rmse: 0.00070202    valid's RMSPE: 0.297768\n[250]   train's rmse: 0.000558947   train's RMSPE: 0.245509 valid's rmse: 0.000698846   valid's RMSPE: 0.296421\n[300]   train's rmse: 0.000548396   train's RMSPE: 0.240875 valid's rmse: 0.000694201   valid's RMSPE: 0.294451\n[350]   train's rmse: 0.000540736   train's RMSPE: 0.23751  valid's rmse: 0.000693636   valid's RMSPE: 0.294212\nEarly stopping, best iteration is:\n[333]   train's rmse: 0.000543294   train's RMSPE: 0.238634 valid's rmse: 0.000692972   valid's RMSPE: 0.29393\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000658388   train's RMSPE: 0.28523  valid's rmse: 0.000650381   valid's RMSPE: 0.291501\n[100]   train's rmse: 0.000618793   train's RMSPE: 0.268076 valid's rmse: 0.000624014   valid's RMSPE: 0.279684\n[150]   train's rmse: 0.000600976   train's RMSPE: 0.260358 valid's rmse: 0.000617916   valid's RMSPE: 0.276951\n[200]   train's rmse: 0.000588288   train's RMSPE: 0.254861 valid's rmse: 0.000615701   valid's RMSPE: 0.275958\n[250]   train's rmse: 0.000576903   train's RMSPE: 0.249929 valid's rmse: 0.000613306   valid's RMSPE: 0.274885\n[300]   train's rmse: 0.000567887   train's RMSPE: 0.246023 valid's rmse: 0.000611892   valid's RMSPE: 0.274251\n[350]   train's rmse: 0.000558752   train's RMSPE: 0.242065 valid's rmse: 0.000610563   valid's RMSPE: 0.273655\nEarly stopping, best iteration is:\n[339]   train's rmse: 0.000560427   train's RMSPE: 0.242791 valid's rmse: 0.000609634   valid's RMSPE: 0.273239\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000657689   train's RMSPE: 0.286063 valid's rmse: 0.000653216   valid's RMSPE: 0.288372\n[100]   train's rmse: 0.000616121   train's RMSPE: 0.267982 valid's rmse: 0.000631939   valid's RMSPE: 0.278978\n[150]   train's rmse: 0.000598411   train's RMSPE: 0.260279 valid's rmse: 0.000627939   valid's RMSPE: 0.277212\n[200]   train's rmse: 0.000586262   train's RMSPE: 0.254995 valid's rmse: 0.000623271   valid's RMSPE: 0.275152\n[250]   train's rmse: 0.00057668    train's RMSPE: 0.250827 valid's rmse: 0.000620468   valid's RMSPE: 0.273914\n[300]   train's rmse: 0.000567081   train's RMSPE: 0.246653 valid's rmse: 0.000621924   valid's RMSPE: 0.274557\nEarly stopping, best iteration is:\n[253]   train's rmse: 0.000575936   train's RMSPE: 0.250504 valid's rmse: 0.000620043   valid's RMSPE: 0.273727\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000658365   train's RMSPE: 0.288675 valid's rmse: 0.000701107   valid's RMSPE: 0.299583\n[100]   train's rmse: 0.000620059   train's RMSPE: 0.271879 valid's rmse: 0.000671588   valid's RMSPE: 0.286969\n[150]   train's rmse: 0.000600608   train's RMSPE: 0.26335  valid's rmse: 0.000665254   valid's RMSPE: 0.284263\n[200]   train's rmse: 0.000586583   train's RMSPE: 0.257201 valid's rmse: 0.000661195   valid's RMSPE: 0.282528\n[250]   train's rmse: 0.00057478    train's RMSPE: 0.252026 valid's rmse: 0.00065954    valid's RMSPE: 0.281821\n[300]   train's rmse: 0.000564957   train's RMSPE: 0.247719 valid's rmse: 0.000656489   valid's RMSPE: 0.280518\nEarly stopping, best iteration is:\n[291]   train's rmse: 0.000566392   train's RMSPE: 0.248348 valid's rmse: 0.000653194   valid's RMSPE: 0.27911\nOur out of folds RMSPE is 0.28, compared to 0.2571888420300794, giving gain 0.022811157969920615\nOur cv fold scores are [0.279, 0.294, 0.273, 0.274, 0.279]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000592643   train's RMSPE: 0.239815 valid's rmse: 0.000649744   valid's RMSPE: 0.261161\n[100]   train's rmse: 0.000564777   train's RMSPE: 0.228539 valid's rmse: 0.000631439   valid's RMSPE: 0.253803\n[150]   train's rmse: 0.0005525 train's RMSPE: 0.223571 valid's rmse: 0.000627468   valid's RMSPE: 0.252207\n[200]   train's rmse: 0.000542016   train's RMSPE: 0.219329 valid's rmse: 0.000624393   valid's RMSPE: 0.250971\n[250]   train's rmse: 0.000533366   train's RMSPE: 0.215828 valid's rmse: 0.00062263    valid's RMSPE: 0.250263\n[300]   train's rmse: 0.000525572   train's RMSPE: 0.212674 valid's rmse: 0.000620122   valid's RMSPE: 0.249255\n[350]   train's rmse: 0.000519037   train's RMSPE: 0.21003  valid's rmse: 0.000619169   valid's RMSPE: 0.248872\n[400]   train's rmse: 0.0005129 train's RMSPE: 0.207547 valid's rmse: 0.000619507   valid's RMSPE: 0.249007\nEarly stopping, best iteration is:\n[355]   train's rmse: 0.000518265   train's RMSPE: 0.209718 valid's rmse: 0.000618675   valid's RMSPE: 0.248673\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000588115   train's RMSPE: 0.235936 valid's rmse: 0.000659847   valid's RMSPE: 0.274274\n[100]   train's rmse: 0.00056167    train's RMSPE: 0.225327 valid's rmse: 0.000639841   valid's RMSPE: 0.265958\n[150]   train's rmse: 0.000549552   train's RMSPE: 0.220465 valid's rmse: 0.000633935   valid's RMSPE: 0.263504\n[200]   train's rmse: 0.000538994   train's RMSPE: 0.21623  valid's rmse: 0.000630732   valid's RMSPE: 0.262172\n[250]   train's rmse: 0.000529825   train's RMSPE: 0.212552 valid's rmse: 0.000628428   valid's RMSPE: 0.261214\n[300]   train's rmse: 0.000522013   train's RMSPE: 0.209418 valid's rmse: 0.000627584   valid's RMSPE: 0.260863\n[350]   train's rmse: 0.000515379   train's RMSPE: 0.206756 valid's rmse: 0.000626335   valid's RMSPE: 0.260345\n[400]   train's rmse: 0.000509091   train's RMSPE: 0.204233 valid's rmse: 0.000626693   valid's RMSPE: 0.260493\nEarly stopping, best iteration is:\n[360]   train's rmse: 0.000514039   train's RMSPE: 0.206218 valid's rmse: 0.000626034   valid's RMSPE: 0.260219\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000604796   train's RMSPE: 0.244743 valid's rmse: 0.000578225   valid's RMSPE: 0.232372\n[100]   train's rmse: 0.000577325   train's RMSPE: 0.233627 valid's rmse: 0.000566194   valid's RMSPE: 0.227537\n[150]   train's rmse: 0.000564589   train's RMSPE: 0.228473 valid's rmse: 0.00056717    valid's RMSPE: 0.22793\nEarly stopping, best iteration is:\n[125]   train's rmse: 0.000570275   train's RMSPE: 0.230774 valid's rmse: 0.000565499   valid's RMSPE: 0.227258\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000610668   train's RMSPE: 0.246852 valid's rmse: 0.00056888    valid's RMSPE: 0.229618\n[100]   train's rmse: 0.000582751   train's RMSPE: 0.235567 valid's rmse: 0.000554773   valid's RMSPE: 0.223924\nEarly stopping, best iteration is:\n[98]    train's rmse: 0.000583262   train's RMSPE: 0.235774 valid's rmse: 0.000554434   valid's RMSPE: 0.223787\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000603144   train's RMSPE: 0.244767 valid's rmse: 0.000611424   valid's RMSPE: 0.242867\n[100]   train's rmse: 0.000575411   train's RMSPE: 0.233512 valid's rmse: 0.000593664   valid's RMSPE: 0.235813\n[150]   train's rmse: 0.00056308    train's RMSPE: 0.228508 valid's rmse: 0.000591702   valid's RMSPE: 0.235033\n[200]   train's rmse: 0.000553042   train's RMSPE: 0.224435 valid's rmse: 0.000591264   valid's RMSPE: 0.234859\n[250]   train's rmse: 0.000544438   train's RMSPE: 0.220943 valid's rmse: 0.000589866   valid's RMSPE: 0.234304\n[300]   train's rmse: 0.000536829   train's RMSPE: 0.217855 valid's rmse: 0.000588097   valid's RMSPE: 0.233601\n[350]   train's rmse: 0.000528788   train's RMSPE: 0.214592 valid's rmse: 0.000587547   valid's RMSPE: 0.233383\nEarly stopping, best iteration is:\n[314]   train's rmse: 0.000533983   train's RMSPE: 0.2167   valid's rmse: 0.000586689   valid's RMSPE: 0.233042\nOur out of folds RMSPE is 0.239, compared to 0.2034623871895212, giving gain 0.03553761281047879\nOur cv fold scores are [0.249, 0.26, 0.227, 0.224, 0.233]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000647078   train's RMSPE: 0.293665 valid's rmse: 0.000685696   valid's RMSPE: 0.311645\n[100]   train's rmse: 0.000619927   train's RMSPE: 0.281343 valid's rmse: 0.000679838   valid's RMSPE: 0.308982\n[150]   train's rmse: 0.000603621   train's RMSPE: 0.273942 valid's rmse: 0.000678228   valid's RMSPE: 0.308251\nEarly stopping, best iteration is:\n[124]   train's rmse: 0.000611371   train's RMSPE: 0.27746  valid's rmse: 0.000677764   valid's RMSPE: 0.30804\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000647619   train's RMSPE: 0.294631 valid's rmse: 0.000692665   valid's RMSPE: 0.311713\n[100]   train's rmse: 0.000619039   train's RMSPE: 0.281629 valid's rmse: 0.000677564   valid's RMSPE: 0.304918\n[150]   train's rmse: 0.000602966   train's RMSPE: 0.274316 valid's rmse: 0.000676745   valid's RMSPE: 0.304549\nEarly stopping, best iteration is:\n[141]   train's rmse: 0.000605885   train's RMSPE: 0.275645 valid's rmse: 0.000676201   valid's RMSPE: 0.304304\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000650616   train's RMSPE: 0.294064 valid's rmse: 0.000669726   valid's RMSPE: 0.309296\n[100]   train's rmse: 0.000623311   train's RMSPE: 0.281723 valid's rmse: 0.000659633   valid's RMSPE: 0.304635\nEarly stopping, best iteration is:\n[98]    train's rmse: 0.000624403   train's RMSPE: 0.282216 valid's rmse: 0.000659542   valid's RMSPE: 0.304593\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000659495   train's RMSPE: 0.298752 valid's rmse: 0.000645272   valid's RMSPE: 0.295403\n[100]   train's rmse: 0.00063007    train's RMSPE: 0.285423 valid's rmse: 0.000649741   valid's RMSPE: 0.297449\nEarly stopping, best iteration is:\n[52]    train's rmse: 0.000656908   train's RMSPE: 0.29758  valid's rmse: 0.000644148   valid's RMSPE: 0.294888\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000651301   train's RMSPE: 0.297029 valid's rmse: 0.000678911   valid's RMSPE: 0.302459\n[100]   train's rmse: 0.000624452   train's RMSPE: 0.284784 valid's rmse: 0.00066566    valid's RMSPE: 0.296556\n[150]   train's rmse: 0.000609248   train's RMSPE: 0.27785  valid's rmse: 0.00066511    valid's RMSPE: 0.296311\n[200]   train's rmse: 0.000596537   train's RMSPE: 0.272053 valid's rmse: 0.000665137   valid's RMSPE: 0.296323\n[250]   train's rmse: 0.000585274   train's RMSPE: 0.266917 valid's rmse: 0.000664061   valid's RMSPE: 0.295844\nEarly stopping, best iteration is:\n[227]   train's rmse: 0.000590226   train's RMSPE: 0.269175 valid's rmse: 0.000661964   valid's RMSPE: 0.294909\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.301, compared to 0.2733105310684778, giving gain 0.027689468931522188\nOur cv fold scores are [0.308, 0.304, 0.305, 0.295, 0.295]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000554553   train's RMSPE: 0.192769 valid's rmse: 0.000581179   valid's RMSPE: 0.202781\n[100]   train's rmse: 0.000526003   train's RMSPE: 0.182845 valid's rmse: 0.000560138   valid's RMSPE: 0.195439\n[150]   train's rmse: 0.000513714   train's RMSPE: 0.178573 valid's rmse: 0.000556266   valid's RMSPE: 0.194088\n[200]   train's rmse: 0.000503673   train's RMSPE: 0.175082 valid's rmse: 0.000554582   valid's RMSPE: 0.193501\n[250]   train's rmse: 0.000494841   train's RMSPE: 0.172012 valid's rmse: 0.000551328   valid's RMSPE: 0.192365\n[300]   train's rmse: 0.000487175   train's RMSPE: 0.169348 valid's rmse: 0.000549686   valid's RMSPE: 0.191793\n[350]   train's rmse: 0.000480328   train's RMSPE: 0.166967 valid's rmse: 0.000549545   valid's RMSPE: 0.191743\n[400]   train's rmse: 0.000474671   train's RMSPE: 0.165001 valid's rmse: 0.000548515   valid's RMSPE: 0.191384\n[450]   train's rmse: 0.000468371   train's RMSPE: 0.162811 valid's rmse: 0.000548118   valid's RMSPE: 0.191245\n[500]   train's rmse: 0.000463146   train's RMSPE: 0.160995 valid's rmse: 0.000547567   valid's RMSPE: 0.191053\n[550]   train's rmse: 0.000458006   train's RMSPE: 0.159208 valid's rmse: 0.000546866   valid's RMSPE: 0.190809\nEarly stopping, best iteration is:\n[540]   train's rmse: 0.000459026   train's RMSPE: 0.159563 valid's rmse: 0.000546802   valid's RMSPE: 0.190786\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000555916   train's RMSPE: 0.192921 valid's rmse: 0.00057217    valid's RMSPE: 0.200951\n[100]   train's rmse: 0.000525743   train's RMSPE: 0.18245  valid's rmse: 0.000563328   valid's RMSPE: 0.197846\n[150]   train's rmse: 0.000511696   train's RMSPE: 0.177575 valid's rmse: 0.000562272   valid's RMSPE: 0.197475\nEarly stopping, best iteration is:\n[135]   train's rmse: 0.000515395   train's RMSPE: 0.178859 valid's rmse: 0.000561119   valid's RMSPE: 0.19707\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000563361   train's RMSPE: 0.195209 valid's rmse: 0.000550007   valid's RMSPE: 0.194303\n[100]   train's rmse: 0.000533299   train's RMSPE: 0.184792 valid's rmse: 0.0005275 valid's RMSPE: 0.186352\n[150]   train's rmse: 0.000521538   train's RMSPE: 0.180717 valid's rmse: 0.000524835   valid's RMSPE: 0.185411\nEarly stopping, best iteration is:\n[118]   train's rmse: 0.000528483   train's RMSPE: 0.183124 valid's rmse: 0.000524685   valid's RMSPE: 0.185357\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000552832   train's RMSPE: 0.192807 valid's rmse: 0.000586216   valid's RMSPE: 0.201827\n[100]   train's rmse: 0.000521447   train's RMSPE: 0.181861 valid's rmse: 0.000568689   valid's RMSPE: 0.195792\n[150]   train's rmse: 0.000508269   train's RMSPE: 0.177265 valid's rmse: 0.000565374   valid's RMSPE: 0.194651\n[200]   train's rmse: 0.000497927   train's RMSPE: 0.173658 valid's rmse: 0.000563661   valid's RMSPE: 0.194061\n[250]   train's rmse: 0.000490015   train's RMSPE: 0.170899 valid's rmse: 0.000561812   valid's RMSPE: 0.193424\n[300]   train's rmse: 0.000483104   train's RMSPE: 0.168488 valid's rmse: 0.000560362   valid's RMSPE: 0.192925\n[350]   train's rmse: 0.000475974   train's RMSPE: 0.166002 valid's rmse: 0.000559414   valid's RMSPE: 0.192599\n[400]   train's rmse: 0.000469909   train's RMSPE: 0.163886 valid's rmse: 0.0005591 valid's RMSPE: 0.192491\n[450]   train's rmse: 0.000464384   train's RMSPE: 0.16196  valid's rmse: 0.000557918   valid's RMSPE: 0.192084\n[500]   train's rmse: 0.0004591 train's RMSPE: 0.160117 valid's rmse: 0.000557501   valid's RMSPE: 0.191941\n[550]   train's rmse: 0.000453454   train's RMSPE: 0.158148 valid's rmse: 0.00055683    valid's RMSPE: 0.191709\nEarly stopping, best iteration is:\n[544]   train's rmse: 0.000454245   train's RMSPE: 0.158424 valid's rmse: 0.000556531   valid's RMSPE: 0.191606\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000559425   train's RMSPE: 0.195484 valid's rmse: 0.00056871    valid's RMSPE: 0.194238\n[100]   train's rmse: 0.000528071   train's RMSPE: 0.184527 valid's rmse: 0.000552926   valid's RMSPE: 0.188847\n[150]   train's rmse: 0.000515257   train's RMSPE: 0.18005  valid's rmse: 0.000551374   valid's RMSPE: 0.188317\n[200]   train's rmse: 0.000505178   train's RMSPE: 0.176528 valid's rmse: 0.000550552   valid's RMSPE: 0.188036\n[250]   train's rmse: 0.00049654    train's RMSPE: 0.173509 valid's rmse: 0.000550167   valid's RMSPE: 0.187904\nEarly stopping, best iteration is:\n[219]   train's rmse: 0.000501717   train's RMSPE: 0.175318 valid's rmse: 0.000548835   valid's RMSPE: 0.18745\nOur out of folds RMSPE is 0.19, compared to 0.1692650099200244, giving gain 0.02073499007997559\nOur cv fold scores are [0.191, 0.197, 0.185, 0.192, 0.187]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000851682   train's RMSPE: 0.226868 valid's rmse: 0.000896929   valid's RMSPE: 0.239833\n[100]   train's rmse: 0.000811057   train's RMSPE: 0.216046 valid's rmse: 0.000868569   valid's RMSPE: 0.23225\n[150]   train's rmse: 0.000791799   train's RMSPE: 0.210916 valid's rmse: 0.000862799   valid's RMSPE: 0.230707\n[200]   train's rmse: 0.000777334   train's RMSPE: 0.207063 valid's rmse: 0.000860982   valid's RMSPE: 0.230221\nEarly stopping, best iteration is:\n[186]   train's rmse: 0.000781278   train's RMSPE: 0.208114 valid's rmse: 0.000860174   valid's RMSPE: 0.230005\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000857015   train's RMSPE: 0.227693 valid's rmse: 0.000875075   valid's RMSPE: 0.236397\n[100]   train's rmse: 0.000815757   train's RMSPE: 0.216731 valid's rmse: 0.000854086   valid's RMSPE: 0.230727\n[150]   train's rmse: 0.000798119   train's RMSPE: 0.212045 valid's rmse: 0.000852753   valid's RMSPE: 0.230367\n[200]   train's rmse: 0.000783392   train's RMSPE: 0.208132 valid's rmse: 0.000848316   valid's RMSPE: 0.229168\n[250]   train's rmse: 0.000771322   train's RMSPE: 0.204925 valid's rmse: 0.00084747    valid's RMSPE: 0.22894\n[300]   train's rmse: 0.000759969   train's RMSPE: 0.201909 valid's rmse: 0.000846513   valid's RMSPE: 0.228681\n[350]   train's rmse: 0.000749992   train's RMSPE: 0.199259 valid's rmse: 0.000846192   valid's RMSPE: 0.228594\nEarly stopping, best iteration is:\n[328]   train's rmse: 0.000754583   train's RMSPE: 0.200478 valid's rmse: 0.000845535   valid's RMSPE: 0.228417\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000850433   train's RMSPE: 0.226681 valid's rmse: 0.000863004   valid's RMSPE: 0.23017\n[100]   train's rmse: 0.000811659   train's RMSPE: 0.216346 valid's rmse: 0.000833426   valid's RMSPE: 0.222281\n[150]   train's rmse: 0.000795082   train's RMSPE: 0.211927 valid's rmse: 0.000832319   valid's RMSPE: 0.221986\nEarly stopping, best iteration is:\n[144]   train's rmse: 0.0007969 train's RMSPE: 0.212412 valid's rmse: 0.000831595   valid's RMSPE: 0.221793\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000844683   train's RMSPE: 0.225866 valid's rmse: 0.000898947   valid's RMSPE: 0.236678\n[100]   train's rmse: 0.000804166   train's RMSPE: 0.215032 valid's rmse: 0.000881621   valid's RMSPE: 0.232116\n[150]   train's rmse: 0.000786661   train's RMSPE: 0.210351 valid's rmse: 0.000878811   valid's RMSPE: 0.231376\n[200]   train's rmse: 0.00077232    train's RMSPE: 0.206516 valid's rmse: 0.000876985   valid's RMSPE: 0.230896\n[250]   train's rmse: 0.00075904    train's RMSPE: 0.202965 valid's rmse: 0.000878257   valid's RMSPE: 0.231231\nEarly stopping, best iteration is:\n[204]   train's rmse: 0.000771091   train's RMSPE: 0.206188 valid's rmse: 0.000876752   valid's RMSPE: 0.230834\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00085827    train's RMSPE: 0.229067 valid's rmse: 0.000843225   valid's RMSPE: 0.223725\n[100]   train's rmse: 0.000817196   train's RMSPE: 0.218105 valid's rmse: 0.000821287   valid's RMSPE: 0.217904\n[150]   train's rmse: 0.000798899   train's RMSPE: 0.213221 valid's rmse: 0.000819659   valid's RMSPE: 0.217472\n[200]   train's rmse: 0.000785274   train's RMSPE: 0.209585 valid's rmse: 0.000817562   valid's RMSPE: 0.216916\n[250]   train's rmse: 0.000772876   train's RMSPE: 0.206276 valid's rmse: 0.000819399   valid's RMSPE: 0.217403\nEarly stopping, best iteration is:\n[210]   train's rmse: 0.000782296   train's RMSPE: 0.20879  valid's rmse: 0.000816871   valid's RMSPE: 0.216732\nOur out of folds RMSPE is 0.226, compared to 0.20024889662073747, giving gain 0.025751103379262535\nOur cv fold scores are [0.23, 0.228, 0.222, 0.231, 0.217]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000507026   train's RMSPE: 0.20618  valid's rmse: 0.000547288   valid's RMSPE: 0.225075\n[100]   train's rmse: 0.000477092   train's RMSPE: 0.194007 valid's rmse: 0.000526681   valid's RMSPE: 0.2166\n[150]   train's rmse: 0.000466161   train's RMSPE: 0.189563 valid's rmse: 0.000522931   valid's RMSPE: 0.215058\n[200]   train's rmse: 0.000457379   train's RMSPE: 0.185991 valid's rmse: 0.000521497   valid's RMSPE: 0.214468\n[250]   train's rmse: 0.000449717   train's RMSPE: 0.182875 valid's rmse: 0.000519175   valid's RMSPE: 0.213513\n[300]   train's rmse: 0.000442827   train's RMSPE: 0.180074 valid's rmse: 0.000518729   valid's RMSPE: 0.21333\n[350]   train's rmse: 0.000436482   train's RMSPE: 0.177493 valid's rmse: 0.000517745   valid's RMSPE: 0.212925\n[400]   train's rmse: 0.00043069    train's RMSPE: 0.175138 valid's rmse: 0.000516889   valid's RMSPE: 0.212573\n[450]   train's rmse: 0.000425096   train's RMSPE: 0.172864 valid's rmse: 0.00051669    valid's RMSPE: 0.212492\n[500]   train's rmse: 0.0004206 train's RMSPE: 0.171035 valid's rmse: 0.000515644   valid's RMSPE: 0.212061\nEarly stopping, best iteration is:\n[490]   train's rmse: 0.000421336   train's RMSPE: 0.171335 valid's rmse: 0.000515409   valid's RMSPE: 0.211965\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000504681   train's RMSPE: 0.205312 valid's rmse: 0.00055277    valid's RMSPE: 0.226957\n[100]   train's rmse: 0.000475629   train's RMSPE: 0.193493 valid's rmse: 0.000529467   valid's RMSPE: 0.21739\n[150]   train's rmse: 0.000463096   train's RMSPE: 0.188395 valid's rmse: 0.000527179   valid's RMSPE: 0.21645\n[200]   train's rmse: 0.000453806   train's RMSPE: 0.184616 valid's rmse: 0.000527686   valid's RMSPE: 0.216659\n[250]   train's rmse: 0.000445677   train's RMSPE: 0.181309 valid's rmse: 0.000526267   valid's RMSPE: 0.216076\nEarly stopping, best iteration is:\n[249]   train's rmse: 0.000445737   train's RMSPE: 0.181333 valid's rmse: 0.000526168   valid's RMSPE: 0.216035\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000518078   train's RMSPE: 0.210202 valid's rmse: 0.000496007   valid's RMSPE: 0.205764\n[100]   train's rmse: 0.000486903   train's RMSPE: 0.197553 valid's rmse: 0.000477075   valid's RMSPE: 0.19791\n[150]   train's rmse: 0.000474265   train's RMSPE: 0.192426 valid's rmse: 0.000476173   valid's RMSPE: 0.197536\n[200]   train's rmse: 0.000464431   train's RMSPE: 0.188436 valid's rmse: 0.000476087   valid's RMSPE: 0.1975\nEarly stopping, best iteration is:\n[176]   train's rmse: 0.000468662   train's RMSPE: 0.190153 valid's rmse: 0.000475617   valid's RMSPE: 0.197305\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000514363   train's RMSPE: 0.210361 valid's rmse: 0.000516239   valid's RMSPE: 0.207485\n[100]   train's rmse: 0.000483773   train's RMSPE: 0.197851 valid's rmse: 0.00050172    valid's RMSPE: 0.201649\n[150]   train's rmse: 0.000472607   train's RMSPE: 0.193284 valid's rmse: 0.000499953   valid's RMSPE: 0.200939\n[200]   train's rmse: 0.00046278    train's RMSPE: 0.189265 valid's rmse: 0.000499481   valid's RMSPE: 0.200749\n[250]   train's rmse: 0.000454348   train's RMSPE: 0.185817 valid's rmse: 0.000497751   valid's RMSPE: 0.200054\n[300]   train's rmse: 0.000447286   train's RMSPE: 0.182928 valid's rmse: 0.000496789   valid's RMSPE: 0.199667\n[350]   train's rmse: 0.000440984   train's RMSPE: 0.180351 valid's rmse: 0.000495637   valid's RMSPE: 0.199204\n[400]   train's rmse: 0.0004353 train's RMSPE: 0.178026 valid's rmse: 0.000495336   valid's RMSPE: 0.199083\n[450]   train's rmse: 0.000430339   train's RMSPE: 0.175997 valid's rmse: 0.000495352   valid's RMSPE: 0.19909\nEarly stopping, best iteration is:\n[414]   train's rmse: 0.000433944   train's RMSPE: 0.177472 valid's rmse: 0.000494468   valid's RMSPE: 0.198734\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000513289   train's RMSPE: 0.210282 valid's rmse: 0.000519671   valid's RMSPE: 0.207373\n[100]   train's rmse: 0.000482986   train's RMSPE: 0.197867 valid's rmse: 0.000508594   valid's RMSPE: 0.202953\n[150]   train's rmse: 0.000470847   train's RMSPE: 0.192895 valid's rmse: 0.000506309   valid's RMSPE: 0.202041\n[200]   train's rmse: 0.000460839   train's RMSPE: 0.188795 valid's rmse: 0.000504388   valid's RMSPE: 0.201274\n[250]   train's rmse: 0.000451799   train's RMSPE: 0.185091 valid's rmse: 0.000503017   valid's RMSPE: 0.200727\n[300]   train's rmse: 0.000444348   train's RMSPE: 0.182038 valid's rmse: 0.000503367   valid's RMSPE: 0.200867\n[350]   train's rmse: 0.000437803   train's RMSPE: 0.179357 valid's rmse: 0.000502146   valid's RMSPE: 0.200379\n[400]   train's rmse: 0.000431879   train's RMSPE: 0.17693  valid's rmse: 0.000502718   valid's RMSPE: 0.200608\nEarly stopping, best iteration is:\n[362]   train's rmse: 0.000436314   train's RMSPE: 0.178747 valid's rmse: 0.000501424   valid's RMSPE: 0.200091\nOur out of folds RMSPE is 0.205, compared to 0.19076291548509186, giving gain 0.014237084514908127\nOur cv fold scores are [0.212, 0.216, 0.197, 0.199, 0.2]\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000376799   train's RMSPE: 0.231146 valid's rmse: 0.000404137   valid's RMSPE: 0.247565\n[100]   train's rmse: 0.000359359   train's RMSPE: 0.220448 valid's rmse: 0.000391165   valid's RMSPE: 0.239618\n[150]   train's rmse: 0.000351228   train's RMSPE: 0.21546  valid's rmse: 0.000389375   valid's RMSPE: 0.238522\n[200]   train's rmse: 0.00034423    train's RMSPE: 0.211167 valid's rmse: 0.000387454   valid's RMSPE: 0.237345\n[250]   train's rmse: 0.000338112   train's RMSPE: 0.207414 valid's rmse: 0.000385162   valid's RMSPE: 0.235941\n[300]   train's rmse: 0.000333216   train's RMSPE: 0.20441  valid's rmse: 0.00038362    valid's RMSPE: 0.234997\n[350]   train's rmse: 0.000328844   train's RMSPE: 0.201728 valid's rmse: 0.00038301    valid's RMSPE: 0.234623\n[400]   train's rmse: 0.000324751   train's RMSPE: 0.199218 valid's rmse: 0.000380855   valid's RMSPE: 0.233303\n[450]   train's rmse: 0.000321097   train's RMSPE: 0.196976 valid's rmse: 0.000380074   valid's RMSPE: 0.232825\n[500]   train's rmse: 0.000317557   train's RMSPE: 0.194804 valid's rmse: 0.000379689   valid's RMSPE: 0.232588\n[550]   train's rmse: 0.000313988   train's RMSPE: 0.192615 valid's rmse: 0.00037842    valid's RMSPE: 0.231811\n[600]   train's rmse: 0.000310924   train's RMSPE: 0.190736 valid's rmse: 0.000378195   valid's RMSPE: 0.231674\n[650]   train's rmse: 0.000308302   train's RMSPE: 0.189127 valid's rmse: 0.000378574   valid's RMSPE: 0.231905\nEarly stopping, best iteration is:\n[619]   train's rmse: 0.000309937   train's RMSPE: 0.19013  valid's rmse: 0.000378007   valid's RMSPE: 0.231558\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000374348   train's RMSPE: 0.229207 valid's rmse: 0.000404253   valid's RMSPE: 0.249513\n[100]   train's rmse: 0.000356271   train's RMSPE: 0.218138 valid's rmse: 0.000391955   valid's RMSPE: 0.241923\n[150]   train's rmse: 0.000347931   train's RMSPE: 0.213032 valid's rmse: 0.000389802   valid's RMSPE: 0.240594\n[200]   train's rmse: 0.000340845   train's RMSPE: 0.208694 valid's rmse: 0.000387349   valid's RMSPE: 0.239079\n[250]   train's rmse: 0.000335069   train's RMSPE: 0.205157 valid's rmse: 0.000384978   valid's RMSPE: 0.237616\n[300]   train's rmse: 0.000329524   train's RMSPE: 0.201762 valid's rmse: 0.000383088   valid's RMSPE: 0.236449\n[350]   train's rmse: 0.000324627   train's RMSPE: 0.198763 valid's rmse: 0.000382422   valid's RMSPE: 0.236039\n[400]   train's rmse: 0.0003208 train's RMSPE: 0.19642  valid's rmse: 0.000381492   valid's RMSPE: 0.235464\nEarly stopping, best iteration is:\n[383]   train's rmse: 0.000322099   train's RMSPE: 0.197215 valid's rmse: 0.000380985   valid's RMSPE: 0.235152\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000382683   train's RMSPE: 0.232931 valid's rmse: 0.000362272   valid's RMSPE: 0.228708\n[100]   train's rmse: 0.000363483   train's RMSPE: 0.221244 valid's rmse: 0.000354905   valid's RMSPE: 0.224057\n[150]   train's rmse: 0.000354712   train's RMSPE: 0.215906 valid's rmse: 0.000354732   valid's RMSPE: 0.223948\nEarly stopping, best iteration is:\n[122]   train's rmse: 0.000359394   train's RMSPE: 0.218755 valid's rmse: 0.000353647   valid's RMSPE: 0.223263\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000381485   train's RMSPE: 0.234822 valid's rmse: 0.000376463   valid's RMSPE: 0.227417\n[100]   train's rmse: 0.000362999   train's RMSPE: 0.223443 valid's rmse: 0.000364272   valid's RMSPE: 0.220052\n[150]   train's rmse: 0.000354037   train's RMSPE: 0.217927 valid's rmse: 0.000361229   valid's RMSPE: 0.218214\n[200]   train's rmse: 0.000346385   train's RMSPE: 0.213217 valid's rmse: 0.00035976    valid's RMSPE: 0.217327\n[250]   train's rmse: 0.00034007    train's RMSPE: 0.20933  valid's rmse: 0.000358037   valid's RMSPE: 0.216286\n[300]   train's rmse: 0.000334479   train's RMSPE: 0.205888 valid's rmse: 0.000357263   valid's RMSPE: 0.215818\n[350]   train's rmse: 0.000329483   train's RMSPE: 0.202812 valid's rmse: 0.000356789   valid's RMSPE: 0.215532\n[400]   train's rmse: 0.000325092   train's RMSPE: 0.20011  valid's rmse: 0.000355783   valid's RMSPE: 0.214924\n[450]   train's rmse: 0.000321273   train's RMSPE: 0.197759 valid's rmse: 0.000355189   valid's RMSPE: 0.214565\nEarly stopping, best iteration is:\n[446]   train's rmse: 0.000321593   train's RMSPE: 0.197956 valid's rmse: 0.000354924   valid's RMSPE: 0.214405\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000377732   train's RMSPE: 0.232826 valid's rmse: 0.000386763   valid's RMSPE: 0.232324\n[100]   train's rmse: 0.000359772   train's RMSPE: 0.221756 valid's rmse: 0.000376073   valid's RMSPE: 0.225902\n[150]   train's rmse: 0.000351702   train's RMSPE: 0.216782 valid's rmse: 0.000373365   valid's RMSPE: 0.224275\n[200]   train's rmse: 0.000344799   train's RMSPE: 0.212527 valid's rmse: 0.000371322   valid's RMSPE: 0.223049\n[250]   train's rmse: 0.000339426   train's RMSPE: 0.209215 valid's rmse: 0.000370377   valid's RMSPE: 0.222481\n[300]   train's rmse: 0.000334211   train's RMSPE: 0.206001 valid's rmse: 0.00036862    valid's RMSPE: 0.221425\n[350]   train's rmse: 0.000329497   train's RMSPE: 0.203095 valid's rmse: 0.000367918   valid's RMSPE: 0.221004\n[400]   train's rmse: 0.000325246   train's RMSPE: 0.200475 valid's rmse: 0.000367886   valid's RMSPE: 0.220985\n[450]   train's rmse: 0.000321717   train's RMSPE: 0.198299 valid's rmse: 0.000367854   valid's RMSPE: 0.220966\n[500]   train's rmse: 0.000318381   train's RMSPE: 0.196244 valid's rmse: 0.000367419   valid's RMSPE: 0.220704\n[550]   train's rmse: 0.000315203   train's RMSPE: 0.194285 valid's rmse: 0.000366688   valid's RMSPE: 0.220265\n[600]   train's rmse: 0.000312036   train's RMSPE: 0.192332 valid's rmse: 0.000367127   valid's RMSPE: 0.220528\nEarly stopping, best iteration is:\n[565]   train's rmse: 0.000314317   train's RMSPE: 0.193738 valid's rmse: 0.000366406   valid's RMSPE: 0.220095\nOur out of folds RMSPE is 0.225, compared to 0.19287498737385145, giving gain 0.03212501262614856\nOur cv fold scores are [0.232, 0.235, 0.223, 0.214, 0.22]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000602067   train's RMSPE: 0.265293 valid's rmse: 0.000660112   valid's RMSPE: 0.287981\n[100]   train's rmse: 0.000571319   train's RMSPE: 0.251744 valid's rmse: 0.000648742   valid's RMSPE: 0.28302\n[150]   train's rmse: 0.000558184   train's RMSPE: 0.245956 valid's rmse: 0.000646453   valid's RMSPE: 0.282022\n[200]   train's rmse: 0.000546798   train's RMSPE: 0.240939 valid's rmse: 0.000644711   valid's RMSPE: 0.281261\n[250]   train's rmse: 0.000535684   train's RMSPE: 0.236042 valid's rmse: 0.000640624   valid's RMSPE: 0.279479\n[300]   train's rmse: 0.000526119   train's RMSPE: 0.231827 valid's rmse: 0.000641294   valid's RMSPE: 0.279771\nEarly stopping, best iteration is:\n[259]   train's rmse: 0.000533687   train's RMSPE: 0.235162 valid's rmse: 0.000640328   valid's RMSPE: 0.279349\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000610385   train's RMSPE: 0.268811 valid's rmse: 0.000622238   valid's RMSPE: 0.272062\n[100]   train's rmse: 0.000581086   train's RMSPE: 0.255907 valid's rmse: 0.000604524   valid's RMSPE: 0.264318\n[150]   train's rmse: 0.000565682   train's RMSPE: 0.249123 valid's rmse: 0.000598973   valid's RMSPE: 0.26189\n[200]   train's rmse: 0.000553326   train's RMSPE: 0.243682 valid's rmse: 0.00059689    valid's RMSPE: 0.26098\n[250]   train's rmse: 0.000542278   train's RMSPE: 0.238817 valid's rmse: 0.000594252   valid's RMSPE: 0.259826\n[300]   train's rmse: 0.000533347   train's RMSPE: 0.234884 valid's rmse: 0.000592494   valid's RMSPE: 0.259058\n[350]   train's rmse: 0.00052429    train's RMSPE: 0.230895 valid's rmse: 0.000590833   valid's RMSPE: 0.258331\n[400]   train's rmse: 0.000517358   train's RMSPE: 0.227842 valid's rmse: 0.000588829   valid's RMSPE: 0.257455\n[450]   train's rmse: 0.000511204   train's RMSPE: 0.225132 valid's rmse: 0.0005875 valid's RMSPE: 0.256874\n[500]   train's rmse: 0.000504956   train's RMSPE: 0.22238  valid's rmse: 0.000586521   valid's RMSPE: 0.256446\n[550]   train's rmse: 0.00049934    train's RMSPE: 0.219907 valid's rmse: 0.000586646   valid's RMSPE: 0.256501\nEarly stopping, best iteration is:\n[517]   train's rmse: 0.000503068   train's RMSPE: 0.221549 valid's rmse: 0.000586244   valid's RMSPE: 0.256325\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000613962   train's RMSPE: 0.268909 valid's rmse: 0.000611982   valid's RMSPE: 0.27343\n[100]   train's rmse: 0.000583663   train's RMSPE: 0.255638 valid's rmse: 0.000593652   valid's RMSPE: 0.26524\n[150]   train's rmse: 0.000569927   train's RMSPE: 0.249622 valid's rmse: 0.000589956   valid's RMSPE: 0.263589\n[200]   train's rmse: 0.000557645   train's RMSPE: 0.244243 valid's rmse: 0.000586722   valid's RMSPE: 0.262143\n[250]   train's rmse: 0.000548078   train's RMSPE: 0.240053 valid's rmse: 0.000585518   valid's RMSPE: 0.261606\n[300]   train's rmse: 0.000539311   train's RMSPE: 0.236212 valid's rmse: 0.000586058   valid's RMSPE: 0.261847\nEarly stopping, best iteration is:\n[255]   train's rmse: 0.000547306   train's RMSPE: 0.239715 valid's rmse: 0.000585187   valid's RMSPE: 0.261458\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000612043   train's RMSPE: 0.269036 valid's rmse: 0.000612464   valid's RMSPE: 0.269814\n[100]   train's rmse: 0.000580475   train's RMSPE: 0.25516  valid's rmse: 0.000607419   valid's RMSPE: 0.267591\nEarly stopping, best iteration is:\n[75]    train's rmse: 0.000592006   train's RMSPE: 0.260229 valid's rmse: 0.000606608   valid's RMSPE: 0.267234\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000611141   train's RMSPE: 0.26904  valid's rmse: 0.000624944   valid's RMSPE: 0.273673\n[100]   train's rmse: 0.000583239   train's RMSPE: 0.256757 valid's rmse: 0.000602051   valid's RMSPE: 0.263648\n[150]   train's rmse: 0.000568708   train's RMSPE: 0.25036  valid's rmse: 0.000598554   valid's RMSPE: 0.262117\n[200]   train's rmse: 0.000556861   train's RMSPE: 0.245144 valid's rmse: 0.000597655   valid's RMSPE: 0.261723\n[250]   train's rmse: 0.000546608   train's RMSPE: 0.240631 valid's rmse: 0.000595421   valid's RMSPE: 0.260745\n[300]   train's rmse: 0.000538043   train's RMSPE: 0.23686  valid's rmse: 0.000593699   valid's RMSPE: 0.259991\n[350]   train's rmse: 0.000530558   train's RMSPE: 0.233565 valid's rmse: 0.00059338    valid's RMSPE: 0.259851\n[400]   train's rmse: 0.000523236   train's RMSPE: 0.230342 valid's rmse: 0.000592491   valid's RMSPE: 0.259462\nEarly stopping, best iteration is:\n[364]   train's rmse: 0.000528334   train's RMSPE: 0.232586 valid's rmse: 0.000592319   valid's RMSPE: 0.259387\nOur out of folds RMSPE is 0.265, compared to 0.2352463789322846, giving gain 0.029753621067715424\nOur cv fold scores are [0.279, 0.256, 0.261, 0.267, 0.259]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000430111   train's RMSPE: 0.233273 valid's rmse: 0.000467896   valid's RMSPE: 0.253851\n[100]   train's rmse: 0.000410974   train's RMSPE: 0.222894 valid's rmse: 0.000450308   valid's RMSPE: 0.244308\n[150]   train's rmse: 0.000401482   train's RMSPE: 0.217746 valid's rmse: 0.000444669   valid's RMSPE: 0.241249\n[200]   train's rmse: 0.000394701   train's RMSPE: 0.214068 valid's rmse: 0.000442663   valid's RMSPE: 0.24016\n[250]   train's rmse: 0.000388104   train's RMSPE: 0.21049  valid's rmse: 0.000440236   valid's RMSPE: 0.238844\n[300]   train's rmse: 0.00038251    train's RMSPE: 0.207456 valid's rmse: 0.000438881   valid's RMSPE: 0.238109\n[350]   train's rmse: 0.000377628   train's RMSPE: 0.204809 valid's rmse: 0.00043739    valid's RMSPE: 0.2373\n[400]   train's rmse: 0.000373084   train's RMSPE: 0.202344 valid's rmse: 0.000436172   valid's RMSPE: 0.236639\n[450]   train's rmse: 0.000369202   train's RMSPE: 0.200239 valid's rmse: 0.000435833   valid's RMSPE: 0.236455\n[500]   train's rmse: 0.000365306   train's RMSPE: 0.198126 valid's rmse: 0.00043491    valid's RMSPE: 0.235954\n[550]   train's rmse: 0.00036204    train's RMSPE: 0.196355 valid's rmse: 0.00043444    valid's RMSPE: 0.235699\nEarly stopping, best iteration is:\n[545]   train's rmse: 0.000362381   train's RMSPE: 0.19654  valid's rmse: 0.000434307   valid's RMSPE: 0.235627\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000429461   train's RMSPE: 0.232837 valid's rmse: 0.000460611   valid's RMSPE: 0.250255\n[100]   train's rmse: 0.000409081   train's RMSPE: 0.221788 valid's rmse: 0.000448583   valid's RMSPE: 0.24372\n[150]   train's rmse: 0.000400761   train's RMSPE: 0.217277 valid's rmse: 0.000445531   valid's RMSPE: 0.242062\n[200]   train's rmse: 0.000394394   train's RMSPE: 0.213825 valid's rmse: 0.000444651   valid's RMSPE: 0.241583\n[250]   train's rmse: 0.000388222   train's RMSPE: 0.210479 valid's rmse: 0.000443192   valid's RMSPE: 0.240791\n[300]   train's rmse: 0.000382206   train's RMSPE: 0.207217 valid's rmse: 0.000442357   valid's RMSPE: 0.240337\n[350]   train's rmse: 0.000377042   train's RMSPE: 0.204418 valid's rmse: 0.000440543   valid's RMSPE: 0.239352\n[400]   train's rmse: 0.000372448   train's RMSPE: 0.201927 valid's rmse: 0.000440375   valid's RMSPE: 0.23926\n[450]   train's rmse: 0.000368545   train's RMSPE: 0.199811 valid's rmse: 0.00044114    valid's RMSPE: 0.239676\nEarly stopping, best iteration is:\n[401]   train's rmse: 0.000372397   train's RMSPE: 0.201899 valid's rmse: 0.000440222   valid's RMSPE: 0.239177\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000432589   train's RMSPE: 0.234403 valid's rmse: 0.000451375   valid's RMSPE: 0.245779\n[100]   train's rmse: 0.000413906   train's RMSPE: 0.224279 valid's rmse: 0.000440484   valid's RMSPE: 0.239849\n[150]   train's rmse: 0.000404958   train's RMSPE: 0.219431 valid's rmse: 0.000437762   valid's RMSPE: 0.238367\n[200]   train's rmse: 0.000397351   train's RMSPE: 0.215309 valid's rmse: 0.000437105   valid's RMSPE: 0.238009\n[250]   train's rmse: 0.000390896   train's RMSPE: 0.211811 valid's rmse: 0.000435226   valid's RMSPE: 0.236986\n[300]   train's rmse: 0.000385333   train's RMSPE: 0.208797 valid's rmse: 0.000434606   valid's RMSPE: 0.236649\n[350]   train's rmse: 0.000380894   train's RMSPE: 0.206391 valid's rmse: 0.000435175   valid's RMSPE: 0.236958\nEarly stopping, best iteration is:\n[309]   train's rmse: 0.000384462   train's RMSPE: 0.208324 valid's rmse: 0.000434274   valid's RMSPE: 0.236468\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000440703   train's RMSPE: 0.238942 valid's rmse: 0.000417088   valid's RMSPE: 0.226571\n[100]   train's rmse: 0.000419876   train's RMSPE: 0.22765  valid's rmse: 0.000408072   valid's RMSPE: 0.221674\n[150]   train's rmse: 0.000410697   train's RMSPE: 0.222673 valid's rmse: 0.000406021   valid's RMSPE: 0.220559\n[200]   train's rmse: 0.000403617   train's RMSPE: 0.218835 valid's rmse: 0.00040581    valid's RMSPE: 0.220445\n[250]   train's rmse: 0.000397828   train's RMSPE: 0.215696 valid's rmse: 0.000404016   valid's RMSPE: 0.21947\n[300]   train's rmse: 0.000392225   train's RMSPE: 0.212658 valid's rmse: 0.000402878   valid's RMSPE: 0.218852\n[350]   train's rmse: 0.000386813   train's RMSPE: 0.209724 valid's rmse: 0.000401766   valid's RMSPE: 0.218248\n[400]   train's rmse: 0.000381422   train's RMSPE: 0.206801 valid's rmse: 0.000400845   valid's RMSPE: 0.217748\nEarly stopping, best iteration is:\n[362]   train's rmse: 0.000385311   train's RMSPE: 0.208909 valid's rmse: 0.00040054    valid's RMSPE: 0.217582\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000437956   train's RMSPE: 0.237983 valid's rmse: 0.000422216   valid's RMSPE: 0.227303\n[100]   train's rmse: 0.000419281   train's RMSPE: 0.227836 valid's rmse: 0.000412983   valid's RMSPE: 0.222332\n[150]   train's rmse: 0.00041007    train's RMSPE: 0.22283  valid's rmse: 0.000409831   valid's RMSPE: 0.220635\n[200]   train's rmse: 0.000402202   train's RMSPE: 0.218555 valid's rmse: 0.000407584   valid's RMSPE: 0.219426\n[250]   train's rmse: 0.000395445   train's RMSPE: 0.214883 valid's rmse: 0.000406958   valid's RMSPE: 0.219088\n[300]   train's rmse: 0.000390022   train's RMSPE: 0.211936 valid's rmse: 0.000406037   valid's RMSPE: 0.218593\nEarly stopping, best iteration is:\n[288]   train's rmse: 0.000391207   train's RMSPE: 0.21258  valid's rmse: 0.000405673   valid's RMSPE: 0.218397\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.23, compared to 0.18588084352573406, giving gain 0.04411915647426595\nOur cv fold scores are [0.236, 0.239, 0.236, 0.218, 0.218]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000509811   train's RMSPE: 0.259309 valid's rmse: 0.00053327    valid's RMSPE: 0.272249\n[100]   train's rmse: 0.000487741   train's RMSPE: 0.248083 valid's rmse: 0.000517672   valid's RMSPE: 0.264286\n[150]   train's rmse: 0.000476966   train's RMSPE: 0.242603 valid's rmse: 0.000514161   valid's RMSPE: 0.262493\n[200]   train's rmse: 0.000467961   train's RMSPE: 0.238023 valid's rmse: 0.000510741   valid's RMSPE: 0.260747\n[250]   train's rmse: 0.00046002    train's RMSPE: 0.233983 valid's rmse: 0.000509485   valid's RMSPE: 0.260106\n[300]   train's rmse: 0.00045357    train's RMSPE: 0.230703 valid's rmse: 0.000506574   valid's RMSPE: 0.25862\n[350]   train's rmse: 0.000448121   train's RMSPE: 0.227931 valid's rmse: 0.000505014   valid's RMSPE: 0.257824\n[400]   train's rmse: 0.000442681   train's RMSPE: 0.225164 valid's rmse: 0.000503781   valid's RMSPE: 0.257194\n[450]   train's rmse: 0.000438041   train's RMSPE: 0.222804 valid's rmse: 0.000503567   valid's RMSPE: 0.257085\n[500]   train's rmse: 0.000433547   train's RMSPE: 0.220518 valid's rmse: 0.000502695   valid's RMSPE: 0.25664\n[550]   train's rmse: 0.000428989   train's RMSPE: 0.2182   valid's rmse: 0.000501747   valid's RMSPE: 0.256156\n[600]   train's rmse: 0.000424781   train's RMSPE: 0.21606  valid's rmse: 0.000500041   valid's RMSPE: 0.255285\n[650]   train's rmse: 0.000421061   train's RMSPE: 0.214168 valid's rmse: 0.00049895    valid's RMSPE: 0.254728\n[700]   train's rmse: 0.000417705   train's RMSPE: 0.21246  valid's rmse: 0.000499018   valid's RMSPE: 0.254762\nEarly stopping, best iteration is:\n[669]   train's rmse: 0.000419842   train's RMSPE: 0.213547 valid's rmse: 0.000498301   valid's RMSPE: 0.254396\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000504709   train's RMSPE: 0.256708 valid's rmse: 0.000548306   valid's RMSPE: 0.279952\n[100]   train's rmse: 0.000484521   train's RMSPE: 0.24644  valid's rmse: 0.0005377 valid's RMSPE: 0.274537\n[150]   train's rmse: 0.000474146   train's RMSPE: 0.241163 valid's rmse: 0.00053526    valid's RMSPE: 0.273291\n[200]   train's rmse: 0.000465469   train's RMSPE: 0.236749 valid's rmse: 0.000534155   valid's RMSPE: 0.272726\n[250]   train's rmse: 0.00045797    train's RMSPE: 0.232935 valid's rmse: 0.000531676   valid's RMSPE: 0.271461\n[300]   train's rmse: 0.000451602   train's RMSPE: 0.229696 valid's rmse: 0.000530185   valid's RMSPE: 0.2707\n[350]   train's rmse: 0.000446173   train's RMSPE: 0.226935 valid's rmse: 0.000529539   valid's RMSPE: 0.27037\n[400]   train's rmse: 0.00044069    train's RMSPE: 0.224146 valid's rmse: 0.000529249   valid's RMSPE: 0.270222\n[450]   train's rmse: 0.000435914   train's RMSPE: 0.221717 valid's rmse: 0.000528702   valid's RMSPE: 0.269943\nEarly stopping, best iteration is:\n[428]   train's rmse: 0.000438044   train's RMSPE: 0.2228   valid's rmse: 0.000528397   valid's RMSPE: 0.269786\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000512479   train's RMSPE: 0.260254 valid's rmse: 0.000509737   valid's RMSPE: 0.26186\n[100]   train's rmse: 0.000491841   train's RMSPE: 0.249774 valid's rmse: 0.000498237   valid's RMSPE: 0.255953\n[150]   train's rmse: 0.00048211    train's RMSPE: 0.244832 valid's rmse: 0.000496918   valid's RMSPE: 0.255275\n[200]   train's rmse: 0.000472649   train's RMSPE: 0.240027 valid's rmse: 0.000493745   valid's RMSPE: 0.253645\n[250]   train's rmse: 0.000465577   train's RMSPE: 0.236436 valid's rmse: 0.00049128    valid's RMSPE: 0.252379\nEarly stopping, best iteration is:\n[243]   train's rmse: 0.00046635    train's RMSPE: 0.236828 valid's rmse: 0.000490901   valid's RMSPE: 0.252184\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000515909   train's RMSPE: 0.263375 valid's rmse: 0.000492388   valid's RMSPE: 0.247676\n[100]   train's rmse: 0.000493681   train's RMSPE: 0.252027 valid's rmse: 0.000480763   valid's RMSPE: 0.241828\n[150]   train's rmse: 0.000482455   train's RMSPE: 0.246296 valid's rmse: 0.000478192   valid's RMSPE: 0.240535\n[200]   train's rmse: 0.0004737 train's RMSPE: 0.241827 valid's rmse: 0.000477539   valid's RMSPE: 0.240207\n[250]   train's rmse: 0.000466209   train's RMSPE: 0.238003 valid's rmse: 0.000475623   valid's RMSPE: 0.239243\n[300]   train's rmse: 0.000459745   train's RMSPE: 0.234703 valid's rmse: 0.000475869   valid's RMSPE: 0.239367\nEarly stopping, best iteration is:\n[262]   train's rmse: 0.00046453    train's RMSPE: 0.237146 valid's rmse: 0.000475278   valid's RMSPE: 0.23907\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000512518   train's RMSPE: 0.261114 valid's rmse: 0.000525835   valid's RMSPE: 0.266696\n[100]   train's rmse: 0.000492654   train's RMSPE: 0.250994 valid's rmse: 0.000515652   valid's RMSPE: 0.261531\n[150]   train's rmse: 0.000480921   train's RMSPE: 0.245016 valid's rmse: 0.000516212   valid's RMSPE: 0.261815\nEarly stopping, best iteration is:\n[118]   train's rmse: 0.000487667   train's RMSPE: 0.248453 valid's rmse: 0.000513919   valid's RMSPE: 0.260652\nOur out of folds RMSPE is 0.255, compared to 0.2073331029306695, giving gain 0.0476668970693305\nOur cv fold scores are [0.254, 0.27, 0.252, 0.239, 0.261]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000356952   train's RMSPE: 0.228317 valid's rmse: 0.000396208   valid's RMSPE: 0.257044\n[100]   train's rmse: 0.000339253   train's RMSPE: 0.216996 valid's rmse: 0.000380672   valid's RMSPE: 0.246965\n[150]   train's rmse: 0.000332083   train's RMSPE: 0.21241  valid's rmse: 0.00037613    valid's RMSPE: 0.244018\n[200]   train's rmse: 0.000325732   train's RMSPE: 0.208348 valid's rmse: 0.000372461   valid's RMSPE: 0.241638\n[250]   train's rmse: 0.000320849   train's RMSPE: 0.205225 valid's rmse: 0.000370056   valid's RMSPE: 0.240078\n[300]   train's rmse: 0.00031711    train's RMSPE: 0.202833 valid's rmse: 0.000369607   valid's RMSPE: 0.239787\n[350]   train's rmse: 0.000313452   train's RMSPE: 0.200493 valid's rmse: 0.000368784   valid's RMSPE: 0.239252\n[400]   train's rmse: 0.000310177   train's RMSPE: 0.198398 valid's rmse: 0.000368282   valid's RMSPE: 0.238927\nEarly stopping, best iteration is:\n[375]   train's rmse: 0.000311695   train's RMSPE: 0.199369 valid's rmse: 0.00036801    valid's RMSPE: 0.23875\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000359292   train's RMSPE: 0.229248 valid's rmse: 0.000391718   valid's RMSPE: 0.25655\n[100]   train's rmse: 0.000340377   train's RMSPE: 0.21718  valid's rmse: 0.000376653   valid's RMSPE: 0.246683\n[150]   train's rmse: 0.000332985   train's RMSPE: 0.212463 valid's rmse: 0.000373564   valid's RMSPE: 0.24466\n[200]   train's rmse: 0.000327402   train's RMSPE: 0.208901 valid's rmse: 0.000370881   valid's RMSPE: 0.242903\n[250]   train's rmse: 0.000323206   train's RMSPE: 0.206223 valid's rmse: 0.000371028   valid's RMSPE: 0.242999\nEarly stopping, best iteration is:\n[203]   train's rmse: 0.000327177   train's RMSPE: 0.208757 valid's rmse: 0.000370624   valid's RMSPE: 0.242735\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000366005   train's RMSPE: 0.234963 valid's rmse: 0.000342851   valid's RMSPE: 0.21924\n[100]   train's rmse: 0.00034619    train's RMSPE: 0.222243 valid's rmse: 0.000333747   valid's RMSPE: 0.213418\n[150]   train's rmse: 0.000338544   train's RMSPE: 0.217334 valid's rmse: 0.000331713   valid's RMSPE: 0.212118\n[200]   train's rmse: 0.000333376   train's RMSPE: 0.214016 valid's rmse: 0.000330358   valid's RMSPE: 0.211252\n[250]   train's rmse: 0.000328936   train's RMSPE: 0.211166 valid's rmse: 0.000330063   valid's RMSPE: 0.211063\nEarly stopping, best iteration is:\n[205]   train's rmse: 0.000332942   train's RMSPE: 0.213738 valid's rmse: 0.000329908   valid's RMSPE: 0.210964\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000365702   train's RMSPE: 0.234822 valid's rmse: 0.000348875   valid's RMSPE: 0.222889\n[100]   train's rmse: 0.000346211   train's RMSPE: 0.222306 valid's rmse: 0.000336785   valid's RMSPE: 0.215165\n[150]   train's rmse: 0.00033929    train's RMSPE: 0.217862 valid's rmse: 0.000335356   valid's RMSPE: 0.214252\n[200]   train's rmse: 0.000333739   train's RMSPE: 0.214298 valid's rmse: 0.000334544   valid's RMSPE: 0.213733\n[250]   train's rmse: 0.000329286   train's RMSPE: 0.211438 valid's rmse: 0.000334314   valid's RMSPE: 0.213587\n[300]   train's rmse: 0.000325013   train's RMSPE: 0.208695 valid's rmse: 0.000333161   valid's RMSPE: 0.21285\n[350]   train's rmse: 0.000321041   train's RMSPE: 0.206144 valid's rmse: 0.00033263    valid's RMSPE: 0.21251\n[400]   train's rmse: 0.000317733   train's RMSPE: 0.20402  valid's rmse: 0.000332152   valid's RMSPE: 0.212205\nEarly stopping, best iteration is:\n[389]   train's rmse: 0.000318515   train's RMSPE: 0.204523 valid's rmse: 0.000332065   valid's RMSPE: 0.21215\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000364635   train's RMSPE: 0.235388 valid's rmse: 0.00036751    valid's RMSPE: 0.229653\n[100]   train's rmse: 0.000344059   train's RMSPE: 0.222105 valid's rmse: 0.000355329   valid's RMSPE: 0.222041\n[150]   train's rmse: 0.000336592   train's RMSPE: 0.217285 valid's rmse: 0.000353523   valid's RMSPE: 0.220913\n[200]   train's rmse: 0.000331448   train's RMSPE: 0.213965 valid's rmse: 0.000352891   valid's RMSPE: 0.220518\n[250]   train's rmse: 0.000326893   train's RMSPE: 0.211024 valid's rmse: 0.000351551   valid's RMSPE: 0.219681\n[300]   train's rmse: 0.000322709   train's RMSPE: 0.208323 valid's rmse: 0.000350918   valid's RMSPE: 0.219285\n[350]   train's rmse: 0.000319018   train's RMSPE: 0.20594  valid's rmse: 0.000350714   valid's RMSPE: 0.219157\n[400]   train's rmse: 0.000315422   train's RMSPE: 0.203619 valid's rmse: 0.000349857   valid's RMSPE: 0.218622\n[450]   train's rmse: 0.00031208    train's RMSPE: 0.201461 valid's rmse: 0.000349336   valid's RMSPE: 0.218296\n[500]   train's rmse: 0.000309241   train's RMSPE: 0.199629 valid's rmse: 0.000349146   valid's RMSPE: 0.218178\n[550]   train's rmse: 0.000306617   train's RMSPE: 0.197935 valid's rmse: 0.000349325   valid's RMSPE: 0.21829\nEarly stopping, best iteration is:\n[505]   train's rmse: 0.000309018   train's RMSPE: 0.199485 valid's rmse: 0.000348939   valid's RMSPE: 0.218048\nOur out of folds RMSPE is 0.225, compared to 0.1820360318807276, giving gain 0.04296396811927242\nOur cv fold scores are [0.239, 0.243, 0.211, 0.212, 0.218]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000458083   train's RMSPE: 0.257949 valid's rmse: 0.000507298   valid's RMSPE: 0.274822\n[100]   train's rmse: 0.000434666   train's RMSPE: 0.244763 valid's rmse: 0.000494276   valid's RMSPE: 0.267767\n[150]   train's rmse: 0.000423453   train's RMSPE: 0.238449 valid's rmse: 0.000489306   valid's RMSPE: 0.265075\n[200]   train's rmse: 0.000414848   train's RMSPE: 0.233604 valid's rmse: 0.000488022   valid's RMSPE: 0.264379\n[250]   train's rmse: 0.000407502   train's RMSPE: 0.229467 valid's rmse: 0.000483455   valid's RMSPE: 0.261905\n[300]   train's rmse: 0.000401289   train's RMSPE: 0.225968 valid's rmse: 0.000482082   valid's RMSPE: 0.261161\n[350]   train's rmse: 0.000395343   train's RMSPE: 0.22262  valid's rmse: 0.000480966   valid's RMSPE: 0.260557\n[400]   train's rmse: 0.000389761   train's RMSPE: 0.219477 valid's rmse: 0.000479409   valid's RMSPE: 0.259713\n[450]   train's rmse: 0.00038554    train's RMSPE: 0.2171   valid's rmse: 0.000479033   valid's RMSPE: 0.259509\nEarly stopping, best iteration is:\n[438]   train's rmse: 0.000386348   train's RMSPE: 0.217555 valid's rmse: 0.000478095   valid's RMSPE: 0.259001\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000460466   train's RMSPE: 0.25632  valid's rmse: 0.00049442    valid's RMSPE: 0.280722\n[100]   train's rmse: 0.0004369 train's RMSPE: 0.243202 valid's rmse: 0.000478539   valid's RMSPE: 0.271705\n[150]   train's rmse: 0.000426932   train's RMSPE: 0.237654 valid's rmse: 0.000474134   valid's RMSPE: 0.269204\n[200]   train's rmse: 0.000417218   train's RMSPE: 0.232246 valid's rmse: 0.000471553   valid's RMSPE: 0.267738\n[250]   train's rmse: 0.000410552   train's RMSPE: 0.228536 valid's rmse: 0.00047086    valid's RMSPE: 0.267345\n[300]   train's rmse: 0.000404709   train's RMSPE: 0.225283 valid's rmse: 0.000469996   valid's RMSPE: 0.266854\n[350]   train's rmse: 0.000399001   train's RMSPE: 0.222106 valid's rmse: 0.000469865   valid's RMSPE: 0.26678\n[400]   train's rmse: 0.000394071   train's RMSPE: 0.219361 valid's rmse: 0.00046796    valid's RMSPE: 0.265699\n[450]   train's rmse: 0.000389323   train's RMSPE: 0.216718 valid's rmse: 0.000467973   valid's RMSPE: 0.265706\nEarly stopping, best iteration is:\n[413]   train's rmse: 0.000392552   train's RMSPE: 0.218516 valid's rmse: 0.000467405   valid's RMSPE: 0.265383\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000470174   train's RMSPE: 0.26157  valid's rmse: 0.000445851   valid's RMSPE: 0.253719\n[100]   train's rmse: 0.000445797   train's RMSPE: 0.248008 valid's rmse: 0.000432949   valid's RMSPE: 0.246377\n[150]   train's rmse: 0.000434793   train's RMSPE: 0.241887 valid's rmse: 0.000429427   valid's RMSPE: 0.244373\nEarly stopping, best iteration is:\n[147]   train's rmse: 0.000435194   train's RMSPE: 0.24211  valid's rmse: 0.000429332   valid's RMSPE: 0.244319\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000471379   train's RMSPE: 0.262959 valid's rmse: 0.000446624   valid's RMSPE: 0.251479\n[100]   train's rmse: 0.000447099   train's RMSPE: 0.249415 valid's rmse: 0.000430975   valid's RMSPE: 0.242667\n[150]   train's rmse: 0.000437577   train's RMSPE: 0.244102 valid's rmse: 0.000428383   valid's RMSPE: 0.241208\n[200]   train's rmse: 0.000428928   train's RMSPE: 0.239278 valid's rmse: 0.000428957   valid's RMSPE: 0.241531\nEarly stopping, best iteration is:\n[152]   train's rmse: 0.00043715    train's RMSPE: 0.243864 valid's rmse: 0.000428028   valid's RMSPE: 0.241008\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000463149   train's RMSPE: 0.259605 valid's rmse: 0.000483699   valid's RMSPE: 0.267175\n[100]   train's rmse: 0.000440592   train's RMSPE: 0.246961 valid's rmse: 0.000469752   valid's RMSPE: 0.259471\n[150]   train's rmse: 0.000429377   train's RMSPE: 0.240675 valid's rmse: 0.000464743   valid's RMSPE: 0.256704\n[200]   train's rmse: 0.000421435   train's RMSPE: 0.236223 valid's rmse: 0.00046295    valid's RMSPE: 0.255714\n[250]   train's rmse: 0.000413722   train's RMSPE: 0.231899 valid's rmse: 0.000461052   valid's RMSPE: 0.254666\n[300]   train's rmse: 0.000407993   train's RMSPE: 0.228689 valid's rmse: 0.00046142    valid's RMSPE: 0.254869\nEarly stopping, best iteration is:\n[268]   train's rmse: 0.000411479   train's RMSPE: 0.230642 valid's rmse: 0.000460379   valid's RMSPE: 0.254294\nOur out of folds RMSPE is 0.253, compared to 0.21683397615845648, giving gain 0.03616602384154352\nOur cv fold scores are [0.259, 0.265, 0.244, 0.241, 0.254]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000537405   train's RMSPE: 0.260913 valid's rmse: 0.000576788   valid's RMSPE: 0.275982\n[100]   train's rmse: 0.000512389   train's RMSPE: 0.248767 valid's rmse: 0.000563651   valid's RMSPE: 0.269697\n[150]   train's rmse: 0.000499026   train's RMSPE: 0.24228  valid's rmse: 0.000559439   valid's RMSPE: 0.267681\n[200]   train's rmse: 0.000487799   train's RMSPE: 0.236829 valid's rmse: 0.000554911   valid's RMSPE: 0.265515\n[250]   train's rmse: 0.000478858   train's RMSPE: 0.232488 valid's rmse: 0.000551539   valid's RMSPE: 0.263902\n[300]   train's rmse: 0.00047041    train's RMSPE: 0.228387 valid's rmse: 0.000549146   valid's RMSPE: 0.262756\n[350]   train's rmse: 0.000463087   train's RMSPE: 0.224831 valid's rmse: 0.000547998   valid's RMSPE: 0.262207\n[400]   train's rmse: 0.000457036   train's RMSPE: 0.221893 valid's rmse: 0.000548984   valid's RMSPE: 0.262679\nEarly stopping, best iteration is:\n[356]   train's rmse: 0.000462374   train's RMSPE: 0.224485 valid's rmse: 0.000547744   valid's RMSPE: 0.262085\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000538024   train's RMSPE: 0.259672 valid's rmse: 0.000579501   valid's RMSPE: 0.283921\n[100]   train's rmse: 0.00051363    train's RMSPE: 0.247899 valid's rmse: 0.000569232   valid's RMSPE: 0.27889\n[150]   train's rmse: 0.000500677   train's RMSPE: 0.241647 valid's rmse: 0.00056456    valid's RMSPE: 0.276601\n[200]   train's rmse: 0.000490488   train's RMSPE: 0.236729 valid's rmse: 0.000560659   valid's RMSPE: 0.27469\n[250]   train's rmse: 0.0004826 train's RMSPE: 0.232922 valid's rmse: 0.000559461   valid's RMSPE: 0.274103\n[300]   train's rmse: 0.000474694   train's RMSPE: 0.229106 valid's rmse: 0.000555702   valid's RMSPE: 0.272261\n[350]   train's rmse: 0.000467811   train's RMSPE: 0.225784 valid's rmse: 0.000554188   valid's RMSPE: 0.271519\n[400]   train's rmse: 0.00046211    train's RMSPE: 0.223033 valid's rmse: 0.000555074   valid's RMSPE: 0.271953\nEarly stopping, best iteration is:\n[360]   train's rmse: 0.000466723   train's RMSPE: 0.225259 valid's rmse: 0.000553756   valid's RMSPE: 0.271307\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000549544   train's RMSPE: 0.265739 valid's rmse: 0.000528384   valid's RMSPE: 0.256946\n[100]   train's rmse: 0.000522551   train's RMSPE: 0.252686 valid's rmse: 0.000511119   valid's RMSPE: 0.248551\n[150]   train's rmse: 0.000508981   train's RMSPE: 0.246124 valid's rmse: 0.000505203   valid's RMSPE: 0.245674\n[200]   train's rmse: 0.000497616   train's RMSPE: 0.240628 valid's rmse: 0.000501399   valid's RMSPE: 0.243824\n[250]   train's rmse: 0.000489522   train's RMSPE: 0.236715 valid's rmse: 0.000500122   valid's RMSPE: 0.243203\n[300]   train's rmse: 0.000481379   train's RMSPE: 0.232777 valid's rmse: 0.000499631   valid's RMSPE: 0.242964\n[350]   train's rmse: 0.00047501    train's RMSPE: 0.229697 valid's rmse: 0.000497232   valid's RMSPE: 0.241798\n[400]   train's rmse: 0.000468754   train's RMSPE: 0.226672 valid's rmse: 0.000496987   valid's RMSPE: 0.241678\n[450]   train's rmse: 0.000462387   train's RMSPE: 0.223593 valid's rmse: 0.000496672   valid's RMSPE: 0.241525\nEarly stopping, best iteration is:\n[419]   train's rmse: 0.000466349   train's RMSPE: 0.225509 valid's rmse: 0.000495897   valid's RMSPE: 0.241148\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000548101   train's RMSPE: 0.264629 valid's rmse: 0.00054142    valid's RMSPE: 0.2649\n[100]   train's rmse: 0.000522338   train's RMSPE: 0.25219  valid's rmse: 0.000520595   valid's RMSPE: 0.254711\n[150]   train's rmse: 0.000508051   train's RMSPE: 0.245292 valid's rmse: 0.000513643   valid's RMSPE: 0.251309\n[200]   train's rmse: 0.000498183   train's RMSPE: 0.240528 valid's rmse: 0.000513183   valid's RMSPE: 0.251084\nEarly stopping, best iteration is:\n[161]   train's rmse: 0.000505488   train's RMSPE: 0.244055 valid's rmse: 0.000512341   valid's RMSPE: 0.250672\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000544548   train's RMSPE: 0.264659 valid's rmse: 0.000552976   valid's RMSPE: 0.26344\n[100]   train's rmse: 0.000518581   train's RMSPE: 0.252039 valid's rmse: 0.000541886   valid's RMSPE: 0.258157\n[150]   train's rmse: 0.00050572    train's RMSPE: 0.245788 valid's rmse: 0.000538184   valid's RMSPE: 0.256393\n[200]   train's rmse: 0.000494255   train's RMSPE: 0.240215 valid's rmse: 0.000536072   valid's RMSPE: 0.255387\n[250]   train's rmse: 0.000485442   train's RMSPE: 0.235933 valid's rmse: 0.000535036   valid's RMSPE: 0.254894\n[300]   train's rmse: 0.000477326   train's RMSPE: 0.231988 valid's rmse: 0.000534276   valid's RMSPE: 0.254531\n[350]   train's rmse: 0.000470796   train's RMSPE: 0.228814 valid's rmse: 0.000533135   valid's RMSPE: 0.253988\n[400]   train's rmse: 0.000465008   train's RMSPE: 0.226001 valid's rmse: 0.000531293   valid's RMSPE: 0.25311\nEarly stopping, best iteration is:\n[398]   train's rmse: 0.000465215   train's RMSPE: 0.226102 valid's rmse: 0.000531027   valid's RMSPE: 0.252984\nOur out of folds RMSPE is 0.256, compared to 0.21855958211975457, giving gain 0.037440417880245436\nOur cv fold scores are [0.262, 0.271, 0.241, 0.251, 0.253]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000581782   train's RMSPE: 0.2095   valid's rmse: 0.000617178   valid's RMSPE: 0.219567\n[100]   train's rmse: 0.000542805   train's RMSPE: 0.195464 valid's rmse: 0.000597274   valid's RMSPE: 0.212486\n[150]   train's rmse: 0.000528932   train's RMSPE: 0.190468 valid's rmse: 0.000592981   valid's RMSPE: 0.210959\n[200]   train's rmse: 0.000518597   train's RMSPE: 0.186747 valid's rmse: 0.000590925   valid's RMSPE: 0.210227\n[250]   train's rmse: 0.000509795   train's RMSPE: 0.183577 valid's rmse: 0.000590227   valid's RMSPE: 0.209979\n[300]   train's rmse: 0.000501791   train's RMSPE: 0.180695 valid's rmse: 0.000589193   valid's RMSPE: 0.209611\n[350]   train's rmse: 0.000494907   train's RMSPE: 0.178216 valid's rmse: 0.000588486   valid's RMSPE: 0.20936\n[400]   train's rmse: 0.000488443   train's RMSPE: 0.175889 valid's rmse: 0.000588449   valid's RMSPE: 0.209346\n[450]   train's rmse: 0.000481905   train's RMSPE: 0.173534 valid's rmse: 0.000587807   valid's RMSPE: 0.209118\nEarly stopping, best iteration is:\n[429]   train's rmse: 0.000484464   train's RMSPE: 0.174456 valid's rmse: 0.00058741    valid's RMSPE: 0.208977\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000582123   train's RMSPE: 0.207613 valid's rmse: 0.000626697   valid's RMSPE: 0.231505\n[100]   train's rmse: 0.000547738   train's RMSPE: 0.19535  valid's rmse: 0.000590935   valid's RMSPE: 0.218294\n[150]   train's rmse: 0.000534341   train's RMSPE: 0.190572 valid's rmse: 0.000586729   valid's RMSPE: 0.216741\n[200]   train's rmse: 0.000524247   train's RMSPE: 0.186972 valid's rmse: 0.000585769   valid's RMSPE: 0.216386\n[250]   train's rmse: 0.000514615   train's RMSPE: 0.183537 valid's rmse: 0.000582179   valid's RMSPE: 0.21506\n[300]   train's rmse: 0.000506749   train's RMSPE: 0.180731 valid's rmse: 0.000579139   valid's RMSPE: 0.213937\n[350]   train's rmse: 0.000499312   train's RMSPE: 0.178079 valid's rmse: 0.000576535   valid's RMSPE: 0.212975\n[400]   train's rmse: 0.000492604   train's RMSPE: 0.175687 valid's rmse: 0.000575242   valid's RMSPE: 0.212497\n[450]   train's rmse: 0.0004861 train's RMSPE: 0.173367 valid's rmse: 0.000573467   valid's RMSPE: 0.211842\n[500]   train's rmse: 0.000480444   train's RMSPE: 0.17135  valid's rmse: 0.00057312    valid's RMSPE: 0.211714\n[550]   train's rmse: 0.000474642   train's RMSPE: 0.16928  valid's rmse: 0.000571291   valid's RMSPE: 0.211038\n[600]   train's rmse: 0.000469865   train's RMSPE: 0.167577 valid's rmse: 0.000569594   valid's RMSPE: 0.210411\n[650]   train's rmse: 0.000465071   train's RMSPE: 0.165867 valid's rmse: 0.000568846   valid's RMSPE: 0.210135\n[700]   train's rmse: 0.000460382   train's RMSPE: 0.164194 valid's rmse: 0.000568263   valid's RMSPE: 0.20992\n[750]   train's rmse: 0.000455852   train's RMSPE: 0.162579 valid's rmse: 0.000568594   valid's RMSPE: 0.210042\nEarly stopping, best iteration is:\n[703]   train's rmse: 0.000460029   train's RMSPE: 0.164069 valid's rmse: 0.000568012   valid's RMSPE: 0.209827\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000587149   train's RMSPE: 0.21058  valid's rmse: 0.000581324   valid's RMSPE: 0.210195\n[100]   train's rmse: 0.000550563   train's RMSPE: 0.197458 valid's rmse: 0.000561208   valid's RMSPE: 0.202922\n[150]   train's rmse: 0.000537571   train's RMSPE: 0.192799 valid's rmse: 0.000557619   valid's RMSPE: 0.201624\n[200]   train's rmse: 0.000526811   train's RMSPE: 0.18894  valid's rmse: 0.000558387   valid's RMSPE: 0.201902\nEarly stopping, best iteration is:\n[187]   train's rmse: 0.000529224   train's RMSPE: 0.189805 valid's rmse: 0.000556606   valid's RMSPE: 0.201258\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000584502   train's RMSPE: 0.209694 valid's rmse: 0.000596987   valid's RMSPE: 0.215603\n[100]   train's rmse: 0.000545788   train's RMSPE: 0.195804 valid's rmse: 0.00057097    valid's RMSPE: 0.206207\n[150]   train's rmse: 0.000532721   train's RMSPE: 0.191117 valid's rmse: 0.000570264   valid's RMSPE: 0.205952\nEarly stopping, best iteration is:\n[133]   train's rmse: 0.000536551   train's RMSPE: 0.192491 valid's rmse: 0.000569798   valid's RMSPE: 0.205784\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000586306   train's RMSPE: 0.212247 valid's rmse: 0.000580796   valid's RMSPE: 0.202078\n[100]   train's rmse: 0.000550904   train's RMSPE: 0.199431 valid's rmse: 0.000566277   valid's RMSPE: 0.197026\nEarly stopping, best iteration is:\n[97]    train's rmse: 0.000551888   train's RMSPE: 0.199787 valid's rmse: 0.000565992   valid's RMSPE: 0.196927\nOur out of folds RMSPE is 0.205, compared to 0.1819471504420077, giving gain 0.023052849557992278\nOur cv fold scores are [0.209, 0.21, 0.201, 0.206, 0.197]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000566734   train's RMSPE: 0.242855 valid's rmse: 0.00060816    valid's RMSPE: 0.264038\n[100]   train's rmse: 0.00053628    train's RMSPE: 0.229805 valid's rmse: 0.000586685   valid's RMSPE: 0.254714\n[150]   train's rmse: 0.000521165   train's RMSPE: 0.223328 valid's rmse: 0.000581427   valid's RMSPE: 0.252432\n[200]   train's rmse: 0.000509479   train's RMSPE: 0.21832  valid's rmse: 0.000579331   valid's RMSPE: 0.251522\n[250]   train's rmse: 0.000500124   train's RMSPE: 0.214311 valid's rmse: 0.000578194   valid's RMSPE: 0.251028\n[300]   train's rmse: 0.00049039    train's RMSPE: 0.21014  valid's rmse: 0.000575329   valid's RMSPE: 0.249784\n[350]   train's rmse: 0.000482867   train's RMSPE: 0.206916 valid's rmse: 0.000575986   valid's RMSPE: 0.250069\nEarly stopping, best iteration is:\n[304]   train's rmse: 0.000489577   train's RMSPE: 0.209791 valid's rmse: 0.000574966   valid's RMSPE: 0.249627\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00056408    train's RMSPE: 0.242116 valid's rmse: 0.000602345   valid's RMSPE: 0.259827\n[100]   train's rmse: 0.000532044   train's RMSPE: 0.228365 valid's rmse: 0.000590182   valid's RMSPE: 0.254581\nEarly stopping, best iteration is:\n[92]    train's rmse: 0.000534361   train's RMSPE: 0.22936  valid's rmse: 0.000588919   valid's RMSPE: 0.254036\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.00057247    train's RMSPE: 0.245755 valid's rmse: 0.000564963   valid's RMSPE: 0.243552\n[100]   train's rmse: 0.000539921   train's RMSPE: 0.231782 valid's rmse: 0.000547116   valid's RMSPE: 0.235858\n[150]   train's rmse: 0.000524914   train's RMSPE: 0.22534  valid's rmse: 0.000545541   valid's RMSPE: 0.235179\n[200]   train's rmse: 0.00051326    train's RMSPE: 0.220337 valid's rmse: 0.000545363   valid's RMSPE: 0.235102\n[250]   train's rmse: 0.000504157   train's RMSPE: 0.216429 valid's rmse: 0.000545537   valid's RMSPE: 0.235177\nEarly stopping, best iteration is:\n[225]   train's rmse: 0.000508623   train's RMSPE: 0.218346 valid's rmse: 0.00054477    valid's RMSPE: 0.234847\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000572534   train's RMSPE: 0.246019 valid's rmse: 0.000586165   valid's RMSPE: 0.251726\n[100]   train's rmse: 0.000541195   train's RMSPE: 0.232552 valid's rmse: 0.00056543    valid's RMSPE: 0.242822\n[150]   train's rmse: 0.000528371   train's RMSPE: 0.227042 valid's rmse: 0.000564979   valid's RMSPE: 0.242628\nEarly stopping, best iteration is:\n[131]   train's rmse: 0.000532645   train's RMSPE: 0.228878 valid's rmse: 0.000563772   valid's RMSPE: 0.24211\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000572878   train's RMSPE: 0.247207 valid's rmse: 0.000571769   valid's RMSPE: 0.241343\n[100]   train's rmse: 0.000543083   train's RMSPE: 0.23435  valid's rmse: 0.000555619   valid's RMSPE: 0.234526\n[150]   train's rmse: 0.000528723   train's RMSPE: 0.228153 valid's rmse: 0.000551832   valid's RMSPE: 0.232927\n[200]   train's rmse: 0.000517586   train's RMSPE: 0.223348 valid's rmse: 0.000552707   valid's RMSPE: 0.233297\nEarly stopping, best iteration is:\n[161]   train's rmse: 0.000526152   train's RMSPE: 0.227044 valid's rmse: 0.000551391   valid's RMSPE: 0.232741\nOur out of folds RMSPE is 0.243, compared to 0.21239050356685427, giving gain 0.030609496433145728\nOur cv fold scores are [0.25, 0.254, 0.235, 0.242, 0.233]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00125597    train's RMSPE: 0.25398  valid's rmse: 0.00133036    valid's RMSPE: 0.269266\n[100]   train's rmse: 0.00120359    train's RMSPE: 0.243388 valid's rmse: 0.00131837    valid's RMSPE: 0.266839\nEarly stopping, best iteration is:\n[82]    train's rmse: 0.0012181 train's RMSPE: 0.246322 valid's rmse: 0.0013169 valid's RMSPE: 0.266541\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00125382    train's RMSPE: 0.253216 valid's rmse: 0.00131614    valid's RMSPE: 0.267762\n[100]   train's rmse: 0.00120414    train's RMSPE: 0.243184 valid's rmse: 0.00130231    valid's RMSPE: 0.264947\n[150]   train's rmse: 0.00116878    train's RMSPE: 0.236042 valid's rmse: 0.00130049    valid's RMSPE: 0.264578\n[200]   train's rmse: 0.00114183    train's RMSPE: 0.230599 valid's rmse: 0.00130328    valid's RMSPE: 0.265147\nEarly stopping, best iteration is:\n[165]   train's rmse: 0.00115989    train's RMSPE: 0.234248 valid's rmse: 0.00129964    valid's RMSPE: 0.264405\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00124894    train's RMSPE: 0.251835 valid's rmse: 0.00136328    valid's RMSPE: 0.279056\n[100]   train's rmse: 0.00120059    train's RMSPE: 0.242087 valid's rmse: 0.00135766    valid's RMSPE: 0.277904\n[150]   train's rmse: 0.00117056    train's RMSPE: 0.236031 valid's rmse: 0.00135283    valid's RMSPE: 0.276916\n[200]   train's rmse: 0.00114545    train's RMSPE: 0.230968 valid's rmse: 0.00135801    valid's RMSPE: 0.277976\nEarly stopping, best iteration is:\n[158]   train's rmse: 0.00116658    train's RMSPE: 0.235228 valid's rmse: 0.0013512 valid's RMSPE: 0.276582\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00127376    train's RMSPE: 0.25714  valid's rmse: 0.00126053    valid's RMSPE: 0.256853\n[100]   train's rmse: 0.00122271    train's RMSPE: 0.246834 valid's rmse: 0.00125068    valid's RMSPE: 0.254844\n[150]   train's rmse: 0.00119322    train's RMSPE: 0.240881 valid's rmse: 0.00124779    valid's RMSPE: 0.254256\nEarly stopping, best iteration is:\n[124]   train's rmse: 0.00120686    train's RMSPE: 0.243635 valid's rmse: 0.00124683    valid's RMSPE: 0.25406\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.00127917    train's RMSPE: 0.260412 valid's rmse: 0.00123468    valid's RMSPE: 0.243075\n[100]   train's rmse: 0.00123   train's RMSPE: 0.250401 valid's rmse: 0.00121841    valid's RMSPE: 0.239872\nEarly stopping, best iteration is:\n[89]    train's rmse: 0.00123779    train's RMSPE: 0.251987 valid's rmse: 0.00121725    valid's RMSPE: 0.239644\nOur out of folds RMSPE is 0.261, compared to 0.24476881619667987, giving gain 0.016231183803320143\nOur cv fold scores are [0.267, 0.264, 0.277, 0.254, 0.24]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000603909   train's RMSPE: 0.209152 valid's rmse: 0.000662158   valid's RMSPE: 0.227311\n[100]   train's rmse: 0.000573538   train's RMSPE: 0.198633 valid's rmse: 0.000641397   valid's RMSPE: 0.220184\n[150]   train's rmse: 0.00056009    train's RMSPE: 0.193976 valid's rmse: 0.000636365   valid's RMSPE: 0.218456\n[200]   train's rmse: 0.000548184   train's RMSPE: 0.189853 valid's rmse: 0.000634728   valid's RMSPE: 0.217895\n[250]   train's rmse: 0.000538035   train's RMSPE: 0.186338 valid's rmse: 0.000633519   valid's RMSPE: 0.217479\n[300]   train's rmse: 0.000530174   train's RMSPE: 0.183615 valid's rmse: 0.000632618   valid's RMSPE: 0.21717\nEarly stopping, best iteration is:\n[273]   train's rmse: 0.000533994   train's RMSPE: 0.184938 valid's rmse: 0.000632236   valid's RMSPE: 0.217039\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000603613   train's RMSPE: 0.208383 valid's rmse: 0.000674021   valid's RMSPE: 0.234363\n[100]   train's rmse: 0.000568819   train's RMSPE: 0.196371 valid's rmse: 0.000657435   valid's RMSPE: 0.228596\n[150]   train's rmse: 0.000555085   train's RMSPE: 0.19163  valid's rmse: 0.000652756   valid's RMSPE: 0.226969\n[200]   train's rmse: 0.000544363   train's RMSPE: 0.187928 valid's rmse: 0.000652122   valid's RMSPE: 0.226748\n[250]   train's rmse: 0.000535419   train's RMSPE: 0.184841 valid's rmse: 0.000649036   valid's RMSPE: 0.225675\n[300]   train's rmse: 0.000526509   train's RMSPE: 0.181765 valid's rmse: 0.000647956   valid's RMSPE: 0.2253\n[350]   train's rmse: 0.000519234   train's RMSPE: 0.179253 valid's rmse: 0.000646768   valid's RMSPE: 0.224886\n[400]   train's rmse: 0.000512983   train's RMSPE: 0.177095 valid's rmse: 0.000646535   valid's RMSPE: 0.224805\nEarly stopping, best iteration is:\n[368]   train's rmse: 0.000516776   train's RMSPE: 0.178404 valid's rmse: 0.000646272   valid's RMSPE: 0.224714\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.0006206 train's RMSPE: 0.213192 valid's rmse: 0.000599062   valid's RMSPE: 0.212295\n[100]   train's rmse: 0.000585169   train's RMSPE: 0.201021 valid's rmse: 0.000581892   valid's RMSPE: 0.20621\n[150]   train's rmse: 0.000571238   train's RMSPE: 0.196235 valid's rmse: 0.000581256   valid's RMSPE: 0.205985\nEarly stopping, best iteration is:\n[147]   train's rmse: 0.000571927   train's RMSPE: 0.196472 valid's rmse: 0.000580817   valid's RMSPE: 0.205829\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000622636   train's RMSPE: 0.215935 valid's rmse: 0.000607949   valid's RMSPE: 0.207524\n[100]   train's rmse: 0.000588277   train's RMSPE: 0.204019 valid's rmse: 0.000581424   valid's RMSPE: 0.19847\n[150]   train's rmse: 0.00057586    train's RMSPE: 0.199713 valid's rmse: 0.0005766 valid's RMSPE: 0.196823\n[200]   train's rmse: 0.000565277   train's RMSPE: 0.196043 valid's rmse: 0.000573429   valid's RMSPE: 0.195741\n[250]   train's rmse: 0.000557087   train's RMSPE: 0.193203 valid's rmse: 0.000573556   valid's RMSPE: 0.195784\n[300]   train's rmse: 0.000548231   train's RMSPE: 0.190131 valid's rmse: 0.000573053   valid's RMSPE: 0.195612\nEarly stopping, best iteration is:\n[288]   train's rmse: 0.000550124   train's RMSPE: 0.190788 valid's rmse: 0.000572659   valid's RMSPE: 0.195478\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000620666   train's RMSPE: 0.215196 valid's rmse: 0.000613031   valid's RMSPE: 0.209484\n[100]   train's rmse: 0.000588667   train's RMSPE: 0.204101 valid's rmse: 0.000592272   valid's RMSPE: 0.20239\n[150]   train's rmse: 0.000574429   train's RMSPE: 0.199165 valid's rmse: 0.000588093   valid's RMSPE: 0.200963\n[200]   train's rmse: 0.000563771   train's RMSPE: 0.19547  valid's rmse: 0.000587783   valid's RMSPE: 0.200856\n[250]   train's rmse: 0.000553603   train's RMSPE: 0.191944 valid's rmse: 0.000585326   valid's RMSPE: 0.200017\n[300]   train's rmse: 0.000544726   train's RMSPE: 0.188866 valid's rmse: 0.0005851 valid's RMSPE: 0.19994\n[350]   train's rmse: 0.000536625   train's RMSPE: 0.186058 valid's rmse: 0.000583672   valid's RMSPE: 0.199452\n[400]   train's rmse: 0.00052957    train's RMSPE: 0.183611 valid's rmse: 0.000582484   valid's RMSPE: 0.199046\n[450]   train's rmse: 0.000522447   train's RMSPE: 0.181142 valid's rmse: 0.000582583   valid's RMSPE: 0.19908\nEarly stopping, best iteration is:\n[411]   train's rmse: 0.00052804    train's RMSPE: 0.183081 valid's rmse: 0.000581992   valid's RMSPE: 0.198877\nOur out of folds RMSPE is 0.209, compared to 0.18132182041428943, giving gain 0.02767817958571056\nOur cv fold scores are [0.217, 0.225, 0.206, 0.195, 0.199]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000434626   train's RMSPE: 0.199601 valid's rmse: 0.000448672   valid's RMSPE: 0.210609\n[100]   train's rmse: 0.000408326   train's RMSPE: 0.187523 valid's rmse: 0.000427868   valid's RMSPE: 0.200844\n[150]   train's rmse: 0.000395985   train's RMSPE: 0.181855 valid's rmse: 0.000423469   valid's RMSPE: 0.198779\n[200]   train's rmse: 0.000386962   train's RMSPE: 0.177711 valid's rmse: 0.000420436   valid's RMSPE: 0.197355\n[250]   train's rmse: 0.000379633   train's RMSPE: 0.174346 valid's rmse: 0.000417507   valid's RMSPE: 0.19598\n[300]   train's rmse: 0.000373548   train's RMSPE: 0.171551 valid's rmse: 0.000415828   valid's RMSPE: 0.195192\n[350]   train's rmse: 0.000367841   train's RMSPE: 0.16893  valid's rmse: 0.000414159   valid's RMSPE: 0.194408\n[400]   train's rmse: 0.00036363    train's RMSPE: 0.166996 valid's rmse: 0.000413005   valid's RMSPE: 0.193867\n[450]   train's rmse: 0.000359603   train's RMSPE: 0.165147 valid's rmse: 0.000412338   valid's RMSPE: 0.193553\n[500]   train's rmse: 0.00035538    train's RMSPE: 0.163208 valid's rmse: 0.000411421   valid's RMSPE: 0.193123\n[550]   train's rmse: 0.000351951   train's RMSPE: 0.161633 valid's rmse: 0.000410939   valid's RMSPE: 0.192897\n[600]   train's rmse: 0.000348475   train's RMSPE: 0.160037 valid's rmse: 0.000409907   valid's RMSPE: 0.192412\n[650]   train's rmse: 0.000345451   train's RMSPE: 0.158648 valid's rmse: 0.00040896    valid's RMSPE: 0.191968\n[700]   train's rmse: 0.000342216   train's RMSPE: 0.157162 valid's rmse: 0.000408175   valid's RMSPE: 0.191599\n[750]   train's rmse: 0.000339268   train's RMSPE: 0.155808 valid's rmse: 0.000407909   valid's RMSPE: 0.191475\n[800]   train's rmse: 0.000336482   train's RMSPE: 0.154529 valid's rmse: 0.000407547   valid's RMSPE: 0.191305\n[850]   train's rmse: 0.000333892   train's RMSPE: 0.153339 valid's rmse: 0.000407609   valid's RMSPE: 0.191334\n[900]   train's rmse: 0.000331416   train's RMSPE: 0.152202 valid's rmse: 0.000406987   valid's RMSPE: 0.191042\n[950]   train's rmse: 0.000329114   train's RMSPE: 0.151145 valid's rmse: 0.000406987   valid's RMSPE: 0.191042\n[1000]  train's rmse: 0.000326795   train's RMSPE: 0.15008  valid's rmse: 0.000406473   valid's RMSPE: 0.1908\n[1050]  train's rmse: 0.000324639   train's RMSPE: 0.14909  valid's rmse: 0.000407127   valid's RMSPE: 0.191108\nEarly stopping, best iteration is:\n[1000]  train's rmse: 0.000326795   train's RMSPE: 0.15008  valid's rmse: 0.000406473   valid's RMSPE: 0.1908\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000430379   train's RMSPE: 0.198042 valid's rmse: 0.000455708   valid's RMSPE: 0.212281\n[100]   train's rmse: 0.000404225   train's RMSPE: 0.186007 valid's rmse: 0.000439262   valid's RMSPE: 0.20462\n[150]   train's rmse: 0.000393438   train's RMSPE: 0.181044 valid's rmse: 0.00043463    valid's RMSPE: 0.202462\n[200]   train's rmse: 0.000384794   train's RMSPE: 0.177066 valid's rmse: 0.000430094   valid's RMSPE: 0.200349\n[250]   train's rmse: 0.00037891    train's RMSPE: 0.174358 valid's rmse: 0.000428851   valid's RMSPE: 0.19977\n[300]   train's rmse: 0.000373039   train's RMSPE: 0.171657 valid's rmse: 0.000427345   valid's RMSPE: 0.199069\n[350]   train's rmse: 0.00036772    train's RMSPE: 0.16921  valid's rmse: 0.000425388   valid's RMSPE: 0.198157\n[400]   train's rmse: 0.000363685   train's RMSPE: 0.167352 valid's rmse: 0.000425753   valid's RMSPE: 0.198327\nEarly stopping, best iteration is:\n[350]   train's rmse: 0.00036772    train's RMSPE: 0.16921  valid's rmse: 0.000425388   valid's RMSPE: 0.198157\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000438649   train's RMSPE: 0.202519 valid's rmse: 0.000417162   valid's RMSPE: 0.191782\n[100]   train's rmse: 0.000412518   train's RMSPE: 0.190455 valid's rmse: 0.000394813   valid's RMSPE: 0.181508\n[150]   train's rmse: 0.000400528   train's RMSPE: 0.184919 valid's rmse: 0.000389328   valid's RMSPE: 0.178986\n[200]   train's rmse: 0.000391958   train's RMSPE: 0.180962 valid's rmse: 0.000385922   valid's RMSPE: 0.17742\n[250]   train's rmse: 0.000384957   train's RMSPE: 0.17773  valid's rmse: 0.000384351   valid's RMSPE: 0.176698\n[300]   train's rmse: 0.000378689   train's RMSPE: 0.174836 valid's rmse: 0.000382984   valid's RMSPE: 0.17607\n[350]   train's rmse: 0.000373352   train's RMSPE: 0.172372 valid's rmse: 0.000381891   valid's RMSPE: 0.175567\n[400]   train's rmse: 0.00036856    train's RMSPE: 0.17016  valid's rmse: 0.000381326   valid's RMSPE: 0.175307\n[450]   train's rmse: 0.00036427    train's RMSPE: 0.168179 valid's rmse: 0.000381296   valid's RMSPE: 0.175294\nEarly stopping, best iteration is:\n[420]   train's rmse: 0.000366623   train's RMSPE: 0.169265 valid's rmse: 0.000380741   valid's RMSPE: 0.175039\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000438696   train's RMSPE: 0.202768 valid's rmse: 0.000436621   valid's RMSPE: 0.199817\n[100]   train's rmse: 0.000411649   train's RMSPE: 0.190267 valid's rmse: 0.000418449   valid's RMSPE: 0.191501\n[150]   train's rmse: 0.000400344   train's RMSPE: 0.185041 valid's rmse: 0.000415545   valid's RMSPE: 0.190172\n[200]   train's rmse: 0.000392005   train's RMSPE: 0.181187 valid's rmse: 0.0004121 valid's RMSPE: 0.188595\n[250]   train's rmse: 0.000385988   train's RMSPE: 0.178406 valid's rmse: 0.000411558   valid's RMSPE: 0.188347\n[300]   train's rmse: 0.000380046   train's RMSPE: 0.17566  valid's rmse: 0.000410723   valid's RMSPE: 0.187965\n[350]   train's rmse: 0.000374946   train's RMSPE: 0.173302 valid's rmse: 0.000409852   valid's RMSPE: 0.187566\nEarly stopping, best iteration is:\n[328]   train's rmse: 0.000377009   train's RMSPE: 0.174256 valid's rmse: 0.000409452   valid's RMSPE: 0.187383\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00043188    train's RMSPE: 0.200036 valid's rmse: 0.000455327   valid's RMSPE: 0.206585\n[100]   train's rmse: 0.000406364   train's RMSPE: 0.188218 valid's rmse: 0.000438422   valid's RMSPE: 0.198914\n[150]   train's rmse: 0.000395214   train's RMSPE: 0.183054 valid's rmse: 0.000434234   valid's RMSPE: 0.197014\n[200]   train's rmse: 0.000386618   train's RMSPE: 0.179072 valid's rmse: 0.000431955   valid's RMSPE: 0.19598\n[250]   train's rmse: 0.00038063    train's RMSPE: 0.176298 valid's rmse: 0.000431111   valid's RMSPE: 0.195598\nEarly stopping, best iteration is:\n[223]   train's rmse: 0.000383825   train's RMSPE: 0.177778 valid's rmse: 0.000430824   valid's RMSPE: 0.195467\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.19, compared to 0.16990778241496282, giving gain 0.02009221758503718\nOur cv fold scores are [0.191, 0.198, 0.175, 0.187, 0.195]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000776612   train's RMSPE: 0.228189 valid's rmse: 0.000813077   valid's RMSPE: 0.239094\n[100]   train's rmse: 0.00074033    train's RMSPE: 0.217528 valid's rmse: 0.000798015   valid's RMSPE: 0.234665\n[150]   train's rmse: 0.000721395   train's RMSPE: 0.211964 valid's rmse: 0.00079684    valid's RMSPE: 0.234319\n[200]   train's rmse: 0.000705656   train's RMSPE: 0.20734  valid's rmse: 0.000793142   valid's RMSPE: 0.233232\n[250]   train's rmse: 0.000692778   train's RMSPE: 0.203556 valid's rmse: 0.000793585   valid's RMSPE: 0.233362\nEarly stopping, best iteration is:\n[218]   train's rmse: 0.000700864   train's RMSPE: 0.205932 valid's rmse: 0.00079232    valid's RMSPE: 0.23299\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000776122   train's RMSPE: 0.226793 valid's rmse: 0.000816951   valid's RMSPE: 0.245429\n[100]   train's rmse: 0.000741536   train's RMSPE: 0.216686 valid's rmse: 0.000790972   valid's RMSPE: 0.237625\n[150]   train's rmse: 0.000722092   train's RMSPE: 0.211004 valid's rmse: 0.000786204   valid's RMSPE: 0.236192\nEarly stopping, best iteration is:\n[149]   train's rmse: 0.000722261   train's RMSPE: 0.211054 valid's rmse: 0.000785833   valid's RMSPE: 0.236081\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000784108   train's RMSPE: 0.229698 valid's rmse: 0.000778834   valid's RMSPE: 0.231757\n[100]   train's rmse: 0.000748653   train's RMSPE: 0.219311 valid's rmse: 0.000765088   valid's RMSPE: 0.227667\n[150]   train's rmse: 0.000728915   train's RMSPE: 0.213529 valid's rmse: 0.000762636   valid's RMSPE: 0.226937\n[200]   train's rmse: 0.000713382   train's RMSPE: 0.208979 valid's rmse: 0.000765094   valid's RMSPE: 0.227668\nEarly stopping, best iteration is:\n[153]   train's rmse: 0.000727953   train's RMSPE: 0.213247 valid's rmse: 0.000762123   valid's RMSPE: 0.226784\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000771106   train's RMSPE: 0.227306 valid's rmse: 0.000840125   valid's RMSPE: 0.24382\n[100]   train's rmse: 0.000733315   train's RMSPE: 0.216166 valid's rmse: 0.000831469   valid's RMSPE: 0.241308\nEarly stopping, best iteration is:\n[76]    train's rmse: 0.000744735   train's RMSPE: 0.219532 valid's rmse: 0.000830039   valid's RMSPE: 0.240893\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000783469   train's RMSPE: 0.231587 valid's rmse: 0.000771185   valid's RMSPE: 0.221247\n[100]   train's rmse: 0.0007497 train's RMSPE: 0.221605 valid's rmse: 0.000753054   valid's RMSPE: 0.216045\n[150]   train's rmse: 0.00073066    train's RMSPE: 0.215977 valid's rmse: 0.000753189   valid's RMSPE: 0.216084\nEarly stopping, best iteration is:\n[102]   train's rmse: 0.000748536   train's RMSPE: 0.221261 valid's rmse: 0.000752458   valid's RMSPE: 0.215874\nOur out of folds RMSPE is 0.231, compared to 0.21143836908517027, giving gain 0.019561630914829736\nOur cv fold scores are [0.233, 0.236, 0.227, 0.241, 0.216]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00125607    train's RMSPE: 0.2637   valid's rmse: 0.00139675    valid's RMSPE: 0.289916\n[100]   train's rmse: 0.00118274    train's RMSPE: 0.248305 valid's rmse: 0.00137234    valid's RMSPE: 0.28485\n[150]   train's rmse: 0.00114729    train's RMSPE: 0.240863 valid's rmse: 0.00136479    valid's RMSPE: 0.283282\n[200]   train's rmse: 0.00111579    train's RMSPE: 0.234249 valid's rmse: 0.00135467    valid's RMSPE: 0.281182\n[250]   train's rmse: 0.00109024    train's RMSPE: 0.228886 valid's rmse: 0.00134986    valid's RMSPE: 0.280182\nEarly stopping, best iteration is:\n[239]   train's rmse: 0.00109565    train's RMSPE: 0.23002  valid's rmse: 0.00134837    valid's RMSPE: 0.279873\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00127376    train's RMSPE: 0.26183  valid's rmse: 0.00132568    valid's RMSPE: 0.297465\n[100]   train's rmse: 0.00120218    train's RMSPE: 0.247115 valid's rmse: 0.00129404    valid's RMSPE: 0.290364\n[150]   train's rmse: 0.00116562    train's RMSPE: 0.239601 valid's rmse: 0.00130074    valid's RMSPE: 0.291868\nEarly stopping, best iteration is:\n[106]   train's rmse: 0.00119694    train's RMSPE: 0.246038 valid's rmse: 0.00128865    valid's RMSPE: 0.289154\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00127096    train's RMSPE: 0.266979 valid's rmse: 0.00124417    valid's RMSPE: 0.25764\n[100]   train's rmse: 0.00119751    train's RMSPE: 0.251551 valid's rmse: 0.00122135    valid's RMSPE: 0.252916\n[150]   train's rmse: 0.00116139    train's RMSPE: 0.243962 valid's rmse: 0.00121982    valid's RMSPE: 0.252598\n[200]   train's rmse: 0.00113061    train's RMSPE: 0.237498 valid's rmse: 0.00121861    valid's RMSPE: 0.252348\n[250]   train's rmse: 0.00110579    train's RMSPE: 0.232284 valid's rmse: 0.00121411    valid's RMSPE: 0.251416\nEarly stopping, best iteration is:\n[221]   train's rmse: 0.00111995    train's RMSPE: 0.235257 valid's rmse: 0.00121307    valid's RMSPE: 0.251201\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.0012717 train's RMSPE: 0.269703 valid's rmse: 0.00128828    valid's RMSPE: 0.255924\n[100]   train's rmse: 0.00119866    train's RMSPE: 0.254212 valid's rmse: 0.00127095    valid's RMSPE: 0.252481\n[150]   train's rmse: 0.00115793    train's RMSPE: 0.245574 valid's rmse: 0.00126277    valid's RMSPE: 0.250856\n[200]   train's rmse: 0.00112844    train's RMSPE: 0.239319 valid's rmse: 0.00126049    valid's RMSPE: 0.250402\n[250]   train's rmse: 0.00110468    train's RMSPE: 0.234281 valid's rmse: 0.0012556 valid's RMSPE: 0.24943\n[300]   train's rmse: 0.00108457    train's RMSPE: 0.230016 valid's rmse: 0.00125441    valid's RMSPE: 0.249194\n[350]   train's rmse: 0.00106721    train's RMSPE: 0.226335 valid's rmse: 0.00125149    valid's RMSPE: 0.248614\n[400]   train's rmse: 0.00105233    train's RMSPE: 0.223178 valid's rmse: 0.00124787    valid's RMSPE: 0.247895\n[450]   train's rmse: 0.00103853    train's RMSPE: 0.220252 valid's rmse: 0.00124706    valid's RMSPE: 0.247734\n[500]   train's rmse: 0.00102493    train's RMSPE: 0.217368 valid's rmse: 0.00125171    valid's RMSPE: 0.248658\nEarly stopping, best iteration is:\n[466]   train's rmse: 0.00103396    train's RMSPE: 0.219283 valid's rmse: 0.00124496    valid's RMSPE: 0.247318\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.0012565 train's RMSPE: 0.263417 valid's rmse: 0.00137292    valid's RMSPE: 0.286616\n[100]   train's rmse: 0.00118308    train's RMSPE: 0.248024 valid's rmse: 0.00133543    valid's RMSPE: 0.27879\nEarly stopping, best iteration is:\n[92]    train's rmse: 0.00119128    train's RMSPE: 0.249744 valid's rmse: 0.00133472    valid's RMSPE: 0.278642\nOur out of folds RMSPE is 0.27, compared to 0.252659555011557, giving gain 0.017340444988443005\nOur cv fold scores are [0.28, 0.289, 0.251, 0.247, 0.279]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000859374   train's RMSPE: 0.238913 valid's rmse: 0.00111969    valid's RMSPE: 0.324016\nEarly stopping, best iteration is:\n[30]    train's rmse: 0.000940611   train's RMSPE: 0.261498 valid's rmse: 0.00110555    valid's RMSPE: 0.319925\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000883416   train's RMSPE: 0.248503 valid's rmse: 0.000924472   valid's RMSPE: 0.255497\n[100]   train's rmse: 0.000824528   train's RMSPE: 0.231938 valid's rmse: 0.000907675   valid's RMSPE: 0.250855\n[150]   train's rmse: 0.00079671    train's RMSPE: 0.224113 valid's rmse: 0.000907227   valid's RMSPE: 0.250731\nEarly stopping, best iteration is:\n[142]   train's rmse: 0.000800431   train's RMSPE: 0.22516  valid's rmse: 0.00090506    valid's RMSPE: 0.250132\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000887387   train's RMSPE: 0.247454 valid's rmse: 0.000899849   valid's RMSPE: 0.257444\n[100]   train's rmse: 0.000830622   train's RMSPE: 0.231624 valid's rmse: 0.00089047    valid's RMSPE: 0.25476\nEarly stopping, best iteration is:\n[66]    train's rmse: 0.000866151   train's RMSPE: 0.241532 valid's rmse: 0.000880169   valid's RMSPE: 0.251813\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000902314   train's RMSPE: 0.253216 valid's rmse: 0.000857521   valid's RMSPE: 0.239314\n[100]   train's rmse: 0.000840801   train's RMSPE: 0.235953 valid's rmse: 0.000854473   valid's RMSPE: 0.238463\nEarly stopping, best iteration is:\n[68]    train's rmse: 0.000870068   train's RMSPE: 0.244167 valid's rmse: 0.000844345   valid's RMSPE: 0.235637\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000890606   train's RMSPE: 0.251845 valid's rmse: 0.000884328   valid's RMSPE: 0.238995\n[100]   train's rmse: 0.000832472   train's RMSPE: 0.235406 valid's rmse: 0.000873685   valid's RMSPE: 0.236119\n[150]   train's rmse: 0.000798956   train's RMSPE: 0.225928 valid's rmse: 0.000868872   valid's RMSPE: 0.234818\nEarly stopping, best iteration is:\n[139]   train's rmse: 0.00080607    train's RMSPE: 0.22794  valid's rmse: 0.000867499   valid's RMSPE: 0.234447\nOur out of folds RMSPE is 0.26, compared to 0.25720950158996386, giving gain 0.0027904984100361463\nOur cv fold scores are [0.32, 0.25, 0.252, 0.236, 0.234]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.0005912 train's RMSPE: 0.256216 valid's rmse: 0.000595862   valid's RMSPE: 0.262508\n[100]   train's rmse: 0.000567636   train's RMSPE: 0.246003 valid's rmse: 0.000580197   valid's RMSPE: 0.255606\n[150]   train's rmse: 0.000555138   train's RMSPE: 0.240587 valid's rmse: 0.000577446   valid's RMSPE: 0.254394\n[200]   train's rmse: 0.000544827   train's RMSPE: 0.236119 valid's rmse: 0.000576202   valid's RMSPE: 0.253846\n[250]   train's rmse: 0.000536114   train's RMSPE: 0.232342 valid's rmse: 0.000577043   valid's RMSPE: 0.254217\nEarly stopping, best iteration is:\n[209]   train's rmse: 0.000543098   train's RMSPE: 0.235369 valid's rmse: 0.000575467   valid's RMSPE: 0.253523\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000587992   train's RMSPE: 0.256752 valid's rmse: 0.000605714   valid's RMSPE: 0.258891\n[100]   train's rmse: 0.000563195   train's RMSPE: 0.245924 valid's rmse: 0.000591377   valid's RMSPE: 0.252763\n[150]   train's rmse: 0.000549547   train's RMSPE: 0.239965 valid's rmse: 0.000590004   valid's RMSPE: 0.252176\n[200]   train's rmse: 0.000538666   train's RMSPE: 0.235213 valid's rmse: 0.000588343   valid's RMSPE: 0.251466\n[250]   train's rmse: 0.000529653   train's RMSPE: 0.231278 valid's rmse: 0.000585925   valid's RMSPE: 0.250433\n[300]   train's rmse: 0.000522218   train's RMSPE: 0.228031 valid's rmse: 0.000585774   valid's RMSPE: 0.250368\n[350]   train's rmse: 0.000515565   train's RMSPE: 0.225126 valid's rmse: 0.000584894   valid's RMSPE: 0.249992\nEarly stopping, best iteration is:\n[349]   train's rmse: 0.000515645   train's RMSPE: 0.225161 valid's rmse: 0.000584665   valid's RMSPE: 0.249894\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000587395   train's RMSPE: 0.254243 valid's rmse: 0.000604562   valid's RMSPE: 0.267649\n[100]   train's rmse: 0.000563248   train's RMSPE: 0.243791 valid's rmse: 0.000587464   valid's RMSPE: 0.26008\n[150]   train's rmse: 0.000553038   train's RMSPE: 0.239372 valid's rmse: 0.00058266    valid's RMSPE: 0.257953\n[200]   train's rmse: 0.000542611   train's RMSPE: 0.234859 valid's rmse: 0.000579881   valid's RMSPE: 0.256722\n[250]   train's rmse: 0.000533871   train's RMSPE: 0.231076 valid's rmse: 0.000577869   valid's RMSPE: 0.255832\n[300]   train's rmse: 0.000526284   train's RMSPE: 0.227792 valid's rmse: 0.0005764 valid's RMSPE: 0.255181\n[350]   train's rmse: 0.000520033   train's RMSPE: 0.225086 valid's rmse: 0.000576727   valid's RMSPE: 0.255326\nEarly stopping, best iteration is:\n[317]   train's rmse: 0.000524219   train's RMSPE: 0.226898 valid's rmse: 0.000575308   valid's RMSPE: 0.254698\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000592784   train's RMSPE: 0.258697 valid's rmse: 0.000574199   valid's RMSPE: 0.246003\n[100]   train's rmse: 0.000568757   train's RMSPE: 0.248212 valid's rmse: 0.000565677   valid's RMSPE: 0.242352\n[150]   train's rmse: 0.000556475   train's RMSPE: 0.242852 valid's rmse: 0.000564477   valid's RMSPE: 0.241838\nEarly stopping, best iteration is:\n[144]   train's rmse: 0.000557731   train's RMSPE: 0.243399 valid's rmse: 0.000564057   valid's RMSPE: 0.241658\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000580131   train's RMSPE: 0.25226  valid's rmse: 0.000631366   valid's RMSPE: 0.274518\n[100]   train's rmse: 0.000556472   train's RMSPE: 0.241972 valid's rmse: 0.000623675   valid's RMSPE: 0.271174\n[150]   train's rmse: 0.000543833   train's RMSPE: 0.236476 valid's rmse: 0.000620774   valid's RMSPE: 0.269912\n[200]   train's rmse: 0.000533269   train's RMSPE: 0.231883 valid's rmse: 0.000621072   valid's RMSPE: 0.270042\nEarly stopping, best iteration is:\n[151]   train's rmse: 0.000543389   train's RMSPE: 0.236283 valid's rmse: 0.000620303   valid's RMSPE: 0.269708\nOur out of folds RMSPE is 0.254, compared to 0.22477318010808972, giving gain 0.029226819891910283\nOur cv fold scores are [0.254, 0.25, 0.255, 0.242, 0.27]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000786756   train's RMSPE: 0.247637 valid's rmse: 0.000852991   valid's RMSPE: 0.271178\n[100]   train's rmse: 0.000752664   train's RMSPE: 0.236907 valid's rmse: 0.000836619   valid's RMSPE: 0.265973\n[150]   train's rmse: 0.000734339   train's RMSPE: 0.231139 valid's rmse: 0.000830671   valid's RMSPE: 0.264082\n[200]   train's rmse: 0.000720413   train's RMSPE: 0.226756 valid's rmse: 0.0008279 valid's RMSPE: 0.263201\n[250]   train's rmse: 0.000708212   train's RMSPE: 0.222915 valid's rmse: 0.000825797   valid's RMSPE: 0.262532\n[300]   train's rmse: 0.000697318   train's RMSPE: 0.219486 valid's rmse: 0.000826573   valid's RMSPE: 0.262779\nEarly stopping, best iteration is:\n[252]   train's rmse: 0.000707835   train's RMSPE: 0.222797 valid's rmse: 0.000825425   valid's RMSPE: 0.262414\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000787808   train's RMSPE: 0.248668 valid's rmse: 0.000849822   valid's RMSPE: 0.26716\n[100]   train's rmse: 0.000751861   train's RMSPE: 0.237322 valid's rmse: 0.000829397   valid's RMSPE: 0.260739\n[150]   train's rmse: 0.000733492   train's RMSPE: 0.231524 valid's rmse: 0.000826519   valid's RMSPE: 0.259834\n[200]   train's rmse: 0.000719201   train's RMSPE: 0.227013 valid's rmse: 0.000824125   valid's RMSPE: 0.259081\n[250]   train's rmse: 0.000704544   train's RMSPE: 0.222387 valid's rmse: 0.000823403   valid's RMSPE: 0.258854\n[300]   train's rmse: 0.00069285    train's RMSPE: 0.218695 valid's rmse: 0.000823599   valid's RMSPE: 0.258916\nEarly stopping, best iteration is:\n[280]   train's rmse: 0.000697257   train's RMSPE: 0.220086 valid's rmse: 0.00082196    valid's RMSPE: 0.258401\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000801363   train's RMSPE: 0.253708 valid's rmse: 0.000776594   valid's RMSPE: 0.241156\n[100]   train's rmse: 0.00076904    train's RMSPE: 0.243474 valid's rmse: 0.00076251    valid's RMSPE: 0.236783\n[150]   train's rmse: 0.000748897   train's RMSPE: 0.237097 valid's rmse: 0.000762682   valid's RMSPE: 0.236836\nEarly stopping, best iteration is:\n[128]   train's rmse: 0.000756703   train's RMSPE: 0.239568 valid's rmse: 0.00076045    valid's RMSPE: 0.236143\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000798816   train's RMSPE: 0.252005 valid's rmse: 0.000815938   valid's RMSPE: 0.257073\n[100]   train's rmse: 0.000764994   train's RMSPE: 0.241335 valid's rmse: 0.000797392   valid's RMSPE: 0.25123\n[150]   train's rmse: 0.000746452   train's RMSPE: 0.235486 valid's rmse: 0.000794203   valid's RMSPE: 0.250225\n[200]   train's rmse: 0.000730356   train's RMSPE: 0.230408 valid's rmse: 0.000790642   valid's RMSPE: 0.249103\n[250]   train's rmse: 0.000717452   train's RMSPE: 0.226337 valid's rmse: 0.000789336   valid's RMSPE: 0.248692\nEarly stopping, best iteration is:\n[242]   train's rmse: 0.000719158   train's RMSPE: 0.226875 valid's rmse: 0.000788282   valid's RMSPE: 0.24836\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000802989   train's RMSPE: 0.252525 valid's rmse: 0.000796074   valid's RMSPE: 0.253953\n[100]   train's rmse: 0.000767627   train's RMSPE: 0.241404 valid's rmse: 0.000775393   valid's RMSPE: 0.247355\n[150]   train's rmse: 0.000748761   train's RMSPE: 0.235471 valid's rmse: 0.000773228   valid's RMSPE: 0.246665\n[200]   train's rmse: 0.000733276   train's RMSPE: 0.230602 valid's rmse: 0.000771356   valid's RMSPE: 0.246068\n[250]   train's rmse: 0.000720612   train's RMSPE: 0.226619 valid's rmse: 0.000768289   valid's RMSPE: 0.245089\nEarly stopping, best iteration is:\n[240]   train's rmse: 0.000723026   train's RMSPE: 0.227378 valid's rmse: 0.000767688   valid's RMSPE: 0.244898\nOur out of folds RMSPE is 0.25, compared to 0.23302903670661276, giving gain 0.016970963293387237\nOur cv fold scores are [0.262, 0.258, 0.236, 0.248, 0.245]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00050701    train's RMSPE: 0.197631 valid's rmse: 0.000555618   valid's RMSPE: 0.21158\n[100]   train's rmse: 0.000470677   train's RMSPE: 0.183468 valid's rmse: 0.000536578   valid's RMSPE: 0.20433\n[150]   train's rmse: 0.000459419   train's RMSPE: 0.17908  valid's rmse: 0.000534323   valid's RMSPE: 0.203471\n[200]   train's rmse: 0.000450343   train's RMSPE: 0.175543 valid's rmse: 0.000532011   valid's RMSPE: 0.202591\n[250]   train's rmse: 0.000442545   train's RMSPE: 0.172503 valid's rmse: 0.000529697   valid's RMSPE: 0.20171\n[300]   train's rmse: 0.000435716   train's RMSPE: 0.169841 valid's rmse: 0.000528681   valid's RMSPE: 0.201323\n[350]   train's rmse: 0.000429951   train's RMSPE: 0.167594 valid's rmse: 0.000528788   valid's RMSPE: 0.201363\n[400]   train's rmse: 0.00042367    train's RMSPE: 0.165145 valid's rmse: 0.000527062   valid's RMSPE: 0.200706\n[450]   train's rmse: 0.000419098   train's RMSPE: 0.163363 valid's rmse: 0.000527251   valid's RMSPE: 0.200778\n[500]   train's rmse: 0.000414687   train's RMSPE: 0.161644 valid's rmse: 0.000526738   valid's RMSPE: 0.200583\n[550]   train's rmse: 0.000409968   train's RMSPE: 0.159804 valid's rmse: 0.000526032   valid's RMSPE: 0.200314\n[600]   train's rmse: 0.000406169   train's RMSPE: 0.158324 valid's rmse: 0.000525791   valid's RMSPE: 0.200222\nEarly stopping, best iteration is:\n[577]   train's rmse: 0.000407878   train's RMSPE: 0.15899  valid's rmse: 0.000525707   valid's RMSPE: 0.200191\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000520336   train's RMSPE: 0.200131 valid's rmse: 0.000535971   valid's RMSPE: 0.215092\n[100]   train's rmse: 0.000486072   train's RMSPE: 0.186952 valid's rmse: 0.00050119    valid's RMSPE: 0.201134\n[150]   train's rmse: 0.000474641   train's RMSPE: 0.182556 valid's rmse: 0.00049606    valid's RMSPE: 0.199075\n[200]   train's rmse: 0.000464454   train's RMSPE: 0.178638 valid's rmse: 0.000492751   valid's RMSPE: 0.197747\n[250]   train's rmse: 0.000456125   train's RMSPE: 0.175434 valid's rmse: 0.000491353   valid's RMSPE: 0.197186\n[300]   train's rmse: 0.000448917   train's RMSPE: 0.172662 valid's rmse: 0.000489143   valid's RMSPE: 0.196299\n[350]   train's rmse: 0.000442296   train's RMSPE: 0.170115 valid's rmse: 0.000485563   valid's RMSPE: 0.194862\n[400]   train's rmse: 0.000436606   train's RMSPE: 0.167927 valid's rmse: 0.000484759   valid's RMSPE: 0.19454\n[450]   train's rmse: 0.000431388   train's RMSPE: 0.16592  valid's rmse: 0.000483853   valid's RMSPE: 0.194176\n[500]   train's rmse: 0.000426854   train's RMSPE: 0.164176 valid's rmse: 0.000483305   valid's RMSPE: 0.193956\n[550]   train's rmse: 0.00042213    train's RMSPE: 0.162359 valid's rmse: 0.000482412   valid's RMSPE: 0.193598\n[600]   train's rmse: 0.000417739   train's RMSPE: 0.16067  valid's rmse: 0.000483401   valid's RMSPE: 0.193995\nEarly stopping, best iteration is:\n[564]   train's rmse: 0.000421168   train's RMSPE: 0.161989 valid's rmse: 0.000481899   valid's RMSPE: 0.193392\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000521355   train's RMSPE: 0.202161 valid's rmse: 0.00051672    valid's RMSPE: 0.201021\n[100]   train's rmse: 0.000482038   train's RMSPE: 0.186915 valid's rmse: 0.000495474   valid's RMSPE: 0.192755\n[150]   train's rmse: 0.000470308   train's RMSPE: 0.182367 valid's rmse: 0.000493342   valid's RMSPE: 0.191926\n[200]   train's rmse: 0.000461697   train's RMSPE: 0.179028 valid's rmse: 0.000493651   valid's RMSPE: 0.192046\nEarly stopping, best iteration is:\n[184]   train's rmse: 0.00046442    train's RMSPE: 0.180084 valid's rmse: 0.000491873   valid's RMSPE: 0.191355\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00051638    train's RMSPE: 0.200637 valid's rmse: 0.000533314   valid's RMSPE: 0.205799\n[100]   train's rmse: 0.000480431   train's RMSPE: 0.186669 valid's rmse: 0.000509478   valid's RMSPE: 0.196601\n[150]   train's rmse: 0.000467963   train's RMSPE: 0.181825 valid's rmse: 0.000507839   valid's RMSPE: 0.195969\nEarly stopping, best iteration is:\n[148]   train's rmse: 0.000468317   train's RMSPE: 0.181962 valid's rmse: 0.000507081   valid's RMSPE: 0.195676\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000523437   train's RMSPE: 0.203791 valid's rmse: 0.000517142   valid's RMSPE: 0.197911\n[100]   train's rmse: 0.000487977   train's RMSPE: 0.189985 valid's rmse: 0.000487325   valid's RMSPE: 0.1865\n[150]   train's rmse: 0.000475391   train's RMSPE: 0.185085 valid's rmse: 0.000483722   valid's RMSPE: 0.185121\n[200]   train's rmse: 0.000466086   train's RMSPE: 0.181462 valid's rmse: 0.000482079   valid's RMSPE: 0.184492\n[250]   train's rmse: 0.000457584   train's RMSPE: 0.178152 valid's rmse: 0.000480619   valid's RMSPE: 0.183934\n[300]   train's rmse: 0.000450316   train's RMSPE: 0.175322 valid's rmse: 0.000480031   valid's RMSPE: 0.183709\nEarly stopping, best iteration is:\n[285]   train's rmse: 0.000452458   train's RMSPE: 0.176156 valid's rmse: 0.00047931    valid's RMSPE: 0.183433\nOur out of folds RMSPE is 0.193, compared to 0.16946425653881092, giving gain 0.023535743461189085\nOur cv fold scores are [0.2, 0.193, 0.191, 0.196, 0.183]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000476716   train's RMSPE: 0.240945 valid's rmse: 0.000489848   valid's RMSPE: 0.24539\n[100]   train's rmse: 0.000448124   train's RMSPE: 0.226494 valid's rmse: 0.000477045   valid's RMSPE: 0.238976\n[150]   train's rmse: 0.000432803   train's RMSPE: 0.21875  valid's rmse: 0.000472804   valid's RMSPE: 0.236851\n[200]   train's rmse: 0.00042161    train's RMSPE: 0.213093 valid's rmse: 0.000471003   valid's RMSPE: 0.235949\n[250]   train's rmse: 0.000412061   train's RMSPE: 0.208267 valid's rmse: 0.000468224   valid's RMSPE: 0.234557\n[300]   train's rmse: 0.000403522   train's RMSPE: 0.203951 valid's rmse: 0.000467577   valid's RMSPE: 0.234233\n[350]   train's rmse: 0.00039677    train's RMSPE: 0.200538 valid's rmse: 0.000466959   valid's RMSPE: 0.233923\n[400]   train's rmse: 0.000390883   train's RMSPE: 0.197563 valid's rmse: 0.000466683   valid's RMSPE: 0.233785\n[450]   train's rmse: 0.000385647   train's RMSPE: 0.194916 valid's rmse: 0.000464296   valid's RMSPE: 0.232589\n[500]   train's rmse: 0.000380804   train's RMSPE: 0.192469 valid's rmse: 0.000463508   valid's RMSPE: 0.232194\n[550]   train's rmse: 0.000376428   train's RMSPE: 0.190257 valid's rmse: 0.000462203   valid's RMSPE: 0.231541\nEarly stopping, best iteration is:\n[535]   train's rmse: 0.000377852   train's RMSPE: 0.190977 valid's rmse: 0.000461978   valid's RMSPE: 0.231428\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000472473   train's RMSPE: 0.239542 valid's rmse: 0.00050551    valid's RMSPE: 0.25001\n[100]   train's rmse: 0.000442399   train's RMSPE: 0.224294 valid's rmse: 0.000498573   valid's RMSPE: 0.24658\n[150]   train's rmse: 0.000426059   train's RMSPE: 0.21601  valid's rmse: 0.000496963   valid's RMSPE: 0.245783\n[200]   train's rmse: 0.000414683   train's RMSPE: 0.210243 valid's rmse: 0.000497637   valid's RMSPE: 0.246116\nEarly stopping, best iteration is:\n[180]   train's rmse: 0.000418357   train's RMSPE: 0.212105 valid's rmse: 0.000496646   valid's RMSPE: 0.245626\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00047743    train's RMSPE: 0.239616 valid's rmse: 0.000503229   valid's RMSPE: 0.25916\n[100]   train's rmse: 0.00044837    train's RMSPE: 0.225031 valid's rmse: 0.000490546   valid's RMSPE: 0.252628\n[150]   train's rmse: 0.000432772   train's RMSPE: 0.217202 valid's rmse: 0.000489657   valid's RMSPE: 0.25217\n[200]   train's rmse: 0.000422214   train's RMSPE: 0.211904 valid's rmse: 0.000488483   valid's RMSPE: 0.251566\nEarly stopping, best iteration is:\n[169]   train's rmse: 0.000428729   train's RMSPE: 0.215173 valid's rmse: 0.000487816   valid's RMSPE: 0.251222\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000480426   train's RMSPE: 0.243369 valid's rmse: 0.000459814   valid's RMSPE: 0.228212\n[100]   train's rmse: 0.000451539   train's RMSPE: 0.228736 valid's rmse: 0.000451499   valid's RMSPE: 0.224085\n[150]   train's rmse: 0.000436649   train's RMSPE: 0.221193 valid's rmse: 0.000449818   valid's RMSPE: 0.223251\nEarly stopping, best iteration is:\n[123]   train's rmse: 0.000443509   train's RMSPE: 0.224668 valid's rmse: 0.000449082   valid's RMSPE: 0.222886\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000477687   train's RMSPE: 0.23969  valid's rmse: 0.000532458   valid's RMSPE: 0.274452\n[100]   train's rmse: 0.000451544   train's RMSPE: 0.226572 valid's rmse: 0.000511332   valid's RMSPE: 0.263562\n[150]   train's rmse: 0.000438294   train's RMSPE: 0.219923 valid's rmse: 0.000515922   valid's RMSPE: 0.265929\nEarly stopping, best iteration is:\n[124]   train's rmse: 0.000445054   train's RMSPE: 0.223315 valid's rmse: 0.000508233   valid's RMSPE: 0.261965\nOur out of folds RMSPE is 0.243, compared to 0.21071689415292186, giving gain 0.032283105847078136\nOur cv fold scores are [0.231, 0.246, 0.251, 0.223, 0.262]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000440131   train's RMSPE: 0.232742 valid's rmse: 0.000474224   valid's RMSPE: 0.240135\n[100]   train's rmse: 0.000409977   train's RMSPE: 0.216797 valid's rmse: 0.000458973   valid's RMSPE: 0.232412\n[150]   train's rmse: 0.000396138   train's RMSPE: 0.209479 valid's rmse: 0.000454192   valid's RMSPE: 0.229992\n[200]   train's rmse: 0.000387063   train's RMSPE: 0.20468  valid's rmse: 0.000451409   valid's RMSPE: 0.228582\n[250]   train's rmse: 0.000379487   train's RMSPE: 0.200674 valid's rmse: 0.000449586   valid's RMSPE: 0.227659\n[300]   train's rmse: 0.000372728   train's RMSPE: 0.1971   valid's rmse: 0.000446829   valid's RMSPE: 0.226263\n[350]   train's rmse: 0.000367199   train's RMSPE: 0.194176 valid's rmse: 0.000445359   valid's RMSPE: 0.225519\n[400]   train's rmse: 0.000362131   train's RMSPE: 0.191496 valid's rmse: 0.000444039   valid's RMSPE: 0.224851\n[450]   train's rmse: 0.000357329   train's RMSPE: 0.188957 valid's rmse: 0.000442055   valid's RMSPE: 0.223846\n[500]   train's rmse: 0.000353518   train's RMSPE: 0.186941 valid's rmse: 0.000441399   valid's RMSPE: 0.223513\n[550]   train's rmse: 0.000349406   train's RMSPE: 0.184767 valid's rmse: 0.000440564   valid's RMSPE: 0.223091\n[600]   train's rmse: 0.000345404   train's RMSPE: 0.182651 valid's rmse: 0.00044061    valid's RMSPE: 0.223114\nEarly stopping, best iteration is:\n[557]   train's rmse: 0.000348964   train's RMSPE: 0.184533 valid's rmse: 0.000440233   valid's RMSPE: 0.222923\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000440085   train's RMSPE: 0.228433 valid's rmse: 0.000478733   valid's RMSPE: 0.261\n[100]   train's rmse: 0.00041191    train's RMSPE: 0.213808 valid's rmse: 0.000457349   valid's RMSPE: 0.249342\n[150]   train's rmse: 0.000399074   train's RMSPE: 0.207145 valid's rmse: 0.000452255   valid's RMSPE: 0.246565\n[200]   train's rmse: 0.000389438   train's RMSPE: 0.202144 valid's rmse: 0.000450564   valid's RMSPE: 0.245643\n[250]   train's rmse: 0.000381928   train's RMSPE: 0.198245 valid's rmse: 0.000449387   valid's RMSPE: 0.245002\nEarly stopping, best iteration is:\n[240]   train's rmse: 0.000383133   train's RMSPE: 0.198871 valid's rmse: 0.000448765   valid's RMSPE: 0.244662\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000451626   train's RMSPE: 0.235513 valid's rmse: 0.000430134   valid's RMSPE: 0.23051\n[100]   train's rmse: 0.000421608   train's RMSPE: 0.219859 valid's rmse: 0.00040436    valid's RMSPE: 0.216698\n[150]   train's rmse: 0.000408574   train's RMSPE: 0.213062 valid's rmse: 0.000400054   valid's RMSPE: 0.21439\n[200]   train's rmse: 0.000398639   train's RMSPE: 0.207881 valid's rmse: 0.000398257   valid's RMSPE: 0.213427\n[250]   train's rmse: 0.000390586   train's RMSPE: 0.203682 valid's rmse: 0.000397598   valid's RMSPE: 0.213074\nEarly stopping, best iteration is:\n[227]   train's rmse: 0.000394036   train's RMSPE: 0.205481 valid's rmse: 0.000396942   valid's RMSPE: 0.212723\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000438908   train's RMSPE: 0.230845 valid's rmse: 0.000481403   valid's RMSPE: 0.249422\n[100]   train's rmse: 0.000409979   train's RMSPE: 0.215629 valid's rmse: 0.000470739   valid's RMSPE: 0.243896\n[150]   train's rmse: 0.000397344   train's RMSPE: 0.208984 valid's rmse: 0.000467545   valid's RMSPE: 0.242241\n[200]   train's rmse: 0.000387965   train's RMSPE: 0.204051 valid's rmse: 0.000466083   valid's RMSPE: 0.241484\n[250]   train's rmse: 0.000379791   train's RMSPE: 0.199752 valid's rmse: 0.000464886   valid's RMSPE: 0.240864\nEarly stopping, best iteration is:\n[228]   train's rmse: 0.00038327    train's RMSPE: 0.201582 valid's rmse: 0.000464628   valid's RMSPE: 0.24073\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000448186   train's RMSPE: 0.23602  valid's rmse: 0.000434564   valid's RMSPE: 0.223985\n[100]   train's rmse: 0.000419599   train's RMSPE: 0.220966 valid's rmse: 0.000415263   valid's RMSPE: 0.214037\n[150]   train's rmse: 0.000405756   train's RMSPE: 0.213676 valid's rmse: 0.000409702   valid's RMSPE: 0.211171\n[200]   train's rmse: 0.000395761   train's RMSPE: 0.208412 valid's rmse: 0.00041017    valid's RMSPE: 0.211412\nEarly stopping, best iteration is:\n[162]   train's rmse: 0.000403185   train's RMSPE: 0.212322 valid's rmse: 0.000408971   valid's RMSPE: 0.210794\nOur out of folds RMSPE is 0.227, compared to 0.2142372903386656, giving gain 0.012762709661334415\nOur cv fold scores are [0.223, 0.245, 0.213, 0.241, 0.211]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000712395   train's RMSPE: 0.22981  valid's rmse: 0.000735326   valid's RMSPE: 0.235179\n[100]   train's rmse: 0.000679388   train's RMSPE: 0.219162 valid's rmse: 0.000706437   valid's RMSPE: 0.225939\n[150]   train's rmse: 0.000664594   train's RMSPE: 0.214389 valid's rmse: 0.000700107   valid's RMSPE: 0.223915\n[200]   train's rmse: 0.000653316   train's RMSPE: 0.210751 valid's rmse: 0.000697839   valid's RMSPE: 0.223189\n[250]   train's rmse: 0.000643487   train's RMSPE: 0.207581 valid's rmse: 0.000697106   valid's RMSPE: 0.222955\n[300]   train's rmse: 0.000633841   train's RMSPE: 0.204469 valid's rmse: 0.000693588   valid's RMSPE: 0.22183\n[350]   train's rmse: 0.000625418   train's RMSPE: 0.201752 valid's rmse: 0.000691788   valid's RMSPE: 0.221254\n[400]   train's rmse: 0.000617754   train's RMSPE: 0.199279 valid's rmse: 0.000691129   valid's RMSPE: 0.221043\n[450]   train's rmse: 0.000609212   train's RMSPE: 0.196524 valid's rmse: 0.000688109   valid's RMSPE: 0.220077\n[500]   train's rmse: 0.0006027 train's RMSPE: 0.194423 valid's rmse: 0.000687326   valid's RMSPE: 0.219827\n[550]   train's rmse: 0.000596618   train's RMSPE: 0.192461 valid's rmse: 0.000687566   valid's RMSPE: 0.219904\n[600]   train's rmse: 0.000590649   train's RMSPE: 0.190536 valid's rmse: 0.000687086   valid's RMSPE: 0.21975\nEarly stopping, best iteration is:\n[591]   train's rmse: 0.000591509   train's RMSPE: 0.190813 valid's rmse: 0.000686476   valid's RMSPE: 0.219555\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000709548   train's RMSPE: 0.2278   valid's rmse: 0.000749436   valid's RMSPE: 0.244283\n[100]   train's rmse: 0.000674406   train's RMSPE: 0.216518 valid's rmse: 0.000729646   valid's RMSPE: 0.237832\n[150]   train's rmse: 0.000660853   train's RMSPE: 0.212167 valid's rmse: 0.000726196   valid's RMSPE: 0.236708\n[200]   train's rmse: 0.000647928   train's RMSPE: 0.208018 valid's rmse: 0.000726356   valid's RMSPE: 0.23676\nEarly stopping, best iteration is:\n[164]   train's rmse: 0.000657033   train's RMSPE: 0.21094  valid's rmse: 0.000724836   valid's RMSPE: 0.236265\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000717705   train's RMSPE: 0.230558 valid's rmse: 0.000725756   valid's RMSPE: 0.236011\n[100]   train's rmse: 0.000681213   train's RMSPE: 0.218835 valid's rmse: 0.000700727   valid's RMSPE: 0.227872\n[150]   train's rmse: 0.000665687   train's RMSPE: 0.213847 valid's rmse: 0.000698775   valid's RMSPE: 0.227237\n[200]   train's rmse: 0.000653588   train's RMSPE: 0.209961 valid's rmse: 0.000695587   valid's RMSPE: 0.226201\n[250]   train's rmse: 0.000643308   train's RMSPE: 0.206659 valid's rmse: 0.000694996   valid's RMSPE: 0.226008\nEarly stopping, best iteration is:\n[228]   train's rmse: 0.000647875   train's RMSPE: 0.208126 valid's rmse: 0.000694142   valid's RMSPE: 0.225731\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000714872   train's RMSPE: 0.230709 valid's rmse: 0.000727805   valid's RMSPE: 0.232361\n[100]   train's rmse: 0.000680467   train's RMSPE: 0.219605 valid's rmse: 0.000710144   valid's RMSPE: 0.226722\n[150]   train's rmse: 0.000665586   train's RMSPE: 0.214803 valid's rmse: 0.000708692   valid's RMSPE: 0.226259\n[200]   train's rmse: 0.000653292   train's RMSPE: 0.210835 valid's rmse: 0.000707713   valid's RMSPE: 0.225946\n[250]   train's rmse: 0.000641881   train's RMSPE: 0.207153 valid's rmse: 0.00070613    valid's RMSPE: 0.225441\n[300]   train's rmse: 0.000632358   train's RMSPE: 0.204079 valid's rmse: 0.000705814   valid's RMSPE: 0.22534\nEarly stopping, best iteration is:\n[297]   train's rmse: 0.000632894   train's RMSPE: 0.204252 valid's rmse: 0.000705039   valid's RMSPE: 0.225093\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00071502    train's RMSPE: 0.230647 valid's rmse: 0.000716721   valid's RMSPE: 0.229264\n[100]   train's rmse: 0.000680058   train's RMSPE: 0.219369 valid's rmse: 0.000705658   valid's RMSPE: 0.225725\n[150]   train's rmse: 0.000664748   train's RMSPE: 0.214431 valid's rmse: 0.000704343   valid's RMSPE: 0.225305\nEarly stopping, best iteration is:\n[140]   train's rmse: 0.000668179   train's RMSPE: 0.215538 valid's rmse: 0.000703558   valid's RMSPE: 0.225053\nOur out of folds RMSPE is 0.226, compared to 0.1966253016482257, giving gain 0.02937469835177431\nOur cv fold scores are [0.22, 0.236, 0.226, 0.225, 0.225]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000964701   train's RMSPE: 0.301217 valid's rmse: 0.000994454   valid's RMSPE: 0.312071\n[100]   train's rmse: 0.00091996    train's RMSPE: 0.287247 valid's rmse: 0.000979224   valid's RMSPE: 0.307292\n[150]   train's rmse: 0.000894427   train's RMSPE: 0.279275 valid's rmse: 0.000975147   valid's RMSPE: 0.306012\n[200]   train's rmse: 0.000873807   train's RMSPE: 0.272836 valid's rmse: 0.000972872   valid's RMSPE: 0.305299\n[250]   train's rmse: 0.000856355   train's RMSPE: 0.267387 valid's rmse: 0.00097159    valid's RMSPE: 0.304896\n[300]   train's rmse: 0.000840137   train's RMSPE: 0.262323 valid's rmse: 0.000968595   valid's RMSPE: 0.303956\n[350]   train's rmse: 0.000826789   train's RMSPE: 0.258156 valid's rmse: 0.000968221   valid's RMSPE: 0.303839\nEarly stopping, best iteration is:\n[344]   train's rmse: 0.000828218   train's RMSPE: 0.258602 valid's rmse: 0.000966917   valid's RMSPE: 0.30343\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000951501   train's RMSPE: 0.298494 valid's rmse: 0.00103469    valid's RMSPE: 0.31857\n[100]   train's rmse: 0.000909125   train's RMSPE: 0.285201 valid's rmse: 0.00102522    valid's RMSPE: 0.315655\n[150]   train's rmse: 0.000882433   train's RMSPE: 0.276827 valid's rmse: 0.00102132    valid's RMSPE: 0.314455\n[200]   train's rmse: 0.000861598   train's RMSPE: 0.270291 valid's rmse: 0.00101556    valid's RMSPE: 0.31268\n[250]   train's rmse: 0.000844232   train's RMSPE: 0.264843 valid's rmse: 0.00101101    valid's RMSPE: 0.31128\n[300]   train's rmse: 0.000828937   train's RMSPE: 0.260045 valid's rmse: 0.00100942    valid's RMSPE: 0.310792\nEarly stopping, best iteration is:\n[287]   train's rmse: 0.000832551   train's RMSPE: 0.261179 valid's rmse: 0.00100772    valid's RMSPE: 0.310268\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000966182   train's RMSPE: 0.299767 valid's rmse: 0.000988458   valid's RMSPE: 0.317856\n[100]   train's rmse: 0.00092251    train's RMSPE: 0.286217 valid's rmse: 0.00097041    valid's RMSPE: 0.312053\nEarly stopping, best iteration is:\n[82]    train's rmse: 0.000933965   train's RMSPE: 0.289771 valid's rmse: 0.000967095   valid's RMSPE: 0.310986\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000968632   train's RMSPE: 0.303557 valid's rmse: 0.000964182   valid's RMSPE: 0.298122\n[100]   train's rmse: 0.000925969   train's RMSPE: 0.290187 valid's rmse: 0.000958094   valid's RMSPE: 0.296239\n[150]   train's rmse: 0.000898408   train's RMSPE: 0.28155  valid's rmse: 0.000957749   valid's RMSPE: 0.296132\n[200]   train's rmse: 0.000878659   train's RMSPE: 0.275361 valid's rmse: 0.000958066   valid's RMSPE: 0.296231\nEarly stopping, best iteration is:\n[160]   train's rmse: 0.000894148   train's RMSPE: 0.280215 valid's rmse: 0.000955551   valid's RMSPE: 0.295453\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000965863   train's RMSPE: 0.302472 valid's rmse: 0.000988226   valid's RMSPE: 0.306457\n[100]   train's rmse: 0.000921834   train's RMSPE: 0.288684 valid's rmse: 0.000971172   valid's RMSPE: 0.301168\n[150]   train's rmse: 0.000893613   train's RMSPE: 0.279846 valid's rmse: 0.000968803   valid's RMSPE: 0.300434\n[200]   train's rmse: 0.000872609   train's RMSPE: 0.273268 valid's rmse: 0.000967977   valid's RMSPE: 0.300178\n[250]   train's rmse: 0.000854649   train's RMSPE: 0.267644 valid's rmse: 0.000966159   valid's RMSPE: 0.299614\n[300]   train's rmse: 0.000838888   train's RMSPE: 0.262708 valid's rmse: 0.000965478   valid's RMSPE: 0.299403\n[350]   train's rmse: 0.000825379   train's RMSPE: 0.258478 valid's rmse: 0.000967105   valid's RMSPE: 0.299907\nEarly stopping, best iteration is:\n[314]   train's rmse: 0.000835205   train's RMSPE: 0.261555 valid's rmse: 0.00096449    valid's RMSPE: 0.299096\nOur out of folds RMSPE is 0.304, compared to 0.283514033038324, giving gain 0.020485966961675983\nOur cv fold scores are [0.303, 0.31, 0.311, 0.295, 0.299]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000588827   train's RMSPE: 0.25951  valid's rmse: 0.000619821   valid's RMSPE: 0.275645\n[100]   train's rmse: 0.000554423   train's RMSPE: 0.244348 valid's rmse: 0.000598485   valid's RMSPE: 0.266157\n[150]   train's rmse: 0.000534863   train's RMSPE: 0.235727 valid's rmse: 0.000598055   valid's RMSPE: 0.265966\nEarly stopping, best iteration is:\n[115]   train's rmse: 0.000547916   train's RMSPE: 0.24148  valid's rmse: 0.000595775   valid's RMSPE: 0.264952\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000590436   train's RMSPE: 0.259291 valid's rmse: 0.000610662   valid's RMSPE: 0.275345\n[100]   train's rmse: 0.000555297   train's RMSPE: 0.24386  valid's rmse: 0.000589978   valid's RMSPE: 0.266018\n[150]   train's rmse: 0.00053713    train's RMSPE: 0.235882 valid's rmse: 0.000586955   valid's RMSPE: 0.264655\n[200]   train's rmse: 0.000523068   train's RMSPE: 0.229706 valid's rmse: 0.000587153   valid's RMSPE: 0.264745\nEarly stopping, best iteration is:\n[169]   train's rmse: 0.000531264   train's RMSPE: 0.233306 valid's rmse: 0.000584984   valid's RMSPE: 0.263767\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000590851   train's RMSPE: 0.26041  valid's rmse: 0.000605041   valid's RMSPE: 0.269042\n[100]   train's rmse: 0.000558045   train's RMSPE: 0.245951 valid's rmse: 0.000588474   valid's RMSPE: 0.261675\nEarly stopping, best iteration is:\n[76]    train's rmse: 0.000568652   train's RMSPE: 0.250626 valid's rmse: 0.000586894   valid's RMSPE: 0.260972\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000593166   train's RMSPE: 0.262589 valid's rmse: 0.0006077 valid's RMSPE: 0.265463\n[100]   train's rmse: 0.000557276   train's RMSPE: 0.246701 valid's rmse: 0.000601953   valid's RMSPE: 0.262952\n[150]   train's rmse: 0.000538577   train's RMSPE: 0.238423 valid's rmse: 0.000599199   valid's RMSPE: 0.261749\n[200]   train's rmse: 0.00052404    train's RMSPE: 0.231988 valid's rmse: 0.000595127   valid's RMSPE: 0.259971\n[250]   train's rmse: 0.000512541   train's RMSPE: 0.226897 valid's rmse: 0.000597854   valid's RMSPE: 0.261162\nEarly stopping, best iteration is:\n[206]   train's rmse: 0.000522451   train's RMSPE: 0.231285 valid's rmse: 0.00059485    valid's RMSPE: 0.25985\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000593502   train's RMSPE: 0.263696 valid's rmse: 0.000604598   valid's RMSPE: 0.260113\n[100]   train's rmse: 0.000560618   train's RMSPE: 0.249086 valid's rmse: 0.000583898   valid's RMSPE: 0.251207\n[150]   train's rmse: 0.000543579   train's RMSPE: 0.241515 valid's rmse: 0.0005797 valid's RMSPE: 0.249401\n[200]   train's rmse: 0.000529069   train's RMSPE: 0.235069 valid's rmse: 0.000576824   valid's RMSPE: 0.248164\n[250]   train's rmse: 0.000517388   train's RMSPE: 0.229878 valid's rmse: 0.00057339    valid's RMSPE: 0.246687\n[300]   train's rmse: 0.000507916   train's RMSPE: 0.22567  valid's rmse: 0.000573645   valid's RMSPE: 0.246796\n[350]   train's rmse: 0.00049916    train's RMSPE: 0.22178  valid's rmse: 0.000571809   valid's RMSPE: 0.246006\n[400]   train's rmse: 0.000490789   train's RMSPE: 0.21806  valid's rmse: 0.0005737 valid's RMSPE: 0.24682\nEarly stopping, best iteration is:\n[354]   train's rmse: 0.000498504   train's RMSPE: 0.221489 valid's rmse: 0.000571522   valid's RMSPE: 0.245883\nOur out of folds RMSPE is 0.259, compared to 0.24449780064112345, giving gain 0.01450219935887656\nOur cv fold scores are [0.265, 0.264, 0.261, 0.26, 0.246]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000930657   train's RMSPE: 0.266921 valid's rmse: 0.000966669   valid's RMSPE: 0.267247\n[100]   train's rmse: 0.000888957   train's RMSPE: 0.254961 valid's rmse: 0.000949897   valid's RMSPE: 0.26261\n[150]   train's rmse: 0.000867355   train's RMSPE: 0.248766 valid's rmse: 0.000944181   valid's RMSPE: 0.26103\n[200]   train's rmse: 0.000848453   train's RMSPE: 0.243344 valid's rmse: 0.000944353   valid's RMSPE: 0.261078\nEarly stopping, best iteration is:\n[163]   train's rmse: 0.000862692   train's RMSPE: 0.247428 valid's rmse: 0.000943323   valid's RMSPE: 0.260793\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000928833   train's RMSPE: 0.262419 valid's rmse: 0.000978251   valid's RMSPE: 0.287191\n[100]   train's rmse: 0.000885827   train's RMSPE: 0.250269 valid's rmse: 0.000962207   valid's RMSPE: 0.282481\n[150]   train's rmse: 0.000863576   train's RMSPE: 0.243982 valid's rmse: 0.000958458   valid's RMSPE: 0.28138\n[200]   train's rmse: 0.000846276   train's RMSPE: 0.239095 valid's rmse: 0.000954824   valid's RMSPE: 0.280314\n[250]   train's rmse: 0.000830713   train's RMSPE: 0.234698 valid's rmse: 0.00095194    valid's RMSPE: 0.279467\nEarly stopping, best iteration is:\n[243]   train's rmse: 0.0008327 train's RMSPE: 0.235259 valid's rmse: 0.000951439   valid's RMSPE: 0.27932\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000931639   train's RMSPE: 0.266363 valid's rmse: 0.000967899   valid's RMSPE: 0.271178\n[100]   train's rmse: 0.000889222   train's RMSPE: 0.254236 valid's rmse: 0.000953028   valid's RMSPE: 0.267011\n[150]   train's rmse: 0.000867002   train's RMSPE: 0.247883 valid's rmse: 0.000950891   valid's RMSPE: 0.266413\nEarly stopping, best iteration is:\n[125]   train's rmse: 0.000877243   train's RMSPE: 0.250811 valid's rmse: 0.000948453   valid's RMSPE: 0.26573\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000936534   train's RMSPE: 0.26789  valid's rmse: 0.000948565   valid's RMSPE: 0.265233\n[100]   train's rmse: 0.000894348   train's RMSPE: 0.255823 valid's rmse: 0.000938935   valid's RMSPE: 0.26254\n[150]   train's rmse: 0.000872785   train's RMSPE: 0.249655 valid's rmse: 0.000937338   valid's RMSPE: 0.262094\n[200]   train's rmse: 0.000853897   train's RMSPE: 0.244252 valid's rmse: 0.000930101   valid's RMSPE: 0.26007\nEarly stopping, best iteration is:\n[188]   train's rmse: 0.000857532   train's RMSPE: 0.245292 valid's rmse: 0.000930081   valid's RMSPE: 0.260065\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000939579   train's RMSPE: 0.265462 valid's rmse: 0.000940261   valid's RMSPE: 0.276013\n[100]   train's rmse: 0.000901656   train's RMSPE: 0.254747 valid's rmse: 0.000909632   valid's RMSPE: 0.267022\n[150]   train's rmse: 0.000881668   train's RMSPE: 0.2491   valid's rmse: 0.000906189   valid's RMSPE: 0.266011\n[200]   train's rmse: 0.000863597   train's RMSPE: 0.243994 valid's rmse: 0.000897487   valid's RMSPE: 0.263457\n[250]   train's rmse: 0.000848374   train's RMSPE: 0.239693 valid's rmse: 0.000893715   valid's RMSPE: 0.262349\n[300]   train's rmse: 0.000835552   train's RMSPE: 0.236071 valid's rmse: 0.000890168   valid's RMSPE: 0.261308\n[350]   train's rmse: 0.000823274   train's RMSPE: 0.232602 valid's rmse: 0.000889818   valid's RMSPE: 0.261206\n[400]   train's rmse: 0.000812412   train's RMSPE: 0.229533 valid's rmse: 0.000889914   valid's RMSPE: 0.261234\nEarly stopping, best iteration is:\n[359]   train's rmse: 0.000821039   train's RMSPE: 0.23197  valid's rmse: 0.000888069   valid's RMSPE: 0.260692\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.265, compared to 0.23262856524594397, giving gain 0.032371434754056044\nOur cv fold scores are [0.261, 0.279, 0.266, 0.26, 0.261]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000372408   train's RMSPE: 0.238591 valid's rmse: 0.000419037   valid's RMSPE: 0.268817\n[100]   train's rmse: 0.000354431   train's RMSPE: 0.227074 valid's rmse: 0.000402946   valid's RMSPE: 0.258495\n[150]   train's rmse: 0.000347043   train's RMSPE: 0.222341 valid's rmse: 0.000399094   valid's RMSPE: 0.256024\n[200]   train's rmse: 0.000340927   train's RMSPE: 0.218422 valid's rmse: 0.000396471   valid's RMSPE: 0.254341\n[250]   train's rmse: 0.000335971   train's RMSPE: 0.215247 valid's rmse: 0.000394518   valid's RMSPE: 0.253088\n[300]   train's rmse: 0.000331465   train's RMSPE: 0.21236  valid's rmse: 0.00039235    valid's RMSPE: 0.251697\n[350]   train's rmse: 0.000327886   train's RMSPE: 0.210067 valid's rmse: 0.000390887   valid's RMSPE: 0.250759\n[400]   train's rmse: 0.000323925   train's RMSPE: 0.207529 valid's rmse: 0.000389455   valid's RMSPE: 0.24984\n[450]   train's rmse: 0.000320218   train's RMSPE: 0.205154 valid's rmse: 0.000388436   valid's RMSPE: 0.249186\n[500]   train's rmse: 0.000317056   train's RMSPE: 0.203129 valid's rmse: 0.000387889   valid's RMSPE: 0.248835\n[550]   train's rmse: 0.000314214   train's RMSPE: 0.201308 valid's rmse: 0.000387163   valid's RMSPE: 0.24837\n[600]   train's rmse: 0.000311268   train's RMSPE: 0.19942  valid's rmse: 0.000385804   valid's RMSPE: 0.247498\n[650]   train's rmse: 0.000308721   train's RMSPE: 0.197788 valid's rmse: 0.000385289   valid's RMSPE: 0.247168\n[700]   train's rmse: 0.000305828   train's RMSPE: 0.195935 valid's rmse: 0.00038494    valid's RMSPE: 0.246944\n[750]   train's rmse: 0.000303355   train's RMSPE: 0.194351 valid's rmse: 0.000384664   valid's RMSPE: 0.246767\nEarly stopping, best iteration is:\n[722]   train's rmse: 0.000304617   train's RMSPE: 0.195159 valid's rmse: 0.000384491   valid's RMSPE: 0.246655\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000374896   train's RMSPE: 0.240309 valid's rmse: 0.000403127   valid's RMSPE: 0.258079\n[100]   train's rmse: 0.000356202   train's RMSPE: 0.228326 valid's rmse: 0.000389594   valid's RMSPE: 0.249415\n[150]   train's rmse: 0.000347999   train's RMSPE: 0.223068 valid's rmse: 0.000385396   valid's RMSPE: 0.246728\n[200]   train's rmse: 0.000341418   train's RMSPE: 0.218849 valid's rmse: 0.000382114   valid's RMSPE: 0.244627\n[250]   train's rmse: 0.000336316   train's RMSPE: 0.215579 valid's rmse: 0.000380479   valid's RMSPE: 0.24358\n[300]   train's rmse: 0.000331477   train's RMSPE: 0.212477 valid's rmse: 0.000379227   valid's RMSPE: 0.242778\n[350]   train's rmse: 0.000327227   train's RMSPE: 0.209753 valid's rmse: 0.000378156   valid's RMSPE: 0.242093\n[400]   train's rmse: 0.000323643   train's RMSPE: 0.207456 valid's rmse: 0.000377038   valid's RMSPE: 0.241377\n[450]   train's rmse: 0.000320442   train's RMSPE: 0.205404 valid's rmse: 0.000376976   valid's RMSPE: 0.241337\n[500]   train's rmse: 0.000317603   train's RMSPE: 0.203584 valid's rmse: 0.000376476   valid's RMSPE: 0.241017\n[550]   train's rmse: 0.000314633   train's RMSPE: 0.20168  valid's rmse: 0.000375884   valid's RMSPE: 0.240638\nEarly stopping, best iteration is:\n[541]   train's rmse: 0.000315087   train's RMSPE: 0.201971 valid's rmse: 0.000375791   valid's RMSPE: 0.240578\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000380779   train's RMSPE: 0.24353  valid's rmse: 0.00037262    valid's RMSPE: 0.240692\n[100]   train's rmse: 0.000362122   train's RMSPE: 0.231598 valid's rmse: 0.000361063   valid's RMSPE: 0.233227\n[150]   train's rmse: 0.000354808   train's RMSPE: 0.22692  valid's rmse: 0.000358387   valid's RMSPE: 0.231498\n[200]   train's rmse: 0.000349344   train's RMSPE: 0.223425 valid's rmse: 0.000357334   valid's RMSPE: 0.230818\n[250]   train's rmse: 0.000343091   train's RMSPE: 0.219426 valid's rmse: 0.000354386   valid's RMSPE: 0.228914\n[300]   train's rmse: 0.000338293   train's RMSPE: 0.216358 valid's rmse: 0.000353533   valid's RMSPE: 0.228363\n[350]   train's rmse: 0.000334335   train's RMSPE: 0.213826 valid's rmse: 0.000352119   valid's RMSPE: 0.22745\n[400]   train's rmse: 0.000330296   train's RMSPE: 0.211243 valid's rmse: 0.000352119   valid's RMSPE: 0.22745\n[450]   train's rmse: 0.000326637   train's RMSPE: 0.208903 valid's rmse: 0.000351718   valid's RMSPE: 0.227191\nEarly stopping, best iteration is:\n[428]   train's rmse: 0.000328326   train's RMSPE: 0.209983 valid's rmse: 0.000351638   valid's RMSPE: 0.227139\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000386185   train's RMSPE: 0.248015 valid's rmse: 0.00035839    valid's RMSPE: 0.227683\n[100]   train's rmse: 0.000367017   train's RMSPE: 0.235705 valid's rmse: 0.000346953   valid's RMSPE: 0.220417\n[150]   train's rmse: 0.000359586   train's RMSPE: 0.230933 valid's rmse: 0.000346371   valid's RMSPE: 0.220048\n[200]   train's rmse: 0.000353622   train's RMSPE: 0.227103 valid's rmse: 0.000345637   valid's RMSPE: 0.219581\n[250]   train's rmse: 0.00034847    train's RMSPE: 0.223794 valid's rmse: 0.000345537   valid's RMSPE: 0.219517\nEarly stopping, best iteration is:\n[228]   train's rmse: 0.000350555   train's RMSPE: 0.225133 valid's rmse: 0.000345089   valid's RMSPE: 0.219233\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00038105    train's RMSPE: 0.244157 valid's rmse: 0.000377149   valid's RMSPE: 0.241831\n[100]   train's rmse: 0.000363108   train's RMSPE: 0.23266  valid's rmse: 0.00036647    valid's RMSPE: 0.234983\n[150]   train's rmse: 0.000354585   train's RMSPE: 0.227199 valid's rmse: 0.000362696   valid's RMSPE: 0.232563\n[200]   train's rmse: 0.000348785   train's RMSPE: 0.223483 valid's rmse: 0.0003623 valid's RMSPE: 0.23231\n[250]   train's rmse: 0.000343742   train's RMSPE: 0.220252 valid's rmse: 0.00036111    valid's RMSPE: 0.231547\n[300]   train's rmse: 0.00033953    train's RMSPE: 0.217553 valid's rmse: 0.000360479   valid's RMSPE: 0.231142\n[350]   train's rmse: 0.000335194   train's RMSPE: 0.214774 valid's rmse: 0.000360726   valid's RMSPE: 0.2313\nEarly stopping, best iteration is:\n[302]   train's rmse: 0.000339287   train's RMSPE: 0.217397 valid's rmse: 0.000360236   valid's RMSPE: 0.230986\nOur out of folds RMSPE is 0.233, compared to 0.1891958234747661, giving gain 0.04380417652523391\nOur cv fold scores are [0.247, 0.241, 0.227, 0.219, 0.231]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000645755   train's RMSPE: 0.242209 valid's rmse: 0.00065261    valid's RMSPE: 0.250796\n[100]   train's rmse: 0.000608497   train's RMSPE: 0.228234 valid's rmse: 0.000628907   valid's RMSPE: 0.241687\n[150]   train's rmse: 0.000591864   train's RMSPE: 0.221995 valid's rmse: 0.000622411   valid's RMSPE: 0.23919\n[200]   train's rmse: 0.000578248   train's RMSPE: 0.216888 valid's rmse: 0.000618606   valid's RMSPE: 0.237728\n[250]   train's rmse: 0.000567018   train's RMSPE: 0.212676 valid's rmse: 0.000616927   valid's RMSPE: 0.237083\n[300]   train's rmse: 0.000558904   train's RMSPE: 0.209633 valid's rmse: 0.000617544   valid's RMSPE: 0.23732\nEarly stopping, best iteration is:\n[276]   train's rmse: 0.0005624 train's RMSPE: 0.210944 valid's rmse: 0.00061633    valid's RMSPE: 0.236854\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000633331   train's RMSPE: 0.237505 valid's rmse: 0.000718038   valid's RMSPE: 0.276134\n[100]   train's rmse: 0.000597305   train's RMSPE: 0.223995 valid's rmse: 0.000681815   valid's RMSPE: 0.262204\n[150]   train's rmse: 0.000581477   train's RMSPE: 0.218059 valid's rmse: 0.000677228   valid's RMSPE: 0.26044\n[200]   train's rmse: 0.000569638   train's RMSPE: 0.21362  valid's rmse: 0.000673823   valid's RMSPE: 0.25913\n[250]   train's rmse: 0.000559143   train's RMSPE: 0.209684 valid's rmse: 0.000669266   valid's RMSPE: 0.257378\n[300]   train's rmse: 0.000549509   train's RMSPE: 0.206071 valid's rmse: 0.000668243   valid's RMSPE: 0.256985\n[350]   train's rmse: 0.000541409   train's RMSPE: 0.203033 valid's rmse: 0.000668205   valid's RMSPE: 0.25697\n[400]   train's rmse: 0.000533405   train's RMSPE: 0.200032 valid's rmse: 0.000666126   valid's RMSPE: 0.25617\nEarly stopping, best iteration is:\n[395]   train's rmse: 0.000534066   train's RMSPE: 0.200279 valid's rmse: 0.000665595   valid's RMSPE: 0.255966\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000641801   train's RMSPE: 0.241363 valid's rmse: 0.000619974   valid's RMSPE: 0.235836\n[100]   train's rmse: 0.000607091   train's RMSPE: 0.228309 valid's rmse: 0.000606186   valid's RMSPE: 0.230591\n[150]   train's rmse: 0.00059135    train's RMSPE: 0.22239  valid's rmse: 0.000605376   valid's RMSPE: 0.230283\nEarly stopping, best iteration is:\n[120]   train's rmse: 0.000600299   train's RMSPE: 0.225755 valid's rmse: 0.00060408    valid's RMSPE: 0.22979\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00063781    train's RMSPE: 0.242013 valid's rmse: 0.000645532   valid's RMSPE: 0.236752\n[100]   train's rmse: 0.000599782   train's RMSPE: 0.227584 valid's rmse: 0.000629068   valid's RMSPE: 0.230714\n[150]   train's rmse: 0.000584285   train's RMSPE: 0.221703 valid's rmse: 0.000623699   valid's RMSPE: 0.228745\n[200]   train's rmse: 0.000573169   train's RMSPE: 0.217485 valid's rmse: 0.000621597   valid's RMSPE: 0.227973\n[250]   train's rmse: 0.00056404    train's RMSPE: 0.214021 valid's rmse: 0.000620947   valid's RMSPE: 0.227735\n[300]   train's rmse: 0.00055548    train's RMSPE: 0.210773 valid's rmse: 0.000620034   valid's RMSPE: 0.2274\n[350]   train's rmse: 0.000546966   train's RMSPE: 0.207543 valid's rmse: 0.000618955   valid's RMSPE: 0.227004\n[400]   train's rmse: 0.000540498   train's RMSPE: 0.205089 valid's rmse: 0.0006189 valid's RMSPE: 0.226984\nEarly stopping, best iteration is:\n[354]   train's rmse: 0.000546437   train's RMSPE: 0.207342 valid's rmse: 0.00061859    valid's RMSPE: 0.226871\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000639017   train's RMSPE: 0.242234 valid's rmse: 0.000665049   valid's RMSPE: 0.244927\n[100]   train's rmse: 0.000603196   train's RMSPE: 0.228656 valid's rmse: 0.000650337   valid's RMSPE: 0.239508\n[150]   train's rmse: 0.0005881 train's RMSPE: 0.222933 valid's rmse: 0.000648167   valid's RMSPE: 0.238709\n[200]   train's rmse: 0.000576715   train's RMSPE: 0.218617 valid's rmse: 0.000647098   valid's RMSPE: 0.238315\n[250]   train's rmse: 0.000565971   train's RMSPE: 0.214544 valid's rmse: 0.000644731   valid's RMSPE: 0.237444\n[300]   train's rmse: 0.000557449   train's RMSPE: 0.211314 valid's rmse: 0.000645945   valid's RMSPE: 0.237891\nEarly stopping, best iteration is:\n[250]   train's rmse: 0.000565971   train's RMSPE: 0.214544 valid's rmse: 0.000644731   valid's RMSPE: 0.237444\nOur out of folds RMSPE is 0.238, compared to 0.210502884168752, giving gain 0.027497115831247976\nOur cv fold scores are [0.237, 0.256, 0.23, 0.227, 0.237]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000475499   train's RMSPE: 0.222177 valid's rmse: 0.000501513   valid's RMSPE: 0.229924\n[100]   train's rmse: 0.000451002   train's RMSPE: 0.21073  valid's rmse: 0.00048327    valid's RMSPE: 0.22156\n[150]   train's rmse: 0.00044037    train's RMSPE: 0.205762 valid's rmse: 0.000479763   valid's RMSPE: 0.219952\n[200]   train's rmse: 0.000432065   train's RMSPE: 0.201882 valid's rmse: 0.000475635   valid's RMSPE: 0.21806\n[250]   train's rmse: 0.000424424   train's RMSPE: 0.198312 valid's rmse: 0.000474535   valid's RMSPE: 0.217555\n[300]   train's rmse: 0.000417968   train's RMSPE: 0.195295 valid's rmse: 0.000473103   valid's RMSPE: 0.216899\n[350]   train's rmse: 0.000413  train's RMSPE: 0.192974 valid's rmse: 0.000471231   valid's RMSPE: 0.21604\n[400]   train's rmse: 0.000407639   train's RMSPE: 0.190469 valid's rmse: 0.000470086   valid's RMSPE: 0.215516\n[450]   train's rmse: 0.00040316    train's RMSPE: 0.188376 valid's rmse: 0.000469052   valid's RMSPE: 0.215042\n[500]   train's rmse: 0.000398583   train's RMSPE: 0.186238 valid's rmse: 0.000469878   valid's RMSPE: 0.21542\nEarly stopping, best iteration is:\n[480]   train's rmse: 0.000400182   train's RMSPE: 0.186985 valid's rmse: 0.000468622   valid's RMSPE: 0.214844\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000474172   train's RMSPE: 0.219795 valid's rmse: 0.000507889   valid's RMSPE: 0.240389\n[100]   train's rmse: 0.000449064   train's RMSPE: 0.208156 valid's rmse: 0.000490142   valid's RMSPE: 0.231989\n[150]   train's rmse: 0.000439146   train's RMSPE: 0.203559 valid's rmse: 0.000486344   valid's RMSPE: 0.230191\n[200]   train's rmse: 0.00043174    train's RMSPE: 0.200126 valid's rmse: 0.000486169   valid's RMSPE: 0.230109\n[250]   train's rmse: 0.000424922   train's RMSPE: 0.196965 valid's rmse: 0.000483863   valid's RMSPE: 0.229017\n[300]   train's rmse: 0.000418862   train's RMSPE: 0.194157 valid's rmse: 0.000483086   valid's RMSPE: 0.228649\n[350]   train's rmse: 0.000413369   train's RMSPE: 0.19161  valid's rmse: 0.000481812   valid's RMSPE: 0.228046\nEarly stopping, best iteration is:\n[345]   train's rmse: 0.000413719   train's RMSPE: 0.191772 valid's rmse: 0.000481538   valid's RMSPE: 0.227917\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00047938    train's RMSPE: 0.222543 valid's rmse: 0.000476849   valid's RMSPE: 0.224388\n[100]   train's rmse: 0.000452882   train's RMSPE: 0.210242 valid's rmse: 0.000461836   valid's RMSPE: 0.217324\n[150]   train's rmse: 0.000442147   train's RMSPE: 0.205258 valid's rmse: 0.000459855   valid's RMSPE: 0.216391\n[200]   train's rmse: 0.000433321   train's RMSPE: 0.201161 valid's rmse: 0.000459516   valid's RMSPE: 0.216232\n[250]   train's rmse: 0.00042606    train's RMSPE: 0.19779  valid's rmse: 0.000459866   valid's RMSPE: 0.216397\nEarly stopping, best iteration is:\n[215]   train's rmse: 0.000430995   train's RMSPE: 0.200081 valid's rmse: 0.000458792   valid's RMSPE: 0.215892\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000483613   train's RMSPE: 0.22563  valid's rmse: 0.000470558   valid's RMSPE: 0.217064\n[100]   train's rmse: 0.000456027   train's RMSPE: 0.21276  valid's rmse: 0.000456814   valid's RMSPE: 0.210724\n[150]   train's rmse: 0.000444718   train's RMSPE: 0.207484 valid's rmse: 0.000455643   valid's RMSPE: 0.210184\n[200]   train's rmse: 0.000436111   train's RMSPE: 0.203469 valid's rmse: 0.000454987   valid's RMSPE: 0.209882\nEarly stopping, best iteration is:\n[174]   train's rmse: 0.000440069   train's RMSPE: 0.205315 valid's rmse: 0.000454293   valid's RMSPE: 0.209561\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000480531   train's RMSPE: 0.223902 valid's rmse: 0.000492141   valid's RMSPE: 0.22822\n[100]   train's rmse: 0.000455391   train's RMSPE: 0.212188 valid's rmse: 0.000471626   valid's RMSPE: 0.218706\n[150]   train's rmse: 0.000443968   train's RMSPE: 0.206866 valid's rmse: 0.000467748   valid's RMSPE: 0.216908\n[200]   train's rmse: 0.000435913   train's RMSPE: 0.203113 valid's rmse: 0.0004665 valid's RMSPE: 0.216329\n[250]   train's rmse: 0.000428089   train's RMSPE: 0.199467 valid's rmse: 0.000465846   valid's RMSPE: 0.216026\n[300]   train's rmse: 0.000421871   train's RMSPE: 0.19657  valid's rmse: 0.000464787   valid's RMSPE: 0.215535\n[350]   train's rmse: 0.000415913   train's RMSPE: 0.193794 valid's rmse: 0.000466711   valid's RMSPE: 0.216427\nEarly stopping, best iteration is:\n[312]   train's rmse: 0.00042025    train's RMSPE: 0.195814 valid's rmse: 0.000464494   valid's RMSPE: 0.215399\nOur out of folds RMSPE is 0.217, compared to 0.18540826325940205, giving gain 0.03159173674059795\nOur cv fold scores are [0.215, 0.228, 0.216, 0.21, 0.215]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000631903   train's RMSPE: 0.188603 valid's rmse: 0.000687421   valid's RMSPE: 0.203406\n[100]   train's rmse: 0.000596106   train's RMSPE: 0.177918 valid's rmse: 0.00066195    valid's RMSPE: 0.195869\n[150]   train's rmse: 0.00058033    train's RMSPE: 0.17321  valid's rmse: 0.000656777   valid's RMSPE: 0.194338\n[200]   train's rmse: 0.000569206   train's RMSPE: 0.169889 valid's rmse: 0.000654043   valid's RMSPE: 0.193529\n[250]   train's rmse: 0.000559339   train's RMSPE: 0.166945 valid's rmse: 0.000653716   valid's RMSPE: 0.193432\n[300]   train's rmse: 0.000551271   train's RMSPE: 0.164537 valid's rmse: 0.000651787   valid's RMSPE: 0.192862\n[350]   train's rmse: 0.000544843   train's RMSPE: 0.162618 valid's rmse: 0.000653232   valid's RMSPE: 0.193289\nEarly stopping, best iteration is:\n[307]   train's rmse: 0.000550205   train's RMSPE: 0.164218 valid's rmse: 0.000651735   valid's RMSPE: 0.192846\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000637895   train's RMSPE: 0.189179 valid's rmse: 0.000656914   valid's RMSPE: 0.199334\n[100]   train's rmse: 0.000603699   train's RMSPE: 0.179038 valid's rmse: 0.000632781   valid's RMSPE: 0.192011\n[150]   train's rmse: 0.000589424   train's RMSPE: 0.174804 valid's rmse: 0.000630173   valid's RMSPE: 0.191219\n[200]   train's rmse: 0.000578063   train's RMSPE: 0.171435 valid's rmse: 0.000630073   valid's RMSPE: 0.191189\nEarly stopping, best iteration is:\n[189]   train's rmse: 0.000580258   train's RMSPE: 0.172086 valid's rmse: 0.000628454   valid's RMSPE: 0.190698\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000643145   train's RMSPE: 0.190865 valid's rmse: 0.000624431   valid's RMSPE: 0.188988\n[100]   train's rmse: 0.000608249   train's RMSPE: 0.180509 valid's rmse: 0.000601565   valid's RMSPE: 0.182067\n[150]   train's rmse: 0.00059361    train's RMSPE: 0.176165 valid's rmse: 0.000596687   valid's RMSPE: 0.18059\n[200]   train's rmse: 0.000582513   train's RMSPE: 0.172871 valid's rmse: 0.000593859   valid's RMSPE: 0.179735\n[250]   train's rmse: 0.000572782   train's RMSPE: 0.169984 valid's rmse: 0.000592081   valid's RMSPE: 0.179197\n[300]   train's rmse: 0.000564558   train's RMSPE: 0.167543 valid's rmse: 0.000590164   valid's RMSPE: 0.178616\nEarly stopping, best iteration is:\n[298]   train's rmse: 0.000564822   train's RMSPE: 0.167621 valid's rmse: 0.000589934   valid's RMSPE: 0.178547\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000633938   train's RMSPE: 0.189575 valid's rmse: 0.000666448   valid's RMSPE: 0.195641\n[100]   train's rmse: 0.000598395   train's RMSPE: 0.178947 valid's rmse: 0.000645333   valid's RMSPE: 0.189443\n[150]   train's rmse: 0.000584202   train's RMSPE: 0.174702 valid's rmse: 0.000646056   valid's RMSPE: 0.189655\nEarly stopping, best iteration is:\n[112]   train's rmse: 0.000594012   train's RMSPE: 0.177636 valid's rmse: 0.000645027   valid's RMSPE: 0.189353\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000641092   train's RMSPE: 0.191634 valid's rmse: 0.000636771   valid's RMSPE: 0.187258\n[100]   train's rmse: 0.0006068 train's RMSPE: 0.181383 valid's rmse: 0.000613768   valid's RMSPE: 0.180493\n[150]   train's rmse: 0.000592956   train's RMSPE: 0.177245 valid's rmse: 0.000609752   valid's RMSPE: 0.179312\n[200]   train's rmse: 0.000581884   train's RMSPE: 0.173935 valid's rmse: 0.000608389   valid's RMSPE: 0.178911\n[250]   train's rmse: 0.000571646   train's RMSPE: 0.170875 valid's rmse: 0.000608534   valid's RMSPE: 0.178954\n[300]   train's rmse: 0.000563322   train's RMSPE: 0.168387 valid's rmse: 0.000606582   valid's RMSPE: 0.17838\nEarly stopping, best iteration is:\n[293]   train's rmse: 0.000564443   train's RMSPE: 0.168722 valid's rmse: 0.000606037   valid's RMSPE: 0.17822\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.186, compared to 0.16624971333012886, giving gain 0.019750286669871137\nOur cv fold scores are [0.193, 0.191, 0.179, 0.189, 0.178]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.0010901 train's RMSPE: 0.234976 valid's rmse: 0.00115226    valid's RMSPE: 0.254064\n[100]   train's rmse: 0.00104095    train's RMSPE: 0.224381 valid's rmse: 0.00111374    valid's RMSPE: 0.24557\n[150]   train's rmse: 0.00101633    train's RMSPE: 0.219074 valid's rmse: 0.00110823    valid's RMSPE: 0.244355\n[200]   train's rmse: 0.000996925   train's RMSPE: 0.214892 valid's rmse: 0.0011045 valid's RMSPE: 0.243533\n[250]   train's rmse: 0.000978353   train's RMSPE: 0.210888 valid's rmse: 0.00110115    valid's RMSPE: 0.242793\n[300]   train's rmse: 0.000962653   train's RMSPE: 0.207504 valid's rmse: 0.00109685    valid's RMSPE: 0.241847\n[350]   train's rmse: 0.000949257   train's RMSPE: 0.204616 valid's rmse: 0.0010996 valid's RMSPE: 0.242452\nEarly stopping, best iteration is:\n[321]   train's rmse: 0.000956195   train's RMSPE: 0.206112 valid's rmse: 0.00109603    valid's RMSPE: 0.241665\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00109069    train's RMSPE: 0.235945 valid's rmse: 0.00112938    valid's RMSPE: 0.245579\n[100]   train's rmse: 0.00104019    train's RMSPE: 0.225021 valid's rmse: 0.00110714    valid's RMSPE: 0.240743\n[150]   train's rmse: 0.00101395    train's RMSPE: 0.219344 valid's rmse: 0.00110402    valid's RMSPE: 0.240065\n[200]   train's rmse: 0.000991802   train's RMSPE: 0.214553 valid's rmse: 0.00110216    valid's RMSPE: 0.239661\nEarly stopping, best iteration is:\n[192]   train's rmse: 0.00099442    train's RMSPE: 0.215119 valid's rmse: 0.00110065    valid's RMSPE: 0.239332\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00108747    train's RMSPE: 0.235801 valid's rmse: 0.00112887    valid's RMSPE: 0.243175\n[100]   train's rmse: 0.00103964    train's RMSPE: 0.225429 valid's rmse: 0.00110068    valid's RMSPE: 0.237102\n[150]   train's rmse: 0.00101408    train's RMSPE: 0.219887 valid's rmse: 0.00109691    valid's RMSPE: 0.236291\n[200]   train's rmse: 0.000991947   train's RMSPE: 0.215088 valid's rmse: 0.00109517    valid's RMSPE: 0.235916\n[250]   train's rmse: 0.000972401   train's RMSPE: 0.21085  valid's rmse: 0.00109207    valid's RMSPE: 0.235247\nEarly stopping, best iteration is:\n[249]   train's rmse: 0.000972731   train's RMSPE: 0.210921 valid's rmse: 0.0010919 valid's RMSPE: 0.235211\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00109323    train's RMSPE: 0.237758 valid's rmse: 0.00110546    valid's RMSPE: 0.235221\n[100]   train's rmse: 0.00103946    train's RMSPE: 0.226065 valid's rmse: 0.00109399    valid's RMSPE: 0.232782\nEarly stopping, best iteration is:\n[83]    train's rmse: 0.00105139    train's RMSPE: 0.228658 valid's rmse: 0.00109384    valid's RMSPE: 0.232748\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00108962    train's RMSPE: 0.235959 valid's rmse: 0.00112831    valid's RMSPE: 0.244333\n[100]   train's rmse: 0.00103838    train's RMSPE: 0.224864 valid's rmse: 0.00111471    valid's RMSPE: 0.241389\nEarly stopping, best iteration is:\n[85]    train's rmse: 0.00104923    train's RMSPE: 0.227213 valid's rmse: 0.00111112    valid's RMSPE: 0.240612\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.238, compared to 0.22397550035495178, giving gain 0.014024499645048205\nOur cv fold scores are [0.242, 0.239, 0.235, 0.233, 0.241]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000840623   train's RMSPE: 0.284471 valid's rmse: 0.000850233   valid's RMSPE: 0.282354\n[100]   train's rmse: 0.000806727   train's RMSPE: 0.273001 valid's rmse: 0.000836277   valid's RMSPE: 0.277719\n[150]   train's rmse: 0.000788228   train's RMSPE: 0.266741 valid's rmse: 0.000834146   valid's RMSPE: 0.277011\n[200]   train's rmse: 0.000773021   train's RMSPE: 0.261595 valid's rmse: 0.000837931   valid's RMSPE: 0.278268\nEarly stopping, best iteration is:\n[162]   train's rmse: 0.000783743   train's RMSPE: 0.265223 valid's rmse: 0.000832611   valid's RMSPE: 0.276502\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000830888   train's RMSPE: 0.281039 valid's rmse: 0.000879018   valid's RMSPE: 0.292508\n[100]   train's rmse: 0.000796633   train's RMSPE: 0.269452 valid's rmse: 0.000862919   valid's RMSPE: 0.287151\n[150]   train's rmse: 0.000777367   train's RMSPE: 0.262936 valid's rmse: 0.00086091    valid's RMSPE: 0.286483\n[200]   train's rmse: 0.000761846   train's RMSPE: 0.257686 valid's rmse: 0.00085624    valid's RMSPE: 0.284929\n[250]   train's rmse: 0.000748265   train's RMSPE: 0.253093 valid's rmse: 0.0008528 valid's RMSPE: 0.283784\nEarly stopping, best iteration is:\n[236]   train's rmse: 0.000751954   train's RMSPE: 0.25434  valid's rmse: 0.000852084   valid's RMSPE: 0.283546\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000842273   train's RMSPE: 0.284163 valid's rmse: 0.000826538   valid's RMSPE: 0.277925\n[100]   train's rmse: 0.000805362   train's RMSPE: 0.27171  valid's rmse: 0.00080714    valid's RMSPE: 0.271402\n[150]   train's rmse: 0.000782963   train's RMSPE: 0.264153 valid's rmse: 0.000803339   valid's RMSPE: 0.270124\n[200]   train's rmse: 0.00076708    train's RMSPE: 0.258795 valid's rmse: 0.000800319   valid's RMSPE: 0.269109\n[250]   train's rmse: 0.000753035   train's RMSPE: 0.254056 valid's rmse: 0.000802097   valid's RMSPE: 0.269706\nEarly stopping, best iteration is:\n[219]   train's rmse: 0.000761753   train's RMSPE: 0.256998 valid's rmse: 0.000800011   valid's RMSPE: 0.269005\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000840862   train's RMSPE: 0.282458 valid's rmse: 0.000862178   valid's RMSPE: 0.294914\n[100]   train's rmse: 0.000805724   train's RMSPE: 0.270655 valid's rmse: 0.000857536   valid's RMSPE: 0.293326\nEarly stopping, best iteration is:\n[86]    train's rmse: 0.000812213   train's RMSPE: 0.272834 valid's rmse: 0.000853652   valid's RMSPE: 0.291997\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000831609   train's RMSPE: 0.279266 valid's rmse: 0.000891345   valid's RMSPE: 0.30524\n[100]   train's rmse: 0.000799893   train's RMSPE: 0.268616 valid's rmse: 0.000881743   valid's RMSPE: 0.301952\n[150]   train's rmse: 0.000779396   train's RMSPE: 0.261732 valid's rmse: 0.000877975   valid's RMSPE: 0.300662\nEarly stopping, best iteration is:\n[136]   train's rmse: 0.000783616   train's RMSPE: 0.26315  valid's rmse: 0.00087755    valid's RMSPE: 0.300516\nOur out of folds RMSPE is 0.285, compared to 0.2524301885495816, giving gain 0.03256981145041837\nOur cv fold scores are [0.277, 0.284, 0.269, 0.292, 0.301]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000400712   train's RMSPE: 0.24585  valid's rmse: 0.000427958   valid's RMSPE: 0.265441\n[100]   train's rmse: 0.000378718   train's RMSPE: 0.232356 valid's rmse: 0.000415029   valid's RMSPE: 0.257422\n[150]   train's rmse: 0.00036832    train's RMSPE: 0.225977 valid's rmse: 0.000410547   valid's RMSPE: 0.254642\n[200]   train's rmse: 0.000360147   train's RMSPE: 0.220962 valid's rmse: 0.000407292   valid's RMSPE: 0.252623\n[250]   train's rmse: 0.000353454   train's RMSPE: 0.216856 valid's rmse: 0.000405415   valid's RMSPE: 0.251459\n[300]   train's rmse: 0.000347894   train's RMSPE: 0.213444 valid's rmse: 0.000403566   valid's RMSPE: 0.250312\n[350]   train's rmse: 0.000342914   train's RMSPE: 0.210389 valid's rmse: 0.000401752   valid's RMSPE: 0.249186\n[400]   train's rmse: 0.000338632   train's RMSPE: 0.207762 valid's rmse: 0.00040066    valid's RMSPE: 0.248509\n[450]   train's rmse: 0.000334659   train's RMSPE: 0.205325 valid's rmse: 0.000400027   valid's RMSPE: 0.248117\n[500]   train's rmse: 0.000331283   train's RMSPE: 0.203253 valid's rmse: 0.000398135   valid's RMSPE: 0.246943\n[550]   train's rmse: 0.000327847   train's RMSPE: 0.201145 valid's rmse: 0.000397434   valid's RMSPE: 0.246509\n[600]   train's rmse: 0.000324563   train's RMSPE: 0.19913  valid's rmse: 0.000397358   valid's RMSPE: 0.246461\n[650]   train's rmse: 0.000321316   train's RMSPE: 0.197138 valid's rmse: 0.000396673   valid's RMSPE: 0.246036\n[700]   train's rmse: 0.000318264   train's RMSPE: 0.195266 valid's rmse: 0.000396229   valid's RMSPE: 0.245761\nEarly stopping, best iteration is:\n[689]   train's rmse: 0.000319036   train's RMSPE: 0.195739 valid's rmse: 0.000395991   valid's RMSPE: 0.245613\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000399741   train's RMSPE: 0.245487 valid's rmse: 0.000439764   valid's RMSPE: 0.271749\n[100]   train's rmse: 0.000377872   train's RMSPE: 0.232057 valid's rmse: 0.000422058   valid's RMSPE: 0.260807\n[150]   train's rmse: 0.000367287   train's RMSPE: 0.225557 valid's rmse: 0.00041924    valid's RMSPE: 0.259066\n[200]   train's rmse: 0.000358995   train's RMSPE: 0.220465 valid's rmse: 0.000415242   valid's RMSPE: 0.256596\n[250]   train's rmse: 0.000352268   train's RMSPE: 0.216333 valid's rmse: 0.000413227   valid's RMSPE: 0.25535\n[300]   train's rmse: 0.000346818   train's RMSPE: 0.212986 valid's rmse: 0.000411867   valid's RMSPE: 0.254511\n[350]   train's rmse: 0.00034182    train's RMSPE: 0.209917 valid's rmse: 0.000411945   valid's RMSPE: 0.254559\n[400]   train's rmse: 0.000337473   train's RMSPE: 0.207247 valid's rmse: 0.000410745   valid's RMSPE: 0.253817\n[450]   train's rmse: 0.000333515   train's RMSPE: 0.204817 valid's rmse: 0.000410609   valid's RMSPE: 0.253733\n[500]   train's rmse: 0.000329872   train's RMSPE: 0.20258  valid's rmse: 0.000410059   valid's RMSPE: 0.253393\n[550]   train's rmse: 0.00032654    train's RMSPE: 0.200533 valid's rmse: 0.000409749   valid's RMSPE: 0.253202\nEarly stopping, best iteration is:\n[524]   train's rmse: 0.000328193   train's RMSPE: 0.201549 valid's rmse: 0.000409636   valid's RMSPE: 0.253132\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00040267    train's RMSPE: 0.247149 valid's rmse: 0.000418216   valid's RMSPE: 0.259\n[100]   train's rmse: 0.00038126    train's RMSPE: 0.234008 valid's rmse: 0.000402406   valid's RMSPE: 0.249209\n[150]   train's rmse: 0.000371162   train's RMSPE: 0.22781  valid's rmse: 0.000398028   valid's RMSPE: 0.246497\n[200]   train's rmse: 0.000363261   train's RMSPE: 0.22296  valid's rmse: 0.000395038   valid's RMSPE: 0.244646\n[250]   train's rmse: 0.000356632   train's RMSPE: 0.218892 valid's rmse: 0.000392601   valid's RMSPE: 0.243137\n[300]   train's rmse: 0.000350541   train's RMSPE: 0.215153 valid's rmse: 0.000392403   valid's RMSPE: 0.243014\n[350]   train's rmse: 0.000345627   train's RMSPE: 0.212137 valid's rmse: 0.000391867   valid's RMSPE: 0.242682\n[400]   train's rmse: 0.00034119    train's RMSPE: 0.209414 valid's rmse: 0.000391828   valid's RMSPE: 0.242658\nEarly stopping, best iteration is:\n[366]   train's rmse: 0.000343918   train's RMSPE: 0.211088 valid's rmse: 0.000391237   valid's RMSPE: 0.242292\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000411397   train's RMSPE: 0.253605 valid's rmse: 0.000378933   valid's RMSPE: 0.230612\n[100]   train's rmse: 0.000387605   train's RMSPE: 0.238938 valid's rmse: 0.000373875   valid's RMSPE: 0.227534\n[150]   train's rmse: 0.00037701    train's RMSPE: 0.232407 valid's rmse: 0.000373359   valid's RMSPE: 0.22722\n[200]   train's rmse: 0.000368171   train's RMSPE: 0.226958 valid's rmse: 0.000373773   valid's RMSPE: 0.227472\nEarly stopping, best iteration is:\n[156]   train's rmse: 0.000375767   train's RMSPE: 0.23164  valid's rmse: 0.000372855   valid's RMSPE: 0.226913\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000407674   train's RMSPE: 0.251346 valid's rmse: 0.000402054   valid's RMSPE: 0.24454\n[100]   train's rmse: 0.000386915   train's RMSPE: 0.238547 valid's rmse: 0.000383499   valid's RMSPE: 0.233254\n[150]   train's rmse: 0.000376889   train's RMSPE: 0.232366 valid's rmse: 0.000380031   valid's RMSPE: 0.231144\n[200]   train's rmse: 0.000368858   train's RMSPE: 0.227414 valid's rmse: 0.000378267   valid's RMSPE: 0.230072\n[250]   train's rmse: 0.000362341   train's RMSPE: 0.223396 valid's rmse: 0.000376732   valid's RMSPE: 0.229138\n[300]   train's rmse: 0.000356255   train's RMSPE: 0.219644 valid's rmse: 0.000373997   valid's RMSPE: 0.227475\n[350]   train's rmse: 0.000350736   train's RMSPE: 0.216241 valid's rmse: 0.000373381   valid's RMSPE: 0.2271\nEarly stopping, best iteration is:\n[332]   train's rmse: 0.000352731   train's RMSPE: 0.217471 valid's rmse: 0.00037255    valid's RMSPE: 0.226595\nOur out of folds RMSPE is 0.239, compared to 0.20861916092721863, giving gain 0.030380839072781357\nOur cv fold scores are [0.246, 0.253, 0.242, 0.227, 0.227]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000716357   train's RMSPE: 0.240895 valid's rmse: 0.000737814   valid's RMSPE: 0.253702\n[100]   train's rmse: 0.00067347    train's RMSPE: 0.226473 valid's rmse: 0.000697632   valid's RMSPE: 0.239885\n[150]   train's rmse: 0.000657522   train's RMSPE: 0.22111  valid's rmse: 0.000688751   valid's RMSPE: 0.236831\n[200]   train's rmse: 0.000646331   train's RMSPE: 0.217346 valid's rmse: 0.000686401   valid's RMSPE: 0.236024\n[250]   train's rmse: 0.000635189   train's RMSPE: 0.2136   valid's rmse: 0.000684948   valid's RMSPE: 0.235524\nEarly stopping, best iteration is:\n[236]   train's rmse: 0.00063785    train's RMSPE: 0.214495 valid's rmse: 0.000684195   valid's RMSPE: 0.235265\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000708432   train's RMSPE: 0.238696 valid's rmse: 0.000747498   valid's RMSPE: 0.255102\n[100]   train's rmse: 0.000669011   train's RMSPE: 0.225414 valid's rmse: 0.000720727   valid's RMSPE: 0.245966\n[150]   train's rmse: 0.000652866   train's RMSPE: 0.219974 valid's rmse: 0.000718765   valid's RMSPE: 0.245296\n[200]   train's rmse: 0.000639666   train's RMSPE: 0.215527 valid's rmse: 0.000717656   valid's RMSPE: 0.244918\nEarly stopping, best iteration is:\n[192]   train's rmse: 0.00064172    train's RMSPE: 0.216219 valid's rmse: 0.000717122   valid's RMSPE: 0.244736\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000707283   train's RMSPE: 0.23988  valid's rmse: 0.000729996   valid's RMSPE: 0.242619\n[100]   train's rmse: 0.000666597   train's RMSPE: 0.226081 valid's rmse: 0.000713077   valid's RMSPE: 0.236996\n[150]   train's rmse: 0.000650258   train's RMSPE: 0.220539 valid's rmse: 0.00071144    valid's RMSPE: 0.236452\n[200]   train's rmse: 0.000638205   train's RMSPE: 0.216451 valid's rmse: 0.000711856   valid's RMSPE: 0.23659\n[250]   train's rmse: 0.000627349   train's RMSPE: 0.21277  valid's rmse: 0.000709853   valid's RMSPE: 0.235924\n[300]   train's rmse: 0.000618193   train's RMSPE: 0.209665 valid's rmse: 0.000708963   valid's RMSPE: 0.235629\n[350]   train's rmse: 0.000610277   train's RMSPE: 0.20698  valid's rmse: 0.000707922   valid's RMSPE: 0.235282\n[400]   train's rmse: 0.000602063   train's RMSPE: 0.204194 valid's rmse: 0.000708764   valid's RMSPE: 0.235562\nEarly stopping, best iteration is:\n[367]   train's rmse: 0.000607575   train's RMSPE: 0.206063 valid's rmse: 0.000707144   valid's RMSPE: 0.235024\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000710562   train's RMSPE: 0.241335 valid's rmse: 0.000707376   valid's RMSPE: 0.233701\n[100]   train's rmse: 0.000668272   train's RMSPE: 0.226972 valid's rmse: 0.000696656   valid's RMSPE: 0.23016\nEarly stopping, best iteration is:\n[87]    train's rmse: 0.000673585   train's RMSPE: 0.228776 valid's rmse: 0.000696109   valid's RMSPE: 0.229979\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000715358   train's RMSPE: 0.241085 valid's rmse: 0.000738706   valid's RMSPE: 0.251871\n[100]   train's rmse: 0.0006747 train's RMSPE: 0.227383 valid's rmse: 0.000701942   valid's RMSPE: 0.239336\n[150]   train's rmse: 0.00065968    train's RMSPE: 0.222321 valid's rmse: 0.00069779    valid's RMSPE: 0.237921\n[200]   train's rmse: 0.000648311   train's RMSPE: 0.21849  valid's rmse: 0.000694225   valid's RMSPE: 0.236705\n[250]   train's rmse: 0.000637993   train's RMSPE: 0.215012 valid's rmse: 0.000693763   valid's RMSPE: 0.236548\nEarly stopping, best iteration is:\n[228]   train's rmse: 0.000641917   train's RMSPE: 0.216335 valid's rmse: 0.000691087   valid's RMSPE: 0.235635\nOur out of folds RMSPE is 0.236, compared to 0.20714316103379152, giving gain 0.02885683896620847\nOur cv fold scores are [0.235, 0.245, 0.235, 0.23, 0.236]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000593939   train's RMSPE: 0.213721 valid's rmse: 0.000669988   valid's RMSPE: 0.236097\n[100]   train's rmse: 0.000555796   train's RMSPE: 0.199996 valid's rmse: 0.000643857   valid's RMSPE: 0.226889\n[150]   train's rmse: 0.000540744   train's RMSPE: 0.194579 valid's rmse: 0.000642392   valid's RMSPE: 0.226372\n[200]   train's rmse: 0.000529582   train's RMSPE: 0.190563 valid's rmse: 0.000639788   valid's RMSPE: 0.225454\n[250]   train's rmse: 0.000519909   train's RMSPE: 0.187082 valid's rmse: 0.000638735   valid's RMSPE: 0.225083\n[300]   train's rmse: 0.000511137   train's RMSPE: 0.183926 valid's rmse: 0.000637264   valid's RMSPE: 0.224565\n[350]   train's rmse: 0.000503998   train's RMSPE: 0.181357 valid's rmse: 0.000636047   valid's RMSPE: 0.224136\n[400]   train's rmse: 0.000496857   train's RMSPE: 0.178787 valid's rmse: 0.000635718   valid's RMSPE: 0.22402\n[450]   train's rmse: 0.000490648   train's RMSPE: 0.176553 valid's rmse: 0.000637089   valid's RMSPE: 0.224503\nEarly stopping, best iteration is:\n[422]   train's rmse: 0.000493501   train's RMSPE: 0.17758  valid's rmse: 0.000635575   valid's RMSPE: 0.22397\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000607397   train's RMSPE: 0.216809 valid's rmse: 0.000612045   valid's RMSPE: 0.222757\n[100]   train's rmse: 0.00057069    train's RMSPE: 0.203706 valid's rmse: 0.00058347    valid's RMSPE: 0.212357\n[150]   train's rmse: 0.000556558   train's RMSPE: 0.198661 valid's rmse: 0.000582138   valid's RMSPE: 0.211872\nEarly stopping, best iteration is:\n[138]   train's rmse: 0.000559052   train's RMSPE: 0.199552 valid's rmse: 0.000580588   valid's RMSPE: 0.211308\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000611964   train's RMSPE: 0.219147 valid's rmse: 0.000592289   valid's RMSPE: 0.212855\n[100]   train's rmse: 0.000574899   train's RMSPE: 0.205874 valid's rmse: 0.000568249   valid's RMSPE: 0.204216\n[150]   train's rmse: 0.000559635   train's RMSPE: 0.200408 valid's rmse: 0.000563457   valid's RMSPE: 0.202493\n[200]   train's rmse: 0.000547846   train's RMSPE: 0.196186 valid's rmse: 0.000561507   valid's RMSPE: 0.201793\n[250]   train's rmse: 0.000537984   train's RMSPE: 0.192655 valid's rmse: 0.0005609 valid's RMSPE: 0.201574\n[300]   train's rmse: 0.000529667   train's RMSPE: 0.189676 valid's rmse: 0.000559578   valid's RMSPE: 0.2011\n[350]   train's rmse: 0.000521028   train's RMSPE: 0.186583 valid's rmse: 0.000557493   valid's RMSPE: 0.20035\n[400]   train's rmse: 0.000514583   train's RMSPE: 0.184275 valid's rmse: 0.000558709   valid's RMSPE: 0.200787\nEarly stopping, best iteration is:\n[356]   train's rmse: 0.000520161   train's RMSPE: 0.186272 valid's rmse: 0.000557397   valid's RMSPE: 0.200316\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000607998   train's RMSPE: 0.217218 valid's rmse: 0.000619802   valid's RMSPE: 0.2248\n[100]   train's rmse: 0.000570688   train's RMSPE: 0.203888 valid's rmse: 0.000599484   valid's RMSPE: 0.217431\n[150]   train's rmse: 0.000556307   train's RMSPE: 0.19875  valid's rmse: 0.000595564   valid's RMSPE: 0.216009\n[200]   train's rmse: 0.0005455 train's RMSPE: 0.194889 valid's rmse: 0.000594771   valid's RMSPE: 0.215721\n[250]   train's rmse: 0.000535987   train's RMSPE: 0.191491 valid's rmse: 0.000594531   valid's RMSPE: 0.215634\nEarly stopping, best iteration is:\n[220]   train's rmse: 0.000541338   train's RMSPE: 0.193402 valid's rmse: 0.000593448   valid's RMSPE: 0.215241\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000608833   train's RMSPE: 0.218956 valid's rmse: 0.000607616   valid's RMSPE: 0.214623\n[100]   train's rmse: 0.000572655   train's RMSPE: 0.205945 valid's rmse: 0.000584793   valid's RMSPE: 0.206561\n[150]   train's rmse: 0.00055727    train's RMSPE: 0.200413 valid's rmse: 0.000583536   valid's RMSPE: 0.206117\n[200]   train's rmse: 0.000545508   train's RMSPE: 0.196182 valid's rmse: 0.000582752   valid's RMSPE: 0.205841\nEarly stopping, best iteration is:\n[189]   train's rmse: 0.000547782   train's RMSPE: 0.197    valid's rmse: 0.000581961   valid's RMSPE: 0.205561\nOur out of folds RMSPE is 0.211, compared to 0.19115350809715234, giving gain 0.01984649190284765\nOur cv fold scores are [0.224, 0.211, 0.2, 0.215, 0.206]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000698212   train's RMSPE: 0.242413 valid's rmse: 0.000757357   valid's RMSPE: 0.262954\n[100]   train's rmse: 0.00066275    train's RMSPE: 0.230102 valid's rmse: 0.00073952    valid's RMSPE: 0.256761\n[150]   train's rmse: 0.000648143   train's RMSPE: 0.22503  valid's rmse: 0.00073914    valid's RMSPE: 0.256628\nEarly stopping, best iteration is:\n[123]   train's rmse: 0.000656058   train's RMSPE: 0.227778 valid's rmse: 0.000738034   valid's RMSPE: 0.256245\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000701194   train's RMSPE: 0.242369 valid's rmse: 0.000743423   valid's RMSPE: 0.262646\n[100]   train's rmse: 0.000667213   train's RMSPE: 0.230623 valid's rmse: 0.000720921   valid's RMSPE: 0.254696\n[150]   train's rmse: 0.000651045   train's RMSPE: 0.225035 valid's rmse: 0.000718037   valid's RMSPE: 0.253678\n[200]   train's rmse: 0.000637353   train's RMSPE: 0.220302 valid's rmse: 0.000715077   valid's RMSPE: 0.252632\n[250]   train's rmse: 0.000626524   train's RMSPE: 0.216559 valid's rmse: 0.000714606   valid's RMSPE: 0.252465\n[300]   train's rmse: 0.000616608   train's RMSPE: 0.213131 valid's rmse: 0.000711146   valid's RMSPE: 0.251243\n[350]   train's rmse: 0.000608163   train's RMSPE: 0.210213 valid's rmse: 0.000709208   valid's RMSPE: 0.250559\n[400]   train's rmse: 0.000600419   train's RMSPE: 0.207536 valid's rmse: 0.000709426   valid's RMSPE: 0.250635\nEarly stopping, best iteration is:\n[372]   train's rmse: 0.000604543   train's RMSPE: 0.208961 valid's rmse: 0.000709119   valid's RMSPE: 0.250527\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000712942   train's RMSPE: 0.246397 valid's rmse: 0.000687011   valid's RMSPE: 0.24284\n[100]   train's rmse: 0.00067728    train's RMSPE: 0.234072 valid's rmse: 0.000663251   valid's RMSPE: 0.234441\n[150]   train's rmse: 0.000660955   train's RMSPE: 0.22843  valid's rmse: 0.000661055   valid's RMSPE: 0.233665\n[200]   train's rmse: 0.000648296   train's RMSPE: 0.224055 valid's rmse: 0.000659698   valid's RMSPE: 0.233185\nEarly stopping, best iteration is:\n[181]   train's rmse: 0.000652606   train's RMSPE: 0.225544 valid's rmse: 0.000658758   valid's RMSPE: 0.232853\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000712089   train's RMSPE: 0.247954 valid's rmse: 0.000711572   valid's RMSPE: 0.244148\n[100]   train's rmse: 0.000675948   train's RMSPE: 0.235369 valid's rmse: 0.000695026   valid's RMSPE: 0.238471\n[150]   train's rmse: 0.000659174   train's RMSPE: 0.229529 valid's rmse: 0.000689266   valid's RMSPE: 0.236495\n[200]   train's rmse: 0.00064716    train's RMSPE: 0.225345 valid's rmse: 0.000686697   valid's RMSPE: 0.235613\n[250]   train's rmse: 0.000636442   train's RMSPE: 0.221613 valid's rmse: 0.000686749   valid's RMSPE: 0.235631\n[300]   train's rmse: 0.000626771   train's RMSPE: 0.218246 valid's rmse: 0.000685589   valid's RMSPE: 0.235233\n[350]   train's rmse: 0.000618647   train's RMSPE: 0.215417 valid's rmse: 0.000686458   valid's RMSPE: 0.235531\nEarly stopping, best iteration is:\n[307]   train's rmse: 0.000625588   train's RMSPE: 0.217834 valid's rmse: 0.000685232   valid's RMSPE: 0.235111\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000706779   train's RMSPE: 0.246875 valid's rmse: 0.000728727   valid's RMSPE: 0.246784\n[100]   train's rmse: 0.000674472   train's RMSPE: 0.23559  valid's rmse: 0.000714592   valid's RMSPE: 0.241998\n[150]   train's rmse: 0.000657375   train's RMSPE: 0.229619 valid's rmse: 0.000710653   valid's RMSPE: 0.240664\n[200]   train's rmse: 0.000643781   train's RMSPE: 0.22487  valid's rmse: 0.000706376   valid's RMSPE: 0.239215\n[250]   train's rmse: 0.000633789   train's RMSPE: 0.22138  valid's rmse: 0.000706215   valid's RMSPE: 0.239161\nEarly stopping, best iteration is:\n[215]   train's rmse: 0.000640547   train's RMSPE: 0.223741 valid's rmse: 0.00070552    valid's RMSPE: 0.238925\nOur out of folds RMSPE is 0.243, compared to 0.21093487209875394, giving gain 0.03206512790124605\nOur cv fold scores are [0.256, 0.251, 0.233, 0.235, 0.239]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000923915   train's RMSPE: 0.285916 valid's rmse: 0.00101814    valid's RMSPE: 0.308634\n[100]   train's rmse: 0.000883547   train's RMSPE: 0.273424 valid's rmse: 0.00100395    valid's RMSPE: 0.304333\n[150]   train's rmse: 0.000860182   train's RMSPE: 0.266193 valid's rmse: 0.000992926   valid's RMSPE: 0.300991\n[200]   train's rmse: 0.000841612   train's RMSPE: 0.260447 valid's rmse: 0.000988184   valid's RMSPE: 0.299554\n[250]   train's rmse: 0.000825409   train's RMSPE: 0.255433 valid's rmse: 0.000987051   valid's RMSPE: 0.29921\n[300]   train's rmse: 0.000812097   train's RMSPE: 0.251313 valid's rmse: 0.000982297   valid's RMSPE: 0.297769\n[350]   train's rmse: 0.000801244   train's RMSPE: 0.247954 valid's rmse: 0.000982647   valid's RMSPE: 0.297875\nEarly stopping, best iteration is:\n[327]   train's rmse: 0.000805928   train's RMSPE: 0.249404 valid's rmse: 0.000981133   valid's RMSPE: 0.297416\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000927434   train's RMSPE: 0.284639 valid's rmse: 0.000979401   valid's RMSPE: 0.306886\n[100]   train's rmse: 0.000885899   train's RMSPE: 0.271891 valid's rmse: 0.000957289   valid's RMSPE: 0.299958\n[150]   train's rmse: 0.000861436   train's RMSPE: 0.264383 valid's rmse: 0.000951414   valid's RMSPE: 0.298117\n[200]   train's rmse: 0.000842509   train's RMSPE: 0.258574 valid's rmse: 0.000948574   valid's RMSPE: 0.297227\n[250]   train's rmse: 0.000825816   train's RMSPE: 0.253451 valid's rmse: 0.000943476   valid's RMSPE: 0.29563\n[300]   train's rmse: 0.000811479   train's RMSPE: 0.249051 valid's rmse: 0.000943714   valid's RMSPE: 0.295704\nEarly stopping, best iteration is:\n[287]   train's rmse: 0.000814701   train's RMSPE: 0.25004  valid's rmse: 0.000942742   valid's RMSPE: 0.2954\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00093514    train's RMSPE: 0.288    valid's rmse: 0.000941571   valid's RMSPE: 0.291067\n[100]   train's rmse: 0.000893008   train's RMSPE: 0.275025 valid's rmse: 0.000921712   valid's RMSPE: 0.284928\n[150]   train's rmse: 0.000871125   train's RMSPE: 0.268286 valid's rmse: 0.000915274   valid's RMSPE: 0.282938\n[200]   train's rmse: 0.000851891   train's RMSPE: 0.262362 valid's rmse: 0.000913994   valid's RMSPE: 0.282542\nEarly stopping, best iteration is:\n[169]   train's rmse: 0.00086294    train's RMSPE: 0.265765 valid's rmse: 0.000912685   valid's RMSPE: 0.282138\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000944019   train's RMSPE: 0.28993  valid's rmse: 0.000907501   valid's RMSPE: 0.283597\n[100]   train's rmse: 0.000903983   train's RMSPE: 0.277634 valid's rmse: 0.000893995   valid's RMSPE: 0.279377\n[150]   train's rmse: 0.000879026   train's RMSPE: 0.269969 valid's rmse: 0.000890486   valid's RMSPE: 0.27828\n[200]   train's rmse: 0.000860736   train's RMSPE: 0.264352 valid's rmse: 0.000890489   valid's RMSPE: 0.278281\n[250]   train's rmse: 0.000843658   train's RMSPE: 0.259107 valid's rmse: 0.00088708    valid's RMSPE: 0.277216\n[300]   train's rmse: 0.000827694   train's RMSPE: 0.254204 valid's rmse: 0.000885531   valid's RMSPE: 0.276731\n[350]   train's rmse: 0.00081621    train's RMSPE: 0.250677 valid's rmse: 0.000887581   valid's RMSPE: 0.277372\nEarly stopping, best iteration is:\n[309]   train's rmse: 0.000825792   train's RMSPE: 0.25362  valid's rmse: 0.00088507    valid's RMSPE: 0.276588\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000935128   train's RMSPE: 0.289472 valid's rmse: 0.000935255   valid's RMSPE: 0.283159\n[100]   train's rmse: 0.000895432   train's RMSPE: 0.277184 valid's rmse: 0.000914353   valid's RMSPE: 0.27683\n[150]   train's rmse: 0.000871796   train's RMSPE: 0.269867 valid's rmse: 0.000910514   valid's RMSPE: 0.275668\n[200]   train's rmse: 0.000852381   train's RMSPE: 0.263857 valid's rmse: 0.000905493   valid's RMSPE: 0.274148\n[250]   train's rmse: 0.000836551   train's RMSPE: 0.258957 valid's rmse: 0.000904224   valid's RMSPE: 0.273764\n[300]   train's rmse: 0.000821907   train's RMSPE: 0.254424 valid's rmse: 0.000901649   valid's RMSPE: 0.272984\n[350]   train's rmse: 0.000810509   train's RMSPE: 0.250896 valid's rmse: 0.000900796   valid's RMSPE: 0.272726\n[400]   train's rmse: 0.000799737   train's RMSPE: 0.247561 valid's rmse: 0.000901383   valid's RMSPE: 0.272903\nEarly stopping, best iteration is:\n[367]   train's rmse: 0.0008065 train's RMSPE: 0.249655 valid's rmse: 0.000900352   valid's RMSPE: 0.272591\nOur out of folds RMSPE is 0.285, compared to 0.2536966485935066, giving gain 0.031303351406493374\nOur cv fold scores are [0.297, 0.295, 0.282, 0.277, 0.273]\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000536062   train's RMSPE: 0.255047 valid's rmse: 0.000556521   valid's RMSPE: 0.264837\n[100]   train's rmse: 0.000507308   train's RMSPE: 0.241367 valid's rmse: 0.000537848   valid's RMSPE: 0.255951\n[150]   train's rmse: 0.000493843   train's RMSPE: 0.234961 valid's rmse: 0.000533952   valid's RMSPE: 0.254097\n[200]   train's rmse: 0.000483153   train's RMSPE: 0.229874 valid's rmse: 0.000532044   valid's RMSPE: 0.253189\n[250]   train's rmse: 0.000473997   train's RMSPE: 0.225518 valid's rmse: 0.000529497   valid's RMSPE: 0.251977\n[300]   train's rmse: 0.000466121   train's RMSPE: 0.221771 valid's rmse: 0.00052777    valid's RMSPE: 0.251155\n[350]   train's rmse: 0.00045898    train's RMSPE: 0.218373 valid's rmse: 0.000527188   valid's RMSPE: 0.250878\nEarly stopping, best iteration is:\n[343]   train's rmse: 0.000459974   train's RMSPE: 0.218846 valid's rmse: 0.000526687   valid's RMSPE: 0.25064\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000531538   train's RMSPE: 0.251207 valid's rmse: 0.000576619   valid's RMSPE: 0.281606\n[100]   train's rmse: 0.000503602   train's RMSPE: 0.238004 valid's rmse: 0.000553999   valid's RMSPE: 0.270559\n[150]   train's rmse: 0.000491509   train's RMSPE: 0.232289 valid's rmse: 0.00054868    valid's RMSPE: 0.267962\n[200]   train's rmse: 0.00048179    train's RMSPE: 0.227696 valid's rmse: 0.00054582    valid's RMSPE: 0.266565\n[250]   train's rmse: 0.000473153   train's RMSPE: 0.223614 valid's rmse: 0.000543868   valid's RMSPE: 0.265611\n[300]   train's rmse: 0.000465569   train's RMSPE: 0.220029 valid's rmse: 0.000543908   valid's RMSPE: 0.265631\n[350]   train's rmse: 0.000459523   train's RMSPE: 0.217172 valid's rmse: 0.00054318    valid's RMSPE: 0.265275\nEarly stopping, best iteration is:\n[318]   train's rmse: 0.000463382   train's RMSPE: 0.218996 valid's rmse: 0.000542336   valid's RMSPE: 0.264863\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000540811   train's RMSPE: 0.257667 valid's rmse: 0.000537245   valid's RMSPE: 0.254228\n[100]   train's rmse: 0.000512059   train's RMSPE: 0.243968 valid's rmse: 0.000516289   valid's RMSPE: 0.244312\n[150]   train's rmse: 0.000499235   train's RMSPE: 0.237858 valid's rmse: 0.000511427   valid's RMSPE: 0.242011\n[200]   train's rmse: 0.000488967   train's RMSPE: 0.232967 valid's rmse: 0.000508634   valid's RMSPE: 0.240689\n[250]   train's rmse: 0.000480632   train's RMSPE: 0.228995 valid's rmse: 0.000506873   valid's RMSPE: 0.239856\n[300]   train's rmse: 0.000472937   train's RMSPE: 0.225329 valid's rmse: 0.00050559    valid's RMSPE: 0.239249\nEarly stopping, best iteration is:\n[296]   train's rmse: 0.000473593   train's RMSPE: 0.225642 valid's rmse: 0.000505253   valid's RMSPE: 0.239089\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000542004   train's RMSPE: 0.25881  valid's rmse: 0.00052886    valid's RMSPE: 0.247988\n[100]   train's rmse: 0.000511057   train's RMSPE: 0.244033 valid's rmse: 0.000516908   valid's RMSPE: 0.242384\n[150]   train's rmse: 0.000498178   train's RMSPE: 0.237883 valid's rmse: 0.00051525    valid's RMSPE: 0.241606\n[200]   train's rmse: 0.000487235   train's RMSPE: 0.232658 valid's rmse: 0.000512017   valid's RMSPE: 0.24009\n[250]   train's rmse: 0.000477847   train's RMSPE: 0.228175 valid's rmse: 0.000511441   valid's RMSPE: 0.23982\n[300]   train's rmse: 0.000469718   train's RMSPE: 0.224294 valid's rmse: 0.00051087    valid's RMSPE: 0.239553\nEarly stopping, best iteration is:\n[277]   train's rmse: 0.000473253   train's RMSPE: 0.225981 valid's rmse: 0.00051038    valid's RMSPE: 0.239323\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000537171   train's RMSPE: 0.256042 valid's rmse: 0.000551229   valid's RMSPE: 0.260396\n[100]   train's rmse: 0.000509653   train's RMSPE: 0.242925 valid's rmse: 0.00053575    valid's RMSPE: 0.253084\n[150]   train's rmse: 0.000496625   train's RMSPE: 0.236716 valid's rmse: 0.00053219    valid's RMSPE: 0.251402\n[200]   train's rmse: 0.000486308   train's RMSPE: 0.231798 valid's rmse: 0.000531072   valid's RMSPE: 0.250874\n[250]   train's rmse: 0.000477364   train's RMSPE: 0.227534 valid's rmse: 0.000528655   valid's RMSPE: 0.249732\n[300]   train's rmse: 0.000470305   train's RMSPE: 0.22417  valid's rmse: 0.000525923   valid's RMSPE: 0.248442\n[350]   train's rmse: 0.000463917   train's RMSPE: 0.221125 valid's rmse: 0.000523626   valid's RMSPE: 0.247356\n[400]   train's rmse: 0.000457398   train's RMSPE: 0.218018 valid's rmse: 0.000521483   valid's RMSPE: 0.246344\n[450]   train's rmse: 0.000451882   train's RMSPE: 0.215389 valid's rmse: 0.000520633   valid's RMSPE: 0.245943\n[500]   train's rmse: 0.000446936   train's RMSPE: 0.213031 valid's rmse: 0.000521024   valid's RMSPE: 0.246127\nEarly stopping, best iteration is:\n[490]   train's rmse: 0.000447898   train's RMSPE: 0.21349  valid's rmse: 0.000519915   valid's RMSPE: 0.245604\nOur out of folds RMSPE is 0.248, compared to 0.21260165312455714, giving gain 0.035398346875442854\nOur cv fold scores are [0.251, 0.265, 0.239, 0.239, 0.246]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000439165   train's RMSPE: 0.252688 valid's rmse: 0.000479389   valid's RMSPE: 0.270325\n[100]   train's rmse: 0.000414394   train's RMSPE: 0.238435 valid's rmse: 0.000464213   valid's RMSPE: 0.261768\n[150]   train's rmse: 0.000401211   train's RMSPE: 0.23085  valid's rmse: 0.000458946   valid's RMSPE: 0.258797\n[200]   train's rmse: 0.000390959   train's RMSPE: 0.224951 valid's rmse: 0.000455571   valid's RMSPE: 0.256895\n[250]   train's rmse: 0.000383124   train's RMSPE: 0.220443 valid's rmse: 0.000452811   valid's RMSPE: 0.255338\n[300]   train's rmse: 0.00037617    train's RMSPE: 0.216442 valid's rmse: 0.000451373   valid's RMSPE: 0.254527\n[350]   train's rmse: 0.000369982   train's RMSPE: 0.212881 valid's rmse: 0.000448524   valid's RMSPE: 0.252921\n[400]   train's rmse: 0.000364317   train's RMSPE: 0.209622 valid's rmse: 0.000447388   valid's RMSPE: 0.25228\n[450]   train's rmse: 0.000359514   train's RMSPE: 0.206858 valid's rmse: 0.000445766   valid's RMSPE: 0.251365\n[500]   train's rmse: 0.000355138   train's RMSPE: 0.20434  valid's rmse: 0.000444776   valid's RMSPE: 0.250807\nEarly stopping, best iteration is:\n[478]   train's rmse: 0.000356887   train's RMSPE: 0.205347 valid's rmse: 0.000444446   valid's RMSPE: 0.250621\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.0004394 train's RMSPE: 0.25136  valid's rmse: 0.000491127   valid's RMSPE: 0.283523\n[100]   train's rmse: 0.000415272   train's RMSPE: 0.237558 valid's rmse: 0.000474338   valid's RMSPE: 0.273831\n[150]   train's rmse: 0.0004029 train's RMSPE: 0.23048  valid's rmse: 0.000468825   valid's RMSPE: 0.270648\n[200]   train's rmse: 0.000394155   train's RMSPE: 0.225477 valid's rmse: 0.000467687   valid's RMSPE: 0.269991\n[250]   train's rmse: 0.000386823   train's RMSPE: 0.221283 valid's rmse: 0.000464327   valid's RMSPE: 0.268052\n[300]   train's rmse: 0.000379658   train's RMSPE: 0.217184 valid's rmse: 0.000462317   valid's RMSPE: 0.266891\n[350]   train's rmse: 0.000374017   train's RMSPE: 0.213957 valid's rmse: 0.000464816   valid's RMSPE: 0.268334\nEarly stopping, best iteration is:\n[300]   train's rmse: 0.000379658   train's RMSPE: 0.217184 valid's rmse: 0.000462317   valid's RMSPE: 0.266891\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000447261   train's RMSPE: 0.255867 valid's rmse: 0.000446094   valid's RMSPE: 0.257487\n[100]   train's rmse: 0.000421214   train's RMSPE: 0.240966 valid's rmse: 0.000427561   valid's RMSPE: 0.24679\n[150]   train's rmse: 0.000408875   train's RMSPE: 0.233907 valid's rmse: 0.000422775   valid's RMSPE: 0.244027\n[200]   train's rmse: 0.000399247   train's RMSPE: 0.228399 valid's rmse: 0.000420908   valid's RMSPE: 0.242949\n[250]   train's rmse: 0.000391346   train's RMSPE: 0.223879 valid's rmse: 0.000423089   valid's RMSPE: 0.244208\nEarly stopping, best iteration is:\n[200]   train's rmse: 0.000399247   train's RMSPE: 0.228399 valid's rmse: 0.000420908   valid's RMSPE: 0.242949\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000452847   train's RMSPE: 0.259342 valid's rmse: 0.000425657   valid's RMSPE: 0.244645\n[100]   train's rmse: 0.000426417   train's RMSPE: 0.244206 valid's rmse: 0.000415679   valid's RMSPE: 0.238911\n[150]   train's rmse: 0.000412752   train's RMSPE: 0.23638  valid's rmse: 0.000413852   valid's RMSPE: 0.23786\n[200]   train's rmse: 0.000401653   train's RMSPE: 0.230024 valid's rmse: 0.000413878   valid's RMSPE: 0.237875\nEarly stopping, best iteration is:\n[186]   train's rmse: 0.000404755   train's RMSPE: 0.2318   valid's rmse: 0.000412875   valid's RMSPE: 0.237299\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000449411   train's RMSPE: 0.257652 valid's rmse: 0.000439338   valid's RMSPE: 0.251423\n[100]   train's rmse: 0.000423167   train's RMSPE: 0.242606 valid's rmse: 0.000425349   valid's RMSPE: 0.243417\n[150]   train's rmse: 0.000409754   train's RMSPE: 0.234917 valid's rmse: 0.000420392   valid's RMSPE: 0.240581\n[200]   train's rmse: 0.000400763   train's RMSPE: 0.229762 valid's rmse: 0.000418058   valid's RMSPE: 0.239245\n[250]   train's rmse: 0.000393165   train's RMSPE: 0.225406 valid's rmse: 0.000415751   valid's RMSPE: 0.237925\n[300]   train's rmse: 0.000386051   train's RMSPE: 0.221327 valid's rmse: 0.000413183   valid's RMSPE: 0.236455\n[350]   train's rmse: 0.000380191   train's RMSPE: 0.217967 valid's rmse: 0.0004126 valid's RMSPE: 0.236121\nEarly stopping, best iteration is:\n[326]   train's rmse: 0.000382753   train's RMSPE: 0.219436 valid's rmse: 0.000411749   valid's RMSPE: 0.235634\nOur out of folds RMSPE is 0.247, compared to 0.20796490181588065, giving gain 0.03903509818411935\nOur cv fold scores are [0.251, 0.267, 0.243, 0.237, 0.236]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000503507   train's RMSPE: 0.260534 valid's rmse: 0.00054317    valid's RMSPE: 0.279398\n[100]   train's rmse: 0.000478479   train's RMSPE: 0.247583 valid's rmse: 0.000528356   valid's RMSPE: 0.271778\n[150]   train's rmse: 0.000466056   train's RMSPE: 0.241155 valid's rmse: 0.00052486    valid's RMSPE: 0.26998\n[200]   train's rmse: 0.000457524   train's RMSPE: 0.236741 valid's rmse: 0.000522172   valid's RMSPE: 0.268597\n[250]   train's rmse: 0.000448672   train's RMSPE: 0.23216  valid's rmse: 0.000520784   valid's RMSPE: 0.267883\n[300]   train's rmse: 0.000442068   train's RMSPE: 0.228743 valid's rmse: 0.000520434   valid's RMSPE: 0.267703\n[350]   train's rmse: 0.000435515   train's RMSPE: 0.225352 valid's rmse: 0.000518646   valid's RMSPE: 0.266783\n[400]   train's rmse: 0.000430752   train's RMSPE: 0.222888 valid's rmse: 0.00051799    valid's RMSPE: 0.266446\n[450]   train's rmse: 0.00042542    train's RMSPE: 0.220128 valid's rmse: 0.00051713    valid's RMSPE: 0.266004\n[500]   train's rmse: 0.000421101   train's RMSPE: 0.217894 valid's rmse: 0.000517652   valid's RMSPE: 0.266272\nEarly stopping, best iteration is:\n[454]   train's rmse: 0.000425145   train's RMSPE: 0.219986 valid's rmse: 0.000517097   valid's RMSPE: 0.265987\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000507374   train's RMSPE: 0.260832 valid's rmse: 0.000539737   valid's RMSPE: 0.284803\n[100]   train's rmse: 0.000482809   train's RMSPE: 0.248204 valid's rmse: 0.000521399   valid's RMSPE: 0.275126\n[150]   train's rmse: 0.000472751   train's RMSPE: 0.243033 valid's rmse: 0.000515243   valid's RMSPE: 0.271878\n[200]   train's rmse: 0.000463779   train's RMSPE: 0.238421 valid's rmse: 0.000510281   valid's RMSPE: 0.26926\n[250]   train's rmse: 0.00045605    train's RMSPE: 0.234447 valid's rmse: 0.000506411   valid's RMSPE: 0.267217\n[300]   train's rmse: 0.00044974    train's RMSPE: 0.231204 valid's rmse: 0.000505239   valid's RMSPE: 0.266599\n[350]   train's rmse: 0.000443647   train's RMSPE: 0.228071 valid's rmse: 0.000502559   valid's RMSPE: 0.265185\n[400]   train's rmse: 0.000438234   train's RMSPE: 0.225289 valid's rmse: 0.00050105    valid's RMSPE: 0.264389\n[450]   train's rmse: 0.00043303    train's RMSPE: 0.222613 valid's rmse: 0.000498849   valid's RMSPE: 0.263227\n[500]   train's rmse: 0.000428717   train's RMSPE: 0.220396 valid's rmse: 0.000498641   valid's RMSPE: 0.263117\n[550]   train's rmse: 0.00042445    train's RMSPE: 0.218202 valid's rmse: 0.000497775   valid's RMSPE: 0.262661\n[600]   train's rmse: 0.000420381   train's RMSPE: 0.216111 valid's rmse: 0.00049831    valid's RMSPE: 0.262943\nEarly stopping, best iteration is:\n[558]   train's rmse: 0.000423764   train's RMSPE: 0.21785  valid's rmse: 0.000497496   valid's RMSPE: 0.262514\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000510844   train's RMSPE: 0.264728 valid's rmse: 0.0005158 valid's RMSPE: 0.263699\n[100]   train's rmse: 0.000485359   train's RMSPE: 0.251521 valid's rmse: 0.000499678   valid's RMSPE: 0.255458\n[150]   train's rmse: 0.000473574   train's RMSPE: 0.245413 valid's rmse: 0.000497183   valid's RMSPE: 0.254182\n[200]   train's rmse: 0.000464005   train's RMSPE: 0.240454 valid's rmse: 0.000495819   valid's RMSPE: 0.253485\n[250]   train's rmse: 0.000457067   train's RMSPE: 0.236859 valid's rmse: 0.000494881   valid's RMSPE: 0.253005\n[300]   train's rmse: 0.000450534   train's RMSPE: 0.233474 valid's rmse: 0.000493973   valid's RMSPE: 0.252541\n[350]   train's rmse: 0.000444374   train's RMSPE: 0.230282 valid's rmse: 0.000492954   valid's RMSPE: 0.25202\nEarly stopping, best iteration is:\n[340]   train's rmse: 0.000445446   train's RMSPE: 0.230837 valid's rmse: 0.000492659   valid's RMSPE: 0.251869\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000516952   train's RMSPE: 0.267016 valid's rmse: 0.000498668   valid's RMSPE: 0.25834\n[100]   train's rmse: 0.000491179   train's RMSPE: 0.253704 valid's rmse: 0.000479976   valid's RMSPE: 0.248657\n[150]   train's rmse: 0.000479503   train's RMSPE: 0.247673 valid's rmse: 0.000475231   valid's RMSPE: 0.246198\n[200]   train's rmse: 0.000470622   train's RMSPE: 0.243086 valid's rmse: 0.000471913   valid's RMSPE: 0.24448\n[250]   train's rmse: 0.000463052   train's RMSPE: 0.239176 valid's rmse: 0.000469848   valid's RMSPE: 0.24341\n[300]   train's rmse: 0.000456563   train's RMSPE: 0.235824 valid's rmse: 0.000467462   valid's RMSPE: 0.242174\n[350]   train's rmse: 0.000450605   train's RMSPE: 0.232746 valid's rmse: 0.000466948   valid's RMSPE: 0.241908\n[400]   train's rmse: 0.000445338   train's RMSPE: 0.230026 valid's rmse: 0.000466753   valid's RMSPE: 0.241806\n[450]   train's rmse: 0.000440628   train's RMSPE: 0.227593 valid's rmse: 0.000465722   valid's RMSPE: 0.241272\n[500]   train's rmse: 0.000436514   train's RMSPE: 0.225468 valid's rmse: 0.000466065   valid's RMSPE: 0.24145\nEarly stopping, best iteration is:\n[478]   train's rmse: 0.000438259   train's RMSPE: 0.22637  valid's rmse: 0.000465558   valid's RMSPE: 0.241187\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000513824   train's RMSPE: 0.266097 valid's rmse: 0.00050859    valid's RMSPE: 0.260712\n[100]   train's rmse: 0.000488257   train's RMSPE: 0.252857 valid's rmse: 0.00049243    valid's RMSPE: 0.252428\n[150]   train's rmse: 0.000476587   train's RMSPE: 0.246813 valid's rmse: 0.000490573   valid's RMSPE: 0.251476\n[200]   train's rmse: 0.000467406   train's RMSPE: 0.242059 valid's rmse: 0.000490556   valid's RMSPE: 0.251467\n[250]   train's rmse: 0.000459854   train's RMSPE: 0.238147 valid's rmse: 0.000490108   valid's RMSPE: 0.251238\n[300]   train's rmse: 0.000453919   train's RMSPE: 0.235074 valid's rmse: 0.00048856    valid's RMSPE: 0.250444\nEarly stopping, best iteration is:\n[283]   train's rmse: 0.000456043   train's RMSPE: 0.236174 valid's rmse: 0.00048849    valid's RMSPE: 0.250408\nOur out of folds RMSPE is 0.255, compared to 0.21163535841016978, giving gain 0.04336464158983022\nOur cv fold scores are [0.266, 0.263, 0.252, 0.241, 0.25]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000433375   train's RMSPE: 0.229555 valid's rmse: 0.00045624    valid's RMSPE: 0.241402\n[100]   train's rmse: 0.000403805   train's RMSPE: 0.213892 valid's rmse: 0.00043702    valid's RMSPE: 0.231232\n[150]   train's rmse: 0.000392654   train's RMSPE: 0.207986 valid's rmse: 0.000432894   valid's RMSPE: 0.229049\n[200]   train's rmse: 0.000383119   train's RMSPE: 0.202935 valid's rmse: 0.0004298 valid's RMSPE: 0.227412\n[250]   train's rmse: 0.000375938   train's RMSPE: 0.199131 valid's rmse: 0.000427535   valid's RMSPE: 0.226214\n[300]   train's rmse: 0.000370307   train's RMSPE: 0.196149 valid's rmse: 0.000426193   valid's RMSPE: 0.225504\n[350]   train's rmse: 0.000364909   train's RMSPE: 0.19329  valid's rmse: 0.000424804   valid's RMSPE: 0.224769\nEarly stopping, best iteration is:\n[336]   train's rmse: 0.000366384   train's RMSPE: 0.194071 valid's rmse: 0.000424498   valid's RMSPE: 0.224607\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00042737    train's RMSPE: 0.22477  valid's rmse: 0.000475478   valid's RMSPE: 0.258607\n[100]   train's rmse: 0.000399756   train's RMSPE: 0.210247 valid's rmse: 0.000453635   valid's RMSPE: 0.246727\n[150]   train's rmse: 0.000388703   train's RMSPE: 0.204433 valid's rmse: 0.000448455   valid's RMSPE: 0.243909\n[200]   train's rmse: 0.000380114   train's RMSPE: 0.199916 valid's rmse: 0.000443813   valid's RMSPE: 0.241385\n[250]   train's rmse: 0.000373631   train's RMSPE: 0.196507 valid's rmse: 0.000441216   valid's RMSPE: 0.239972\n[300]   train's rmse: 0.000368436   train's RMSPE: 0.193774 valid's rmse: 0.000439266   valid's RMSPE: 0.238912\n[350]   train's rmse: 0.000363181   train's RMSPE: 0.19101  valid's rmse: 0.000437668   valid's RMSPE: 0.238043\n[400]   train's rmse: 0.00035812    train's RMSPE: 0.188349 valid's rmse: 0.000435305   valid's RMSPE: 0.236757\n[450]   train's rmse: 0.000353328   train's RMSPE: 0.185828 valid's rmse: 0.000433711   valid's RMSPE: 0.235891\n[500]   train's rmse: 0.000348833   train's RMSPE: 0.183464 valid's rmse: 0.000432343   valid's RMSPE: 0.235146\n[550]   train's rmse: 0.000345507   train's RMSPE: 0.181715 valid's rmse: 0.000432291   valid's RMSPE: 0.235118\n[600]   train's rmse: 0.000341286   train's RMSPE: 0.179495 valid's rmse: 0.000431064   valid's RMSPE: 0.234451\n[650]   train's rmse: 0.0003376 train's RMSPE: 0.177557 valid's rmse: 0.000430486   valid's RMSPE: 0.234136\n[700]   train's rmse: 0.000334336   train's RMSPE: 0.17584  valid's rmse: 0.000430166   valid's RMSPE: 0.233962\n[750]   train's rmse: 0.000330808   train's RMSPE: 0.173984 valid's rmse: 0.000429387   valid's RMSPE: 0.233538\n[800]   train's rmse: 0.000327718   train's RMSPE: 0.172359 valid's rmse: 0.000428997   valid's RMSPE: 0.233327\n[850]   train's rmse: 0.000324688   train's RMSPE: 0.170766 valid's rmse: 0.000427411   valid's RMSPE: 0.232464\n[900]   train's rmse: 0.000321891   train's RMSPE: 0.169295 valid's rmse: 0.000426791   valid's RMSPE: 0.232127\n[950]   train's rmse: 0.00031925    train's RMSPE: 0.167906 valid's rmse: 0.000427177   valid's RMSPE: 0.232337\nEarly stopping, best iteration is:\n[917]   train's rmse: 0.000321015   train's RMSPE: 0.168834 valid's rmse: 0.000426489   valid's RMSPE: 0.231962\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000438611   train's RMSPE: 0.231376 valid's rmse: 0.00042281    valid's RMSPE: 0.227356\n[100]   train's rmse: 0.000411008   train's RMSPE: 0.216815 valid's rmse: 0.000406819   valid's RMSPE: 0.218757\n[150]   train's rmse: 0.000400153   train's RMSPE: 0.211089 valid's rmse: 0.000405418   valid's RMSPE: 0.218003\n[200]   train's rmse: 0.000391696   train's RMSPE: 0.206628 valid's rmse: 0.000402529   valid's RMSPE: 0.21645\n[250]   train's rmse: 0.000384726   train's RMSPE: 0.202951 valid's rmse: 0.000401444   valid's RMSPE: 0.215867\n[300]   train's rmse: 0.000378421   train's RMSPE: 0.199624 valid's rmse: 0.000401839   valid's RMSPE: 0.216079\nEarly stopping, best iteration is:\n[288]   train's rmse: 0.000379659   train's RMSPE: 0.200278 valid's rmse: 0.000400391   valid's RMSPE: 0.2153\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000434816   train's RMSPE: 0.231222 valid's rmse: 0.000421672   valid's RMSPE: 0.219571\n[100]   train's rmse: 0.000405794   train's RMSPE: 0.215789 valid's rmse: 0.000402741   valid's RMSPE: 0.209713\n[150]   train's rmse: 0.000395559   train's RMSPE: 0.210346 valid's rmse: 0.000399115   valid's RMSPE: 0.207825\n[200]   train's rmse: 0.000387121   train's RMSPE: 0.205859 valid's rmse: 0.000397773   valid's RMSPE: 0.207126\n[250]   train's rmse: 0.000380664   train's RMSPE: 0.202425 valid's rmse: 0.000396449   valid's RMSPE: 0.206437\n[300]   train's rmse: 0.000374477   train's RMSPE: 0.199135 valid's rmse: 0.000394271   valid's RMSPE: 0.205302\nEarly stopping, best iteration is:\n[294]   train's rmse: 0.000374994   train's RMSPE: 0.19941  valid's rmse: 0.00039382    valid's RMSPE: 0.205068\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000432958   train's RMSPE: 0.230737 valid's rmse: 0.000451296   valid's RMSPE: 0.23284\n[100]   train's rmse: 0.000404783   train's RMSPE: 0.215722 valid's rmse: 0.000431534   valid's RMSPE: 0.222644\n[150]   train's rmse: 0.000393327   train's RMSPE: 0.209616 valid's rmse: 0.000428089   valid's RMSPE: 0.220867\n[200]   train's rmse: 0.000384807   train's RMSPE: 0.205076 valid's rmse: 0.000425706   valid's RMSPE: 0.219637\n[250]   train's rmse: 0.000377397   train's RMSPE: 0.201127 valid's rmse: 0.000424342   valid's RMSPE: 0.218933\n[300]   train's rmse: 0.000371229   train's RMSPE: 0.19784  valid's rmse: 0.00042253    valid's RMSPE: 0.217999\n[350]   train's rmse: 0.000365518   train's RMSPE: 0.194796 valid's rmse: 0.000420799   valid's RMSPE: 0.217105\n[400]   train's rmse: 0.000360235   train's RMSPE: 0.191981 valid's rmse: 0.000419049   valid's RMSPE: 0.216202\n[450]   train's rmse: 0.000355567   train's RMSPE: 0.189493 valid's rmse: 0.000418681   valid's RMSPE: 0.216013\n[500]   train's rmse: 0.000351014   train's RMSPE: 0.187067 valid's rmse: 0.000418437   valid's RMSPE: 0.215887\n[550]   train's rmse: 0.000347028   train's RMSPE: 0.184942 valid's rmse: 0.000417637   valid's RMSPE: 0.215474\n[600]   train's rmse: 0.000343617   train's RMSPE: 0.183125 valid's rmse: 0.000416684   valid's RMSPE: 0.214983\n[650]   train's rmse: 0.000340005   train's RMSPE: 0.1812   valid's rmse: 0.000416126   valid's RMSPE: 0.214695\n[700]   train's rmse: 0.000336943   train's RMSPE: 0.179568 valid's rmse: 0.000415695   valid's RMSPE: 0.214472\n[750]   train's rmse: 0.00033398    train's RMSPE: 0.177989 valid's rmse: 0.000415077   valid's RMSPE: 0.214154\n[800]   train's rmse: 0.000330791   train's RMSPE: 0.176289 valid's rmse: 0.000415161   valid's RMSPE: 0.214197\nEarly stopping, best iteration is:\n[781]   train's rmse: 0.000331922   train's RMSPE: 0.176892 valid's rmse: 0.000414799   valid's RMSPE: 0.21401\nOur out of folds RMSPE is 0.218, compared to 0.19523224853251037, giving gain 0.022767751467489633\nOur cv fold scores are [0.225, 0.232, 0.215, 0.205, 0.214]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000588643   train's RMSPE: 0.214405 valid's rmse: 0.000632458   valid's RMSPE: 0.226375\n[100]   train's rmse: 0.000552954   train's RMSPE: 0.201406 valid's rmse: 0.000598578   valid's RMSPE: 0.214248\n[150]   train's rmse: 0.000539354   train's RMSPE: 0.196452 valid's rmse: 0.000594393   valid's RMSPE: 0.21275\n[200]   train's rmse: 0.000528396   train's RMSPE: 0.192461 valid's rmse: 0.000592854   valid's RMSPE: 0.212199\n[250]   train's rmse: 0.000518421   train's RMSPE: 0.188828 valid's rmse: 0.0005899 valid's RMSPE: 0.211142\n[300]   train's rmse: 0.000509764   train's RMSPE: 0.185675 valid's rmse: 0.000589761   valid's RMSPE: 0.211092\nEarly stopping, best iteration is:\n[270]   train's rmse: 0.000514584   train's RMSPE: 0.18743  valid's rmse: 0.000588924   valid's RMSPE: 0.210793\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000583894   train's RMSPE: 0.211197 valid's rmse: 0.000630341   valid's RMSPE: 0.232002\n[100]   train's rmse: 0.000548864   train's RMSPE: 0.198526 valid's rmse: 0.00061083    valid's RMSPE: 0.224821\n[150]   train's rmse: 0.000535658   train's RMSPE: 0.19375  valid's rmse: 0.000608887   valid's RMSPE: 0.224106\nEarly stopping, best iteration is:\n[137]   train's rmse: 0.000538426   train's RMSPE: 0.194751 valid's rmse: 0.000608062   valid's RMSPE: 0.223802\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000590394   train's RMSPE: 0.212985 valid's rmse: 0.000592535   valid's RMSPE: 0.220293\n[100]   train's rmse: 0.000555686   train's RMSPE: 0.200464 valid's rmse: 0.000571374   valid's RMSPE: 0.212426\n[150]   train's rmse: 0.000541474   train's RMSPE: 0.195337 valid's rmse: 0.000567507   valid's RMSPE: 0.210988\n[200]   train's rmse: 0.000530199   train's RMSPE: 0.19127  valid's rmse: 0.000565001   valid's RMSPE: 0.210057\n[250]   train's rmse: 0.000520766   train's RMSPE: 0.187867 valid's rmse: 0.000562367   valid's RMSPE: 0.209077\n[300]   train's rmse: 0.000513234   train's RMSPE: 0.18515  valid's rmse: 0.000561955   valid's RMSPE: 0.208924\n[350]   train's rmse: 0.000506091   train's RMSPE: 0.182573 valid's rmse: 0.000559889   valid's RMSPE: 0.208156\n[400]   train's rmse: 0.000500168   train's RMSPE: 0.180436 valid's rmse: 0.000559947   valid's RMSPE: 0.208177\n[450]   train's rmse: 0.000494255   train's RMSPE: 0.178303 valid's rmse: 0.000558807   valid's RMSPE: 0.207754\n[500]   train's rmse: 0.000488621   train's RMSPE: 0.17627  valid's rmse: 0.000557885   valid's RMSPE: 0.207411\n[550]   train's rmse: 0.000482765   train's RMSPE: 0.174158 valid's rmse: 0.000556827   valid's RMSPE: 0.207018\nEarly stopping, best iteration is:\n[545]   train's rmse: 0.000483254   train's RMSPE: 0.174334 valid's rmse: 0.00055655    valid's RMSPE: 0.206914\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000600096   train's RMSPE: 0.21824  valid's rmse: 0.000564049   valid's RMSPE: 0.203173\n[100]   train's rmse: 0.000564882   train's RMSPE: 0.205434 valid's rmse: 0.000537837   valid's RMSPE: 0.193731\n[150]   train's rmse: 0.000550604   train's RMSPE: 0.200241 valid's rmse: 0.00053228    valid's RMSPE: 0.19173\n[200]   train's rmse: 0.000540095   train's RMSPE: 0.196419 valid's rmse: 0.000531757   valid's RMSPE: 0.191541\n[250]   train's rmse: 0.000530591   train's RMSPE: 0.192963 valid's rmse: 0.000531029   valid's RMSPE: 0.191279\nEarly stopping, best iteration is:\n[234]   train's rmse: 0.000532835   train's RMSPE: 0.193779 valid's rmse: 0.000530068   valid's RMSPE: 0.190933\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000589744   train's RMSPE: 0.214983 valid's rmse: 0.000608195   valid's RMSPE: 0.216946\n[100]   train's rmse: 0.000557254   train's RMSPE: 0.203139 valid's rmse: 0.000591399   valid's RMSPE: 0.210955\n[150]   train's rmse: 0.000543523   train's RMSPE: 0.198134 valid's rmse: 0.000587386   valid's RMSPE: 0.209523\n[200]   train's rmse: 0.000532058   train's RMSPE: 0.193955 valid's rmse: 0.000583415   valid's RMSPE: 0.208107\n[250]   train's rmse: 0.000522554   train's RMSPE: 0.19049  valid's rmse: 0.000582749   valid's RMSPE: 0.207869\n[300]   train's rmse: 0.000514292   train's RMSPE: 0.187478 valid's rmse: 0.000580868   valid's RMSPE: 0.207198\n[350]   train's rmse: 0.000507252   train's RMSPE: 0.184912 valid's rmse: 0.00058048    valid's RMSPE: 0.20706\n[400]   train's rmse: 0.000499927   train's RMSPE: 0.182242 valid's rmse: 0.000579566   valid's RMSPE: 0.206734\nEarly stopping, best iteration is:\n[370]   train's rmse: 0.000503788   train's RMSPE: 0.183649 valid's rmse: 0.000578956   valid's RMSPE: 0.206516\nOur out of folds RMSPE is 0.208, compared to 0.1811865306676827, giving gain 0.02681346933231729\nOur cv fold scores are [0.211, 0.224, 0.207, 0.191, 0.207]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000828059   train's RMSPE: 0.285577 valid's rmse: 0.000875455   valid's RMSPE: 0.302489\n[100]   train's rmse: 0.000785564   train's RMSPE: 0.270922 valid's rmse: 0.000846632   valid's RMSPE: 0.29253\n[150]   train's rmse: 0.000759608   train's RMSPE: 0.26197  valid's rmse: 0.000843559   valid's RMSPE: 0.291468\n[200]   train's rmse: 0.000737796   train's RMSPE: 0.254448 valid's rmse: 0.000840126   valid's RMSPE: 0.290282\n[250]   train's rmse: 0.00071884    train's RMSPE: 0.24791  valid's rmse: 0.000840422   valid's RMSPE: 0.290384\nEarly stopping, best iteration is:\n[224]   train's rmse: 0.000728133   train's RMSPE: 0.251115 valid's rmse: 0.00083791    valid's RMSPE: 0.289516\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000819872   train's RMSPE: 0.280178 valid's rmse: 0.000917117   valid's RMSPE: 0.328137\n[100]   train's rmse: 0.000778431   train's RMSPE: 0.266016 valid's rmse: 0.000906833   valid's RMSPE: 0.324457\n[150]   train's rmse: 0.000754373   train's RMSPE: 0.257794 valid's rmse: 0.000907306   valid's RMSPE: 0.324626\nEarly stopping, best iteration is:\n[126]   train's rmse: 0.000765034   train's RMSPE: 0.261438 valid's rmse: 0.000904  valid's RMSPE: 0.323444\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000826448   train's RMSPE: 0.285496 valid's rmse: 0.000838225   valid's RMSPE: 0.287698\n[100]   train's rmse: 0.000785556   train's RMSPE: 0.27137  valid's rmse: 0.000819586   valid's RMSPE: 0.281301\n[150]   train's rmse: 0.000758745   train's RMSPE: 0.262108 valid's rmse: 0.00081078    valid's RMSPE: 0.278278\n[200]   train's rmse: 0.000737886   train's RMSPE: 0.254902 valid's rmse: 0.000806716   valid's RMSPE: 0.276883\n[250]   train's rmse: 0.000721082   train's RMSPE: 0.249097 valid's rmse: 0.000802443   valid's RMSPE: 0.275417\n[300]   train's rmse: 0.000707205   train's RMSPE: 0.244303 valid's rmse: 0.000800247   valid's RMSPE: 0.274663\n[350]   train's rmse: 0.000694564   train's RMSPE: 0.239937 valid's rmse: 0.000800199   valid's RMSPE: 0.274647\n[400]   train's rmse: 0.000683634   train's RMSPE: 0.236161 valid's rmse: 0.000800307   valid's RMSPE: 0.274684\nEarly stopping, best iteration is:\n[388]   train's rmse: 0.000685841   train's RMSPE: 0.236923 valid's rmse: 0.000799342   valid's RMSPE: 0.274353\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000825374   train's RMSPE: 0.286134 valid's rmse: 0.000830391   valid's RMSPE: 0.280884\n[100]   train's rmse: 0.000781957   train's RMSPE: 0.271083 valid's rmse: 0.000828287   valid's RMSPE: 0.280172\nEarly stopping, best iteration is:\n[56]    train's rmse: 0.00081674    train's RMSPE: 0.283141 valid's rmse: 0.000826878   valid's RMSPE: 0.279695\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000831576   train's RMSPE: 0.287952 valid's rmse: 0.000828485   valid's RMSPE: 0.281591\n[100]   train's rmse: 0.000786615   train's RMSPE: 0.272383 valid's rmse: 0.000809903   valid's RMSPE: 0.275275\n[150]   train's rmse: 0.000762186   train's RMSPE: 0.263924 valid's rmse: 0.00080744    valid's RMSPE: 0.274438\n[200]   train's rmse: 0.000741595   train's RMSPE: 0.256794 valid's rmse: 0.000802298   valid's RMSPE: 0.272691\n[250]   train's rmse: 0.000724285   train's RMSPE: 0.2508   valid's rmse: 0.000801485   valid's RMSPE: 0.272414\n[300]   train's rmse: 0.000708604   train's RMSPE: 0.24537  valid's rmse: 0.000801874   valid's RMSPE: 0.272546\nEarly stopping, best iteration is:\n[283]   train's rmse: 0.00071399    train's RMSPE: 0.247235 valid's rmse: 0.000800565   valid's RMSPE: 0.272101\nOur out of folds RMSPE is 0.288, compared to 0.26987327978046927, giving gain 0.018126720219530712\nOur cv fold scores are [0.29, 0.323, 0.274, 0.28, 0.272]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000401699   train's RMSPE: 0.238643 valid's rmse: 0.000442377   valid's RMSPE: 0.264108\n[100]   train's rmse: 0.000381702   train's RMSPE: 0.226763 valid's rmse: 0.000427399   valid's RMSPE: 0.255166\n[150]   train's rmse: 0.000372053   train's RMSPE: 0.221031 valid's rmse: 0.000422513   valid's RMSPE: 0.252249\n[200]   train's rmse: 0.000364309   train's RMSPE: 0.21643  valid's rmse: 0.000419789   valid's RMSPE: 0.250623\n[250]   train's rmse: 0.000357183   train's RMSPE: 0.212197 valid's rmse: 0.000417128   valid's RMSPE: 0.249035\n[300]   train's rmse: 0.000350986   train's RMSPE: 0.208515 valid's rmse: 0.000416276   valid's RMSPE: 0.248525\nEarly stopping, best iteration is:\n[286]   train's rmse: 0.0003523 train's RMSPE: 0.209296 valid's rmse: 0.000415888   valid's RMSPE: 0.248294\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00040107    train's RMSPE: 0.238336 valid's rmse: 0.000441303   valid's RMSPE: 0.263177\n[100]   train's rmse: 0.000382854   train's RMSPE: 0.22751  valid's rmse: 0.000428899   valid's RMSPE: 0.25578\n[150]   train's rmse: 0.000373179   train's RMSPE: 0.221761 valid's rmse: 0.000422354   valid's RMSPE: 0.251876\n[200]   train's rmse: 0.000365913   train's RMSPE: 0.217444 valid's rmse: 0.000419233   valid's RMSPE: 0.250015\n[250]   train's rmse: 0.000359086   train's RMSPE: 0.213386 valid's rmse: 0.00041797    valid's RMSPE: 0.249262\n[300]   train's rmse: 0.00035322    train's RMSPE: 0.209901 valid's rmse: 0.000415528   valid's RMSPE: 0.247805\n[350]   train's rmse: 0.000348003   train's RMSPE: 0.206801 valid's rmse: 0.000414611   valid's RMSPE: 0.247259\n[400]   train's rmse: 0.000342748   train's RMSPE: 0.203678 valid's rmse: 0.000414033   valid's RMSPE: 0.246914\n[450]   train's rmse: 0.000338547   train's RMSPE: 0.201181 valid's rmse: 0.000413373   valid's RMSPE: 0.24652\n[500]   train's rmse: 0.000334521   train's RMSPE: 0.198789 valid's rmse: 0.000412112   valid's RMSPE: 0.245768\n[550]   train's rmse: 0.000330751   train's RMSPE: 0.196549 valid's rmse: 0.000412329   valid's RMSPE: 0.245898\nEarly stopping, best iteration is:\n[515]   train's rmse: 0.000333217   train's RMSPE: 0.198014 valid's rmse: 0.000411795   valid's RMSPE: 0.245579\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000409759   train's RMSPE: 0.243841 valid's rmse: 0.000403405   valid's RMSPE: 0.239232\n[100]   train's rmse: 0.000389356   train's RMSPE: 0.231699 valid's rmse: 0.000390009   valid's RMSPE: 0.231288\n[150]   train's rmse: 0.000379678   train's RMSPE: 0.22594  valid's rmse: 0.000387197   valid's RMSPE: 0.22962\n[200]   train's rmse: 0.000372009   train's RMSPE: 0.221376 valid's rmse: 0.000386535   valid's RMSPE: 0.229227\n[250]   train's rmse: 0.000365835   train's RMSPE: 0.217702 valid's rmse: 0.000386416   valid's RMSPE: 0.229157\n[300]   train's rmse: 0.000359289   train's RMSPE: 0.213806 valid's rmse: 0.000384125   valid's RMSPE: 0.227798\n[350]   train's rmse: 0.000354118   train's RMSPE: 0.210729 valid's rmse: 0.000382998   valid's RMSPE: 0.22713\n[400]   train's rmse: 0.00034945    train's RMSPE: 0.207952 valid's rmse: 0.000381971   valid's RMSPE: 0.226521\n[450]   train's rmse: 0.000345218   train's RMSPE: 0.205433 valid's rmse: 0.000381386   valid's RMSPE: 0.226174\nEarly stopping, best iteration is:\n[439]   train's rmse: 0.000346155   train's RMSPE: 0.205991 valid's rmse: 0.000380787   valid's RMSPE: 0.225819\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00041328    train's RMSPE: 0.244716 valid's rmse: 0.000403752   valid's RMSPE: 0.244161\n[100]   train's rmse: 0.000390543   train's RMSPE: 0.231253 valid's rmse: 0.000392447   valid's RMSPE: 0.237324\n[150]   train's rmse: 0.000380581   train's RMSPE: 0.225354 valid's rmse: 0.000389765   valid's RMSPE: 0.235703\n[200]   train's rmse: 0.000372851   train's RMSPE: 0.220777 valid's rmse: 0.000390688   valid's RMSPE: 0.236261\nEarly stopping, best iteration is:\n[162]   train's rmse: 0.000378702   train's RMSPE: 0.224241 valid's rmse: 0.000389193   valid's RMSPE: 0.235357\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000412835   train's RMSPE: 0.246794 valid's rmse: 0.000392099   valid's RMSPE: 0.228197\n[100]   train's rmse: 0.00039232    train's RMSPE: 0.234529 valid's rmse: 0.000382783   valid's RMSPE: 0.222775\n[150]   train's rmse: 0.000382831   train's RMSPE: 0.228857 valid's rmse: 0.00038023    valid's RMSPE: 0.221289\n[200]   train's rmse: 0.000375149   train's RMSPE: 0.224265 valid's rmse: 0.000378333   valid's RMSPE: 0.220185\n[250]   train's rmse: 0.000368589   train's RMSPE: 0.220343 valid's rmse: 0.00037679    valid's RMSPE: 0.219287\n[300]   train's rmse: 0.000362429   train's RMSPE: 0.21666  valid's rmse: 0.000375708   valid's RMSPE: 0.218658\n[350]   train's rmse: 0.000357127   train's RMSPE: 0.213491 valid's rmse: 0.000375145   valid's RMSPE: 0.21833\n[400]   train's rmse: 0.000352025   train's RMSPE: 0.210441 valid's rmse: 0.00037431    valid's RMSPE: 0.217844\n[450]   train's rmse: 0.000347068   train's RMSPE: 0.207478 valid's rmse: 0.00037353    valid's RMSPE: 0.21739\nEarly stopping, best iteration is:\n[442]   train's rmse: 0.000347861   train's RMSPE: 0.207952 valid's rmse: 0.000373179   valid's RMSPE: 0.217186\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.235, compared to 0.19908949320829297, giving gain 0.035910506791707014\nOur cv fold scores are [0.248, 0.246, 0.226, 0.235, 0.217]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000966531   train's RMSPE: 0.275754 valid's rmse: 0.00105617    valid's RMSPE: 0.296353\n[100]   train's rmse: 0.000926933   train's RMSPE: 0.264456 valid's rmse: 0.00104278    valid's RMSPE: 0.292595\n[150]   train's rmse: 0.000905197   train's RMSPE: 0.258255 valid's rmse: 0.0010355 valid's RMSPE: 0.290553\n[200]   train's rmse: 0.000887828   train's RMSPE: 0.2533   valid's rmse: 0.0010311 valid's RMSPE: 0.289318\nEarly stopping, best iteration is:\n[181]   train's rmse: 0.000894182   train's RMSPE: 0.255112 valid's rmse: 0.00103097    valid's RMSPE: 0.289281\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000970586   train's RMSPE: 0.274907 valid's rmse: 0.00102836    valid's RMSPE: 0.297029\n[100]   train's rmse: 0.000927383   train's RMSPE: 0.26267  valid's rmse: 0.00100859    valid's RMSPE: 0.291317\n[150]   train's rmse: 0.000905226   train's RMSPE: 0.256394 valid's rmse: 0.00100616    valid's RMSPE: 0.290617\nEarly stopping, best iteration is:\n[135]   train's rmse: 0.000910893   train's RMSPE: 0.258    valid's rmse: 0.00100293    valid's RMSPE: 0.289684\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000974903   train's RMSPE: 0.275911 valid's rmse: 0.000992712   valid's RMSPE: 0.287602\n[100]   train's rmse: 0.000930237   train's RMSPE: 0.26327  valid's rmse: 0.000978206   valid's RMSPE: 0.283399\nEarly stopping, best iteration is:\n[85]    train's rmse: 0.000939181   train's RMSPE: 0.265802 valid's rmse: 0.000975098   valid's RMSPE: 0.282499\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000977923   train's RMSPE: 0.279738 valid's rmse: 0.000984575   valid's RMSPE: 0.273238\n[100]   train's rmse: 0.00093269    train's RMSPE: 0.266799 valid's rmse: 0.000979423   valid's RMSPE: 0.271808\nEarly stopping, best iteration is:\n[67]    train's rmse: 0.000956192   train's RMSPE: 0.273522 valid's rmse: 0.000977365   valid's RMSPE: 0.271237\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000985914   train's RMSPE: 0.28021  valid's rmse: 0.000958301   valid's RMSPE: 0.273095\n[100]   train's rmse: 0.000945632   train's RMSPE: 0.268761 valid's rmse: 0.000924579   valid's RMSPE: 0.263485\n[150]   train's rmse: 0.000923084   train's RMSPE: 0.262353 valid's rmse: 0.000920747   valid's RMSPE: 0.262393\n[200]   train's rmse: 0.000903248   train's RMSPE: 0.256715 valid's rmse: 0.000914998   valid's RMSPE: 0.260755\n[250]   train's rmse: 0.000886836   train's RMSPE: 0.252051 valid's rmse: 0.000913484   valid's RMSPE: 0.260324\nEarly stopping, best iteration is:\n[237]   train's rmse: 0.000890544   train's RMSPE: 0.253104 valid's rmse: 0.000911979   valid's RMSPE: 0.259895\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.279, compared to 0.2556622422314529, giving gain 0.02333775776854713\nOur cv fold scores are [0.289, 0.29, 0.282, 0.271, 0.26]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000671503   train's RMSPE: 0.220092 valid's rmse: 0.000719438   valid's RMSPE: 0.231943\n[100]   train's rmse: 0.000636213   train's RMSPE: 0.208525 valid's rmse: 0.000697306   valid's RMSPE: 0.224807\n[150]   train's rmse: 0.000621263   train's RMSPE: 0.203625 valid's rmse: 0.000690653   valid's RMSPE: 0.222663\n[200]   train's rmse: 0.000608352   train's RMSPE: 0.199393 valid's rmse: 0.000687252   valid's RMSPE: 0.221566\n[250]   train's rmse: 0.000597091   train's RMSPE: 0.195702 valid's rmse: 0.000684716   valid's RMSPE: 0.220748\n[300]   train's rmse: 0.000587965   train's RMSPE: 0.192711 valid's rmse: 0.000684184   valid's RMSPE: 0.220577\nEarly stopping, best iteration is:\n[285]   train's rmse: 0.000590451   train's RMSPE: 0.193526 valid's rmse: 0.000682847   valid's RMSPE: 0.220146\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.00066924    train's RMSPE: 0.21754  valid's rmse: 0.000722351   valid's RMSPE: 0.240661\n[100]   train's rmse: 0.000634675   train's RMSPE: 0.206305 valid's rmse: 0.000704468   valid's RMSPE: 0.234703\n[150]   train's rmse: 0.00061944    train's RMSPE: 0.201353 valid's rmse: 0.000701847   valid's RMSPE: 0.23383\n[200]   train's rmse: 0.000606967   train's RMSPE: 0.197298 valid's rmse: 0.00069715    valid's RMSPE: 0.232265\n[250]   train's rmse: 0.000595439   train's RMSPE: 0.193551 valid's rmse: 0.000694832   valid's RMSPE: 0.231493\n[300]   train's rmse: 0.000585114   train's RMSPE: 0.190195 valid's rmse: 0.000691334   valid's RMSPE: 0.230328\n[350]   train's rmse: 0.000575865   train's RMSPE: 0.187188 valid's rmse: 0.000692137   valid's RMSPE: 0.230595\nEarly stopping, best iteration is:\n[315]   train's rmse: 0.000581916   train's RMSPE: 0.189155 valid's rmse: 0.000690336   valid's RMSPE: 0.229995\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00067624    train's RMSPE: 0.219908 valid's rmse: 0.00067761    valid's RMSPE: 0.225395\n[100]   train's rmse: 0.000641301   train's RMSPE: 0.208546 valid's rmse: 0.000654753   valid's RMSPE: 0.217792\n[150]   train's rmse: 0.000625732   train's RMSPE: 0.203483 valid's rmse: 0.000654127   valid's RMSPE: 0.217584\nEarly stopping, best iteration is:\n[109]   train's rmse: 0.000638302   train's RMSPE: 0.20757  valid's rmse: 0.000653182   valid's RMSPE: 0.21727\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000682478   train's RMSPE: 0.223354 valid's rmse: 0.000669191   valid's RMSPE: 0.217072\n[100]   train's rmse: 0.000647679   train's RMSPE: 0.211966 valid's rmse: 0.000652084   valid's RMSPE: 0.211523\n[150]   train's rmse: 0.000632179   train's RMSPE: 0.206893 valid's rmse: 0.000650607   valid's RMSPE: 0.211044\n[200]   train's rmse: 0.000619913   train's RMSPE: 0.202878 valid's rmse: 0.000647949   valid's RMSPE: 0.210182\n[250]   train's rmse: 0.000608501   train's RMSPE: 0.199144 valid's rmse: 0.000649252   valid's RMSPE: 0.210604\n[300]   train's rmse: 0.000599441   train's RMSPE: 0.196179 valid's rmse: 0.000648619   valid's RMSPE: 0.210399\nEarly stopping, best iteration is:\n[265]   train's rmse: 0.000605666   train's RMSPE: 0.198216 valid's rmse: 0.00064644    valid's RMSPE: 0.209692\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000676269   train's RMSPE: 0.221936 valid's rmse: 0.00067738    valid's RMSPE: 0.217227\n[100]   train's rmse: 0.00064433    train's RMSPE: 0.211455 valid's rmse: 0.000664445   valid's RMSPE: 0.213079\n[150]   train's rmse: 0.000629079   train's RMSPE: 0.20645  valid's rmse: 0.000661125   valid's RMSPE: 0.212014\n[200]   train's rmse: 0.000617246   train's RMSPE: 0.202567 valid's rmse: 0.00065925    valid's RMSPE: 0.211413\n[250]   train's rmse: 0.000606492   train's RMSPE: 0.199037 valid's rmse: 0.000657244   valid's RMSPE: 0.210769\n[300]   train's rmse: 0.000597002   train's RMSPE: 0.195923 valid's rmse: 0.000654204   valid's RMSPE: 0.209795\n[350]   train's rmse: 0.000588455   train's RMSPE: 0.193118 valid's rmse: 0.000653909   valid's RMSPE: 0.2097\n[400]   train's rmse: 0.000580104   train's RMSPE: 0.190377 valid's rmse: 0.000651924   valid's RMSPE: 0.209063\n[450]   train's rmse: 0.000573211   train's RMSPE: 0.188115 valid's rmse: 0.00065125    valid's RMSPE: 0.208847\n[500]   train's rmse: 0.000566745   train's RMSPE: 0.185993 valid's rmse: 0.000651571   valid's RMSPE: 0.20895\nEarly stopping, best iteration is:\n[453]   train's rmse: 0.000572761   train's RMSPE: 0.187967 valid's rmse: 0.000650945   valid's RMSPE: 0.20875\nOur out of folds RMSPE is 0.217, compared to 0.18802345650080163, giving gain 0.02897654349919837\nOur cv fold scores are [0.22, 0.23, 0.217, 0.21, 0.209]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000720035   train's RMSPE: 0.246997 valid's rmse: 0.000785814   valid's RMSPE: 0.265101\n[100]   train's rmse: 0.00068521    train's RMSPE: 0.235051 valid's rmse: 0.000762224   valid's RMSPE: 0.257142\n[150]   train's rmse: 0.000670944   train's RMSPE: 0.230157 valid's rmse: 0.000757917   valid's RMSPE: 0.255689\n[200]   train's rmse: 0.000658389   train's RMSPE: 0.225851 valid's rmse: 0.000754953   valid's RMSPE: 0.254689\n[250]   train's rmse: 0.000647975   train's RMSPE: 0.222278 valid's rmse: 0.000753617   valid's RMSPE: 0.254239\n[300]   train's rmse: 0.000638913   train's RMSPE: 0.21917  valid's rmse: 0.000751547   valid's RMSPE: 0.25354\n[350]   train's rmse: 0.000630726   train's RMSPE: 0.216361 valid's rmse: 0.000751759   valid's RMSPE: 0.253612\nEarly stopping, best iteration is:\n[327]   train's rmse: 0.000634364   train's RMSPE: 0.217609 valid's rmse: 0.000751162   valid's RMSPE: 0.25341\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000719354   train's RMSPE: 0.244942 valid's rmse: 0.000784767   valid's RMSPE: 0.272682\n[100]   train's rmse: 0.000686664   train's RMSPE: 0.233811 valid's rmse: 0.000758885   valid's RMSPE: 0.263689\n[150]   train's rmse: 0.000671218   train's RMSPE: 0.228551 valid's rmse: 0.000751434   valid's RMSPE: 0.2611\n[200]   train's rmse: 0.000657596   train's RMSPE: 0.223913 valid's rmse: 0.000745935   valid's RMSPE: 0.25919\n[250]   train's rmse: 0.00064678    train's RMSPE: 0.22023  valid's rmse: 0.000745549   valid's RMSPE: 0.259056\n[300]   train's rmse: 0.000638471   train's RMSPE: 0.217401 valid's rmse: 0.000743057   valid's RMSPE: 0.258189\n[350]   train's rmse: 0.000630213   train's RMSPE: 0.214589 valid's rmse: 0.000741062   valid's RMSPE: 0.257496\n[400]   train's rmse: 0.000621855   train's RMSPE: 0.211743 valid's rmse: 0.000742353   valid's RMSPE: 0.257945\nEarly stopping, best iteration is:\n[362]   train's rmse: 0.000627535   train's RMSPE: 0.213677 valid's rmse: 0.000740873   valid's RMSPE: 0.257431\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000733308   train's RMSPE: 0.249725 valid's rmse: 0.000705627   valid's RMSPE: 0.245063\n[100]   train's rmse: 0.000699119   train's RMSPE: 0.238082 valid's rmse: 0.000687647   valid's RMSPE: 0.238818\n[150]   train's rmse: 0.000683053   train's RMSPE: 0.232611 valid's rmse: 0.000684786   valid's RMSPE: 0.237825\n[200]   train's rmse: 0.000670071   train's RMSPE: 0.22819  valid's rmse: 0.000681267   valid's RMSPE: 0.236603\nEarly stopping, best iteration is:\n[185]   train's rmse: 0.000672819   train's RMSPE: 0.229126 valid's rmse: 0.000680356   valid's RMSPE: 0.236286\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000733082   train's RMSPE: 0.251635 valid's rmse: 0.000717983   valid's RMSPE: 0.241571\n[100]   train's rmse: 0.000699778   train's RMSPE: 0.240203 valid's rmse: 0.000705037   valid's RMSPE: 0.237216\n[150]   train's rmse: 0.000683459   train's RMSPE: 0.234601 valid's rmse: 0.000703246   valid's RMSPE: 0.236613\nEarly stopping, best iteration is:\n[147]   train's rmse: 0.00068447    train's RMSPE: 0.234949 valid's rmse: 0.000703004   valid's RMSPE: 0.236532\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000729936   train's RMSPE: 0.249774 valid's rmse: 0.000723213   valid's RMSPE: 0.246463\n[100]   train's rmse: 0.000696083   train's RMSPE: 0.23819  valid's rmse: 0.000704774   valid's RMSPE: 0.240179\n[150]   train's rmse: 0.000678294   train's RMSPE: 0.232103 valid's rmse: 0.000698949   valid's RMSPE: 0.238194\n[200]   train's rmse: 0.000666239   train's RMSPE: 0.227978 valid's rmse: 0.00069628    valid's RMSPE: 0.237285\n[250]   train's rmse: 0.000654334   train's RMSPE: 0.223904 valid's rmse: 0.000695086   valid's RMSPE: 0.236878\n[300]   train's rmse: 0.000643867   train's RMSPE: 0.220322 valid's rmse: 0.000693432   valid's RMSPE: 0.236314\n[350]   train's rmse: 0.000635356   train's RMSPE: 0.21741  valid's rmse: 0.000693551   valid's RMSPE: 0.236355\nEarly stopping, best iteration is:\n[308]   train's rmse: 0.000642364   train's RMSPE: 0.219808 valid's rmse: 0.00069275    valid's RMSPE: 0.236082\nOur out of folds RMSPE is 0.244, compared to 0.20085218354438011, giving gain 0.04314781645561988\nOur cv fold scores are [0.253, 0.257, 0.236, 0.237, 0.236]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000483198   train's RMSPE: 0.247469 valid's rmse: 0.000514765   valid's RMSPE: 0.260316\n[100]   train's rmse: 0.000459823   train's RMSPE: 0.235497 valid's rmse: 0.000501464   valid's RMSPE: 0.253589\n[150]   train's rmse: 0.000449864   train's RMSPE: 0.230397 valid's rmse: 0.000498144   valid's RMSPE: 0.25191\n[200]   train's rmse: 0.000441349   train's RMSPE: 0.226036 valid's rmse: 0.000495083   valid's RMSPE: 0.250362\n[250]   train's rmse: 0.000433618   train's RMSPE: 0.222077 valid's rmse: 0.000494468   valid's RMSPE: 0.250051\n[300]   train's rmse: 0.000426188   train's RMSPE: 0.218271 valid's rmse: 0.000492902   valid's RMSPE: 0.249259\n[350]   train's rmse: 0.000419314   train's RMSPE: 0.214751 valid's rmse: 0.000490036   valid's RMSPE: 0.24781\n[400]   train's rmse: 0.000413728   train's RMSPE: 0.21189  valid's rmse: 0.000488779   valid's RMSPE: 0.247175\n[450]   train's rmse: 0.000408851   train's RMSPE: 0.209392 valid's rmse: 0.000488751   valid's RMSPE: 0.24716\n[500]   train's rmse: 0.000403891   train's RMSPE: 0.206852 valid's rmse: 0.000487112   valid's RMSPE: 0.246332\nEarly stopping, best iteration is:\n[484]   train's rmse: 0.000405522   train's RMSPE: 0.207687 valid's rmse: 0.000485987   valid's RMSPE: 0.245762\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000477994   train's RMSPE: 0.243677 valid's rmse: 0.000535865   valid's RMSPE: 0.276043\n[100]   train's rmse: 0.000455431   train's RMSPE: 0.232175 valid's rmse: 0.000519367   valid's RMSPE: 0.267544\n[150]   train's rmse: 0.00044389    train's RMSPE: 0.226291 valid's rmse: 0.000515775   valid's RMSPE: 0.265694\n[200]   train's rmse: 0.000434962   train's RMSPE: 0.22174  valid's rmse: 0.000512244   valid's RMSPE: 0.263875\n[250]   train's rmse: 0.000427247   train's RMSPE: 0.217807 valid's rmse: 0.00050977    valid's RMSPE: 0.262601\n[300]   train's rmse: 0.000420445   train's RMSPE: 0.214339 valid's rmse: 0.000508816   valid's RMSPE: 0.262109\n[350]   train's rmse: 0.000414658   train's RMSPE: 0.211389 valid's rmse: 0.000507887   valid's RMSPE: 0.26163\n[400]   train's rmse: 0.000409255   train's RMSPE: 0.208635 valid's rmse: 0.00050697    valid's RMSPE: 0.261158\nEarly stopping, best iteration is:\n[382]   train's rmse: 0.000411007   train's RMSPE: 0.209528 valid's rmse: 0.000506615   valid's RMSPE: 0.260975\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000489821   train's RMSPE: 0.25016  valid's rmse: 0.000478955   valid's RMSPE: 0.244962\n[100]   train's rmse: 0.000465543   train's RMSPE: 0.237761 valid's rmse: 0.000469296   valid's RMSPE: 0.240022\n[150]   train's rmse: 0.000454328   train's RMSPE: 0.232034 valid's rmse: 0.000465908   valid's RMSPE: 0.238289\n[200]   train's rmse: 0.000444609   train's RMSPE: 0.22707  valid's rmse: 0.000464113   valid's RMSPE: 0.237371\n[250]   train's rmse: 0.00043672    train's RMSPE: 0.223041 valid's rmse: 0.00046237    valid's RMSPE: 0.236479\n[300]   train's rmse: 0.000429808   train's RMSPE: 0.21951  valid's rmse: 0.000460927   valid's RMSPE: 0.235741\nEarly stopping, best iteration is:\n[284]   train's rmse: 0.000431668   train's RMSPE: 0.220461 valid's rmse: 0.000460801   valid's RMSPE: 0.235677\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000492297   train's RMSPE: 0.25141  valid's rmse: 0.000482719   valid's RMSPE: 0.246946\n[100]   train's rmse: 0.000467923   train's RMSPE: 0.238962 valid's rmse: 0.000465912   valid's RMSPE: 0.238348\n[150]   train's rmse: 0.000456589   train's RMSPE: 0.233174 valid's rmse: 0.000462464   valid's RMSPE: 0.236584\n[200]   train's rmse: 0.000445713   train's RMSPE: 0.22762  valid's rmse: 0.000459206   valid's RMSPE: 0.234918\n[250]   train's rmse: 0.000438319   train's RMSPE: 0.223844 valid's rmse: 0.000459761   valid's RMSPE: 0.235201\nEarly stopping, best iteration is:\n[216]   train's rmse: 0.000442836   train's RMSPE: 0.226151 valid's rmse: 0.000458796   valid's RMSPE: 0.234708\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00049029    train's RMSPE: 0.250526 valid's rmse: 0.000487921   valid's RMSPE: 0.249045\n[100]   train's rmse: 0.000464893   train's RMSPE: 0.237549 valid's rmse: 0.000478099   valid's RMSPE: 0.244032\n[150]   train's rmse: 0.000452375   train's RMSPE: 0.231152 valid's rmse: 0.000476123   valid's RMSPE: 0.243023\n[200]   train's rmse: 0.000442941   train's RMSPE: 0.226332 valid's rmse: 0.000476674   valid's RMSPE: 0.243305\n[250]   train's rmse: 0.000434371   train's RMSPE: 0.221953 valid's rmse: 0.000476557   valid's RMSPE: 0.243245\nEarly stopping, best iteration is:\n[221]   train's rmse: 0.000438784   train's RMSPE: 0.224208 valid's rmse: 0.000475763   valid's RMSPE: 0.242839\nOur out of folds RMSPE is 0.244, compared to 0.21907995999798716, giving gain 0.02492004000201284\nOur cv fold scores are [0.246, 0.261, 0.236, 0.235, 0.243]\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000766016   train's RMSPE: 0.247381 valid's rmse: 0.000810082   valid's RMSPE: 0.261403\n[100]   train's rmse: 0.000727891   train's RMSPE: 0.235069 valid's rmse: 0.000788124   valid's RMSPE: 0.254318\n[150]   train's rmse: 0.00070864    train's RMSPE: 0.228852 valid's rmse: 0.000787296   valid's RMSPE: 0.25405\nEarly stopping, best iteration is:\n[105]   train's rmse: 0.000725561   train's RMSPE: 0.234316 valid's rmse: 0.000786912   valid's RMSPE: 0.253927\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000767556   train's RMSPE: 0.247397 valid's rmse: 0.000803508   valid's RMSPE: 0.261287\n[100]   train's rmse: 0.000728942   train's RMSPE: 0.234951 valid's rmse: 0.000783814   valid's RMSPE: 0.254883\n[150]   train's rmse: 0.000709525   train's RMSPE: 0.228693 valid's rmse: 0.000779286   valid's RMSPE: 0.25341\nEarly stopping, best iteration is:\n[149]   train's rmse: 0.000709877   train's RMSPE: 0.228807 valid's rmse: 0.000779134   valid's RMSPE: 0.253361\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000772148   train's RMSPE: 0.248495 valid's rmse: 0.000775178   valid's RMSPE: 0.253591\n[100]   train's rmse: 0.000735768   train's RMSPE: 0.236787 valid's rmse: 0.000757326   valid's RMSPE: 0.247751\n[150]   train's rmse: 0.00071703    train's RMSPE: 0.230757 valid's rmse: 0.000754548   valid's RMSPE: 0.246842\n[200]   train's rmse: 0.00069991    train's RMSPE: 0.225247 valid's rmse: 0.000754343   valid's RMSPE: 0.246776\nEarly stopping, best iteration is:\n[172]   train's rmse: 0.000708751   train's RMSPE: 0.228092 valid's rmse: 0.000752804   valid's RMSPE: 0.246272\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000767649   train's RMSPE: 0.248021 valid's rmse: 0.000815939   valid's RMSPE: 0.262813\n[100]   train's rmse: 0.000730703   train's RMSPE: 0.236084 valid's rmse: 0.000809155   valid's RMSPE: 0.260628\nEarly stopping, best iteration is:\n[82]    train's rmse: 0.000738596   train's RMSPE: 0.238634 valid's rmse: 0.000805585   valid's RMSPE: 0.259478\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000775758   train's RMSPE: 0.251565 valid's rmse: 0.000763853   valid's RMSPE: 0.242349\n[100]   train's rmse: 0.000741239   train's RMSPE: 0.240372 valid's rmse: 0.000746848   valid's RMSPE: 0.236954\n[150]   train's rmse: 0.000722732   train's RMSPE: 0.23437  valid's rmse: 0.000746581   valid's RMSPE: 0.236869\n[200]   train's rmse: 0.000706244   train's RMSPE: 0.229023 valid's rmse: 0.00074795    valid's RMSPE: 0.237303\nEarly stopping, best iteration is:\n[158]   train's rmse: 0.000720052   train's RMSPE: 0.233501 valid's rmse: 0.000745528   valid's RMSPE: 0.236535\nOur out of folds RMSPE is 0.25, compared to 0.22483761681905104, giving gain 0.02516238318094896\nOur cv fold scores are [0.254, 0.253, 0.246, 0.259, 0.237]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000796405   train's RMSPE: 0.241336 valid's rmse: 0.000850369   valid's RMSPE: 0.254966\n[100]   train's rmse: 0.000762222   train's RMSPE: 0.230978 valid's rmse: 0.000831883   valid's RMSPE: 0.249424\n[150]   train's rmse: 0.000743648   train's RMSPE: 0.225349 valid's rmse: 0.00083068    valid's RMSPE: 0.249063\nEarly stopping, best iteration is:\n[145]   train's rmse: 0.000745126   train's RMSPE: 0.225797 valid's rmse: 0.000830512   valid's RMSPE: 0.249012\nTraining fold 1\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000794044   train's RMSPE: 0.239732 valid's rmse: 0.000860875   valid's RMSPE: 0.261976\n[100]   train's rmse: 0.000761981   train's RMSPE: 0.230052 valid's rmse: 0.000838938   valid's RMSPE: 0.2553\n[150]   train's rmse: 0.00074641    train's RMSPE: 0.225351 valid's rmse: 0.000836098   valid's RMSPE: 0.254436\n[200]   train's rmse: 0.000732617   train's RMSPE: 0.221187 valid's rmse: 0.000832905   valid's RMSPE: 0.253464\n[250]   train's rmse: 0.000720847   train's RMSPE: 0.217633 valid's rmse: 0.000828586   valid's RMSPE: 0.25215\n[300]   train's rmse: 0.000710347   train's RMSPE: 0.214463 valid's rmse: 0.000825012   valid's RMSPE: 0.251062\n[350]   train's rmse: 0.000700525   train's RMSPE: 0.211498 valid's rmse: 0.000821121   valid's RMSPE: 0.249878\n[400]   train's rmse: 0.000690936   train's RMSPE: 0.208602 valid's rmse: 0.000817889   valid's RMSPE: 0.248894\n[450]   train's rmse: 0.000683951   train's RMSPE: 0.206494 valid's rmse: 0.000816371   valid's RMSPE: 0.248433\n[500]   train's rmse: 0.000676005   train's RMSPE: 0.204095 valid's rmse: 0.000815849   valid's RMSPE: 0.248274\n[550]   train's rmse: 0.000669009   train's RMSPE: 0.201982 valid's rmse: 0.000816165   valid's RMSPE: 0.24837\nEarly stopping, best iteration is:\n[505]   train's rmse: 0.00067529    train's RMSPE: 0.203879 valid's rmse: 0.00081555    valid's RMSPE: 0.248183\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000803125   train's RMSPE: 0.242739 valid's rmse: 0.000807417   valid's RMSPE: 0.244647\n[100]   train's rmse: 0.00076812    train's RMSPE: 0.232159 valid's rmse: 0.000795677   valid's RMSPE: 0.24109\n[150]   train's rmse: 0.000751633   train's RMSPE: 0.227176 valid's rmse: 0.000793798   valid's RMSPE: 0.240521\nEarly stopping, best iteration is:\n[120]   train's rmse: 0.000760523   train's RMSPE: 0.229863 valid's rmse: 0.000792885   valid's RMSPE: 0.240244\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000811262   train's RMSPE: 0.244334 valid's rmse: 0.00079528    valid's RMSPE: 0.24432\n[100]   train's rmse: 0.00077797    train's RMSPE: 0.234307 valid's rmse: 0.000768355   valid's RMSPE: 0.236048\n[150]   train's rmse: 0.000760992   train's RMSPE: 0.229194 valid's rmse: 0.000763801   valid's RMSPE: 0.234649\n[200]   train's rmse: 0.000746667   train's RMSPE: 0.22488  valid's rmse: 0.000761645   valid's RMSPE: 0.233986\n[250]   train's rmse: 0.000734409   train's RMSPE: 0.221188 valid's rmse: 0.000759407   valid's RMSPE: 0.233299\n[300]   train's rmse: 0.000723793   train's RMSPE: 0.21799  valid's rmse: 0.000758377   valid's RMSPE: 0.232983\nEarly stopping, best iteration is:\n[264]   train's rmse: 0.000730825   train's RMSPE: 0.220108 valid's rmse: 0.000757745   valid's RMSPE: 0.232789\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000807005   train's RMSPE: 0.245007 valid's rmse: 0.000794392   valid's RMSPE: 0.236349\n[100]   train's rmse: 0.000775519   train's RMSPE: 0.235448 valid's rmse: 0.000778175   valid's RMSPE: 0.231524\n[150]   train's rmse: 0.000759005   train's RMSPE: 0.230434 valid's rmse: 0.000776665   valid's RMSPE: 0.231074\n[200]   train's rmse: 0.000745231   train's RMSPE: 0.226253 valid's rmse: 0.000772044   valid's RMSPE: 0.2297\n[250]   train's rmse: 0.000732808   train's RMSPE: 0.222481 valid's rmse: 0.000769865   valid's RMSPE: 0.229051\n[300]   train's rmse: 0.000721846   train's RMSPE: 0.219153 valid's rmse: 0.000767522   valid's RMSPE: 0.228354\n[350]   train's rmse: 0.000712418   train's RMSPE: 0.21629  valid's rmse: 0.00076531    valid's RMSPE: 0.227696\n[400]   train's rmse: 0.000703604   train's RMSPE: 0.213614 valid's rmse: 0.00076582    valid's RMSPE: 0.227848\nEarly stopping, best iteration is:\n[359]   train's rmse: 0.000710835   train's RMSPE: 0.21581  valid's rmse: 0.000764387   valid's RMSPE: 0.227422\nOur out of folds RMSPE is 0.24, compared to 0.2094257055987473, giving gain 0.0305742944012527\nOur cv fold scores are [0.249, 0.248, 0.24, 0.233, 0.227]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000458948   train's RMSPE: 0.230019 valid's rmse: 0.00048789    valid's RMSPE: 0.244217\n[100]   train's rmse: 0.000431406   train's RMSPE: 0.216216 valid's rmse: 0.000468433   valid's RMSPE: 0.234478\n[150]   train's rmse: 0.000420635   train's RMSPE: 0.210817 valid's rmse: 0.000462832   valid's RMSPE: 0.231674\n[200]   train's rmse: 0.000412432   train's RMSPE: 0.206706 valid's rmse: 0.000458076   valid's RMSPE: 0.229293\n[250]   train's rmse: 0.000404932   train's RMSPE: 0.202947 valid's rmse: 0.000454365   valid's RMSPE: 0.227436\n[300]   train's rmse: 0.000399198   train's RMSPE: 0.200073 valid's rmse: 0.000451701   valid's RMSPE: 0.226102\n[350]   train's rmse: 0.000394551   train's RMSPE: 0.197744 valid's rmse: 0.000450489   valid's RMSPE: 0.225496\n[400]   train's rmse: 0.000389522   train's RMSPE: 0.195224 valid's rmse: 0.000449206   valid's RMSPE: 0.224853\n[450]   train's rmse: 0.000385143   train's RMSPE: 0.193029 valid's rmse: 0.000448749   valid's RMSPE: 0.224625\n[500]   train's rmse: 0.000381215   train's RMSPE: 0.19106  valid's rmse: 0.000447344   valid's RMSPE: 0.223921\n[550]   train's rmse: 0.000377503   train's RMSPE: 0.1892   valid's rmse: 0.000446852   valid's RMSPE: 0.223675\n[600]   train's rmse: 0.000373994   train's RMSPE: 0.187441 valid's rmse: 0.000446834   valid's RMSPE: 0.223666\n[650]   train's rmse: 0.000370141   train's RMSPE: 0.18551  valid's rmse: 0.000445677   valid's RMSPE: 0.223087\n[700]   train's rmse: 0.000366456   train's RMSPE: 0.183663 valid's rmse: 0.000445475   valid's RMSPE: 0.222986\n[750]   train's rmse: 0.000363409   train's RMSPE: 0.182136 valid's rmse: 0.000444937   valid's RMSPE: 0.222717\nEarly stopping, best iteration is:\n[742]   train's rmse: 0.000363756   train's RMSPE: 0.18231  valid's rmse: 0.000444528   valid's RMSPE: 0.222512\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000460732   train's RMSPE: 0.229628 valid's rmse: 0.000489259   valid's RMSPE: 0.250292\n[100]   train's rmse: 0.000431777   train's RMSPE: 0.215197 valid's rmse: 0.000462107   valid's RMSPE: 0.236402\n[150]   train's rmse: 0.00042156    train's RMSPE: 0.210105 valid's rmse: 0.000456917   valid's RMSPE: 0.233747\n[200]   train's rmse: 0.00041283    train's RMSPE: 0.205754 valid's rmse: 0.000451039   valid's RMSPE: 0.230739\n[250]   train's rmse: 0.000405891   train's RMSPE: 0.202296 valid's rmse: 0.000448419   valid's RMSPE: 0.229399\n[300]   train's rmse: 0.000399858   train's RMSPE: 0.199289 valid's rmse: 0.000446214   valid's RMSPE: 0.228271\n[350]   train's rmse: 0.000394912   train's RMSPE: 0.196824 valid's rmse: 0.000444931   valid's RMSPE: 0.227615\n[400]   train's rmse: 0.000391038   train's RMSPE: 0.194893 valid's rmse: 0.000444232   valid's RMSPE: 0.227257\n[450]   train's rmse: 0.000386436   train's RMSPE: 0.192599 valid's rmse: 0.000442176   valid's RMSPE: 0.226205\n[500]   train's rmse: 0.000382609   train's RMSPE: 0.190692 valid's rmse: 0.000441828   valid's RMSPE: 0.226028\n[550]   train's rmse: 0.000378775   train's RMSPE: 0.188781 valid's rmse: 0.000440307   valid's RMSPE: 0.225249\n[600]   train's rmse: 0.000374893   train's RMSPE: 0.186846 valid's rmse: 0.000439491   valid's RMSPE: 0.224832\n[650]   train's rmse: 0.000371501   train's RMSPE: 0.185156 valid's rmse: 0.000438783   valid's RMSPE: 0.224469\n[700]   train's rmse: 0.000368305   train's RMSPE: 0.183563 valid's rmse: 0.000437734   valid's RMSPE: 0.223933\n[750]   train's rmse: 0.000364967   train's RMSPE: 0.181899 valid's rmse: 0.000436804   valid's RMSPE: 0.223457\n[800]   train's rmse: 0.000362051   train's RMSPE: 0.180446 valid's rmse: 0.000436188   valid's RMSPE: 0.223142\n[850]   train's rmse: 0.000358787   train's RMSPE: 0.178819 valid's rmse: 0.000434968   valid's RMSPE: 0.222518\n[900]   train's rmse: 0.00035597    train's RMSPE: 0.177415 valid's rmse: 0.000434842   valid's RMSPE: 0.222454\nEarly stopping, best iteration is:\n[876]   train's rmse: 0.000357382   train's RMSPE: 0.178119 valid's rmse: 0.000434037   valid's RMSPE: 0.222042\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000464912   train's RMSPE: 0.232244 valid's rmse: 0.000457476   valid's RMSPE: 0.231979\n[100]   train's rmse: 0.000437984   train's RMSPE: 0.218793 valid's rmse: 0.000438594   valid's RMSPE: 0.222405\n[150]   train's rmse: 0.000426986   train's RMSPE: 0.213298 valid's rmse: 0.000434383   valid's RMSPE: 0.22027\n[200]   train's rmse: 0.000418668   train's RMSPE: 0.209143 valid's rmse: 0.000431671   valid's RMSPE: 0.218894\n[250]   train's rmse: 0.000411784   train's RMSPE: 0.205704 valid's rmse: 0.000430031   valid's RMSPE: 0.218062\n[300]   train's rmse: 0.000406248   train's RMSPE: 0.202939 valid's rmse: 0.000429457   valid's RMSPE: 0.217772\n[350]   train's rmse: 0.000400867   train's RMSPE: 0.200251 valid's rmse: 0.000428238   valid's RMSPE: 0.217153\n[400]   train's rmse: 0.000396268   train's RMSPE: 0.197954 valid's rmse: 0.000426699   valid's RMSPE: 0.216373\n[450]   train's rmse: 0.000391712   train's RMSPE: 0.195677 valid's rmse: 0.00042486    valid's RMSPE: 0.21544\n[500]   train's rmse: 0.000387547   train's RMSPE: 0.193597 valid's rmse: 0.000423944   valid's RMSPE: 0.214976\n[550]   train's rmse: 0.000383392   train's RMSPE: 0.191521 valid's rmse: 0.00042314    valid's RMSPE: 0.214568\n[600]   train's rmse: 0.00037973    train's RMSPE: 0.189692 valid's rmse: 0.000423075   valid's RMSPE: 0.214535\nEarly stopping, best iteration is:\n[555]   train's rmse: 0.000382964   train's RMSPE: 0.191308 valid's rmse: 0.000422707   valid's RMSPE: 0.214349\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000466979   train's RMSPE: 0.23441  valid's rmse: 0.000448095   valid's RMSPE: 0.222884\n[100]   train's rmse: 0.000439887   train's RMSPE: 0.220811 valid's rmse: 0.000428072   valid's RMSPE: 0.212925\n[150]   train's rmse: 0.000428291   train's RMSPE: 0.21499  valid's rmse: 0.000422895   valid's RMSPE: 0.21035\n[200]   train's rmse: 0.000419393   train's RMSPE: 0.210524 valid's rmse: 0.000419164   valid's RMSPE: 0.208494\n[250]   train's rmse: 0.000412458   train's RMSPE: 0.207043 valid's rmse: 0.000417152   valid's RMSPE: 0.207493\n[300]   train's rmse: 0.000406802   train's RMSPE: 0.204203 valid's rmse: 0.000415652   valid's RMSPE: 0.206747\n[350]   train's rmse: 0.000401842   train's RMSPE: 0.201714 valid's rmse: 0.000415133   valid's RMSPE: 0.206489\n[400]   train's rmse: 0.000397496   train's RMSPE: 0.199532 valid's rmse: 0.000414845   valid's RMSPE: 0.206345\n[450]   train's rmse: 0.00039319    train's RMSPE: 0.197371 valid's rmse: 0.000414187   valid's RMSPE: 0.206018\n[500]   train's rmse: 0.000388517   train's RMSPE: 0.195025 valid's rmse: 0.00041363    valid's RMSPE: 0.205741\n[550]   train's rmse: 0.00038379    train's RMSPE: 0.192652 valid's rmse: 0.000413074   valid's RMSPE: 0.205464\nEarly stopping, best iteration is:\n[537]   train's rmse: 0.000384791   train's RMSPE: 0.193154 valid's rmse: 0.000412737   valid's RMSPE: 0.205297\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000461845   train's RMSPE: 0.232855 valid's rmse: 0.00047745    valid's RMSPE: 0.233171\n[100]   train's rmse: 0.000436428   train's RMSPE: 0.220041 valid's rmse: 0.000460432   valid's RMSPE: 0.22486\n[150]   train's rmse: 0.000425217   train's RMSPE: 0.214388 valid's rmse: 0.000453468   valid's RMSPE: 0.221459\n[200]   train's rmse: 0.000417153   train's RMSPE: 0.210323 valid's rmse: 0.000448987   valid's RMSPE: 0.219271\n[250]   train's rmse: 0.00040999    train's RMSPE: 0.206711 valid's rmse: 0.000446508   valid's RMSPE: 0.21806\n[300]   train's rmse: 0.00040316    train's RMSPE: 0.203267 valid's rmse: 0.000444308   valid's RMSPE: 0.216986\n[350]   train's rmse: 0.000397923   train's RMSPE: 0.200627 valid's rmse: 0.000442411   valid's RMSPE: 0.216059\n[400]   train's rmse: 0.000393433   train's RMSPE: 0.198363 valid's rmse: 0.000440745   valid's RMSPE: 0.215246\n[450]   train's rmse: 0.000389203   train's RMSPE: 0.196231 valid's rmse: 0.000439736   valid's RMSPE: 0.214753\n[500]   train's rmse: 0.000385277   train's RMSPE: 0.194251 valid's rmse: 0.000439198   valid's RMSPE: 0.21449\n[550]   train's rmse: 0.000381759   train's RMSPE: 0.192477 valid's rmse: 0.000438258   valid's RMSPE: 0.214031\n[600]   train's rmse: 0.000378143   train's RMSPE: 0.190654 valid's rmse: 0.000436786   valid's RMSPE: 0.213312\n[650]   train's rmse: 0.00037491    train's RMSPE: 0.189024 valid's rmse: 0.000436589   valid's RMSPE: 0.213216\n[700]   train's rmse: 0.000372011   train's RMSPE: 0.187562 valid's rmse: 0.000435893   valid's RMSPE: 0.212876\n[750]   train's rmse: 0.00036834    train's RMSPE: 0.185711 valid's rmse: 0.00043454    valid's RMSPE: 0.212215\n[800]   train's rmse: 0.000365265   train's RMSPE: 0.184161 valid's rmse: 0.000434059   valid's RMSPE: 0.21198\n[850]   train's rmse: 0.000362675   train's RMSPE: 0.182855 valid's rmse: 0.000433454   valid's RMSPE: 0.211685\n[900]   train's rmse: 0.000359833   train's RMSPE: 0.181423 valid's rmse: 0.000432465   valid's RMSPE: 0.211202\n[950]   train's rmse: 0.000357202   train's RMSPE: 0.180096 valid's rmse: 0.000431875   valid's RMSPE: 0.210914\nEarly stopping, best iteration is:\n[931]   train's rmse: 0.000358074   train's RMSPE: 0.180536 valid's rmse: 0.000431609   valid's RMSPE: 0.210784\nOur out of folds RMSPE is 0.215, compared to 0.17836495410073763, giving gain 0.036635045899262364\nOur cv fold scores are [0.223, 0.222, 0.214, 0.205, 0.211]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000425698   train's RMSPE: 0.212161 valid's rmse: 0.00044951    valid's RMSPE: 0.225104\n[100]   train's rmse: 0.000402518   train's RMSPE: 0.200608 valid's rmse: 0.000435586   valid's RMSPE: 0.218131\n[150]   train's rmse: 0.000392035   train's RMSPE: 0.195383 valid's rmse: 0.000432456   valid's RMSPE: 0.216564\n[200]   train's rmse: 0.000383172   train's RMSPE: 0.190966 valid's rmse: 0.000430429   valid's RMSPE: 0.215549\n[250]   train's rmse: 0.000376149   train's RMSPE: 0.187466 valid's rmse: 0.000427592   valid's RMSPE: 0.214128\n[300]   train's rmse: 0.000369913   train's RMSPE: 0.184358 valid's rmse: 0.000425435   valid's RMSPE: 0.213048\n[350]   train's rmse: 0.000364599   train's RMSPE: 0.18171  valid's rmse: 0.000424726   valid's RMSPE: 0.212693\n[400]   train's rmse: 0.000359984   train's RMSPE: 0.17941  valid's rmse: 0.000423711   valid's RMSPE: 0.212185\n[450]   train's rmse: 0.000356014   train's RMSPE: 0.177431 valid's rmse: 0.000422512   valid's RMSPE: 0.211584\nEarly stopping, best iteration is:\n[429]   train's rmse: 0.000357509   train's RMSPE: 0.178176 valid's rmse: 0.000422056   valid's RMSPE: 0.211356\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00042333    train's RMSPE: 0.210311 valid's rmse: 0.00045798    valid's RMSPE: 0.232205\n[100]   train's rmse: 0.000400238   train's RMSPE: 0.198839 valid's rmse: 0.000438376   valid's RMSPE: 0.222266\n[150]   train's rmse: 0.000388968   train's RMSPE: 0.19324  valid's rmse: 0.000432133   valid's RMSPE: 0.2191\n[200]   train's rmse: 0.000380245   train's RMSPE: 0.188907 valid's rmse: 0.000428446   valid's RMSPE: 0.217231\n[250]   train's rmse: 0.000372894   train's RMSPE: 0.185255 valid's rmse: 0.000426699   valid's RMSPE: 0.216345\n[300]   train's rmse: 0.000366363   train's RMSPE: 0.18201  valid's rmse: 0.000425987   valid's RMSPE: 0.215984\n[350]   train's rmse: 0.000360786   train's RMSPE: 0.179239 valid's rmse: 0.000424322   valid's RMSPE: 0.21514\n[400]   train's rmse: 0.000355928   train's RMSPE: 0.176826 valid's rmse: 0.000423568   valid's RMSPE: 0.214757\nEarly stopping, best iteration is:\n[394]   train's rmse: 0.000356616   train's RMSPE: 0.177168 valid's rmse: 0.000423105   valid's RMSPE: 0.214523\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000431486   train's RMSPE: 0.21453  valid's rmse: 0.000412045   valid's RMSPE: 0.208287\n[100]   train's rmse: 0.00040775    train's RMSPE: 0.202729 valid's rmse: 0.000398324   valid's RMSPE: 0.201352\n[150]   train's rmse: 0.000395927   train's RMSPE: 0.196851 valid's rmse: 0.000394094   valid's RMSPE: 0.199213\n[200]   train's rmse: 0.000387182   train's RMSPE: 0.192503 valid's rmse: 0.000391926   valid's RMSPE: 0.198117\n[250]   train's rmse: 0.00037997    train's RMSPE: 0.188917 valid's rmse: 0.000391152   valid's RMSPE: 0.197726\nEarly stopping, best iteration is:\n[240]   train's rmse: 0.000381381   train's RMSPE: 0.189619 valid's rmse: 0.000390613   valid's RMSPE: 0.197454\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000429147   train's RMSPE: 0.214654 valid's rmse: 0.000427842   valid's RMSPE: 0.21115\n[100]   train's rmse: 0.000407087   train's RMSPE: 0.20362  valid's rmse: 0.000412421   valid's RMSPE: 0.20354\n[150]   train's rmse: 0.000396668   train's RMSPE: 0.198408 valid's rmse: 0.00041064    valid's RMSPE: 0.202661\n[200]   train's rmse: 0.000388957   train's RMSPE: 0.194552 valid's rmse: 0.000407537   valid's RMSPE: 0.201129\n[250]   train's rmse: 0.000382261   train's RMSPE: 0.191202 valid's rmse: 0.000404594   valid's RMSPE: 0.199677\n[300]   train's rmse: 0.000376024   train's RMSPE: 0.188083 valid's rmse: 0.000402415   valid's RMSPE: 0.198601\n[350]   train's rmse: 0.00037076    train's RMSPE: 0.18545  valid's rmse: 0.0004007 valid's RMSPE: 0.197755\n[400]   train's rmse: 0.000365346   train's RMSPE: 0.182742 valid's rmse: 0.000399799   valid's RMSPE: 0.19731\n[450]   train's rmse: 0.000361336   train's RMSPE: 0.180736 valid's rmse: 0.000399111   valid's RMSPE: 0.196971\n[500]   train's rmse: 0.000357424   train's RMSPE: 0.178779 valid's rmse: 0.000397771   valid's RMSPE: 0.19631\nEarly stopping, best iteration is:\n[489]   train's rmse: 0.000358126   train's RMSPE: 0.17913  valid's rmse: 0.000397605   valid's RMSPE: 0.196228\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000427609   train's RMSPE: 0.214545 valid's rmse: 0.000435969   valid's RMSPE: 0.212411\n[100]   train's rmse: 0.00040316    train's RMSPE: 0.202278 valid's rmse: 0.00042628    valid's RMSPE: 0.20769\n[150]   train's rmse: 0.000391086   train's RMSPE: 0.19622  valid's rmse: 0.000423548   valid's RMSPE: 0.206359\n[200]   train's rmse: 0.000382602   train's RMSPE: 0.191964 valid's rmse: 0.000422333   valid's RMSPE: 0.205767\nEarly stopping, best iteration is:\n[197]   train's rmse: 0.000383061   train's RMSPE: 0.192194 valid's rmse: 0.000422251   valid's RMSPE: 0.205727\nOur out of folds RMSPE is 0.205, compared to 0.17936019432433678, giving gain 0.025639805675663208\nOur cv fold scores are [0.211, 0.215, 0.197, 0.196, 0.206]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000565279   train's RMSPE: 0.221688 valid's rmse: 0.000623958   valid's RMSPE: 0.239671\n[100]   train's rmse: 0.000536768   train's RMSPE: 0.210506 valid's rmse: 0.000603674   valid's RMSPE: 0.23188\n[150]   train's rmse: 0.000523463   train's RMSPE: 0.205288 valid's rmse: 0.000598626   valid's RMSPE: 0.229941\n[200]   train's rmse: 0.000513237   train's RMSPE: 0.201278 valid's rmse: 0.000597222   valid's RMSPE: 0.229402\n[250]   train's rmse: 0.000504849   train's RMSPE: 0.197988 valid's rmse: 0.000595947   valid's RMSPE: 0.228912\n[300]   train's rmse: 0.00049754    train's RMSPE: 0.195122 valid's rmse: 0.000596103   valid's RMSPE: 0.228972\nEarly stopping, best iteration is:\n[269]   train's rmse: 0.000501778   train's RMSPE: 0.196784 valid's rmse: 0.000595349   valid's RMSPE: 0.228682\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000570647   train's RMSPE: 0.222356 valid's rmse: 0.000603039   valid's RMSPE: 0.237736\n[100]   train's rmse: 0.000541848   train's RMSPE: 0.211134 valid's rmse: 0.000580953   valid's RMSPE: 0.229029\n[150]   train's rmse: 0.000528188   train's RMSPE: 0.205812 valid's rmse: 0.000577793   valid's RMSPE: 0.227783\n[200]   train's rmse: 0.00051792    train's RMSPE: 0.201811 valid's rmse: 0.000578545   valid's RMSPE: 0.228079\nEarly stopping, best iteration is:\n[184]   train's rmse: 0.000520872   train's RMSPE: 0.202961 valid's rmse: 0.000576241   valid's RMSPE: 0.227171\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000576895   train's RMSPE: 0.223829 valid's rmse: 0.000567851   valid's RMSPE: 0.227566\n[100]   train's rmse: 0.000548175   train's RMSPE: 0.212686 valid's rmse: 0.000555432   valid's RMSPE: 0.222589\n[150]   train's rmse: 0.000535586   train's RMSPE: 0.207802 valid's rmse: 0.000553209   valid's RMSPE: 0.221699\n[200]   train's rmse: 0.00052694    train's RMSPE: 0.204447 valid's rmse: 0.000550549   valid's RMSPE: 0.220633\n[250]   train's rmse: 0.000518169   train's RMSPE: 0.201044 valid's rmse: 0.000550821   valid's RMSPE: 0.220742\n[300]   train's rmse: 0.000511024   train's RMSPE: 0.198272 valid's rmse: 0.000548777   valid's RMSPE: 0.219923\nEarly stopping, best iteration is:\n[293]   train's rmse: 0.000511911   train's RMSPE: 0.198616 valid's rmse: 0.000548192   valid's RMSPE: 0.219688\nTraining fold 3\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000585283   train's RMSPE: 0.228002 valid's rmse: 0.000549641   valid's RMSPE: 0.216896\n[100]   train's rmse: 0.000556658   train's RMSPE: 0.216851 valid's rmse: 0.000530187   valid's RMSPE: 0.209219\n[150]   train's rmse: 0.000544229   train's RMSPE: 0.212009 valid's rmse: 0.000530729   valid's RMSPE: 0.209433\nEarly stopping, best iteration is:\n[118]   train's rmse: 0.000551869   train's RMSPE: 0.214985 valid's rmse: 0.0005292 valid's RMSPE: 0.20883\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000570208   train's RMSPE: 0.224361 valid's rmse: 0.000593845   valid's RMSPE: 0.224928\n[100]   train's rmse: 0.000541764   train's RMSPE: 0.213169 valid's rmse: 0.000582938   valid's RMSPE: 0.220797\n[150]   train's rmse: 0.000529018   train's RMSPE: 0.208154 valid's rmse: 0.00058164    valid's RMSPE: 0.220305\n[200]   train's rmse: 0.000518782   train's RMSPE: 0.204127 valid's rmse: 0.000584028   valid's RMSPE: 0.22121\nEarly stopping, best iteration is:\n[153]   train's rmse: 0.000528166   train's RMSPE: 0.207819 valid's rmse: 0.000581532   valid's RMSPE: 0.220264\nOur out of folds RMSPE is 0.221, compared to 0.19366846745759744, giving gain 0.02733153254240256\nOur cv fold scores are [0.229, 0.227, 0.22, 0.209, 0.22]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000381075   train's RMSPE: 0.236859 valid's rmse: 0.000415942   valid's RMSPE: 0.261251\n[100]   train's rmse: 0.000359987   train's RMSPE: 0.223751 valid's rmse: 0.000395288   valid's RMSPE: 0.248278\n[150]   train's rmse: 0.000350704   train's RMSPE: 0.217982 valid's rmse: 0.000390159   valid's RMSPE: 0.245057\n[200]   train's rmse: 0.000342711   train's RMSPE: 0.213013 valid's rmse: 0.000385669   valid's RMSPE: 0.242236\n[250]   train's rmse: 0.000336488   train's RMSPE: 0.209146 valid's rmse: 0.000382371   valid's RMSPE: 0.240165\n[300]   train's rmse: 0.000331506   train's RMSPE: 0.206049 valid's rmse: 0.000380519   valid's RMSPE: 0.239001\n[350]   train's rmse: 0.00032704    train's RMSPE: 0.203273 valid's rmse: 0.000378413   valid's RMSPE: 0.237679\n[400]   train's rmse: 0.000322585   train's RMSPE: 0.200504 valid's rmse: 0.000376018   valid's RMSPE: 0.236175\n[450]   train's rmse: 0.000318917   train's RMSPE: 0.198224 valid's rmse: 0.000375343   valid's RMSPE: 0.235751\n[500]   train's rmse: 0.000314798   train's RMSPE: 0.195664 valid's rmse: 0.000373198   valid's RMSPE: 0.234403\n[550]   train's rmse: 0.000310857   train's RMSPE: 0.193214 valid's rmse: 0.00037238    valid's RMSPE: 0.233889\n[600]   train's rmse: 0.000308026   train's RMSPE: 0.191455 valid's rmse: 0.000372201   valid's RMSPE: 0.233777\n[650]   train's rmse: 0.000305131   train's RMSPE: 0.189655 valid's rmse: 0.000371863   valid's RMSPE: 0.233565\n[700]   train's rmse: 0.000302108   train's RMSPE: 0.187776 valid's rmse: 0.000371373   valid's RMSPE: 0.233257\n[750]   train's rmse: 0.000299397   train's RMSPE: 0.186092 valid's rmse: 0.000370679   valid's RMSPE: 0.232821\n[800]   train's rmse: 0.000296282   train's RMSPE: 0.184155 valid's rmse: 0.00036924    valid's RMSPE: 0.231917\n[850]   train's rmse: 0.000294155   train's RMSPE: 0.182833 valid's rmse: 0.000368611   valid's RMSPE: 0.231522\n[900]   train's rmse: 0.0002919 train's RMSPE: 0.181432 valid's rmse: 0.000367623   valid's RMSPE: 0.230902\n[950]   train's rmse: 0.000289732   train's RMSPE: 0.180084 valid's rmse: 0.000367233   valid's RMSPE: 0.230657\n[1000]  train's rmse: 0.000287602   train's RMSPE: 0.17876  valid's rmse: 0.000366531   valid's RMSPE: 0.230216\n[1050]  train's rmse: 0.000285629   train's RMSPE: 0.177534 valid's rmse: 0.000366009   valid's RMSPE: 0.229888\n[1100]  train's rmse: 0.000283753   train's RMSPE: 0.176368 valid's rmse: 0.00036534    valid's RMSPE: 0.229468\n[1150]  train's rmse: 0.000281874   train's RMSPE: 0.1752   valid's rmse: 0.000365042   valid's RMSPE: 0.22928\n[1200]  train's rmse: 0.000279959   train's RMSPE: 0.17401  valid's rmse: 0.000364145   valid's RMSPE: 0.228717\n[1250]  train's rmse: 0.000278258   train's RMSPE: 0.172952 valid's rmse: 0.000363887   valid's RMSPE: 0.228555\nEarly stopping, best iteration is:\n[1235]  train's rmse: 0.000278778   train's RMSPE: 0.173276 valid's rmse: 0.000363515   valid's RMSPE: 0.228321\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000380856   train's RMSPE: 0.237084 valid's rmse: 0.00040508    valid's RMSPE: 0.252901\n[100]   train's rmse: 0.000359631   train's RMSPE: 0.223872 valid's rmse: 0.000391625   valid's RMSPE: 0.244501\n[150]   train's rmse: 0.000350293   train's RMSPE: 0.218059 valid's rmse: 0.000385817   valid's RMSPE: 0.240875\n[200]   train's rmse: 0.000343199   train's RMSPE: 0.213642 valid's rmse: 0.000382159   valid's RMSPE: 0.238591\n[250]   train's rmse: 0.000336852   train's RMSPE: 0.209692 valid's rmse: 0.000378903   valid's RMSPE: 0.236558\n[300]   train's rmse: 0.000331006   train's RMSPE: 0.206052 valid's rmse: 0.00037723    valid's RMSPE: 0.235514\n[350]   train's rmse: 0.000325989   train's RMSPE: 0.202929 valid's rmse: 0.000376107   valid's RMSPE: 0.234812\n[400]   train's rmse: 0.000321769   train's RMSPE: 0.200302 valid's rmse: 0.000374968   valid's RMSPE: 0.234102\n[450]   train's rmse: 0.000318272   train's RMSPE: 0.198125 valid's rmse: 0.000374429   valid's RMSPE: 0.233765\n[500]   train's rmse: 0.000315014   train's RMSPE: 0.196097 valid's rmse: 0.000373579   valid's RMSPE: 0.233234\n[550]   train's rmse: 0.000311346   train's RMSPE: 0.193814 valid's rmse: 0.00037323    valid's RMSPE: 0.233017\n[600]   train's rmse: 0.000308232   train's RMSPE: 0.191875 valid's rmse: 0.000372883   valid's RMSPE: 0.2328\n[650]   train's rmse: 0.00030551    train's RMSPE: 0.190181 valid's rmse: 0.000372253   valid's RMSPE: 0.232406\n[700]   train's rmse: 0.000302765   train's RMSPE: 0.188472 valid's rmse: 0.000372068   valid's RMSPE: 0.232291\nEarly stopping, best iteration is:\n[678]   train's rmse: 0.000303871   train's RMSPE: 0.18916  valid's rmse: 0.000371776   valid's RMSPE: 0.232109\nTraining fold 2\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000387423   train's RMSPE: 0.240157 valid's rmse: 0.000377594   valid's RMSPE: 0.239647\n[100]   train's rmse: 0.000364307   train's RMSPE: 0.225827 valid's rmse: 0.00035794    valid's RMSPE: 0.227173\n[150]   train's rmse: 0.000355338   train's RMSPE: 0.220268 valid's rmse: 0.000354571   valid's RMSPE: 0.225035\n[200]   train's rmse: 0.00034753    train's RMSPE: 0.215428 valid's rmse: 0.000351801   valid's RMSPE: 0.223277\n[250]   train's rmse: 0.000341687   train's RMSPE: 0.211805 valid's rmse: 0.000350342   valid's RMSPE: 0.222351\n[300]   train's rmse: 0.000336688   train's RMSPE: 0.208707 valid's rmse: 0.000349739   valid's RMSPE: 0.221969\n[350]   train's rmse: 0.000332339   train's RMSPE: 0.206011 valid's rmse: 0.000348505   valid's RMSPE: 0.221185\nEarly stopping, best iteration is:\n[346]   train's rmse: 0.000332664   train's RMSPE: 0.206212 valid's rmse: 0.000348392   valid's RMSPE: 0.221114\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000386171   train's RMSPE: 0.24211  valid's rmse: 0.000373601   valid's RMSPE: 0.226501\n[100]   train's rmse: 0.000364855   train's RMSPE: 0.228746 valid's rmse: 0.000365624   valid's RMSPE: 0.221665\n[150]   train's rmse: 0.000355822   train's RMSPE: 0.223083 valid's rmse: 0.000362963   valid's RMSPE: 0.220051\n[200]   train's rmse: 0.000348128   train's RMSPE: 0.218259 valid's rmse: 0.000360705   valid's RMSPE: 0.218683\n[250]   train's rmse: 0.000342674   train's RMSPE: 0.214839 valid's rmse: 0.000359969   valid's RMSPE: 0.218236\n[300]   train's rmse: 0.000336763   train's RMSPE: 0.211134 valid's rmse: 0.000358218   valid's RMSPE: 0.217175\nEarly stopping, best iteration is:\n[298]   train's rmse: 0.000336941   train's RMSPE: 0.211245 valid's rmse: 0.000357917   valid's RMSPE: 0.216992\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000385108   train's RMSPE: 0.240087 valid's rmse: 0.000387591   valid's RMSPE: 0.240549\n[100]   train's rmse: 0.000363521   train's RMSPE: 0.226629 valid's rmse: 0.000372545   valid's RMSPE: 0.231211\n[150]   train's rmse: 0.000353098   train's RMSPE: 0.220131 valid's rmse: 0.000367746   valid's RMSPE: 0.228233\n[200]   train's rmse: 0.000345252   train's RMSPE: 0.215239 valid's rmse: 0.000365988   valid's RMSPE: 0.227142\n[250]   train's rmse: 0.00033936    train's RMSPE: 0.211566 valid's rmse: 0.000364648   valid's RMSPE: 0.22631\n[300]   train's rmse: 0.00033486    train's RMSPE: 0.208761 valid's rmse: 0.000363786   valid's RMSPE: 0.225775\n[350]   train's rmse: 0.000330257   train's RMSPE: 0.205891 valid's rmse: 0.000363302   valid's RMSPE: 0.225475\n[400]   train's rmse: 0.000325837   train's RMSPE: 0.203135 valid's rmse: 0.000362523   valid's RMSPE: 0.224991\n[450]   train's rmse: 0.000321805   train's RMSPE: 0.200622 valid's rmse: 0.000361421   valid's RMSPE: 0.224307\n[500]   train's rmse: 0.000318194   train's RMSPE: 0.19837  valid's rmse: 0.000361578   valid's RMSPE: 0.224405\nEarly stopping, best iteration is:\n[484]   train's rmse: 0.000319316   train's RMSPE: 0.19907  valid's rmse: 0.000361262   valid's RMSPE: 0.224208\nOur out of folds RMSPE is 0.225, compared to 0.18671098219925594, giving gain 0.03828901780074406\nOur cv fold scores are [0.228, 0.232, 0.221, 0.217, 0.224]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000511642   train's RMSPE: 0.184573 valid's rmse: 0.000553572   valid's RMSPE: 0.201239\n[100]   train's rmse: 0.000484061   train's RMSPE: 0.174623 valid's rmse: 0.000529498   valid's RMSPE: 0.192488\n[150]   train's rmse: 0.00047364    train's RMSPE: 0.170864 valid's rmse: 0.000524291   valid's RMSPE: 0.190595\n[200]   train's rmse: 0.000465031   train's RMSPE: 0.167758 valid's rmse: 0.000522378   valid's RMSPE: 0.189899\n[250]   train's rmse: 0.000457455   train's RMSPE: 0.165025 valid's rmse: 0.000521001   valid's RMSPE: 0.189398\n[300]   train's rmse: 0.000451133   train's RMSPE: 0.162744 valid's rmse: 0.000519391   valid's RMSPE: 0.188813\n[350]   train's rmse: 0.000445738   train's RMSPE: 0.160798 valid's rmse: 0.000518497   valid's RMSPE: 0.188489\n[400]   train's rmse: 0.000440333   train's RMSPE: 0.158848 valid's rmse: 0.000518373   valid's RMSPE: 0.188443\nEarly stopping, best iteration is:\n[364]   train's rmse: 0.000444089   train's RMSPE: 0.160203 valid's rmse: 0.000517661   valid's RMSPE: 0.188184\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000509874   train's RMSPE: 0.183675 valid's rmse: 0.000540538   valid's RMSPE: 0.197591\n[100]   train's rmse: 0.000482726   train's RMSPE: 0.173895 valid's rmse: 0.000525894   valid's RMSPE: 0.192238\n[150]   train's rmse: 0.000472184   train's RMSPE: 0.170098 valid's rmse: 0.000521816   valid's RMSPE: 0.190748\n[200]   train's rmse: 0.000463845   train's RMSPE: 0.167094 valid's rmse: 0.000520068   valid's RMSPE: 0.190109\n[250]   train's rmse: 0.00045634    train's RMSPE: 0.16439  valid's rmse: 0.000518215   valid's RMSPE: 0.189431\n[300]   train's rmse: 0.000449783   train's RMSPE: 0.162028 valid's rmse: 0.00051802    valid's RMSPE: 0.18936\n[350]   train's rmse: 0.000443688   train's RMSPE: 0.159832 valid's rmse: 0.000517258   valid's RMSPE: 0.189081\n[400]   train's rmse: 0.000438641   train's RMSPE: 0.158014 valid's rmse: 0.000515974   valid's RMSPE: 0.188612\n[450]   train's rmse: 0.000433539   train's RMSPE: 0.156176 valid's rmse: 0.000514765   valid's RMSPE: 0.18817\n[500]   train's rmse: 0.000428846   train's RMSPE: 0.154486 valid's rmse: 0.000514641   valid's RMSPE: 0.188125\nEarly stopping, best iteration is:\n[452]   train's rmse: 0.000433172   train's RMSPE: 0.156044 valid's rmse: 0.000514432   valid's RMSPE: 0.188048\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000520889   train's RMSPE: 0.188324 valid's rmse: 0.000494535   valid's RMSPE: 0.178203\n[100]   train's rmse: 0.000492932   train's RMSPE: 0.178217 valid's rmse: 0.000478912   valid's RMSPE: 0.172573\n[150]   train's rmse: 0.000482762   train's RMSPE: 0.17454  valid's rmse: 0.00047617    valid's RMSPE: 0.171585\n[200]   train's rmse: 0.000472985   train's RMSPE: 0.171005 valid's rmse: 0.000475029   valid's RMSPE: 0.171174\nEarly stopping, best iteration is:\n[168]   train's rmse: 0.000479138   train's RMSPE: 0.17323  valid's rmse: 0.000474649   valid's RMSPE: 0.171037\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000512173   train's RMSPE: 0.185126 valid's rmse: 0.000541414   valid's RMSPE: 0.195295\n[100]   train's rmse: 0.000486104   train's RMSPE: 0.175703 valid's rmse: 0.000528984   valid's RMSPE: 0.190811\n[150]   train's rmse: 0.000476131   train's RMSPE: 0.172099 valid's rmse: 0.000526319   valid's RMSPE: 0.18985\n[200]   train's rmse: 0.000468502   train's RMSPE: 0.169341 valid's rmse: 0.000523257   valid's RMSPE: 0.188745\n[250]   train's rmse: 0.000461742   train's RMSPE: 0.166898 valid's rmse: 0.000522848   valid's RMSPE: 0.188597\n[300]   train's rmse: 0.000454922   train's RMSPE: 0.164433 valid's rmse: 0.000522479   valid's RMSPE: 0.188464\nEarly stopping, best iteration is:\n[265]   train's rmse: 0.000459662   train's RMSPE: 0.166146 valid's rmse: 0.000522033   valid's RMSPE: 0.188303\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.00051996    train's RMSPE: 0.188506 valid's rmse: 0.000511448   valid's RMSPE: 0.182241\n[100]   train's rmse: 0.000494047   train's RMSPE: 0.179111 valid's rmse: 0.000490213   valid's RMSPE: 0.174675\n[150]   train's rmse: 0.000483406   train's RMSPE: 0.175253 valid's rmse: 0.000486409   valid's RMSPE: 0.173319\n[200]   train's rmse: 0.00047443    train's RMSPE: 0.171999 valid's rmse: 0.000483315   valid's RMSPE: 0.172217\n[250]   train's rmse: 0.000467255   train's RMSPE: 0.169398 valid's rmse: 0.000483706   valid's RMSPE: 0.172356\nEarly stopping, best iteration is:\n[211]   train's rmse: 0.000472733   train's RMSPE: 0.171384 valid's rmse: 0.000482921   valid's RMSPE: 0.172076\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nOur out of folds RMSPE is 0.182, compared to 0.16288573188551736, giving gain 0.019114268114482635\nOur cv fold scores are [0.188, 0.188, 0.171, 0.188, 0.172]\nTraining fold 0\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000326766   train's RMSPE: 0.251728 valid's rmse: 0.000349054   valid's RMSPE: 0.26695\n[100]   train's rmse: 0.000310544   train's RMSPE: 0.239231 valid's rmse: 0.00033553    valid's RMSPE: 0.256607\n[150]   train's rmse: 0.000303129   train's RMSPE: 0.233519 valid's rmse: 0.000333639   valid's RMSPE: 0.255161\n[200]   train's rmse: 0.000297066   train's RMSPE: 0.228849 valid's rmse: 0.000332756   valid's RMSPE: 0.254486\n[250]   train's rmse: 0.0002915 train's RMSPE: 0.22456  valid's rmse: 0.000332581   valid's RMSPE: 0.254352\nEarly stopping, best iteration is:\n[207]   train's rmse: 0.000296081   train's RMSPE: 0.22809  valid's rmse: 0.000332096   valid's RMSPE: 0.253981\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000322818   train's RMSPE: 0.247082 valid's rmse: 0.000363422   valid's RMSPE: 0.285101\n[100]   train's rmse: 0.000306719   train's RMSPE: 0.23476  valid's rmse: 0.000351669   valid's RMSPE: 0.275881\n[150]   train's rmse: 0.000299174   train's RMSPE: 0.228985 valid's rmse: 0.000348354   valid's RMSPE: 0.273281\n[200]   train's rmse: 0.000293276   train's RMSPE: 0.224471 valid's rmse: 0.000346203   valid's RMSPE: 0.271593\n[250]   train's rmse: 0.000288144   train's RMSPE: 0.220543 valid's rmse: 0.00034496    valid's RMSPE: 0.270618\n[300]   train's rmse: 0.000283819   train's RMSPE: 0.217233 valid's rmse: 0.000344151   valid's RMSPE: 0.269983\n[350]   train's rmse: 0.00027957    train's RMSPE: 0.213981 valid's rmse: 0.000343253   valid's RMSPE: 0.269279\n[400]   train's rmse: 0.000275946   train's RMSPE: 0.211207 valid's rmse: 0.000342919   valid's RMSPE: 0.269017\nEarly stopping, best iteration is:\n[375]   train's rmse: 0.000277822   train's RMSPE: 0.212643 valid's rmse: 0.000342865   valid's RMSPE: 0.268974\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000330568   train's RMSPE: 0.255365 valid's rmse: 0.000320833   valid's RMSPE: 0.242579\n[100]   train's rmse: 0.000313727   train's RMSPE: 0.242356 valid's rmse: 0.000311263   valid's RMSPE: 0.235343\n[150]   train's rmse: 0.000305853   train's RMSPE: 0.236273 valid's rmse: 0.0003083 valid's RMSPE: 0.233103\n[200]   train's rmse: 0.000300339   train's RMSPE: 0.232013 valid's rmse: 0.000306995   valid's RMSPE: 0.232116\n[250]   train's rmse: 0.000295162   train's RMSPE: 0.228014 valid's rmse: 0.000306369   valid's RMSPE: 0.231642\n[300]   train's rmse: 0.000290442   train's RMSPE: 0.224368 valid's rmse: 0.000305353   valid's RMSPE: 0.230874\n[350]   train's rmse: 0.000286873   train's RMSPE: 0.221611 valid's rmse: 0.000305374   valid's RMSPE: 0.230891\nEarly stopping, best iteration is:\n[324]   train's rmse: 0.000288564   train's RMSPE: 0.222917 valid's rmse: 0.000304914   valid's RMSPE: 0.230543\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000334363   train's RMSPE: 0.257079 valid's rmse: 0.000314801   valid's RMSPE: 0.242648\n[100]   train's rmse: 0.000316923   train's RMSPE: 0.24367  valid's rmse: 0.000304585   valid's RMSPE: 0.234773\n[150]   train's rmse: 0.000309206   train's RMSPE: 0.237736 valid's rmse: 0.000301997   valid's RMSPE: 0.232778\n[200]   train's rmse: 0.000303265   train's RMSPE: 0.233169 valid's rmse: 0.000301008   valid's RMSPE: 0.232016\n[250]   train's rmse: 0.000298113   train's RMSPE: 0.229208 valid's rmse: 0.000300169   valid's RMSPE: 0.23137\nEarly stopping, best iteration is:\n[239]   train's rmse: 0.000299269   train's RMSPE: 0.230097 valid's rmse: 0.000299802   valid's RMSPE: 0.231087\nTraining fold 4\nTraining until validation scores don't improve for 50 rounds\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\n[50]    train's rmse: 0.000330887   train's RMSPE: 0.254488 valid's rmse: 0.000333794   valid's RMSPE: 0.256957\n[100]   train's rmse: 0.000314275   train's RMSPE: 0.241712 valid's rmse: 0.000324174   valid's RMSPE: 0.249552\n[150]   train's rmse: 0.000306024   train's RMSPE: 0.235366 valid's rmse: 0.000322307   valid's RMSPE: 0.248115\n[200]   train's rmse: 0.000300087   train's RMSPE: 0.2308   valid's rmse: 0.000322746   valid's RMSPE: 0.248452\nEarly stopping, best iteration is:\n[194]   train's rmse: 0.000300767   train's RMSPE: 0.231323 valid's rmse: 0.00032156    valid's RMSPE: 0.24754\nOur out of folds RMSPE is 0.247, compared to 0.20502529231135952, giving gain 0.04197470768864048\nOur cv fold scores are [0.254, 0.269, 0.231, 0.231, 0.248]\nTraining fold 0\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000850416   train's RMSPE: 0.234921 valid's rmse: 0.000873041   valid's RMSPE: 0.244797\n[100]   train's rmse: 0.000810529   train's RMSPE: 0.223903 valid's rmse: 0.000846253   valid's RMSPE: 0.237286\n[150]   train's rmse: 0.000790967   train's RMSPE: 0.218499 valid's rmse: 0.000840086   valid's RMSPE: 0.235557\n[200]   train's rmse: 0.000775797   train's RMSPE: 0.214308 valid's rmse: 0.000837966   valid's RMSPE: 0.234962\n[250]   train's rmse: 0.000762035   train's RMSPE: 0.210506 valid's rmse: 0.000838408   valid's RMSPE: 0.235086\n[300]   train's rmse: 0.000749732   train's RMSPE: 0.207108 valid's rmse: 0.000835817   valid's RMSPE: 0.23436\n[350]   train's rmse: 0.000739317   train's RMSPE: 0.204231 valid's rmse: 0.000832894   valid's RMSPE: 0.23354\n[400]   train's rmse: 0.000729864   train's RMSPE: 0.201619 valid's rmse: 0.000835161   valid's RMSPE: 0.234175\nEarly stopping, best iteration is:\n[352]   train's rmse: 0.000739039   train's RMSPE: 0.204154 valid's rmse: 0.000832249   valid's RMSPE: 0.233359\nTraining fold 1\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000846047   train's RMSPE: 0.234839 valid's rmse: 0.000881822   valid's RMSPE: 0.242583\n[100]   train's rmse: 0.00080229    train's RMSPE: 0.222694 valid's rmse: 0.000861711   valid's RMSPE: 0.23705\n[150]   train's rmse: 0.000783302   train's RMSPE: 0.217423 valid's rmse: 0.000859685   valid's RMSPE: 0.236493\n[200]   train's rmse: 0.000767025   train's RMSPE: 0.212905 valid's rmse: 0.000856834   valid's RMSPE: 0.235709\n[250]   train's rmse: 0.000753188   train's RMSPE: 0.209064 valid's rmse: 0.000855508   valid's RMSPE: 0.235344\n[300]   train's rmse: 0.000741655   train's RMSPE: 0.205863 valid's rmse: 0.000854622   valid's RMSPE: 0.2351\n[350]   train's rmse: 0.000732225   train's RMSPE: 0.203245 valid's rmse: 0.000855011   valid's RMSPE: 0.235207\nEarly stopping, best iteration is:\n[322]   train's rmse: 0.000737335   train's RMSPE: 0.204664 valid's rmse: 0.000853501   valid's RMSPE: 0.234792\nTraining fold 2\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000847726   train's RMSPE: 0.235111 valid's rmse: 0.000846945   valid's RMSPE: 0.23377\n[100]   train's rmse: 0.000808669   train's RMSPE: 0.224279 valid's rmse: 0.000828069   valid's RMSPE: 0.22856\n[150]   train's rmse: 0.00078976    train's RMSPE: 0.219034 valid's rmse: 0.000826191   valid's RMSPE: 0.228042\n[200]   train's rmse: 0.000774858   train's RMSPE: 0.214901 valid's rmse: 0.000824001   valid's RMSPE: 0.227437\nEarly stopping, best iteration is:\n[189]   train's rmse: 0.000778547   train's RMSPE: 0.215925 valid's rmse: 0.000823702   valid's RMSPE: 0.227355\nTraining fold 3\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000840108   train's RMSPE: 0.232462 valid's rmse: 0.000889966   valid's RMSPE: 0.247916\n[100]   train's rmse: 0.000800433   train's RMSPE: 0.221483 valid's rmse: 0.000867968   valid's RMSPE: 0.241788\n[150]   train's rmse: 0.000780858   train's RMSPE: 0.216067 valid's rmse: 0.000867771   valid's RMSPE: 0.241733\n[200]   train's rmse: 0.000765963   train's RMSPE: 0.211945 valid's rmse: 0.000865082   valid's RMSPE: 0.240984\nEarly stopping, best iteration is:\n[188]   train's rmse: 0.00076895    train's RMSPE: 0.212772 valid's rmse: 0.000863735   valid's RMSPE: 0.240609\nTraining fold 4\n\n\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n\n\nTraining until validation scores don't improve for 50 rounds\n[50]    train's rmse: 0.000850583   train's RMSPE: 0.236059 valid's rmse: 0.000853338   valid's RMSPE: 0.234907\n[100]   train's rmse: 0.000811834   train's RMSPE: 0.225305 valid's rmse: 0.000829466   valid's RMSPE: 0.228335\n[150]   train's rmse: 0.00079083    train's RMSPE: 0.219476 valid's rmse: 0.000832288   valid's RMSPE: 0.229112\nEarly stopping, best iteration is:\n[100]   train's rmse: 0.000811834   train's RMSPE: 0.225305 valid's rmse: 0.000829466   valid's RMSPE: 0.228335\nOur out of folds RMSPE is 0.233, compared to 0.2129300098765868, giving gain 0.020069990123413206\nOur cv fold scores are [0.233, 0.235, 0.227, 0.241, 0.228]\n\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n\n\n\nrdf(all_preds)\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n\n\n0.2449659904286853\n\n\n\nsdf['diff'] = sdf['new'] - sdf['old']\nsdf[sdf['diff'] < 0]\n\n\n\n\n\n  \n    \n      \n      old\n      new\n      diff\n    \n  \n  \n    \n      31\n      0.55558\n      0.506\n      -0.04958\n    \n  \n\n\n\n\n\nrdf(old_preds[old_preds.stock_id != 31])\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n\n\n0.21287723151184676\n\n\n\nrdf(old_preds)\n\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n\n\n0.21833054495346182\n\n\n\ntmp = old_preds.copy()\ntmp.loc[tmp.stock_id == 31, 'pred'] = all_preds.loc[all_preds.stock_id == 31, 'pred']\n\n\nsdf.loc[[31, 37]]\n\n\n\n\n\n  \n    \n      \n      old\n      new\n      diff\n    \n  \n  \n    \n      31\n      0.555580\n      0.506\n      -0.049580\n    \n    \n      37\n      0.299569\n      0.311\n      0.011431\n    \n  \n\n\n\n\n\nsdf.sort_values('diff')\n\n\n\n\n\n  \n    \n      \n      old\n      new\n      diff\n    \n  \n  \n    \n      31\n      0.555580\n      0.506\n      -0.049580\n    \n    \n      81\n      0.257210\n      0.260\n      0.002790\n    \n    \n      18\n      0.288923\n      0.295\n      0.006077\n    \n    \n      6\n      0.203179\n      0.214\n      0.010821\n    \n    \n      37\n      0.299569\n      0.311\n      0.011431\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      51\n      0.175530\n      0.221\n      0.045470\n    \n    \n      68\n      0.207333\n      0.255\n      0.047667\n    \n    \n      39\n      0.196862\n      0.245\n      0.048138\n    \n    \n      34\n      0.186580\n      0.235\n      0.048420\n    \n    \n      2\n      0.189522\n      0.246\n      0.056478\n    \n  \n\n112 rows × 3 columns\n\n\n\n\nsdf.loc[80]\n\nold     0.25266\nnew     0.27000\ndiff    0.01734\nName: 80, dtype: float64"
  },
  {
    "objectID": "projects/optiver/notebooks/opt-book-trade-eda.html",
    "href": "projects/optiver/notebooks/opt-book-trade-eda.html",
    "title": "chrisrichardmiles",
    "section": "",
    "text": "#all_no_test\nfrom opt_utils import * \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nimport scipy.cluster.hierarchy as sch\nimport seaborn as sns\n\nplt.rcParams['figure.figsize'] = (15, 7)\nplt.rcParams['font.size'] = 18"
  },
  {
    "objectID": "projects/optiver/notebooks/opt-book-trade-eda.html#price-features",
    "href": "projects/optiver/notebooks/opt-book-trade-eda.html#price-features",
    "title": "chrisrichardmiles",
    "section": "price features",
    "text": "price features\n\ndf = load_bt(DATA_RAW, stock_id, train_or_test)\nadd_wap(df)\n\n\ndff = df[df.time_id == 5]\ndff.wap.describe()\n\n\nprint(dff.wap.values[-1], dff.wap.values[0])\n\n\ndef first(x): return x.values[0]\ndef last(x): return x.values[-1]\n\n\ndfa = df.groupby('time_id').agg({'wap': [first, last, np.min, np.max]})\n\n\ndfa.columns =  ['_'.join(c) for c in dfa.columns]\n\n\ndfa.columns\n\n\n\"\"\"Same as p4 except Im goin to use 10 minutes \ninstead of 5.\"\"\"\ndf = load_bt(DATA_RAW, stock_id, train_or_test)\ndf = add_wap(df)\ndf['log_return'] = df.groupby(['time_id'])['wap'].apply(log_return)\ndf['abs_log_return'] = df['log_return'].abs()\ndf['is_pos_return'] = (df['log_return'] > 0).astype(int)\ndf['is_neg_return'] = (df['log_return'] < 0).astype(int)\ndf['spread_pct'] = (df.ask_price1 - df.bid_price1) / df.wap\ndf['spread_2_pct'] = (df.ask_price2 - df.bid_price2) / df.wap\ndf['spread'] = (df.ask_price1 - df.bid_price1) \ndf['spread_2'] = (df.ask_price2 - df.bid_price2) \ndf['sum_bid'] = (df.bid_size1 + df.bid_size2)\ndf['sum_ask'] = (df.ask_size1 + df.ask_size2)\ndf['bid_ask_ratio'] = df['sum_bid'] / df['sum_ask']\ndf['sum_bid_ask'] = df['sum_bid'] + df['sum_ask']\n\n\n# This shows there is no missing data in the book or trade data\nbookna = 0\ntradena = 0\nfor stock_id in train.stock_id.unique():\n    book = load_bt(DATA_RAW, stock_id, train_or_test, book_only=True)\n    trade = load_bt(DATA_RAW, stock_id, train_or_test, trade_only=True)\n    bookna += book.isna().sum().sum()\n    tradena += trade.isna().sum().sum()\nprint('bookna', bookna, 'tradena', tradena)\n\n\n# for stock_id in train.stock_id.unique():\nstock_id = train.stock_id.unique()[0]\nbook = load_bt(DATA_RAW, stock_id, train_or_test, book_only=True, add_stock_id=True)\ntrade = load_bt(DATA_RAW, stock_id, train_or_test, trade_only=True, add_stock_id=True)\n\n\ndfs=[]\nfor stock_id in train.stock_id.unique():\n    book = load_bt(DATA_RAW, stock_id, train_or_test, book_only=True, add_stock_id=True)\n    trade = load_bt(DATA_RAW, stock_id, train_or_test, trade_only=True, add_stock_id=True)\n    b = book.groupby(['stock_id', 'time_id'])['seconds_in_bucket'].agg(len).to_frame().rename(columns={'seconds_in_bucket': 'len_book'})\n    t = trade.groupby(['stock_id', 'time_id'])['seconds_in_bucket'].agg(len).to_frame().rename(columns={'seconds_in_bucket': 'len_trade'})\n    dfs.append(pd.concat([b, t], axis=1))\ndf_len = pd.concat(dfs)\n\n\ndf_len\n\n\ndff = df_len.reset_index()\ndff['row_id'] = dff['stock_id'].astype(str) + '-' + dff['time_id'].astype(str)\ndff = dff[['row_id', 'len_book', 'len_trade']].set_index('row_id')\ndff = dff.join(train).reset_index()\ndff['diff_len_book_len_trade'] = dff['len_book'] - dff['len_trade']\ndff.head()\n\n\ndff[['len_book', 'len_trade','diff_len_book_len_trade']]\\\n    .corrwith(x['target']).to_frame().rename(columns={0: 'target'})\\\n    .style.background_gradient(cmap ='viridis')\\\n    .set_properties(**{'font-size': '20px'})\n\n\nplt.plot(title='ladkfj')\n\n\ndf_len.len_book.hist()\n\n\ndf_len.len_book.min()\n\n\ndf_len.len_book.max()\n\n\nf = lambda x: np.isnan(x).sum()\n\n\ndf.groupby('time_id')['bid_size1'].agg(f)\n\n\ndff = df.groupby('time_id').agg(len)\n\n\ndff.bid_size1.hist()\n\n\nagg_dict = {\n    'log_return': [realized_volatility, 'count', np.std, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n    'is_pos_return': [np.sum, get_mean_decay(.99, -1), get_mean_decay(.99, 1)], \n    'is_neg_return': [np.sum, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n    'abs_log_return': [np.sum, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n    'sum_bid': [np.sum, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n    'sum_ask': [np.sum, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n    'wap': [np.mean, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n    'spread': [np.mean, np.sum, np.std, get_mean_decay(.99, -1), get_mean_decay(.99, 1), get_mean_decay(.95, -1), get_mean_decay(.95, 1)],\n    'bid_ask_ratio': [np.mean, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n    'sum_bid_ask': [np.mean, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n    'size': [np.mean, np.sum, np.std, get_mean_decay(.99, -1), get_mean_decay(.99, 1), get_mean_decay(.95, -1), get_mean_decay(.95, 1)],\n    'spread_pct': [np.mean, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n\n\n}\ndf_agg = df.groupby(['time_id']).agg(agg_dict).rename(\n    columns={'<lambda_0>': 'mean_decay', \n             '<lambda_1>': 'mean_decay_flip', \n             '<lambda_2>': 'mean_decay_95', \n             '<lambda_3>': 'mean_decay_flip_95',\n            }\n)\ndf_agg.columns = ['_'.join(c) for c in df_agg.columns]\n\n\n############ Realized volume for each minute ############\nfor m in range(1, 11): \n    mask = (df.seconds_in_bucket >= 60 * m - 60) & (df.seconds_in_bucket < 60 * m)\n    df_agg[f'real_vol_min_{m}'] = df[mask].groupby('time_id')['log_return'].agg(realized_volatility)\n\n######### Decay sum of realized volume per minute ########\ncols = [f'real_vol_min_{minute}' for minute in range(1, 11)]\nx = df_agg[cols].values\nfor decay, step in product((.99, .95, .9, .85, .75, .65, .55, .45), (1, -1)): \n    df_agg[f'real_vol_mean_decay_{decay}_{step}'] =  mean_decay(x, decay, step, axis=1)\n#     df_agg['end_beg_decay_ratio'] = df_agg['real_vol_mean_decay_0.85_-1'] / df_agg['real_vol_mean_decay_0.85_1'] # replaced by next code\n\nfor c1, c2 in zip(df_agg.columns, df_agg.columns[1:]): \n    if 'mean_decay_flip' in c2: \n        pre, suf = c2.split('mean_decay_flip')\n        df_agg[pre + 'momentum' + suf] = df_agg[c1] / df_agg[c2]\n    if 'vol_mean_decay' in c2 and '-1' in c2: \n        pre, suf = c2.split('vol_mean_decay')\n        df_agg[pre + 'momentum' + suf] = df_agg[c2] / df_agg[c1]\n\ndf_agg = df_agg.astype('float32')\ndf_agg['no_book'] = (df_agg['log_return_count'] == 0).astype(int)\ndf_agg['no_book'] = df_agg['no_book'].astype('category')\n################# Adding 'row_id' column ##################\ndf_agg.reset_index(inplace=True)\ndf_agg['time_id'] = df_agg.time_id.apply(lambda x: f\"{stock_id}-{x}\")\ndf_agg.rename({'time_id': 'row_id'}, axis=1, inplace=True)\nreturn df_agg.set_index('row_id')"
  },
  {
    "objectID": "projects/optiver/notebooks/opt-book-trade-eda.html#looking-at-the-feature-and-target-correlation",
    "href": "projects/optiver/notebooks/opt-book-trade-eda.html#looking-at-the-feature-and-target-correlation",
    "title": "chrisrichardmiles",
    "section": "Looking at the feature and target correlation",
    "text": "Looking at the feature and target correlation\n\ntrain = pd.read_pickle('../input/generate-train-features-script/p5_train.pkl')\n\n\ntop_50_corr_cols = train.corrwith(train.target).abs()\\\n    .sort_values(ascending=False)[:50].index\ntrain[top_50_corr_cols].corr()\n\n\nsns.heatmap(train[top_50_corr_cols].corr())\n\n\ntrain[['log_return_realized_volatility']].corrwith(train.target)\n\n\ntrain['time_id_mean_real_vol'] = train.groupby('time_id')['log_return_realized_volatility'].transform('mean')\n\n\ntrain[['time_id_mean_real_vol']].corrwith(train.target)\n\n\ncols = [c for c in train.columns if 'wap' in c]\ntrain[cols].corrwith(train.target)\n\n\nload_bt(stock_id)"
  },
  {
    "objectID": "projects/optiver/notebooks/opt-eda-modified-from-host-nb.html",
    "href": "projects/optiver/notebooks/opt-eda-modified-from-host-nb.html",
    "title": "Optiver Realized Volatility Prediction",
    "section": "",
    "text": "#all_no_test\n\n\nA glimpse of our trading floor\n\n\n\nwork_at_optiver\n\n\nBackground info Optiver is a market maker, who offers asks and bids to both sides to increase market liquidity. Like a bookie or a casino?\nWhat are we predicting? In this competition, you will be given 10 minutes of book data and we ask you to predict what the volatility will be in the following 10 minutes. Volatility will be measured as follows:\nWe will compute the log returns over all consecutive book updates and we define the realized volatility, σ , as the squared root of the sum of squared log returns. σ=∑tr2t−1,t−−−−−−−√\nWhere we use WAP as price of the stock to compute log returns.\n\n\nIntroduction\nIn order to make Kagglers better prepared for this competition, Optiver’s data scientists have created a tutorial notebook looping through some financial concepts covered in this particular trading challenge. Also, the data structure and the example code submission will also be presented in this notebook.\n\n\nOrder book\nThe term order book refers to an electronic list of buy and sell orders for a specific security or financial instrument organized by price level. An order book lists the number of shares being bid on or offered at each price point.\nBelow is a snapshot of an order book of a stock (let’s call it stock A), as you can see, all intended buy orders are on the left side of the book displayed as “bid” while all intended sell orders are on the right side of the book displayed as “offer/ask”\n\n\n\norder_book_1\n\n\nAn actively traded financial instrument always has a dense order book (A liquid book). As the order book data is a continous representation of market demand/supply it is always considered as the number one data source for market research.\n\n\nTrade\nAn order book is a representation of trading intention on the market, however the market needs a buyer and seller at the same price to make the trade happen. Therefore, sometimes when someone wants to do a trade in a stock, they check the order book and find someone with counter-interest to trade with.\nFor example, imagine you want to buy 20 shares of a stock A when you have the order book in the previous paragraph. Then you need to find some people who are willing to trade against you by selling 20 shares or more in total. You check the offer side of the book starting from the lowest price: there are 221 shares of selling interest on the level of 148. You can lift 20 shares for a price of 148 and guarantee your execution. This will be the resulting order book of stock A after your trade:\n\n\n\norder_book2\n\n\nIn this case, the seller(s) sold 20 shares and buyer bought 20 shares, the exchange will match the order between seller(s) and buyer and one trade message will be broadcast to public:\n\n20 shares of stock A traded on the market at price of 148.\n\nSimilar to order book data, trade data is also extremely crucial to Optiver’s data scientists, as it reflects how active the market is. Actually, some commonly seen technical signals of the financial market are derived from trade data directly, such as high-low or total traded volume.\n\n\nMarket making and market efficiency\nImagine, on another day, stock A’s order book becomes below shape, and you, again, want to buy 20 shares from all the intentional sellers. As you can see the book is not as dense as the previous one, and one can say, compared with the previous one, this book is less liquid.\n\n\n\norder_book_3\n\n\nYou could insert an order to buy at 148. However, there is nobody currently willing to sell to you at 148, so your order will be sitting in the book, waiting for someone to trade against it. If you get unlucky, the price goes up, and others start bidding at 149, and you never get to buy at all. Alternatively, you could insert an order to buy at 155. The exchange would match this order against the outstanding sell order of one share at 149, so you buy 1 lot at 149. Similarly, you’d buy 12 shares at a price of 150, and 7 shares at 151. Compared to trying to buy at 148, there is no risk of not getting the trade that you wanted, but you do end up buying at a higher price.\nYou can see that in such an inefficient market it is difficult to trade, as trading will be more expensive, and if you want quality execution of your orders, you need to deal with higher market risk. That is why investors love liquidity, and market makers like Optiver are there to provide it, no matter how extreme market conditions are.\nA market maker is a firm or individual who actively quotes two-sided markets in a security, providing bids and offers (known as asks) along with the market size of each. As a market maker will show both bid and offer orders, an order book with the presence of market maker will be more liquid, therefore a more efficient market will be provided to end investors to trade freely without concern on executions.\n\n\nOrder book statistics\nThere are a lot of statistics Optiver data scientist can derive from raw order book data to reflect market liquidity and stock valuation. These stats are proven to be fundamental inputs of any market prediction algorithms. Below we would like to list some common stats to inspire Kagglers mining more valuable signals from the order book data.\nLet’s come back to the original order book of stock A\n\n\n\norder_book_1\n\n\n\\[ WAP = \\frac{BidPrice_{1}*AskSize_{1} + AskPrice_{1}*BidSize_{1}}{BidSize_{1} + AskSize_{1}} \\]\n\nwap = ((147 * 221) + (148 * 251)) / (251 + 221)\nwap\n\nbid/ask spread\nAs different stocks trade on different level on the market we take the ratio of best offer price and best bid price to calculate the bid-ask spread.\nThe formula of bid/ask spread can be written in below form: \\[BidAskSpread = BestOffer/BestBid -1\\]\nWeighted averaged price\nThe order book is also one of the primary source for stock valuation. A fair book-based valuation must take two factors into account: the level and the size of orders. In this competition we used weighted averaged price, or WAP, to calculate the instantaneous stock valuation and calculate realized volatility as our target.\nThe formula of WAP can be written as below, which takes the top level price and volume information into account:\n\\[ WAP = \\frac{BidPrice_{1}*AskSize_{1} + AskPrice_{1}*BidSize_{1}}{BidSize_{1} + AskSize_{1}} \\]\nAs you can see, if two books have both bid and ask offers on the same price level respectively, the one with more offers in place will generate a lower stock valuation, as there are more intended seller in the book, and more seller implies a fact of more supply on the market resulting in a lower stock valuation.\nNote that in most of cases, during the continuous trading hours, an order book should not have the scenario when bid order is higher than the offer, or ask, order. In another word, most likely, the bid and ask should never be in cross.\nIn this competition the target is constructed from the WAP. The WAP of the order book snapshot is 147.5317797.\n\n\nLog returns\nHow can we compare the price of a stock between yesterday and today?\nThe easiest method would be to just take the difference. This is definitely the most intuitive way, however price differences are not always comparable across stocks. For example, let’s assume that we have invested $$$1000 dollars in both stock A and stock B and that stock A moves from $$$100 to $$$102 and stock B moves from $$$10 to $$\\(11. We had a total of 10 shares of A (\\)$1000  /  $100 = 10$) which led to a profit of \\(10 \\cdot (\\$102 - \\$100) = \\$20\\) and a total of 100 shares of B that yielded $100. So the price increase was larger for stock A, although the move was proportionally much larger for stock B.\nWe can solve the above problem by dividing the move by the starting price of the stock, effectively computing the percentage change in price, also known as the stock return. In our example, the return for stock A was \\(\\frac{\\$102 - \\$100 }{\\$100} = 2\\%\\), while for stock B it was \\(\\frac{\\$11 - \\$10 }{\\$10} = 10\\%\\). The stock return coincides with the percentage change in our invested capital.\nReturns are widely used in finance, however log returns are preferred whenever some mathematical modelling is required. Calling \\(S_t\\) the price of the stock \\(S\\) at time \\(t\\), we can define the log return between \\(t_1\\) and \\(t_2\\) as: \\[\nr_{t_1, t_2} = \\log \\left( \\frac{S_{t_2}}{S_{t_1}} \\right)\n\\] Usually, we look at log returns over fixed time intervals, so with 10-minute log return we mean \\(r_t = r_{t - 10 min, t}\\).\nLog returns present several advantages, for example: - they are additive across time \\(r_{t_1, t_2} + r_{t_2, t_3} = r_{t_1, t_3}\\) - regular returns cannot go below -100%, while log returns are not bounded\n\n\nRealized volatility\nWhen we trade options, a valuable input to our models is the standard deviation of the stock log returns. The standard deviation will be different for log returns computed over longer or shorter intervals, for this reason it is usually normalized to a 1-year period and the annualized standard deviation is called volatility.\nWhat are we being asked to predict ?\nIn this competition, you will be given 10 minutes of book data and we ask you to predict what the volatility will be in the following 10 minutes. Volatility will be measured as follows:\nWe will compute the log returns over all consecutive book updates and we define the realized volatility, \\(\\sigma\\), as the squared root of the sum of squared log returns. \\[\n\\sigma = \\sqrt{\\sum_{t}r_{t-1, t}^2}\n\\] Where we use WAP as price of the stock to compute log returns.\nWe want to keep definitions as simple and clear as possible, so that Kagglers without financial knowledge will not be penalized. So we are not annualizing the volatility and we are assuming that log returns have 0 mean.\n\n# If there is a 10% return then \nimport math\nimport numpy as np\nr10 = math.log(1.1) ** 2\nr_10 = math.log(.9) ** 2\nr20 = math.log(1.2) ** 2\nr_20 = math.log(.8) ** 2\nprint(f'{r10:.5f} is the addition of a 10% return in a single measurement')\nprint(f'{r_10:.5f} is the addition of a -10% return in a single measurement')\nprint(f'{r20:.5f} is the addition of a 20% return in a single measurement')\nprint(f'{r_20:.5f} is the addition of a -20% return in a single measurement')\nprint(f'This gives a a loss a slightly higher weight, with ratios {r_10 / r10: .4f} and {r_20 / r20: .4f}')\nprint('So the greater the absolute return, the more heavily a loss is weighted compared to a gain.')\n\nfor x in np.linspace(.1, .99, 10): \n    print(f'change {x: .2f}: {math.log((1 - x) / 1) ** 2 / math.log((1 + x)/ 1) ** 2:.4f} loss/gain importance ratio')\n\n\n\nCompetition data\nIn this competition, Kagglers are challenged to generate a series of short-term signals from the book and trade data of a fixed 10-minute window to predict the realized volatility of the next 10-minute window. The target, which is given in train/test.csv, can be linked with the raw order book/trade data by the same time_id and stock_id. There is no overlap between the feature and target window.\nNote that the competition data will come with partitioned parquet file. You can find a tutorial of parquet file handling in this notebook\n\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\ntrain = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain.head()\n\n\n\n\n\n  \n    \n      \n      stock_id\n      time_id\n      target\n    \n  \n  \n    \n      0\n      0\n      5\n      0.004136\n    \n    \n      1\n      0\n      11\n      0.001445\n    \n    \n      2\n      0\n      16\n      0.002168\n    \n    \n      3\n      0\n      31\n      0.002195\n    \n    \n      4\n      0\n      62\n      0.001747\n    \n  \n\n\n\n\nNot all time_ids are included for all stock_ids\n\ntrain.groupby('stock_id')['time_id'].count().value_counts()\n\n3830    107\n3829      3\n3815      1\n3820      1\nName: time_id, dtype: int64\n\n\n\ndisplay(train[train.stock_id == 0]['time_id'].min())\ndisplay(train[train.stock_id == 0]['time_id'].max())\ndisplay(train[train.stock_id == 0]['time_id'].count())\ndisplay(train[train.stock_id == 0]['time_id'].nunique())\n\n5\n\n\n32767\n\n\n3830\n\n\n3830\n\n\nTaking the first row of data, it implies that the realized vol of the target bucket for time_id 5, stock_id 0 is 0.004136. How does the book and trade data in feature bucket look like for us to build signals?\n\nbook_example = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0')\ntrade_example =  pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0')\ndisplay(book_example.head(3))\ndisplay(trade_example.head(3))\n\n\n\n\n\n  \n    \n      \n      time_id\n      seconds_in_bucket\n      bid_price1\n      ask_price1\n      bid_price2\n      ask_price2\n      bid_size1\n      ask_size1\n      bid_size2\n      ask_size2\n    \n  \n  \n    \n      0\n      5\n      0\n      1.001422\n      1.002301\n      1.00137\n      1.002353\n      3\n      226\n      2\n      100\n    \n    \n      1\n      5\n      1\n      1.001422\n      1.002301\n      1.00137\n      1.002353\n      3\n      100\n      2\n      100\n    \n    \n      2\n      5\n      5\n      1.001422\n      1.002301\n      1.00137\n      1.002405\n      3\n      100\n      2\n      100\n    \n  \n\n\n\n\n\n\n\n\n  \n    \n      \n      time_id\n      seconds_in_bucket\n      price\n      size\n      order_count\n    \n  \n  \n    \n      0\n      5\n      21\n      1.002301\n      326\n      12\n    \n    \n      1\n      5\n      46\n      1.002778\n      128\n      4\n    \n    \n      2\n      5\n      50\n      1.002818\n      55\n      1\n    \n  \n\n\n\n\n\nbook_example\n\n\n\n\n\n  \n    \n      \n      time_id\n      seconds_in_bucket\n      bid_price1\n      ask_price1\n      bid_price2\n      ask_price2\n      bid_size1\n      ask_size1\n      bid_size2\n      ask_size2\n    \n  \n  \n    \n      0\n      5\n      0\n      1.001422\n      1.002301\n      1.001370\n      1.002353\n      3\n      226\n      2\n      100\n    \n    \n      1\n      5\n      1\n      1.001422\n      1.002301\n      1.001370\n      1.002353\n      3\n      100\n      2\n      100\n    \n    \n      2\n      5\n      5\n      1.001422\n      1.002301\n      1.001370\n      1.002405\n      3\n      100\n      2\n      100\n    \n    \n      3\n      5\n      6\n      1.001422\n      1.002301\n      1.001370\n      1.002405\n      3\n      126\n      2\n      100\n    \n    \n      4\n      5\n      7\n      1.001422\n      1.002301\n      1.001370\n      1.002405\n      3\n      126\n      2\n      100\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      917548\n      32767\n      568\n      0.998275\n      0.998754\n      0.997796\n      0.998946\n      90\n      90\n      48\n      28\n    \n    \n      917549\n      32767\n      569\n      0.998275\n      0.998754\n      0.997892\n      0.998946\n      91\n      90\n      200\n      28\n    \n    \n      917550\n      32767\n      571\n      0.998275\n      0.998754\n      0.997892\n      0.998946\n      91\n      90\n      100\n      28\n    \n    \n      917551\n      32767\n      572\n      0.998275\n      0.998754\n      0.997892\n      0.998946\n      92\n      90\n      100\n      28\n    \n    \n      917552\n      32767\n      582\n      0.998275\n      0.998754\n      0.998179\n      0.998946\n      92\n      90\n      26\n      28\n    \n  \n\n917553 rows × 10 columns\n\n\n\n\nstock_id = '0'\nbook_example = book_example[book_example['time_id']==5]\nbook_example.loc[:,'stock_id'] = stock_id\ntrade_example = trade_example[trade_example['time_id']==5]\ntrade_example.loc[:,'stock_id'] = stock_id\n\nbook data snapshot\n\nbook_example.head()\n\ntrade date snapshot\n\ntrade_example.head()\n\nRealized volatility calculation in python\nIn this competition, our target is to predict short-term realized volatility. Although the order book and trade data for the target cannot be shared, we can still present the realized volatility calculation using the feature data we provided.\nAs realized volatility is a statistical measure of price changes on a given stock, to calculate the price change we first need to have a stock valuation at the fixed interval (1 second). We will use weighted averaged price, or WAP, of the order book data we provided.\n\nbook_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +\n                                book_example['ask_price1'] * book_example['bid_size1']) / (\n                                       book_example['bid_size1']+ book_example['ask_size1'])\n\nThe WAP of the stock is plotted below\n\nfig = px.line(book_example, x=\"seconds_in_bucket\", y=\"wap\", title='WAP of stock_id_0, time_id_5')\nfig.show()\n\nTo compute the log return, we can simply take the logarithm of the ratio between two consecutive WAP. The first row will have an empty return as the previous book update is unknown, therefore the empty return data point will be dropped.\n\ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff()\n\n\ndisplay(book_example['wap'].head(3))\ndisplay(book_example['wap'].diff().head(3))\n\n\nbook_example.loc[:,'log_return'] = log_return(book_example['wap'])\nbook_example = book_example[~book_example['log_return'].isnull()]\n\nLet’s plot the tick-to-tick return of this instrument over this time bucket\n\nfig = px.line(book_example, x=\"seconds_in_bucket\", y=\"log_return\", title='Log return of stock_id_0, time_id_5')\nfig.show()\n\nThe realized vol of stock 0 in this feature bucket, will be:\n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\n\nrealized_vol = realized_volatility(book_example['log_return'])\nprint(f'Realized volatility for stock_id 0 on time_id 5 is {realized_vol}')\n\n\n\nNaive prediction: using past realized volatility as target\nA commonly known fact about volatility is that it tends to be autocorrelated. We can use this property to implement a naive model that just “predicts” realized volatility by using whatever the realized volatility was in the initial 10 minutes.\nLet’s calculate the past realized volatility across the training set to see how predictive a single naive signal can be.\n\nimport os\nfrom sklearn.metrics import r2_score\nimport glob\nlist_order_book_file_train = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*')\n\nAs the data is partitioned by stock_id in this competition to allow Kagglers better manage the memory, we try to calculcate realized volatility stock by stock and combine them into one submission file. Note that the stock id as the partition column is not present if we load the single file so we will remedy that manually. We will reuse the log return and realized volatility functions defined in the previous session.\n\ndef realized_volatility_per_time_id(file_path, prediction_column_name):\n    df_book_data = pd.read_parquet(file_path)\n    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  / (\n                                      df_book_data['bid_size1']+ df_book_data['ask_size1'])\n    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n    stock_id = file_path.split('=')[1]\n    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n    return df_realized_vol_per_stock[['row_id',prediction_column_name]]\n\nLooping through each individual stocks, we can get the past realized volatility as prediction for each individual stocks.\n\ndef past_realized_volatility_per_stock(list_file,prediction_column_name):\n    df_past_realized = pd.DataFrame()\n    for file in list_file:\n        df_past_realized = pd.concat([df_past_realized,\n                                     realized_volatility_per_time_id(file,prediction_column_name)])\n    return df_past_realized\n\n\ndf_past_realized_train = past_realized_volatility_per_stock(list_file=list_order_book_file_train,\n                                                           prediction_column_name='pred')\n\nLet’s join the output dataframe with train.csv to see the performance of the naive prediction on training set.\n\ntrain['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\ntrain = train[['row_id','target']]\ndf_joined = train.merge(df_past_realized_train[['row_id','pred']], on = ['row_id'], how = 'left')\n\n\ndf_joined\n\nWe will evaluate the naive prediction result by two metrics: RMSPE and R squared.\n\nfrom sklearn.metrics import r2_score\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\nR2 = round(r2_score(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nRMSPE = round(rmspe(y_true = df_joined['target'], y_pred = df_joined['pred']),3)\nprint(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')\n\nThe performance of the naive model is not amazing but as a benchmark it is a reasonable start.\n\n\nSubmission\nAs a last step, we will make a submission via the tutorial notebook – through a file written to output folder. The naive submission scored a RMSPE 0.327 on public LB, the room of improvement is big for sure!\n\nlist_order_book_file_test = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_test.parquet/*')\ndf_naive_pred_test = past_realized_volatility_per_stock(list_file=list_order_book_file_test,\n                                                           prediction_column_name='target')\ndf_naive_pred_test.to_csv('submission.csv',index = False)\n\nNote that in this competition, there will be only few rows of test data that can be downloaded. The actual evaluation program will run in background after you commit the notebook and manually submit the output. Please check to code requirement for more explanation.\nThe private leaderboard will be built against the real market data collected after the training period, therefore the public and private leaderboard data will have zero overlap. It will be exciting to get your model tested against the live market! As this competition will provide a very rich dataset representing market microstructure, there is unlimited amount of signals one can come up with. It is all on you, good luck! We at Optiver are really looking forward to learn from the talented Kaggle community!\nIf you have any question about this notebook or the financial concepts behind it, feel free to ask in the comment section and we will make sure your questions get answered.\nGood luck!"
  },
  {
    "objectID": "projects/optiver/index_optiver.html",
    "href": "projects/optiver/index_optiver.html",
    "title": "Optiver Realized Volatility Prediction: 91st place solution",
    "section": "",
    "text": "#all_no_test\n#|hide\nimport pandas as pd\ntest = pd.read_csv('input/test.csv')\nsample_submission = pd.read_csv('input/sample_submission.csv')\nbook_test = pd.read_parquet('input/book_test.parquet/stock_id=0')\ntrade_test = pd.read_parquet('input/trade_test.parquet/stock_id=0')"
  },
  {
    "objectID": "projects/optiver/index_optiver.html#what-does-the-host-of-this-competition-want",
    "href": "projects/optiver/index_optiver.html#what-does-the-host-of-this-competition-want",
    "title": "Optiver Realized Volatility Prediction: 91st place solution",
    "section": "What does the host of this competition want?",
    "text": "What does the host of this competition want?\nPredictions of the volatility of stock prices over the next 10 minute window, given trading data and book data."
  },
  {
    "objectID": "projects/optiver/index_optiver.html#why-volatility",
    "href": "projects/optiver/index_optiver.html#why-volatility",
    "title": "Optiver Realized Volatility Prediction: 91st place solution",
    "section": "Why volatility?",
    "text": "Why volatility?\nVolatility is important because it is used in calculating the value of a stock option. We can trade more profitably if we are better at determining value.\n\\[\n\\textrm{option value} = \\textrm{intrinsic value} + \\textrm{time value}\n\\]\nIntrinsic value is just the difference between the current price of the stock and strike price of the option, so it is known at the time of sale. But the time value is harder to calculate. To calculate the time value, one would need to know the probability density distribution of stock price at the expiration time of the option. The volatility of a stock’s price will affect that distribution since a stock with high volatility will have larger price changes over time. Therefore if we can better predict the volatility of a stock, we can trade options more profitably."
  },
  {
    "objectID": "projects/optiver/index_optiver.html#precisely-what-are-we-being-asked-to-predict",
    "href": "projects/optiver/index_optiver.html#precisely-what-are-we-being-asked-to-predict",
    "title": "Optiver Realized Volatility Prediction: 91st place solution",
    "section": "Precisely, what are we being asked to predict?",
    "text": "Precisely, what are we being asked to predict?\n\nrealized volatility\nWe will compute the log returns over all consecutive book updates and we define the realized volatility, \\(\\sigma\\), as the squared root of the sum of squared log returns. \\[\n\\sigma = \\sqrt{\\sum_{t}r_{t-1, t}^2}\n\\] ### Log returns Calling \\(S_t\\) the price of the stock \\(S\\) at time \\(t\\), we can define the log return between \\(t_1\\) and \\(t_2\\) as: \\[\nr_{t_1, t_2} = \\log \\left( \\frac{S_{t_2}}{S_{t_1}} \\right)\n\\] Where we use WAP (Weighted Average Price) as price of the stock to compute log returns. \\[ WAP = \\frac{BidPrice_{1}*AskSize_{1} + AskPrice_{1}*BidSize_{1}}{BidSize_{1} + AskSize_{1}} \\] where an order book looks like this:\n\n\n\norder_book_1"
  },
  {
    "objectID": "projects/optiver/index_optiver.html#how-will-our-predictions-be-scored",
    "href": "projects/optiver/index_optiver.html#how-will-our-predictions-be-scored",
    "title": "Optiver Realized Volatility Prediction: 91st place solution",
    "section": "How will our predictions be scored?",
    "text": "How will our predictions be scored?\nSubmissions are evaluated using the root mean square percentage error, defined as:\n\\[\\text{RMSPE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} ((y_i - \\hat{y}_i)/y_i)^2}\\]\nThere will be around 100 stock ids in the test set and around 150,000 rows to predict. With row_id reffering to “stock_id”-“time_id”, the submission file looks like:\n\n# print(sample_submission.to_markdown())\n\n\n\n\n\nrow_id\ntarget\n\n\n\n\n0\n0-4\n0.00304802\n\n\n1\n0-32\n0.00304802\n\n\n2\n0-34\n0.00304802"
  },
  {
    "objectID": "projects/optiver/index_optiver.html#what-does-the-input-data-look-like-at-the-time-of-prediction",
    "href": "projects/optiver/index_optiver.html#what-does-the-input-data-look-like-at-the-time-of-prediction",
    "title": "Optiver Realized Volatility Prediction: 91st place solution",
    "section": "What does the input data look like at the time of prediction?",
    "text": "What does the input data look like at the time of prediction?\n\nbook_test.parque\nA parquet file partitioned by stock_id. Provides order book data on the most competitive buy and sell orders entered into the market. The top two levels of the book are shared. The first level of the book will be more competitive in price terms, it will then receive execution priority over the second level.\nHere are the first few rows of the book data for stock_id 0:\n\n\n# print(book_test.to_markdown())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntime_id\nseconds_in_bucket\nbid_price1\nask_price1\nbid_price2\nask_price2\nbid_size1\nask_size1\nbid_size2\nask_size2\n\n\n\n\n0\n4\n0\n1.00005\n1.00059\n0.999656\n1.00064\n91\n100\n100\n24\n\n\n1\n4\n1\n1.00005\n1.00059\n0.999656\n1.00064\n91\n100\n100\n20\n\n\n2\n4\n5\n1.00005\n1.00064\n0.999656\n1.00089\n290\n20\n101\n15\n\n\n\n\n\ntrade_test.parquet\nA parquet file partitioned by stock_id. Contains data on trades that actually executed. Usually, in the market, there are more passive buy/sell intention updates (book updates) than actual trades, therefore one may expect this file to be more sparse than the order book.\nHere are the first few rows of the trade data for stock_id 0:\n\n# print(trade_test.to_markdown())\n\n\n\n\n\n\n\n\n\n\n\n\n\ntime_id\nseconds_in_bucket\nprice\nsize\norder_count\n\n\n\n\n0\n4\n7\n1.00034\n1\n1\n\n\n1\n4\n24\n1.00005\n100\n7\n\n\n2\n4\n27\n1.00006\n100\n3\n\n\n\n\n\ntest.csv\nProvides the mapping between the other data files and the submission file. As with other test files, most of the data is only available to your notebook upon submission with just the first few rows available for download.\n\n# print(test.to_markdown())\n\n\n\n\n\nstock_id\ntime_id\nrow_id\n\n\n\n\n0\n0\n4\n0-4\n\n\n1\n0\n32\n0-32\n\n\n2\n0\n34\n0-34\n\n\n\n\nImportant notes about the data:\n\nAs stated on the data page, Time IDs are not necessarily sequential but are consistent across all stocks. This is very important information. It means we can use information from all stocks in a given time_id, but can’t create lagging features since we can’t order the data by time. However, this turned out not to be completely true. The winner of the competiton used the price tick size to reverse engineer the order of the time_ids, as stated in their write up: https://www.kaggle.com/competitions/optiver-realized-volatility-prediction/discussion/274970. I did not use this technique in my solution.\nData for all time_ids are given in one batch, instead of sequentially. This is not how predictions are made in the real world, where you need to make predictions and act on them before you have any data from the future. Even though the time_ids are shuffled, we can still use aggregated information accross all time_ids when making predictions. I did take advantage of this in my solution by aggregating data across all time_ids."
  },
  {
    "objectID": "projects/optiver/index_optiver.html#my-solution",
    "href": "projects/optiver/index_optiver.html#my-solution",
    "title": "Optiver Realized Volatility Prediction: 91st place solution",
    "section": "My solution",
    "text": "My solution\n\nHow to reproduce results\nTo predict on the final test data, you must make a submission through kaggle.\nThe script that produces the final predictions for competition test set: https://www.kaggle.com/code/chrisrichardmiles/opt-inf-ensemble-final-1/notebook?scriptVersionId=75800583\nThe last link is to the last step in the pipeline. All of the model training scripts are public. They can be found in the input section of that notebook, also linked here: https://www.kaggle.com/code/chrisrichardmiles/opt-inf-ensemble-final-1/data?scriptVersionId=75800583\nThe rest of the pipeline is also public:\n\nFeature generation: https://www.kaggle.com/chrisrichardmiles/generate-train-features-script-p13\nModule opt_fe.py: https://www.kaggle.com/code/chrisrichardmiles/opt-fe\nModule opt_utils.py: https://www.kaggle.com/code/chrisrichardmiles/opt-utils\n\n\n\nSimple model reproduction locally from scratch\n\nRequirements: 16 GB of RAM and minconda installed\n\nI have provided a script that will process the raw input data into training features and train one of the best single models which scores 0.21986 rmspe on the test set and would place 177th in the competition.\n\n177th place simple model kaggle submission\n\nTraining: https://www.kaggle.com/code/chrisrichardmiles/opt-train-dart-op-175-fold-0/notebook\nSubmission: https://www.kaggle.com/code/chrisrichardmiles/opt-best-dart-inference/notebook\n\n\n\nInstructions to build model locally\n\nClone this repository and navigate to the optiver directory:\n\ngit clone https://github.com/ChrisRichardMiles/chrisrichardmiles.git\ncd chrisrichardmiles/projects/optiver\n\nThe competition data can be found here: https://www.kaggle.com/competitions/optiver-realized-volatility-prediction/overview/evaluation\nDownload data into the input folder. If you have the kaggle api installed, with your kaggle.json file in /root/.kaggle, you can run the following:\n\nkaggle competitions download -p input -c optiver-realized-volatility-prediction\n\nRemove duplicate files and unzip the data\n\nrm -rf input/*.parquet input/*.csv\nunzip -d input -q input/optiver-realized-volatility-prediction.zip\n\nIf you’d like to save the metadata and results of the model training at neptune.ai, run the following with correct edits for your neptune project name and api token:\n\nexport NEPTUNE_PROJECT='neputune_username/project_name'\nexport NEPTUNE_API_TOKEN='YOUR_LONG_API_TOKEN'\n\nCreate the conda environment\n\nconda env create -f env.yml\nconda activate opt\n\nRun run.sh to create features and train the model\n\nbash run.sh\nThis will create train features as a pickle file called p13_train.pkl and then train the lightgbm-dart model, with the output stored in the folder dart_model\n\n\n\nSolution\nI used gradient boosted tree based models and neural networks. For gradient boosting, I used the Lightgbm implementation, using both standard gradient boosting and dart mode. For the neural networks, I used the tabnet architecture, implemented by Optimo, at this repository: https://github.com/dreamquark-ai/tabnet.\n\nDart paper: https://arxiv.org/pdf/1505.01866.pdf K. V. Rashmi, Ran Gilad-Bachrach (2015)\nTabnet paper: https://arxiv.org/pdf/1908.07442.pdf Arik, S. O., & Pfister, T. (2019)\n\nMy final submission is a blend of predictions from 10 different models. The blend is 1/2(weighted arithmetic mean) + 1/2(weighted geometric mean). The weights are determined using the minimize function from scipy. All models have the same input features, generated by the p13 function in fe.py.\n\n\n\noptiver_model_diagram_cropped.png\n\n\n\n\nModels\n\nRegular models trained with 5-fold cross validation.\n\ndart: lightgbm model with dart mode, using lgb_params\ndart_175: lightgbm model with dart mode, using dart_175_params\ntab: tabnet model with tabnet_params\ntab_181: same as tab, except T_0 is changed from 200 to 30 in scheduler_params\ntab_183: same as tab_181 except n_steps is changed from 2 to 3.\n\n\n\nNested models trained with nested cross validation\n\ntab_nested: same as tab, but nested cv.\ndart_nested: same as dart, but nested cv.\ndart_175_nested: same as dart_175, but nested cv.\n\n\n\nLevel 2 models:\nThese models have the same features as the previous models, except with added predictions from tab_nested and dart_nested * dart_l2: same params as dart * lgb_l2: same as dart_l2, except boosting_type=gbdt\n\n\nParameters\nlgb_params = {\n        \"boosting_type\": \"dart\",\n        \"objective\": \"rmse\",\n        \"learning_rate\": .05,\n        \"num_leaves\": 255,\n        \"min_data_in_leaf\": 255,\n        \"feature_fraction\": 0.8,\n        \"bagging_fraction\": .5,\n        \"bagging_freq\": 1,      \n        \"n_estimators\": 10_000,\n        \"early_stopping_rounds\": 400,\n        \"n_jobs\": -1,\n        \"seed\": 42,\n        \"verbose\": -1, \n    }\n    \ndart_175 = {\n        \"boosting_type\": \"dart\",\n        \"objective\": \"rmse\",\n        \"learning_rate\": .05,\n        \"num_leaves\": 255,\n        \"min_data_in_leaf\": 2 ** 10,\n        \"feature_fraction\": 0.25,\n        \"bagging_fraction\": .85, \n        \"bagging_freq\": 1,      \n        \"n_estimators\": 10_000,\n        \"early_stopping_rounds\": 400,\n        \"n_jobs\": -1,\n        \"seed\": 42,\n        \"verbose\": -1, \n    }\n    \ntabnet_params = {\n        'cat_emb_dim': 1,\n        'n_d': ND_NA,\n        'n_a': ND_NA,\n        'n_steps': 2,\n        'gamma': 2,\n        'n_independent': 2,\n        'n_shared': 2,\n        'lambda_sparse': 0,\n        'optimizer_fn': Adam,\n        'optimizer_params': {'lr': 0.02},\n        'mask_type': 'entmax',\n        'scheduler_params': {\n            'T_0': 200,\n            'T_mult': 1,\n            'eta_min': 0.0001,\n            'last_epoch': -1,\n            'verbose': False\n        }\n\n\n\nFeatures\n\nTop 25 features\nThis figure is taken from a dart model trained on a single fold. Standard lightgbm models and tabnet models also showed similar feature importance, with slight variations. \nMeaning of commonly used strings in features * {time_id or stock_id}_{feature}_{mean or std} means that we encoded the mean or standard deviation of feature onto each time_id or stock_id\n\n{feature}_mean_decay: Exponentially weighted mean of feature, with later data being higher weighted.\n{feature}_mean_decay_flip: Exponentially weighted mean of feature, with earlier data being higher weighted.\n{feature}_momentum = {feature}_mean_decay / {feature}_mean_decay_flip.\n\nTop 25 feature summary * real_vol_mean_decay_{decay factor}_{decay direction}: This is a weighted average of the features real_vol_min_{minute x of range(0,9)}. The weights are exponentially weighted by the “decay factor”. The weight of the ith minute has a weight of (decay factor) ^ i. The “decay direction” indicates if the highest weight is at the beginning (1) or at the end (-1). * real_vol_mean_decay_{decay factor}_{decay direction}_2: Just like the last feature, but using the weighted average price of the second level bid and ask book information. * real_vol_min_{minute x of range(0,9)}: The realized volatility calculated for each minute of the 10 minutes of input data. * abs_log_return_std: Standard deviation of the absolute value of the log of the return = abs(log(price1 / price0)). * time_id_order_norm_mean_decay_mean: order_norm is the order count, normalized by the average order count for the stock_id. * time_id_abs_price_wap_diff_mean_decay_mean: abs_price_wap_diff is the absolute difference between the weighted average price and the price of a trade. * time_id_spread_momentum_mean: spread is the difference between the ask price and bid price of the first level in the book data. * time_id_spread_pct_momentum_mean: spread_pct = spread / wap (weighted average price) * time_id_order_norm_sum_mean: order_norm_sum is the sum of order_norm. order_norm is the order count, normalized by the average order count for the stock_id. * abs_log_return_mean_decay: Absolute value of the log of the return = abs(log(price1 / price0)). * time_id_real_vol_ratio_5_10_mean: real_vol_ratio_5_10 is sum_0_5 / sum_6_10, where sum_0_5 is the sum of real_vol_min_{x} for x in the range 1 to 5 and sum_6_10 is the sum of real_vol_min_{x} for x in the range 6 to 10. * time_id_real_vol_ratio_5_10_std: real_vol_ratio_5_10 is sum_0_5 / sum_6_10, where sum_0_5 is the sum of real_vol_min_{x} for x in the range 1 to 5 and sum_6_10 is the sum of real_vol_min_{x} for x in the range 6 to 10. * time_id_spread_2_mean_decay_95_mean: spread_2 is the difference between the ask price and bid price of the second level in the book data. * time_id_order_count_sum_mean: order_count_sum is total number of unique orders made in the 10 minute window of input data in a row.\n\n\nFeature creation pipeline\n\nCreate features for an individual stock with a function p{x} (p13 was the final function used).\nEncode mean and standard deviation of selected features onto the categorical features time_id and stock_id.\nRemove time_id and stock_id.\n\ntime_ids would be bad features because they never appear in both train data and testing data. I also didn’t want to use stock_id because I figured I could easily overfit to training data. By encoding the information and dropping time_id and stock_id, I think the models can be made more robust to shifts in data distribution.\n\n\n\np13 preprocessing function steps:\n\nLoad and merge book data and trade data.\nCalculate base features for each row (600 total, one per second over 10 minutes).\nAggregate base features over the full 10 minutes of each time_id to get one row of data per time_id/stock_id combination. Aggregate functions include max_minus_min, mean, std, sum, mean_decay.\nCreate features by combining aggregate features such as f1 - f2, f1 / f2, f1 + f3.\nAdd three dummy_x features that are random gaussian noise. These are used to identify features that are not more useful than random noise.\n\n\n\nEncoding using encode_cols:\nI create tmp by encoding the mean or standard deviation of selected features onto time_id and stock_id. For the training data, I then use the shake_std variable to add random noise sampled from a gaussian distribution, whose standard deviation is eqaul to shake_std * (standard deviation of tmp). With shake_std=.3, I was able to obtain the same boost in cv score as I obtained with shake_std=0, but with a smaller difference between the training score and validation score. I did not add noise to the test data.\nI did not find using shake, which uses the mean of tmp to scale the noise distribution, to be as usefull as shake_std.\ndef encode_cols(df, cols, funcs=['mean', 'std'], on='stock_id', shake=False, shake_std=False): \n    if not cols or not funcs: return df\n    tmp = df.groupby(on)[cols].agg(funcs)\n    tmp.columns = ['_'.join(c) for c in tmp.columns]\n    tmp = tmp.add_prefix(on + '_')\n    tmp =  df.join(tmp, on=on)\n    if shake: \n        for c in tmp.columns: \n            if c.startswith(on + '_'):\n                c_mean = tmp[c].mean()\n                tmp[c] = tmp[c] + np.random.normal(scale=abs(c_mean * shake), size=len(tmp))\n                \n    if shake_std: \n        for c in tmp.columns: \n            if c.startswith(on + '_'):\n                c_std = tmp[c].std()\n                tmp[c] = tmp[c] + np.random.normal(scale=c_std * shake_std, size=len(tmp))\n    return tmp \n\n\n\n\nValidation\nI used k-fold cross validaton with early stopping on the validation set.\nInformation leakage: General term talking about a model that is trained with information advantages not given to the model when predicting unseen data, causing it to perform badly. For instance, if we encode a categorical variabl\nChoices for early stopping: 1. Use train/validation split for each fold and early stop on validation set. * Pros: We risk overfitting on the validation sets. * Cons: Faster experiments and I believe this is the best way to find the best “fit”\n\nUse choice 1 and then retrain one model on the entire train set with the average (mean or median) number of iterations (no validation set).\n\n\nPros: We get to use all the training data at the same time.\nCons: With only one model, the risk that we missed the optimal number of training iterations.\n\n\nUse nested k fold, with early stopping on the inner loop.\n\n\nPros: We get the “proper fit” benefit of early stopping, but our out-of-fold predictions can be made without any data leakage, which makes our cv score a more realistic estimation of errors in production. We can also use these prediction as features in other models (model stacking) since the predictions aren’t made with information leakage.\n\n\nNo early stopping and use large number of iterations with shrinking learning rate and or regularization. I have little experience with this but I believe it is better suited to neural networks rather than gradient boosted trees.\n\nIn this competition I tested 1 vs 2 using both nested k-fold test sets and the public test set as validation. I found that 1 gave better results, even when I tried using a variation of 2, using many num_iterations to retrain models, which increased computation cost but didn’t improve metric.\nI also tried\n\nK-fold cross validation brief explanation:\nWe divide the data into k equally sized “folds”. For each fold, we use the data in that fold as a validation set and use the remaining data to train a model. So for each set of hyperparameters (model, features, settings etc…) we train k models. When predicting a test set or production set of data, we take an average of all k model predictions.\n\nNote on early stopping: When we are training models, we can choose to use the validation set to choose the optimal number of training iterations (number of tree boosters for gradient boosting and number of epochs for neural nets). This comes at the risk of overconfident cross validation scores. we can also retrain a single model with all the data for training, using the average number of iterations found with early stopping. After a few experiments, judging the outcome by nested cross validation score and the public leaderboard score, I found that using early stopping worked best in this competition.\n\n\n\nNested cross validation brief explanation:\nThis method of cross validation allows us to get out of fold predictions on a validation set, but use a separate validation set for early stopping. The benefit is that our cross validation predictions are not “overfit” due to early stopping on the same data, giving more robust validation as well as providing features that can be used for model stacking. The drawback of this method is that you must create k * (k - 1) models, instead of just k models needed for regular k-fold cross validation. * example with 5 folds: To obtain predictions for fold_5, I train 4 models and take a mean of their predictions. Each model sees 3 of the 4 remaining folds as training data with the remaining fold is a validation set for early stopping. The training/validaton splits look like [123|4], [124|3], [134|2], [234|1]."
  },
  {
    "objectID": "projects/m5/04_out_of_stock_detection.html",
    "href": "projects/m5/04_out_of_stock_detection.html",
    "title": "chrisrichardmiles",
    "section": "",
    "text": "# sns.set()\nplt.rcParams['figure.figsize'] = (14,6)\nplt.rcParams['font.size'] = 16"
  },
  {
    "objectID": "projects/m5/04_out_of_stock_detection.html#total-sales-for-all-series-of-aggregation",
    "href": "projects/m5/04_out_of_stock_detection.html#total-sales-for-all-series-of-aggregation",
    "title": "chrisrichardmiles",
    "section": "Total sales for all series of aggregation",
    "text": "Total sales for all series of aggregation\n\n\nget_stats_df\n\n get_stats_df (series_df)\n\nReturns a dataframe that shows basic stats for all series in sereis_df.\n\n\n\nget_series_df\n\n get_series_df (train_df, rollup_matrix_csr, rollup_index, df_cal=None,\n                fill_xmas=False)\n\nReturns a dataframe with series for all 12 levels of aggregation. We also replace leading zeros with np.nan and if fill_xmas, replace christmas sales with average of the day before and day after christmas\n\nrollup_matrix_csr, rollup_index  = get_agg(df_stv)\nseries_df = get_series_df(df_stv, rollup_matrix_csr, rollup_index, df_cal=df_cal, fill_xmas=True)\nstats_df = get_stats_df(series_df)\nw_df = get_df_weights(df_stv, df_cal, df_prices, rollup_index, rollup_matrix_csr, start_test=1914)\n\n/home/c/crm_build/w/chrisrichardmiles/projects/m5/chrisrichardmiles/m5/metric.py:118: RuntimeWarning: Mean of empty slice\n  scale = np.nanmean(np.diff(agg_series, axis=1) ** 2, axis=1)\n\n\n\nseries_df\n\n\n\n\n\n  \n    \n      \n      \n      d_1802\n      d_1803\n      d_1804\n      d_1805\n      d_1806\n      d_1807\n      d_1808\n      d_1809\n      d_1810\n      d_1811\n      ...\n      d_1932\n      d_1933\n      d_1934\n      d_1935\n      d_1936\n      d_1937\n      d_1938\n      d_1939\n      d_1940\n      d_1941\n    \n    \n      level\n      id\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      Total\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      53.0\n    \n    \n      2\n      CA\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      22.0\n      30.0\n      26.0\n      16.0\n      12.0\n      16.0\n      20.0\n      25.0\n      24.0\n      32.0\n    \n    \n      TX\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      12.0\n      12.0\n      11.0\n    \n    \n      WI\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      10.0\n    \n    \n      3\n      CA_1\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      6.0\n      ...\n      7.0\n      10.0\n      4.0\n      4.0\n      2.0\n      0.0\n      6.0\n      7.0\n      3.0\n      7.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12\n      HOUSEHOLD_2_001_TX_2\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      HOUSEHOLD_2_001_TX_3\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      0.0\n      0.0\n      0.0\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      HOUSEHOLD_2_001_WI_1\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      0.0\n      0.0\n    \n    \n      HOUSEHOLD_2_001_WI_2\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      1.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      HOUSEHOLD_2_001_WI_3\n      NaN\n      NaN\n      NaN\n      NaN\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n    \n  \n\n252 rows × 140 columns"
  },
  {
    "objectID": "projects/m5/04_out_of_stock_detection.html#how-many-zeros-do-series-have",
    "href": "projects/m5/04_out_of_stock_detection.html#how-many-zeros-do-series-have",
    "title": "chrisrichardmiles",
    "section": "How many zeros do series have?",
    "text": "How many zeros do series have?\nLets first take a look at the distribution of the zeros fraction of total sales for the level 12 series.\n\ndf = stats_df.loc[12]\ndf.fraction_0.hist(bins=100)\nplt.title('Distribution of item_id x store_id in terms of proportion zeros')\nplt.xlabel('Proportion of sales days that have zero sales')\nplt.ylabel('Count of series')\nplt.show()\n\n\n\n\n\ndf = stats_df.loc[11]\ndf.fraction_0.hist(bins=100)\nplt.title('Distribution of item_id x state_id in terms of proportion zeros')\nplt.xlabel('Proportion of sales days that have zero sales')\nplt.ylabel('Count of series')\nplt.show()\n\n\n\n\n\ndf = stats_df.loc[10]\ndf.fraction_0.hist(bins=100)\nplt.title('Distribution of item_id aggregated over all stores')\nplt.xlabel('Proportion of sales days that have zero sales')\nplt.ylabel('Count of series')\nplt.show()"
  },
  {
    "objectID": "projects/m5/04_out_of_stock_detection.html#plotting-item-sales-for-different-levels-of-aggregation",
    "href": "projects/m5/04_out_of_stock_detection.html#plotting-item-sales-for-different-levels-of-aggregation",
    "title": "chrisrichardmiles",
    "section": "Plotting item sales for different levels of aggregation",
    "text": "Plotting item sales for different levels of aggregation\n\n\nplot_all_item_series\n\n plot_all_item_series (item, series_df, fillna=False, start=0, end=1941)\n\n\n\n\nplot_item_series\n\n plot_item_series (item, series_df, state=None, fillna=False, start=0,\n                   end=1941)\n\nPlots the level 10-12 series containing the item\nLets look at the top weighted items and their zero sales streaks over different aggregation levels. We will fill nan values with -20 so they stand out\n\ntop_weighted_items = w_df.loc[10].sort_values('weight', ascending=False).index\n\n\nplot_all_item_series(top_weighted_items[0], series_df, fillna=-20)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere are definitely streaks of zero sales that do not look natural. I"
  },
  {
    "objectID": "projects/m5/04_out_of_stock_detection.html#detecting-and-marking-out-of-stock-periods",
    "href": "projects/m5/04_out_of_stock_detection.html#detecting-and-marking-out-of-stock-periods",
    "title": "chrisrichardmiles",
    "section": "Detecting and marking out-of-stock periods",
    "text": "Detecting and marking out-of-stock periods\n\nMain functions\n\n\n\nmark_streaks\n\n mark_streaks (ts)\n\nReturns an array of the same length as ts, except positive values are replaced by zero, and zeros are replaced by the lenth of the zero streak to which they belong.\n\nExample\n\n\n\nin\nseries = np.array([np.nan,3,0,0,0,2,0,0,1,0]) mark_streaks(series)\n\n\nout\narray([nan, 0., 3., 3., 3., 0., 2., 2., 0., 1.])\n\n\n\nnan_zeros\n\n nan_zeros (item_series, item_mean)\n\nReturns item_series with streaks replaced by nans, the new average of item series, and max_streak_length, which is the highest streak count that was not replaced with nans.\n\n\n\nfix_oos\n\n fix_oos (item, series_df)\n\nProcesses item and returns series that has np.nan where we think out of stock zeros occur\n\n\nMain command line function\n\n\n\nmake_oos_data\n\n make_oos_data (PATH_DATA_RAW:str<Pathtorawdata>='data/raw',\n                PATH_DATA_INTERIM:str<Pathtointerimdata>='data/interim')\n\nCreates 2 csv files and stores them in the PATH_DATA_INTERIM.\nThe first file is of all time series in the aggregation levels 10, 11, and 12, stored as ‘oos_series_df_level_10_11_12.csv’.\nThe second file, ‘oos_sales_train_evaluation.csv’, has the same format as ‘sales_train_evaluation.csv’, except zero streaks that are believed to be caused by a stock-out are marked with nan.\n\nmake_oos_data(os.path.join(PATH_DATA, 'raw'), os.path.join(PATH_DATA, 'interim'))\n\n                             d_1802  d_1803  d_1804  d_1805  d_1806  d_1807  \\\nid                                                                            \nFOODS_1_001_CA_1_evaluation     1.0     0.0     0.0     0.0     3.0     0.0   \nFOODS_1_001_CA_2_evaluation     1.0     6.0     0.0     0.0     1.0     2.0   \n\n                             d_1808  d_1809  d_1810  d_1811  ...  d_1932  \\\nid                                                           ...           \nFOODS_1_001_CA_1_evaluation     0.0     0.0     0.0     2.0  ...     2.0   \nFOODS_1_001_CA_2_evaluation     2.0     0.0     0.0     0.0  ...     1.0   \n\n                             d_1933  d_1934  d_1935  d_1936  d_1937  d_1938  \\\nid                                                                            \nFOODS_1_001_CA_1_evaluation     3.0     1.0     0.0     0.0     0.0     1.0   \nFOODS_1_001_CA_2_evaluation     0.0     0.0     1.0     1.0     0.0     0.0   \n\n                             d_1939  d_1940  d_1941  \nid                                                   \nFOODS_1_001_CA_1_evaluation     0.0     0.0     0.0  \nFOODS_1_001_CA_2_evaluation     1.0     2.0     0.0  \n\n[2 rows x 140 columns]\n                            id      item_id  dept_id cat_id store_id state_id  \\\n0  FOODS_1_001_CA_1_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_1       CA   \n1  FOODS_1_001_CA_2_evaluation  FOODS_1_001  FOODS_1  FOODS     CA_2       CA   \n\n   d_1802  d_1803  d_1804  d_1805  ...  d_1932  d_1933  d_1934  d_1935  \\\n0     1.0     0.0     0.0     0.0  ...     2.0     3.0     1.0     0.0   \n1     1.0     6.0     0.0     0.0  ...     1.0     0.0     0.0     1.0   \n\n   d_1936  d_1937  d_1938  d_1939  d_1940  d_1941  \n0     0.0     0.0     1.0     0.0     0.0     0.0  \n1     1.0     0.0     0.0     1.0     2.0     0.0  \n\n[2 rows x 146 columns]\n\n\n/tmp/ipykernel_21690/2233498255.py:81: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  a = accum_add_prod.accumulate(zeros, dtype=np.object)\n\n\n\noos_series_df = pd.read_csv(os.path.join(PATH_DATA, 'interim/oos_series_df_level_10_11_12.csv')).set_index(['level', 'id'])\npd.read_csv(os.path.join(PATH_DATA, 'interim/oos_sales_train_evaluation.csv'))\n\n\n\n\n\n  \n    \n      \n      id\n      item_id\n      dept_id\n      cat_id\n      store_id\n      state_id\n      d_1802\n      d_1803\n      d_1804\n      d_1805\n      ...\n      d_1932\n      d_1933\n      d_1934\n      d_1935\n      d_1936\n      d_1937\n      d_1938\n      d_1939\n      d_1940\n      d_1941\n    \n  \n  \n    \n      0\n      FOODS_1_001_CA_1_evaluation\n      FOODS_1_001\n      FOODS_1\n      FOODS\n      CA_1\n      CA\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      FOODS_1_001_CA_2_evaluation\n      FOODS_1_001\n      FOODS_1\n      FOODS\n      CA_2\n      CA\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      FOODS_1_001_CA_3_evaluation\n      FOODS_1_001\n      FOODS_1\n      FOODS\n      CA_3\n      CA\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      FOODS_1_001_CA_4_evaluation\n      FOODS_1_001\n      FOODS_1\n      FOODS\n      CA_4\n      CA\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      FOODS_1_001_TX_1_evaluation\n      FOODS_1_001\n      FOODS_1\n      FOODS\n      TX_1\n      TX\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      65\n      HOUSEHOLD_2_001_TX_2_evaluation\n      HOUSEHOLD_2_001\n      HOUSEHOLD_2\n      HOUSEHOLD\n      TX_2\n      TX\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      66\n      HOUSEHOLD_2_001_TX_3_evaluation\n      HOUSEHOLD_2_001\n      HOUSEHOLD_2\n      HOUSEHOLD\n      TX_3\n      TX\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      67\n      HOUSEHOLD_2_001_WI_1_evaluation\n      HOUSEHOLD_2_001\n      HOUSEHOLD_2\n      HOUSEHOLD\n      WI_1\n      WI\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      68\n      HOUSEHOLD_2_001_WI_2_evaluation\n      HOUSEHOLD_2_001\n      HOUSEHOLD_2\n      HOUSEHOLD\n      WI_2\n      WI\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      69\n      HOUSEHOLD_2_001_WI_3_evaluation\n      HOUSEHOLD_2_001\n      HOUSEHOLD_2\n      HOUSEHOLD\n      WI_3\n      WI\n      NaN\n      NaN\n      NaN\n      NaN\n      ...\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n70 rows × 146 columns\n\n\n\n\n\nVisualizing out of stock periods\n\nplot_all_item_series(top_weighted_items[0], oos_series_df,  fillna=-50, start=999)"
  },
  {
    "objectID": "projects/m5/wrmsse_metric.html",
    "href": "projects/m5/wrmsse_metric.html",
    "title": "WRMSSE metric implementation",
    "section": "",
    "text": "# For fast testing for Continuous Integration\nPATH_DATA = 'small_data'\nPATH_DATA_RAW = 'small_data/raw'\nos.listdir(PATH_DATA_RAW)\n\n['sample_submission.csv',\n 'sell_prices.csv',\n 'calendar.csv',\n 'sales_train_evaluation.csv']\nWe need to implement the competition metric so that we can validate our prediction methods over different time periods. This notebook documents the intution and code needed to build the WRMSSE object. You may want to jump to it and see how to use it, but here are the main purposes of the object:"
  },
  {
    "objectID": "projects/m5/wrmsse_metric.html#building-from-the-math-up",
    "href": "projects/m5/wrmsse_metric.html#building-from-the-math-up",
    "title": "WRMSSE metric implementation",
    "section": "Building from the math up",
    "text": "Building from the math up\n\nRMSSE of each series\n\\[\n\\mathrm{RMSSE} = \\sqrt{\n\\frac{1}{h} \\frac{\\sum_{t = n + 1}^{n + h}(Y_t - \\hat{Y}_t)^2}{\\frac{1}{n - 1}\\sum_{t = 2}^{n}(Y_t - Y_{t - 1})^2}\n}.\n\\]\n\\(Y_t\\) is the actual value at \\(t\\), \\(\\hat{Y}_t\\) the forecasted value, \\(n\\) the number of time series values, and, \\(h\\) the forecasting horizon.\nThings to notice * The bottom of the numerator sums over all training days through \\(n\\), the last day before the forecast horizon. Its purpose is to normalize the errors of the series by scaling them by the average day-to-day difference in sales. This means that the RMSSE scores of any two series can be compared fairly, since both are scaled by their own volatility. * The top of the numerator sums over the 28 days of the forecast horizon, starting on day \\(n\\) + 1 * A prediction model that predicted the previous days sales should get a score of around 1.\nThe metric in this competition sort of compares the models performance to a naive model that always predicts that the next day will be the same as the current day:\n\n\nWRMSSE\n\\[\n\\mathrm{WRMSSE} = \\sum_{i=1}^{42,840} W_i \\times \\mathrm{RMSSE_i}\n\\]\n\\[\nW_i = \\frac{\\sum_{j = n - 28}^{n - 1} volume\\_series_i}  {\\sum_{j = n - 28}^{n - 1} volume\\_all\\_series\\_in\\_level}\n\\]\nThe weight of each series will be computed based on the last 28 observations of the training sample of the dataset, i.e., the cumulative actual dollar sales that each series displayed in that particular period (sum of units sold multiplied by their respective price). Each of the 12 levels of aggregation is comprised of series whose weights add up to 1, and every product appears once in each level.\nTo simplify notation, I like to write the WRMSSE like this:\n\\[\nWRMSSE = \\sum_{i=1}^{42,840} \\left(W_i \\times \\sqrt{\\frac{\\frac{1}{28}\\sum_{j=1}^{28}{(D_j)^2}}{S_i}}\\right)\n\\] * \\(W_i\\): the weight of the ith series * \\(S_i\\): the scaling factor of the ith series * \\(D_j\\): The difference between sales and predicted sales for the ith series on day j\nwhich further simplifies to this: \\[\nWRMSSE = \\sum_{i=1}^{42,840} \\frac{W_i}{\\sqrt{S_i}} \\times \\sqrt{\\frac{1}{28}\\sum_{j=1}^{28}{(D_j)^2}}\n\\]\n\n\nGenerating all series, weights, and scaling factors\nTo build a WRMSSE scoring object, we will need to create tools that can apply this caclulation as efficiently as possible. We will develop a sparse aggregation matrix, created with a one-hot-encoding style, that serves to compute the aggregations for all 42840 series from the bottme level 30490 series. After the aggregation matrix, we will develop methods to compute the weights W and the scaling factor S for all series. We will then combine our tools to create a WRMSSE object, capable of scoring predictions for any 28 validation period of known data.\n\n################## Variables ####################\n# We will work through an example of calculating \n# the WRMSSE by level, and overall. Then we will \n# \nSTART_TEST = 1914 \n# END_TRAIN = START_TEST - 1 # last training day\n\n\nAggregation matrix\nWe know we can compute all the aggregated series by using matrix multiplication with the correctly designed aggregation matrix. Our daily sales have the shape (number_items, prediction_horizon). Our agg matrix will need to have the shape (number_series, number_items) so that we can execute the matrix multiplication agg x sales.\nWe need a list of the aggregating features that will align with our weights and scales so that our matrices will match up. Level 1 does not need a column to group by.\nFor each sereis of each level of the WRMSSE, we will use pandas get_dummies function on the corresponding column or columns.\n\n\n\n\nget_agg\n\n get_agg (df_stv)\n\nGets a sparse aggregaion matrix and index to align weights and scales.\n\nagg_matrix_csr, agg_index = get_agg(df_stv)\ndisplay(agg_index[:5])\nprint('Number of series per each level')\nagg_index.get_level_values(0).value_counts(sort=False)\n\nMultiIndex([(1, 'Total'),\n            (2,    'CA'),\n            (2,    'TX'),\n            (2,    'WI'),\n            (3,  'CA_1')],\n           names=['level', 'id'])\n\n\nNumber of series per each level\n\n\n1      1\n2      3\n3     10\n4      3\n5      7\n6      9\n7     21\n8     30\n9     70\n10     7\n11    21\n12    70\nName: level, dtype: int64\n\n\n\nWeights and scales\n\n\n\n\nget_df_weights\n\n get_df_weights (df_stv, df_cal, df_prices, agg_index, agg_matrix_csr,\n                 start_test=1914)\n\nReturns the weight, scale, and scaled weight of all series, in a dataframe aligned with the agg_index, created in get_agg()\n\nWeights steps\nWe need to convert the sales data into dollar sales data so that we can correctly weight each series. To begin, we consider only the last 28 days of data before START_TEST. We then put the data into “long” format so we can merge the calendar and price information.\nNow we will get the total dollar sales for each item/store combination. Be sure to set sort=False so that our index stays in the proper order. We don’t need df anymore\nWe want to build a weight, scales, and scaled weight columns that are aligned with agg_index. We will divide dollar_sales by the total dollar sales to get the weight W for each series. We don’t need dollar_sales anymore.\n\n\nScaling factor steps\nWe also need to calculate each series scaling factor S, which is the denominator in the WRMSSE cacluation. It can be pulled out of the square root and combined with the series weight to make a single weight W/sqrt(S), simplifying our calculations a bit.\nS is the average squared difference of day to daily sales for a series, excluding leading zeros, for all training days leading up to START_TEST.\nAggregate all series, and replace leading zeros with np.nan so that we can do numpy calculations that will ignore the np.nan.\nNow we can finish our weights and scales dataframe by adding scale and scaled_weight columns.\n\ndf_weights = get_df_weights(df_stv, df_cal, df_prices, agg_index, agg_matrix_csr, start_test=1914)\ndisplay(df_weights)\n\nprint(\"All weights add to 1 for each level\")\ndf_weights.groupby(level=0)['weight'].sum().to_frame()\n\n/tmp/ipykernel_4101/3272591645.py:70: RuntimeWarning: Mean of empty slice\n  scale = np.nanmean(np.diff(agg_series, axis=1) ** 2, axis=1)\n\n\n\n\n\n\n  \n    \n      \n      \n      weight\n      scale\n      scaled_weight\n    \n    \n      level\n      id\n      \n      \n      \n    \n  \n  \n    \n      1\n      Total\n      1.000000\n      0.068950\n      0.068950\n    \n    \n      2\n      CA\n      0.530249\n      0.099428\n      0.052722\n    \n    \n      TX\n      0.186410\n      0.213903\n      0.039874\n    \n    \n      WI\n      0.283341\n      0.126487\n      0.035839\n    \n    \n      3\n      CA_1\n      0.119939\n      0.304138\n      0.036478\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      12\n      HOUSEHOLD_2_001_TX_2\n      0.006322\n      0.921271\n      0.005825\n    \n    \n      HOUSEHOLD_2_001_TX_3\n      0.007903\n      1.450575\n      0.011464\n    \n    \n      HOUSEHOLD_2_001_WI_1\n      0.011064\n      1.792239\n      0.019829\n    \n    \n      HOUSEHOLD_2_001_WI_2\n      0.009483\n      2.225395\n      0.021104\n    \n    \n      HOUSEHOLD_2_001_WI_3\n      0.007903\n      2.257263\n      0.017839\n    \n  \n\n252 rows × 3 columns\n\n\n\nAll weights add to 1 for each level\n\n\n\n\n\n\n  \n    \n      \n      weight\n    \n    \n      level\n      \n    \n  \n  \n    \n      1\n      1.0\n    \n    \n      2\n      1.0\n    \n    \n      3\n      1.0\n    \n    \n      4\n      1.0\n    \n    \n      5\n      1.0\n    \n    \n      6\n      1.0\n    \n    \n      7\n      1.0\n    \n    \n      8\n      1.0\n    \n    \n      9\n      1.0\n    \n    \n      10\n      1.0\n    \n    \n      11\n      1.0\n    \n    \n      12\n      1.0\n    \n  \n\n\n\n\n\n\n\nSample scoring\nLets code a simple example using the last month as predicted sales\n\nactuals = df_stv.iloc[:, -28:].values\npreds = df_stv.iloc[:, -28 * 2: -28].values \n\nbase_errors = actuals - preds\nerrors = agg_matrix_csr * base_errors\nrmse = np.sqrt(np.mean((errors)**2, axis=1))\nwrmsse_by_series = rmse * df_weights.scaled_weight\ndf_scores = pd.DataFrame(wrmsse_by_series).rename(\n                mapper={'scaled_weight': 'WRMSSE'}, axis=1)\nwrmsse = np.sum(wrmsse_by_series) / 12\nprint(wrmsse)\nprint('Scores for all series')\ndisplay(df_scores)\n\n0.8866951218462568\nScores for all series\n\n\n\n\n\n\n  \n    \n      \n      \n      WRMSSE\n    \n    \n      level\n      id\n      \n    \n  \n  \n    \n      1\n      Total\n      0.690365\n    \n    \n      2\n      CA\n      0.382785\n    \n    \n      TX\n      0.180849\n    \n    \n      WI\n      0.207100\n    \n    \n      3\n      CA_1\n      0.124278\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      12\n      HOUSEHOLD_2_001_TX_2\n      0.003651\n    \n    \n      HOUSEHOLD_2_001_TX_3\n      0.007505\n    \n    \n      HOUSEHOLD_2_001_WI_1\n      0.012429\n    \n    \n      HOUSEHOLD_2_001_WI_2\n      0.011965\n    \n    \n      HOUSEHOLD_2_001_WI_3\n      0.012155\n    \n  \n\n252 rows × 1 columns\n\n\n\n\n\nSaving scores\nInstead of saving the scores for each series, I will only save scores for each level, and the total score.\n\nmodel_name = 'last_month_sales'\nstart_test = 1914\n# level_scores\nlevel_scores = df_scores.groupby(level=0).sum()\nlevel_scores.loc[13] = level_scores.mean()\nlevel_scores['model_name'] = model_name\nlevel_scores['start_test'] = start_test\nlevel_scores.reset_index(inplace=True)\nlevel_scores\n\n\n\n\n\n  \n    \n      \n      level\n      WRMSSE\n      model_name\n      start_test\n    \n  \n  \n    \n      0\n      1\n      0.690365\n      last_month_sales\n      1914\n    \n    \n      1\n      2\n      0.770734\n      last_month_sales\n      1914\n    \n    \n      2\n      3\n      0.894521\n      last_month_sales\n      1914\n    \n    \n      3\n      4\n      0.841782\n      last_month_sales\n      1914\n    \n    \n      4\n      5\n      0.918068\n      last_month_sales\n      1914\n    \n    \n      5\n      6\n      0.858148\n      last_month_sales\n      1914\n    \n    \n      6\n      7\n      0.947597\n      last_month_sales\n      1914\n    \n    \n      7\n      8\n      0.936827\n      last_month_sales\n      1914\n    \n    \n      8\n      9\n      0.958316\n      last_month_sales\n      1914\n    \n    \n      9\n      10\n      0.918068\n      last_month_sales\n      1914\n    \n    \n      10\n      11\n      0.947597\n      last_month_sales\n      1914\n    \n    \n      11\n      12\n      0.958316\n      last_month_sales\n      1914\n    \n    \n      12\n      13\n      0.886695\n      last_month_sales\n      1914\n    \n  \n\n\n\n\n\nKeeping track of model / validation set scores.\nI need to be able to keep track of the scores for each model / validation set combination. To make organizing scores easier, I want to combine the columns ‘model_name’, ‘level’, ‘start_test’ into a single column’id’ so I can store the scores with a single column as a unique identifier. I will also want to reverse this process later.\n\n\n\n\ncombine_cols\n\n combine_cols (df, cols:list, sep='__', name='id', reverse=False)\n\nReturns a copy of df with cols combined into a single coloumn name, separated by sep, or with the name column expanded into cols if reverse is True.\n\ncols, sep, name = ['model_name', 'level', 'start_test'], '__', 'id'\n\nprint('level_scores with columns combined')\nlevel_scores = combine_cols(level_scores, cols, sep, name)\ndisplay(level_scores.head(3))\n\nprint('reversed')\ndf_r = combine_cols(level_scores, cols, sep, name, reverse=True)\ndisplay(df_r.head(3))\n\nlevel_scores with columns combined\n\n\n\n\n\n\n  \n    \n      \n      id\n      WRMSSE\n    \n  \n  \n    \n      0\n      last_month_sales__1__1914\n      0.690365\n    \n    \n      1\n      last_month_sales__2__1914\n      0.770734\n    \n    \n      2\n      last_month_sales__3__1914\n      0.894521\n    \n  \n\n\n\n\nreversed\n\n\n\n\n\n\n  \n    \n      \n      model_name\n      level\n      start_test\n      WRMSSE\n    \n  \n  \n    \n      0\n      last_month_sales\n      1\n      1914\n      0.690365\n    \n    \n      1\n      last_month_sales\n      2\n      1914\n      0.770734\n    \n    \n      2\n      last_month_sales\n      3\n      1914\n      0.894521\n    \n  \n\n\n\n\n\nWhat if the model / validation combo already exists\nI want to be able to append my scores to a dataframe so that I will not override previously logged scores, nor will I have copies. I will need a function that ensures I don’t have any problems.\n\n\n\n\nappend_df_unique_id\n\n append_df_unique_id (df, df_new, id_col='id')\n\nReturns a copy of df with df_new appended to it with ’(n)_’ prepended to the id_col if the new column value is already in the original df. This is used to track scores and ensure there are not copies of a unique identifier.\nid_col should be of string type.\n\ntmp = level_scores.head(3).copy()\ndf = tmp.copy()\nfor _ in range(3): \n    df = append_df_unique_id(df, tmp, id_col='id')\nprint('No copies, no overrides')\ndisplay(df)\n\nNo copies, no overrides\n\n\n\n\n\n\n  \n    \n      \n      id\n      WRMSSE\n    \n  \n  \n    \n      0\n      last_month_sales__1__1914\n      0.690365\n    \n    \n      1\n      last_month_sales__2__1914\n      0.770734\n    \n    \n      2\n      last_month_sales__3__1914\n      0.894521\n    \n    \n      0\n      (1)_last_month_sales__1__1914\n      0.690365\n    \n    \n      1\n      (1)_last_month_sales__2__1914\n      0.770734\n    \n    \n      2\n      (1)_last_month_sales__3__1914\n      0.894521\n    \n    \n      0\n      (2)_last_month_sales__1__1914\n      0.690365\n    \n    \n      1\n      (2)_last_month_sales__2__1914\n      0.770734\n    \n    \n      2\n      (2)_last_month_sales__3__1914\n      0.894521\n    \n    \n      0\n      (3)_last_month_sales__1__1914\n      0.690365\n    \n    \n      1\n      (3)_last_month_sales__2__1914\n      0.770734\n    \n    \n      2\n      (3)_last_month_sales__3__1914\n      0.894521\n    \n  \n\n\n\n\n\n\nVisualizing results\n\nmodel_name = 'all_ones'\nfig, ax = plt.subplots()\nlevel_scores = df_scores.groupby(level=0).sum()\nsns.barplot(x=level_scores.index, y=level_scores['WRMSSE'])\nplt.axhline(level_scores.mean()[0], color='blue', alpha=.5, ls=':')\nname_and_days = f'{model_name} day {START_TEST} to {START_TEST + 27}'\ntitle = f'{name_and_days} WRMSSE total: {round(level_scores.mean()[0], 4)}'\nplt.title(title, fontsize=20, fontweight='bold')\nfor i in range(12): \n    ax.text(i, level_scores['WRMSSE'][i+1], \n            str(round(level_scores['WRMSSE'][i+1], 4)), \n            color='black', ha='center', fontsize=15)\nplt.show()\n\n\n\n\n\n\nSaving predictions for competition scoring\nThe host wants predictions submitted in a format like the sample submission file.\n\nprint('The id column needs a _validation or _evaluation tag')\ndisplay(df_ss.head())\ndisplay(df_ss.tail())\n\nThe id column needs a _validation or _evaluation tag\n\n\n\n\n\n\n  \n    \n      \n      id\n      F1\n      F2\n      F3\n      F4\n      F5\n      F6\n      F7\n      F8\n      F9\n      ...\n      F19\n      F20\n      F21\n      F22\n      F23\n      F24\n      F25\n      F26\n      F27\n      F28\n    \n  \n  \n    \n      0\n      HOBBIES_1_001_CA_1_validation\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      1\n      HOBBIES_2_001_CA_1_validation\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      2\n      HOUSEHOLD_1_001_CA_1_validation\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      3\n      HOUSEHOLD_2_001_CA_1_validation\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      4\n      FOODS_1_001_CA_1_validation\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5 rows × 29 columns\n\n\n\n\n\n\n\n  \n    \n      \n      id\n      F1\n      F2\n      F3\n      F4\n      F5\n      F6\n      F7\n      F8\n      F9\n      ...\n      F19\n      F20\n      F21\n      F22\n      F23\n      F24\n      F25\n      F26\n      F27\n      F28\n    \n  \n  \n    \n      135\n      HOUSEHOLD_1_001_WI_3_evaluation\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      136\n      HOUSEHOLD_2_001_WI_3_evaluation\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      137\n      FOODS_1_001_WI_3_evaluation\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      138\n      FOODS_2_001_WI_3_evaluation\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n    \n      139\n      FOODS_3_001_WI_3_evaluation\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n    \n  \n\n5 rows × 29 columns\n\n\n\nExample\n\ndf_preds = pd.DataFrame(preds, index=df_scores.loc[12].index).reset_index()\n\ntest=False\nif not test: df_preds['id'] = df_preds['id'] + '_validation'\nelse: df_preds['id'] = df_preds['id'] + '_evaluation'\n    \ndf_sub = df_ss[['id']].merge(df_preds, on='id', how='left').fillna(0)\nfile_name = 'sub_' + model_name + '.csv'\ndf_sub.to_csv(file_name, index=False)\n\n\npd.read_csv(file_name)\n\n\n\n\n\n  \n    \n      \n      id\n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      ...\n      18\n      19\n      20\n      21\n      22\n      23\n      24\n      25\n      26\n      27\n    \n  \n  \n    \n      0\n      HOBBIES_1_001_CA_1_validation\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      4.0\n      ...\n      1.0\n      3.0\n      0.0\n      1.0\n      1.0\n      1.0\n      3.0\n      0.0\n      1.0\n      1.0\n    \n    \n      1\n      HOBBIES_2_001_CA_1_validation\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n    \n    \n      2\n      HOUSEHOLD_1_001_CA_1_validation\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      1.0\n      0.0\n      1.0\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n    \n    \n      3\n      HOUSEHOLD_2_001_CA_1_validation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4\n      FOODS_1_001_CA_1_validation\n      2.0\n      1.0\n      1.0\n      0.0\n      4.0\n      0.0\n      0.0\n      4.0\n      1.0\n      ...\n      0.0\n      2.0\n      0.0\n      4.0\n      1.0\n      1.0\n      0.0\n      1.0\n      1.0\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      135\n      HOUSEHOLD_1_001_WI_3_evaluation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      136\n      HOUSEHOLD_2_001_WI_3_evaluation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      137\n      FOODS_1_001_WI_3_evaluation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      138\n      FOODS_2_001_WI_3_evaluation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      139\n      FOODS_3_001_WI_3_evaluation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n140 rows × 29 columns\n\n\n\n\n!rm {file_name}"
  },
  {
    "objectID": "projects/m5/wrmsse_metric.html#main-object",
    "href": "projects/m5/wrmsse_metric.html#main-object",
    "title": "WRMSSE metric implementation",
    "section": "Main object",
    "text": "Main object\n\n\nWRMSSE\n\n WRMSSE (PATH_DATA_RAW:str='data/raw', start_test:int=1914,\n         horizon:int=28, df_stv_trunc:pandas.core.frame.DataFrame=None)\n\nThe main object that will hold data, weights and scales which are associated with the forecast horizon starting on start_test, extending horizon days.\nExample use of the WRMSSE evaluator * Test period: Days 1914 - 1941, same as the competition validation period, so the we should get the same score here as we do if we submit the same predictions to kaggle (confirmed). * Predicton model: simlple baseline of predicting sales to be the same as the previous 28 days.\n\nstart_test = 1914\ne = WRMSSE(PATH_DATA_RAW, start_test=start_test)\ne.add_total_scaled_weight()\n\n/tmp/ipykernel_4101/3272591645.py:70: RuntimeWarning: Mean of empty slice\n  scale = np.nanmean(np.diff(agg_series, axis=1) ** 2, axis=1)\n\n\n\ne.w_12\n\n\n\n\n\n  \n    \n      \n      weight\n      scale\n      scaled_weight\n      total_scaled_weight\n    \n    \n      id\n      \n      \n      \n      \n    \n  \n  \n    \n      FOODS_1_001_CA_1_evaluation\n      0.017258\n      0.639995\n      0.011045\n      0.289121\n    \n    \n      FOODS_1_001_CA_2_evaluation\n      0.016212\n      0.357398\n      0.005794\n      0.272530\n    \n    \n      FOODS_1_001_CA_3_evaluation\n      0.012551\n      0.299844\n      0.003763\n      0.268578\n    \n    \n      FOODS_1_001_CA_4_evaluation\n      0.004707\n      1.203066\n      0.005662\n      0.272424\n    \n    \n      FOODS_1_001_TX_1_evaluation\n      0.000523\n      0.805682\n      0.000421\n      0.227676\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      HOUSEHOLD_2_001_TX_2_evaluation\n      0.006322\n      0.921271\n      0.005825\n      0.348558\n    \n    \n      HOUSEHOLD_2_001_TX_3_evaluation\n      0.007903\n      1.450575\n      0.011464\n      0.363599\n    \n    \n      HOUSEHOLD_2_001_WI_1_evaluation\n      0.011064\n      1.792239\n      0.019829\n      0.464320\n    \n    \n      HOUSEHOLD_2_001_WI_2_evaluation\n      0.009483\n      2.225395\n      0.021104\n      0.468462\n    \n    \n      HOUSEHOLD_2_001_WI_3_evaluation\n      0.007903\n      2.257263\n      0.017839\n      0.437300\n    \n  \n\n70 rows × 4 columns\n\n\n\n\npreds = e.df_stv.loc[:, f'd_{start_test - 28}': f'd_{start_test - 1}'].values\ne.score(preds, model_name='same_as_last_month', fast=False)\n\nSaving level scores with model name: same_as_last_month\n\n\n0.8866951218462568\n\n\n\nfig, ax = e.plot_scores()\n\n\n\n\n\ne.dump_scores(PATH_DATA)\npd.read_csv(PATH_DATA + '/scores.csv')\n\n\n\n\n\n  \n    \n      \n      id\n      WRMSSE\n    \n  \n  \n    \n      0\n      same_as_last_month__1__1914\n      0.690365\n    \n    \n      1\n      same_as_last_month__2__1914\n      0.770734\n    \n    \n      2\n      same_as_last_month__3__1914\n      0.894521\n    \n    \n      3\n      same_as_last_month__4__1914\n      0.841782\n    \n    \n      4\n      same_as_last_month__5__1914\n      0.918068\n    \n    \n      5\n      same_as_last_month__6__1914\n      0.858148\n    \n    \n      6\n      same_as_last_month__7__1914\n      0.947597\n    \n    \n      7\n      same_as_last_month__8__1914\n      0.936827\n    \n    \n      8\n      same_as_last_month__9__1914\n      0.958316\n    \n    \n      9\n      same_as_last_month__10__1914\n      0.918068\n    \n    \n      10\n      same_as_last_month__11__1914\n      0.947597\n    \n    \n      11\n      same_as_last_month__12__1914\n      0.958316\n    \n    \n      12\n      same_as_last_month__13__1914\n      0.886695\n    \n  \n\n\n\n\n\ne.make_sub()\npd.read_csv('sub_' + e.model_name + '.csv')\n\n\n\n\n\n  \n    \n      \n      id\n      0\n      1\n      2\n      3\n      4\n      5\n      6\n      7\n      8\n      ...\n      18\n      19\n      20\n      21\n      22\n      23\n      24\n      25\n      26\n      27\n    \n  \n  \n    \n      0\n      HOBBIES_1_001_CA_1_validation\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      4.0\n      ...\n      1.0\n      3.0\n      0.0\n      1.0\n      1.0\n      1.0\n      3.0\n      0.0\n      1.0\n      1.0\n    \n    \n      1\n      HOBBIES_2_001_CA_1_validation\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n    \n    \n      2\n      HOUSEHOLD_1_001_CA_1_validation\n      0.0\n      0.0\n      0.0\n      1.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      1.0\n      0.0\n      1.0\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n    \n    \n      3\n      HOUSEHOLD_2_001_CA_1_validation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      1.0\n      1.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4\n      FOODS_1_001_CA_1_validation\n      2.0\n      1.0\n      1.0\n      0.0\n      4.0\n      0.0\n      0.0\n      4.0\n      1.0\n      ...\n      0.0\n      2.0\n      0.0\n      4.0\n      1.0\n      1.0\n      0.0\n      1.0\n      1.0\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      135\n      HOUSEHOLD_1_001_WI_3_evaluation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      136\n      HOUSEHOLD_2_001_WI_3_evaluation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      137\n      FOODS_1_001_WI_3_evaluation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      138\n      FOODS_2_001_WI_3_evaluation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      139\n      FOODS_3_001_WI_3_evaluation\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n140 rows × 29 columns\n\n\n\nSubmit this file and see that it scores the same on the kaggle public leaderboard\n\n!rm {'sub_' + e.model_name + '.csv'} {PATH_DATA + '/scores.csv'}"
  },
  {
    "objectID": "projects/m5/wrmsse_metric.html#using-weights-for-custom-objective-functions-and-metrics",
    "href": "projects/m5/wrmsse_metric.html#using-weights-for-custom-objective-functions-and-metrics",
    "title": "WRMSSE metric implementation",
    "section": "Using weights for custom objective functions and metrics",
    "text": "Using weights for custom objective functions and metrics\nThese static methods will help us create custom metrics and evaluation functions for lightgbm training"
  },
  {
    "objectID": "projects/m5/brief_eda.html",
    "href": "projects/m5/brief_eda.html",
    "title": "Brief EDA",
    "section": "",
    "text": "import os\nimport pandas as pd\nsales_train_evaluation: We have six hierarchical categores and 1941 days of sales data for each of the 30490 items\ncalendar gives us some date information. This includes special events like holidays and information about SNAP (ebt foodstamps) acceptance for each day of the training and evaluation periods.\nsell_prices gives the weekly price for each store/item combination.\nsample_submission shows the expected format of a submission. Each item/store combination will have a row with the 28 day forecast as the columns. We submit predictions for the validation period and the test period in the same file."
  },
  {
    "objectID": "projects/m5/brief_eda.html#saving-small-data",
    "href": "projects/m5/brief_eda.html#saving-small-data",
    "title": "Brief EDA",
    "section": "Saving small data",
    "text": "Saving small data\nTo utilize continuous integration on github, and also use nbdev to test all of our code, we will create a truncated version of our files. They need to be less than 100MB to fit on github and allow fast tests.\nLets only save the last 28 * 6 days of sales data for one item from each dept_id / store_id combination.\n\ndf_len = df_stv.shape[1]\ndf_stv_small = df_stv.iloc[:, list(range(6)) + list(range(df_len - 28 * 5, df_len))]\noriginal_col_order = df_stv_small.columns\ndf_stv_small = df_stv_small.groupby(['dept_id', 'store_id']).first().reset_index()[original_col_order]\nprint(f'Now there are only {df_stv_small.shape[0]} rows and {df_stv_small.shape[1]} columns')\ndf_stv_small.head(3)\n\nNow there are only 70 rows and 146 columns\n\n\n\n\n\n\n  \n    \n      \n      id\n      item_id\n      dept_id\n      cat_id\n      store_id\n      state_id\n      d_1802\n      d_1803\n      d_1804\n      d_1805\n      ...\n      d_1932\n      d_1933\n      d_1934\n      d_1935\n      d_1936\n      d_1937\n      d_1938\n      d_1939\n      d_1940\n      d_1941\n    \n  \n  \n    \n      0\n      FOODS_1_001_CA_1_evaluation\n      FOODS_1_001\n      FOODS_1\n      FOODS\n      CA_1\n      CA\n      1\n      0\n      0\n      0\n      ...\n      2\n      3\n      1\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n    \n    \n      1\n      FOODS_1_001_CA_2_evaluation\n      FOODS_1_001\n      FOODS_1\n      FOODS\n      CA_2\n      CA\n      1\n      6\n      0\n      0\n      ...\n      1\n      0\n      0\n      1\n      1\n      0\n      0\n      1\n      2\n      0\n    \n    \n      2\n      FOODS_1_001_CA_3_evaluation\n      FOODS_1_001\n      FOODS_1\n      FOODS\n      CA_3\n      CA\n      0\n      0\n      0\n      0\n      ...\n      1\n      2\n      2\n      0\n      0\n      1\n      0\n      3\n      2\n      2\n    \n  \n\n3 rows × 146 columns\n\n\n\nFor the small calendar file, we only need data for days greater than or equal to 1802\n\nmin_wm_yr_wk = df_cal[df_cal.d == 'd_1802'].wm_yr_wk.values[0]\ndf_cal_small = df_cal[df_cal.wm_yr_wk >= min_wm_yr_wk]\ndf_cal_small.info()\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 170 entries, 0 to 169\nData columns (total 14 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   date          170 non-null    object\n 1   wm_yr_wk      170 non-null    int64 \n 2   weekday       170 non-null    object\n 3   wday          170 non-null    int64 \n 4   month         170 non-null    int64 \n 5   year          170 non-null    int64 \n 6   d             170 non-null    object\n 7   event_name_1  18 non-null     object\n 8   event_type_1  18 non-null     object\n 9   event_name_2  1 non-null      object\n 10  event_type_2  1 non-null      object\n 11  snap_CA       170 non-null    int64 \n 12  snap_TX       170 non-null    int64 \n 13  snap_WI       170 non-null    int64 \ndtypes: int64(7), object(7)\nmemory usage: 19.9+ KB\n\n\nFor the small prices file, we can filter using the items we have in df_stv_small, and the minimun wm_yr_wk we just made.\n\nitem_mask = df_prices.item_id.isin(set(df_stv_small.item_id.tolist()))\ndate_mask = df_prices.wm_yr_wk >= min_wm_yr_wk\ndf_prices_small = df_prices[item_mask & date_mask]\ndf_prices_small.info()\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1750 entries, 0 to 1749\nData columns (total 4 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   store_id    1750 non-null   object \n 1   item_id     1750 non-null   object \n 2   wm_yr_wk    1750 non-null   int64  \n 3   sell_price  1750 non-null   float64\ndtypes: float64(1), int64(1), object(2)\nmemory usage: 68.4+ KB\n\n\nThe sample submission should only have the items in df_stv_small\n\nitem_list = df_stv_small.id.to_list() + df_stv_small.id.str.replace('evaluation', 'validation').to_list()\ndf_ss_small = df_ss[df_ss.id.isin(item_list)]\n\n\nos.makedirs('small_data/raw', exist_ok=True)\ndf_stv_small.to_csv(os.path.join('small_data/raw', 'sales_train_evaluation.csv'), index=False)\ndf_cal_small.to_csv(os.path.join('small_data/raw', 'calendar.csv'), index=False)\ndf_prices_small.to_csv(os.path.join('small_data/raw', 'sell_prices.csv'), index=False)\ndf_ss_small.to_csv(os.path.join('small_data/raw', 'sample_submission.csv'), index=False)"
  },
  {
    "objectID": "projects/m5/training_day_by_day_models.html",
    "href": "projects/m5/training_day_by_day_models.html",
    "title": "Train day-by-day models",
    "section": "",
    "text": "load_cfg\n\n load_cfg (path_cfg)\n\n\ncfg = load_cfg('final_cfg.json')\ncfg\n\n{'start_test': 1942,\n 'start_train': 140,\n 'days_to_predict': 'all',\n 'fobj': None,\n 'fobj_weight_col': 'total_scaled_weight',\n 'weight_hess': 1,\n 'feval': 'mse',\n 'feval_weight_col': 'scale',\n 'weight_col': None,\n 'lgb_params': {'boosting_type': 'gbdt',\n  'objective': 'regression',\n  'metric': None,\n  'subsample': 0.5,\n  'subsample_freq': 1,\n  'learning_rate': 0.03,\n  'num_leaves': 255,\n  'min_data_in_leaf': 255,\n  'feature_fraction': 0.8,\n  'n_estimators': 5000,\n  'early_stopping_rounds': 50,\n  'device_type': 'cpu',\n  'seed': 42,\n  'verbose': -1},\n 'target': 'sales',\n 'p_horizon': 28,\n 'num_series': 30490,\n 'features_json': 'final_features.json',\n 'path_data_raw': '../../../data/raw',\n 'path_features': '../../../data/features',\n 'path_models': '../../../data/models',\n 'use_neptune': 0,\n 'neptune_project': None,\n 'neptune_api_token': None}\n\n\n\nFINAL_CFG\n\n{'start_test': 1942,\n 'start_train': 140,\n 'days_to_predict': 'all',\n 'fobj': 'mse',\n 'fobj_weight_col': 'total_scaled_weight',\n 'weight_hess': 1,\n 'feval': 'mse',\n 'feval_weight_col': 'scale',\n 'weight_col': None,\n 'lgb_params': {'boosting_type': 'gbdt',\n  'objective': None,\n  'metric': None,\n  'subsample': 0.5,\n  'subsample_freq': 1,\n  'learning_rate': 0.03,\n  'num_leaves': 255,\n  'min_data_in_leaf': 255,\n  'feature_fraction': 0.8,\n  'n_estimators': 1,\n  'early_stopping_rounds': 50,\n  'device_type': 'cpu',\n  'seed': 42,\n  'verbose': -1},\n 'target': 'sales',\n 'p_horizon': 28,\n 'num_series': 30490,\n 'features_json': 'pkl_final_features.json',\n 'path_data_raw': 'data/raw',\n 'path_features': 'data/features',\n 'path_models': 'data/models',\n 'use_neptune': 0,\n 'neptune_project': 0,\n 'neptune_api_token': None}\n\n\n\nDICT_FEATURES\n\n{'fe_base.csv': ['dept_id', 'store_id'],\n 'fe_cal.csv': ['event_name_1', 'tm_d', 'tm_w', 'tm_m', 'tm_dw', 'tm_w_end'],\n 'fe_price.csv': ['sell_price',\n  'price_min',\n  'price_max',\n  'price_median',\n  'price_mode',\n  'price_mean',\n  'price_std',\n  'price_norm_max',\n  'price_norm_mode',\n  'price_norm_mean',\n  'price_momentum',\n  'price_roll_momentum_4',\n  'price_roll_momentum_24',\n  'price_end_digits'],\n 'fe_snap_event.csv': ['snap_transform_1',\n  'snap_transform_2',\n  'next_event_type_1',\n  'last_event_type_1',\n  'days_since_event',\n  'days_until_event'],\n 'shift_fe_dow_means_and_days_since_sale.csv': ['mean_4_dow_0',\n  'mean_4_dow_1',\n  'mean_4_dow_2',\n  'mean_4_dow_3',\n  'mean_4_dow_4',\n  'mean_4_dow_5',\n  'mean_4_dow_6',\n  'mean_20_dow_0',\n  'mean_20_dow_1',\n  'mean_20_dow_2',\n  'mean_20_dow_3',\n  'mean_20_dow_4',\n  'mean_20_dow_5',\n  'mean_20_dow_6',\n  'days_since_sale'],\n 'shift_fe_ipca_15_84.csv': ['index',\n  'ipca_15_84_comp_1',\n  'ipca_15_84_comp_2',\n  'ipca_15_84_comp_3',\n  'ipca_15_84_comp_4',\n  'ipca_15_84_comp_5',\n  'ipca_15_84_comp_6',\n  'ipca_15_84_comp_7',\n  'ipca_15_84_comp_8',\n  'ipca_15_84_comp_9',\n  'ipca_15_84_comp_10',\n  'ipca_15_84_comp_11',\n  'ipca_15_84_comp_12',\n  'ipca_15_84_comp_13',\n  'ipca_15_84_comp_14'],\n 'shift_fe_lags_1_14.csv': ['lag_1',\n  'lag_2',\n  'lag_3',\n  'lag_4',\n  'lag_5',\n  'lag_6',\n  'lag_7',\n  'lag_8',\n  'lag_9',\n  'lag_10',\n  'lag_11',\n  'lag_12',\n  'lag_13',\n  'lag_14'],\n 'shift_fe_rw_1.csv': ['shift_1_rolling_nanmean_3',\n  'shift_1_rolling_mean_decay_3',\n  'shift_1_rolling_nanmean_7',\n  'shift_1_rolling_mean_decay_7',\n  'shift_1_rolling_nanstd_7'],\n 'shift_fe_rw_2.csv': ['shift_1_rolling_nanmean_14',\n  'shift_1_rolling_mean_decay_14',\n  'shift_1_rolling_diff_nanmean_14',\n  'shift_1_rolling_nanstd_14',\n  'shift_1_rolling_nanmean_30',\n  'shift_1_rolling_mean_decay_30'],\n 'shift_fe_rw_3.csv': ['shift_1_rolling_nanmean_60',\n  'shift_1_rolling_nanmedian_60',\n  'shift_1_rolling_mean_decay_60',\n  'shift_1_rolling_nanstd_60',\n  'shift_1_rolling_nanmean_140',\n  'shift_1_rolling_mean_decay_140',\n  'shift_1_rolling_nanstd_140'],\n 'shift_fe_shifts_mom_1.csv': ['shift_8_rolling_nanmean_7',\n  'momentum_7_rolling_nanmean_7',\n  'shift_8_rolling_mean_decay_7',\n  'momentum_7_rolling_mean_decay_7',\n  'momentum_7_rolling_diff_nanmean_7',\n  'shift_29_rolling_nanmean_7',\n  'momentum_28_rolling_nanmean_7',\n  'shift_29_rolling_mean_decay_7',\n  'momentum_28_rolling_mean_decay_7',\n  'shift_29_rolling_diff_nanmean_7',\n  'momentum_28_rolling_diff_nanmean_7'],\n 'shift_fe_shifts_mom_2.csv': ['shift_8_rolling_nanmean_30',\n  'momentum_7_rolling_nanmean_30',\n  'shift_8_rolling_mean_decay_30',\n  'shift_29_rolling_nanmean_30',\n  'momentum_28_rolling_nanmean_30',\n  'shift_29_rolling_mean_decay_30'],\n 'shift_fe_shifts_mom_3.csv': ['shift_29_rolling_nanmean_60',\n  'shift_91_rolling_nanmean_60',\n  'shift_91_rolling_mean_decay_60']}\n\n\n\n\n\nprep_data\n\n prep_data (cfg)\n\n\n\n\nneptune\n\n neptune (cfg)\n\nNot implemented\n\nneptune(cfg)\n\n\n\n\ncli_lgb_daily\n\n cli_lgb_daily (path_cfg:str<pathtotheconfigurationjson>='cfg.json')\n\n\n\n\nlgb_daily\n\n lgb_daily (path_cfg:str='cfg.json')\n\nTrain 1 model for each day of prediction accoring to path_cfg."
  },
  {
    "objectID": "projects/m5/index_m5.html",
    "href": "projects/m5/index_m5.html",
    "title": "Welcome to chrisrichardmiles.m5",
    "section": "",
    "text": "This package is built with nbdev, so the source code, testing, and documentation are all built in jupyter notebooks. Please sequentially read through the notebooks or online documentation for details about the solution."
  },
  {
    "objectID": "projects/m5/index_m5.html#create-submission-from-scratch-from-the-command-line",
    "href": "projects/m5/index_m5.html#create-submission-from-scratch-from-the-command-line",
    "title": "Welcome to chrisrichardmiles.m5",
    "section": "Create submission from scratch from the command line",
    "text": "Create submission from scratch from the command line\nRequirements: 20 GB of RAM and pip installed\n\n1. Install package\npip install chrisrichardmiles\n\n\n2. Create data folders, download data, and unzip files\n\nIf you have your kaggle api info in root/.kaggle/kaggle.json then run:\ncrm_download_kaggle_data --comp_name m5-forecasting-accuracy\n\n\nOtherwise, you must run:\ncrm_mkdirs_data\nand manully download the data zipfile from kaggle and upload it into the data/raw folder.\ncd data/raw\nunzip * \ncd ../..\n\n\n\n3. Detect out of stock days for products and change sales to NaN.\ncrm_m5_make_oos_data\n\n\n4. Create features for training\ncrm_m5_fe\n\n\n5. Train models and create submission\ncrm_m5_lgb_daily"
  },
  {
    "objectID": "projects/m5/index_m5.html#overview-of-solution",
    "href": "projects/m5/index_m5.html#overview-of-solution",
    "title": "Welcome to chrisrichardmiles.m5",
    "section": "Overview of solution",
    "text": "Overview of solution\n\nGiven Walmart sales data, tasked with delivering accurate hierarchical sales forecasts over 28 days, preventing potential losses in the millions resulting from overstocking and understocking, my solution placed 77th of 5,558 teams (top 1.4%) with a simple, explainable tree-based model, using LightGBM. It is also a pip installable software package, with testing, documentation, and continuous integration, found at my github.\nGiven a novel scoring metric, I used calculus and numpy to implement a custom objective function utilizable by LightGBM models. After discovering non-convexity, I created another custom function, utilizing insights about the data and metric, which outperformed all other publicly known methods.\nWith stockout-days non-differentiable from zero-sales-days, I used probability to detect stockout days by assuming sales were Poisson distributed, finding streaks of zeroes that were unreasonably long, given the average daily sales of a product, leading to enhanced data, more effective features, and superior models.\nWith limited memory resources, I utilized principal component analysis from scikit-learn to reduce dimensionality of features, allowing more total features and better model performance.\nNeeding feature engineering that did not exist in pandas, I used numpy to calculate novel rolling window features, also giving a 20x speed up, useful to speed up data pipelines."
  },
  {
    "objectID": "projects/m5/index_m5.html#some-lessons-i-learned",
    "href": "projects/m5/index_m5.html#some-lessons-i-learned",
    "title": "Welcome to chrisrichardmiles.m5",
    "section": "Some lessons I learned",
    "text": "Some lessons I learned\n\nRAM issues\n\nComputing rolling window statistics can be very expensive, but can be ok if we do processing in smaller sections like we do with n_splits in the rolling_window statistics calculations.\nDatatype matter: float32 and float16 datatypes can save a lot of RAM, but be careful for float16, which might cause accuracy problems or completely break a process, like when trying to use StandardScaler with float16 datatypes resulted in all zeros.\nBe careful with Pandas DataFrames. I had a lot of problems where I was unmindfully creating large copies of data, such as a saving function, looking something like df[cols].to_csv(....) which was making an entirely new dataframe in memory before saving. This was remedied by using the usecols param in df.to_csv\nBe careful with DataFrame names. It seems that it is better to keep the same name of a DataFrame when doing things like concating an existing df with new data. Its like pandas will use memory more intelligently. So this: df2 = pd.concat([df1, pd.read_csv('data.csv')]; del df2 should be replaced with df1 = pd.concat([df1, pd.read_csv('data.csv')]. It seems like it should work the same, but my experience with RAM crashes seems to indicate the second method is much better.\n\n\n\nOrganization is important\nThe first iteration of this project was code spread accross hundreds of kaggle notebooks. I ran experiments by running a notebook and just looking at the result. It always felt ok while I was doing it, and it worked out ok, but I didn’t have the results saved in a proper manner. Now I use neptune.ai to track experiments."
  },
  {
    "objectID": "projects/m5/feature_engineering.html",
    "href": "projects/m5/feature_engineering.html",
    "title": "Feature engineering",
    "section": "",
    "text": "sns.set()\nplt.rcParams['figure.figsize'] = (14,6)\nplt.rcParams['font.size'] = 16\nWhat you can get out of this notebook"
  },
  {
    "objectID": "projects/m5/feature_engineering.html#making-a-grid-to-align-all-features",
    "href": "projects/m5/feature_engineering.html#making-a-grid-to-align-all-features",
    "title": "Feature engineering",
    "section": "Making a grid to align all features",
    "text": "Making a grid to align all features\nThis section develops code for make_grid_df which will yield: * A dataframe to align all features * A numpy array where each row is a time series. This data representation can be good for for fast feature engineering.\n\nAdd prediction horizon\nWe will start by adding the prediction horizon to our original data so that feature our features will be generated all training data and our test data at the same time.\n\nlast_day = int(df_stv.columns[-1][2:])\npred_horizon = 28\nfor i in range(last_day + 1, last_day + 1 + pred_horizon): \n    df_stv[f'd_{i}'] = np.nan\n\n\n\nMake a tidy grid\nWe want our data in a tidy format, where we have a row for every product/sales_day combination. To do this, we start be reshaping our data to long format. I will call this our grid_df, on which we will build our features\n\nUsing pandas\nWe can use pandas dataframe .melt method\n\ns = time.time()\nstart_time = time.time()\nDROP_COLS = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\ngrid_df = df_stv.drop(DROP_COLS, axis=1).melt(id_vars='id', var_name='d', value_name='sales')\n# print(f\"Total time for melt: {(time.time() - start_time)/60} min\")\nprint(f\"Total time for melt: \", time_taken(start_time))\n\n\n# Saving space\nstart_time = time.time()\ngrid_df['d'] = grid_df.d.str[2:].astype(np.int16)\nprint(f\"Total time for day col change: \", time_taken(start_time))\n\nstart_time = time.time()\ngrid_df['id'] = grid_df.id.astype('category')\nprint(f\"Total time for category: \", time_taken(start_time))\n\nprint(time_taken(s))\ndisplay(grid_df)\n\ndel s\n\n\n\nFaster grid ceation using numpy\n\nd_cols = [col for col in df_stv.columns if col.startswith('d_')]\ng = pd.DataFrame({'id': pd.Series(np.tile(df_stv.id, len(d_cols))).astype('category'), \n                  'd': np.concatenate([[int(s[2:])] * df_stv.shape[0] for s in d_cols]).astype(np.int16), \n                  'sales': df_stv[d_cols].values.T.reshape(-1,)})\n\nprint(f'Both grids are the same: {grid_df.equals(g)}')\n\n\n\n\nIsolate numpy array in “rectangle” representation\nI will take the sales values as they are to form my base “rectangle” of sales. I think I can take this recatangle and quickly reshape it so that it lines up with grid_df. If I am correct we can use this to create features quickly.\nTest: Reshape the basic rectangle so that it matches sales of grid_df\n\nrec = df_stv[d_cols].values\ntest_sales = rec.T.reshape(-1)\nprint('test_sales matches sales?? ', (np.nan_to_num(test_sales) == grid_df['sales'].fillna(0)).all())\n\nThe competition guide states that leading zeros sales should not be considered, therefore we need to convert these leading zeros to NaNs.\n\n\n\nnan_leading_zeros\n\n nan_leading_zeros (rec)\n\nLeading zeros indicate an item was not for sale. We will mark as np.nan to ensure they are not used for training.\n\nprint(rec[: 10, :5])\n\n\nnan_leading_zeros(rec[: 10, :5])\n\n\n\nMain function\n\n\n\nmake_grid_df\n\n make_grid_df (df:pandas.core.frame.DataFrame, pred_horizon=28)\n\nSpecific to the the M5 competition data. Returns a grid_df to allign all features and the sales\ndata in a “rectangle” data representation, a 2D numpy array where ever row is an items time series.\n\ngrid_df, rec = make_grid_df(os.path.join(PATH_DATA_RAW, 'sales_train_evaluation.csv'), pred_horizon=28)\n\n\ngrid_df\n\n\nrec"
  },
  {
    "objectID": "projects/m5/feature_engineering.html#base-features",
    "href": "projects/m5/feature_engineering.html#base-features",
    "title": "Feature engineering",
    "section": "Base features",
    "text": "Base features\n\nFunctions to create basic calendar and price features\n\nWe start with a grid_df so that all our features will be aligned on the same index making it easy to add features for trianing. grid_df was created in the last few cells.\n\nBase categorical variables given by heierarchical levels\nFirst, we will add the grouping levels of the data as features. This is easy because the features are already included in df_stv columns. We just need to make a copy of these columns for every day of training and prediction.\n\n\n\nadd_base\n\n add_base (grid_df, df_stv, rec)\n\nAdds the basic categorical features to grid_df.\n\nadd_base(grid_df, df_stv, rec)\ngrid_df.info()\n\n\ngrid_df.head(3)\n\n\n\nPrice features\n\n\n\ncreate_price_fe\n\n create_price_fe (df_prices)\n\nAdds price features onto price_df. This is the step we take before merging prices onto our grid_df.\n\ndf_prices = create_price_fe(df_prices)\ndf_prices.info()\n\n\n\n\nadd_price_fe\n\n add_price_fe (grid_df, df_prices, df_cal)\n\nAdds on price features to grid_df.\n\ngrid_df = add_price_fe(grid_df, df_prices, df_cal)\ngrid_df.info()\n\n\n\nCalander Features\n\ngrid_df = grid_df[['id', 'd', 'sales']]\n\n\n\n\nadd_cal_fe\n\n add_cal_fe (grid_df, df_cal)\n\nAdds calendar features onto grid_df.\n\ngrid_df = add_cal_fe(grid_df, df_cal)\ngrid_df.info()\n\n\n\nSnap features\nThe columns with a name like ‘snap_CA’ indicates whether SNAP (also known as EBT) benefits are accepted in California for each day. What days can people use their SNAP benefits\n\ndf = df_cal.iloc[-180:, :].copy()\ndf['date'] = pd.to_datetime(df.date)\nfig, ax = plt.subplots(3, 1)\ndf.set_index('date').snap_CA.plot(ax=ax[0], title='California')\ndf.set_index('date').snap_TX.plot(ax=ax[1], title='Texas')\ndf.set_index('date').snap_WI.plot(ax=ax[2], title='Wisconsin')\n\nax[2].xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1))\nax[2].xaxis.set_major_formatter(mdates.DateFormatter(\"%b %Y\"))\nfig.suptitle('Days where people can use SNAP benefits')\nfig.autofmt_xdate()\nfig.tight_layout()\nplt.show()\n\n\nprint()\ndf_cal['date'] = pd.to_datetime(df_cal['date'])\ndf_cal.groupby(df_cal.date.dt.day)[['snap_CA', 'snap_TX', 'snap_WI']].sum().plot(\n    title='Are the snap days distributed accross these days for the entire dataset?',kind='bar', figsize=(14, 6))\nplt.show()\n\nIt seems the snap days are consistent for every month in the dataset since each day has the same number of snap occurances for each date.\n\n############### Snap days of month ###########################\nca = grid_df[grid_df['snap_CA'] == 1].tm_d.unique()\ntx = grid_df[grid_df['snap_TX'] == 1].tm_d.unique()\nwi = grid_df[grid_df['snap_WI'] == 1].tm_d.unique()\nprint('For each state, what days of the month are snap days?')\nprint('CA:', ca)\nprint('TX:', tx)\nprint('WI:', wi)\n\n\nSimple feature\nJust map each snap day to 1 through 10 so the model will know which of the 10 snap days it is.\n\n\n\n\nadd_snap_transform_1\n\n add_snap_transform_1 (grid_df)\n\nAdds a column that shows which of the 10 snap days it is. The value is 0 if it is not a snap day.\n\nA more meaningful mapping?\nI would like to transform the snap information in a way that might give more information about non snap days. In particular, I want the “gap” days, non-snap days right in between two snap days, to be considered different from the long stretch of non-snap days towards the end of the month. I’d also like the non-snap days leading into the first snap day to be the same, no matter what state we are considering, so that algorithms can use this feature without needing state information to decode meaning.\n\n\n\n\nadd_snap_transform_2\n\n add_snap_transform_2 (grid_df)\n\nThis maps snap days and non snap days in way that may be more meaningful than snap_transform_1.\nAny day above 40 will be a snap day. Lower days are non snap, and lowest days are “gap” days in between snap days. In this way I’m hoping the model can can use this feature as non-categorical, and be able to efficiently sort when higher demand days may be. Also, 16-21 will always be the days following the last snap day and 27-31 will be the days leading up to the first snap day. My theory is these numbers will encode more meaning with less confusion caused by states having different snap days.\n\n\nSpecial event features\nHow many days have events?\n\nprint(f'Type 1: {grid_df.event_type_1.count()/grid_df.shape[0] * 100:.2f} percent')\nprint(f'Type 2: {grid_df.event_type_2.count()/grid_df.shape[0] * 100:.2f} percent')\n\nWhat special events do we have?\n\nprint('Unique types in event_type_1:')\ndisplay(grid_df.event_type_1.unique().tolist())\nprint('Unique types in event_type_2:')\ndisplay(grid_df.event_type_2.unique().tolist())\nprint('Unique names in event_name_1:')\ndisplay(grid_df.event_name_1.unique().tolist())\n\nDo we ever have event_type_2 if there is not an even_type_1?\nHow often do we have 2 events on the same day?\n\ngrid_df[grid_df.event_name_2.notnull()].drop_duplicates('d')\n\n\nmask = (grid_df['event_type_1'] == 'Religious') & (grid_df['event_type_2'] == 'Cultural')\ngrid_df[mask].drop_duplicates('d')\n\nSince there are only a few days with 2 events, I will only consider event_type_1 for my new event features. In the cases where I think the event_type_2 will be more relevant, I will move it to event_type_1. I think cultural event types may be more important than religious events. This will basically amount to making Easter cultural and Cinco De Mayo is also accounted for.\n\n\n\nadd_event_features\n\n add_event_features (grid_df, n_items=30490, n_days_in_data=1969)\n\nAdds some features related to special events like holidays to grid_df. The columns added are: next_event_type_1 last_event_type_1 days_since_event days_until_event\n\ndel df_cal, df_prices, df_ss\n\n\n\nMain function\n\n\n\nfe_base_features\n\n fe_base_features (path_data_raw:str<pathtorawdatafolder>='data/raw',\n                   path_features:str<pathtofeaturefolder>='data/features',\n                   path_to_train_file:str<pathtotraindata>=None)\n\nCreates the basic categorical, price, and calendar features using the functions add_base, create_price_fe, add_price_fe, and add_cal_fe, add_snap_transform_1, add_snap_transform_1, and add_event_features.\n\nfe_base_features(PATH_DATA_RAW, os.path.join(PATH_DATA, 'features'))\n\n\ndisplay(load_file(f'{os.path.join(PATH_DATA, \"features\")}/fe_base.csv').info())\ndisplay(load_file(f'{os.path.join(PATH_DATA, \"features\")}/fe_price.csv').info())\ndisplay(load_file(f'{os.path.join(PATH_DATA, \"features\")}/fe_cal.csv').info())\ndisplay(load_file(f'{os.path.join(PATH_DATA, \"features\")}/fe_snap_event.csv').info())"
  },
  {
    "objectID": "projects/m5/feature_engineering.html#encoding-features-with-target-statistics",
    "href": "projects/m5/feature_engineering.html#encoding-features-with-target-statistics",
    "title": "Feature engineering",
    "section": "Encoding features with target statistics",
    "text": "Encoding features with target statistics\n\n\nencode_target\n\n encode_target (df:pandas.core.frame.DataFrame, target:str,\n                cols:Union[list,str], func:Union[str,<built-\n                infunctioncallable>], verbose=True)\n\nUses pandas groupby(col)[target].transform(func) to encode each col in cols. The target col can be any numerical column.\n\n\nMain function\nPoor encoding\nBelow is the method I used in the competition. I found that the models performed much better during training, and much worse during validation, so I dropped them from training.\nI should have done the encoding more carefully, using no future data. I will explore encodings more in the post competition experiments.\n\n\n\nfe_encodings\n\n fe_encodings (path_features:<pathtofeaturefolder>='data/features',\n               path_out_features:str<pathtofeaturefolderforoutput>=None,\n               start_test:int<Firstdaytostartnans>=1942)\n\nCreates target encoding with mean and std for various columns, with sales after start_test set to np.nan.\n\nfe_encodings()\n\n\ndisplay(load_file(f'{PATH_DATA_FEATURES}/fe_enc_mean.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/fe_enc_std.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/fe_enc_special.csv').info())"
  },
  {
    "objectID": "projects/m5/feature_engineering.html#lags-and-rolling-features",
    "href": "projects/m5/feature_engineering.html#lags-and-rolling-features",
    "title": "Feature engineering",
    "section": "Lags and rolling features",
    "text": "Lags and rolling features\n\nThese are the features created from the raw sales data directly.\n\nBe carefule with lag features. We must be mindful that we will not have the same information for all days in forecast horizon. If we want a single model to predict all days, we can only use lagging features from 28 days and older. In order to create one set of features that we can use for all predictions we will do the following: * Create all lagging features as if we are building a model for 1 day into the future. So “lag_1” means sales one day before the first day of the prediction horizon. * When building a model for the nth day of the horizon, we need to shift the lag features n - 1 extra days. Since we have 30490 time series, We do this by shifting the index of the features by (n - 1) * 30490 so that the lag features for all training and testing data will be lagged by an extra (n - 1) days to keep information aligned properly.\n\nBasic lag features\nBefore reshaping the data to become a column, we need to shift our rectangle lag_shift by prepended the data with np.nans to make up for the data we have cut off. Therefore, all the d_1 products in grid_df will have np.nan for lag_1. In fact, as we carry out this process for all lag days, rows with sales on d_x will have np.nan values for all lags lag_y where y >= x.\n\ngrid_df, rec = make_grid_df(os.path.join(PATH_DATA_RAW, 'sales_train_evaluation.csv'))\ngrid_df.shape\n\n\n\n\nmake_lag_col\n\n make_lag_col (rec:<built-infunctionarray>, lag:int)\n\nTransform the ‘rectangle’ of time series into a lag feature\n\nrec[:2, :5]\n\n\nmake_lag_col(rec[:2, :5], 1)\n\n\n\n\nadd_lags\n\n add_lags (grid_df, rec, lags=range(1, 16))\n\n\nadd_lags(grid_df, rec)\n\n\ngrid_df.info()\n\n\nPandas shift\nWe can also just use pandas shift which is easier to implement and not much slower. The only downside is that we must use num_series to shift by the correct increment. Here we will do it for g, which was the same as grid_df before adding lags. Our time was not wasted though, because we learned skills that we will need for making rolling windows.\n\nrec.shape\n\n\ng, rec_tmp = make_grid_df(os.path.join(PATH_DATA_RAW, 'sales_train_evaluation.csv'))\n\n\nnum_series = df_stv.shape[0]\nfor i in range(1,16):\n    g[f'lag_{i}'] = g['sales'].shift(num_series * i).astype(np.float16)\n\n\ndel g\ngc.collect()\n\n\n\nMain function\n\n\n\n\nfe_lags\n\n fe_lags (path_data_raw:str<pathtorawdatafolder>='data/raw',\n          path_features:str<pathtofeaturefolder>='data/features',\n          path_to_train_file:str<pathtotraindata>=None)\n\nCreates lags and rolling window features using add_lags add_rolling_cols\n\nfe_lags()\n# fe_lags(PATH_DATA_RAW, path_features='.')\n\n\nmax_lag = 84\ncols_per_file = 14\nfor lag in range(1, max_lag, cols_per_file):\n    display(load_file(f'{PATH_DATA_FEATURES}/shift_fe_lags_{lag}_{lag + cols_per_file - 1}.csv').info())\n\n\n\nRolling features\n\nrolling window function\nPlease check out “Efficient rolling statistics with NumPy” by Erik Rigtorp. The article shows some cool numpy tricks to do really fast rolling window calculations by creating “rolling windows views”\nUpdate to the article 2021-04-21: “NumPy now comes with a builtin function sliding_window_view that does exactly this. There’s also the Bottleneck library with optimized functions for rolling mean, standard deviation etc.”\n\n\n\n\nrolling_window\n\n rolling_window (a:<built-infunctionarray>, window:int)\n\nA super fast way of getting rolling window view with size window on a numpy array. Reference: https://rigtorp.se/2011/01/01/rolling-statistics-numpy.html\n\nx = np.arange(10).reshape((2,5))\nx\n\n\nrw = rolling_window(x, 3)\nrw\n\n\nnp.mean(rw, axis=-1)\n\n\nnp.std(rw, axis=-1)\n\n\nnp.median(rw, axis=-1)\n\n\ndel x, rw\n\n\n\n\nsplit_array\n\n split_array (ary, sections, axis=0)\n\nWorks just like np.split, but sections must be a single integer. It will work, even when sections doesn’t evenly divide the length of ary.\nThis avoids errors that occur when using make_rolling_col with high n_splits that do not divide the number of series evenly.\n\nx = np.array(range(9))\nx\n\n\nsplit_array(x, 4)\n\n\n\n\nmake_rolling_col\n\n make_rolling_col (rw, function, n_splits=10)\n\nReturns a one dimensional np.array after function has been applied to the rolling window view rw.\n\nrw = rolling_window(rec, 3)\nprint(f'The shape {rw.shape}, represents (num_series, num_windows, window_size)')\nfunction = np.mean\ncol = make_rolling_col(rw, function)\n\nprint('Make sure the shape of the resulting column matches grid_df')\nprint(grid_df.shape[0],'=',  col.shape[0])\n\n\nx = np.arange(10).reshape((2,5))\nx\n\n\nrw = rolling_window(x, 3)\nmake_rolling_col(rw, function, n_splits=1)\n\n\ndel rw, function, col\n\n\nSome more functions for rolling windows\nThese functions are designed to act on a rolling_window array created by the rolling_window function, similar to np.mean or np.std.\n\n\n\n\nmean_decay\n\n mean_decay (rolling_window, axis=-1)\n\nReturns the mean_decay along an axis of a rolling window object, which is created by the rolling_window() function.\n\n\n\ndiff_nanmean\n\n diff_nanmean (rolling_window, axis=-1)\n\nFor M5 purposes, used on an object generated by the rolling_window function. Returns the mean of the first difference of a window of sales.\n\n\n\ndiff_mean\n\n diff_mean (rolling_window, axis=-1)\n\nFor M5 purposes, used on an object generated by the rolling_window function. Returns the mean of the first difference of a window of sales.\n\n\n\nadd_rolling_cols\n\n add_rolling_cols (grid_df:pandas.core.frame.DataFrame, rec:<built-\n                   infunctionarray>, windows:list, functions:list,\n                   function_names:list=None, n_splits:list=10)\n\nAdds rolling features to grid_df.\n\ngrid_df = add_rolling_cols(grid_df, \n                 rec, \n                 windows=[7, 14, 30, 60, 140], \n                 functions=[np.mean, np.std], \n                 function_names=['mean', 'std'])\n\n\ngrid_df.info()\n\n\nMain function\n\n\n\n\nfe_rw_stats\n\n fe_rw_stats (path_data_raw:str<pathtorawdatafolder>='data/raw',\n              path_features:str<pathtofeaturefolder>='data/features',\n              path_to_train_file:str<pathtotraindata>=None)\n\nCreates lags and rolling window features using add_lags add_rolling_cols\n\nfe_rw_stats()\n# fe_rw_stats(PATH_DATA_RAW, path_features='.')\n\n\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_rw_1.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_rw_2.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_rw_3.csv').info())"
  },
  {
    "objectID": "projects/m5/feature_engineering.html#average-for-each-day-of-the-week",
    "href": "projects/m5/feature_engineering.html#average-for-each-day-of-the-week",
    "title": "Feature engineering",
    "section": "Average for each day of the week",
    "text": "Average for each day of the week\n\nFeature telling how long its been since theres been a sale\n\n\n\nget_days_since_sale\n\n get_days_since_sale (grid_df, num_series=30490)\n\nReturns a column that shows how many days its been Since there has been a sale.\n\n\n\nadd_dow_means\n\n add_dow_means (grid_df, rec, n_weeks)\n\nAdds features to grid_df for the mean of each day of the week for the past n_weeks.\nFor any row, the column ‘mean_{n_weeks}dow{i}’ represents the mean of the last n_weeks of sales for the day of the week that is i days behind the date of this row. So if today is Friday, n_weeks=4 and i = 1, this column is equal to the mean sales of the last 4 Thursdays.\n\n\nMain function\n\n\n\nfe_dow_means\n\n fe_dow_means (path_data_raw:str<pathtorawdatafolder>='data/raw',\n               path_features:str<pathtofeaturefolder>='data/features',\n               path_to_train_file:str<pathtotraindata>=None)\n\nCreates the features for day of week means using add_dow_means\nWe also use ‘get_days_since_sale’ in this script since there isn’t another group very similar to this feature.\n\n# fe_dow_means(PATH_DATA_RAW, '.')\\\nfe_dow_means()\n\n\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_dow_means_and_days_since_sale.csv').info())"
  },
  {
    "objectID": "projects/m5/feature_engineering.html#shifted-lag-rolling-features",
    "href": "projects/m5/feature_engineering.html#shifted-lag-rolling-features",
    "title": "Feature engineering",
    "section": "Shifted lag rolling features",
    "text": "Shifted lag rolling features\nPerhaps I want to also want to know 7 day rolling mean, but from 7 seven days ago. This could go directly into a model, or we could create a weekly momentum_7_rolling_mean_7 = shift_1_rolling_mean_7/shift_8_rolling_mean_7. We have already calculated these features, we just need to shift the columns by num_series * (shift_days - 1). We subtract 1 from shift_days because the column shift_1_rolling_mean_7 is already shifted 1 day.\n\n\nadd_shift_cols\n\n add_shift_cols (grid_df:pandas.core.frame.DataFrame, shifts:list,\n                 cols:list, num_series:int=30490, momentum:bool=True)\n\nAdds shift_{shift} and momentum_{shift - 1} features for each int shift in shifts for each column in cols. cols must be a list of columns that begin with ‘shift_1’ for this function to work.\n\n############## Adding shifted rolling mean ###############\nshifts = [8, 15, 22, 29]\ncols = [f'shift_1_rolling_mean_{i}' for i in [7, 14]]\nadd_shift_cols(grid_df, shifts, cols, num_series=df_stv.shape[0])\n\n\ngrid_df.info()\n\n\n\nMain function\n\n\n\nfe_shifts_momentum\n\n fe_shifts_momentum\n                     (path_features:str<pathtofeaturefolder>='data/feature\n                     s', path_out_features:str<pathtofeaturefolderforoutpu\n                     t>='',\n                     num_series:int<Numberofseriesforshifting>=30490)\n\nCreates shifts and momentum features using add_shift_cols\nParameters\n\npath_features: Param(‘path to feature folder’, str)=‘data/features’\npath_out_features: Param(‘path to feature folder for output’, str)=‘data/features’ This is mainly to run on kaggle where path_features is set to an input dataset, because we need the rolling window stat features to be present, and path_out_features is set the working directory for the output.\nnum_series: Param(‘Number of series for shifting’, int)=30490\n\n# fe_shifts_momentum('.', num_series=df_stv.shape[0])\n# time.sleep(1)\nfe_shifts_momentum(num_series=df_stv.shape[0])\n\n\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_shifts_mom_1.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_shifts_mom_2.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_shifts_mom_3.csv').info())"
  },
  {
    "objectID": "projects/m5/feature_engineering.html#dimensionality-reduction-of-lags",
    "href": "projects/m5/feature_engineering.html#dimensionality-reduction-of-lags",
    "title": "Feature engineering",
    "section": "Dimensionality reduction of lags",
    "text": "Dimensionality reduction of lags\nSince we have so many lags, I will try to use pca to reduce the number of features I have. I can’t fit all the lags into memory, so I will create the pca features iteratively, starting with lags 71 through 84, save the file, then save the top 7 components to do pca again with lags 57 through 70, and so on until I have 14 pca components for lags 1 through 84. Then I can decide how many lags features I want to keep without reducing their dimension.\n\nMain function\n\n\n\nfe_ipca_lags\n\n fe_ipca_lags (path_data_raw:str<pathtorawdatafolder>='data/raw',\n               path_features:str<Pathtofeaturefile>='data/features',\n               path_to_train_file:str<pathtotraindata>=None,\n               end:int<lastdaytostartlagsfrom>=1, restart:int<startifresum\n               ingwithlags_df.pklinrestart_dir>=None,\n               target:str<Nameoftargetcolumn>='sales')\n\nCreates ipca columns for 84 lag days, starting from the end and accumulating backward. With 16 GB of RAM, we can only fit 14 with ipca at a time, so for each iteration, we:\n1) Create 14 new lag days, and use ipca to reduce it to \nthe top 7 compnents.\n2) Combine those with the top 7 components from the previous step\n3) Perform ipca on these 14, features, save the output, and \nkeep the top 7 components for the next iteration.\nIn the end we will have files with the top 14 ipca components for each of these separate ranges: Days 1_84 Days 15_84 Days 29_84 Days 43_84 Days 57_84 Days 71_84\n\n# fe_ipca_lags(PATH_DATA_RAW, '.')\nfe_ipca_lags()\n\n\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_ipca_1_84.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_ipca_15_84.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_ipca_29_84.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_ipca_43_84.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_ipca_57_84.csv').info())\ndisplay(load_file(f'{PATH_DATA_FEATURES}/shift_fe_ipca_71_84.csv').info())"
  },
  {
    "objectID": "projects/m5/feature_engineering.html#lets-see-all-the-features-we-created",
    "href": "projects/m5/feature_engineering.html#lets-see-all-the-features-we-created",
    "title": "Feature engineering",
    "section": "Lets see all the features we created",
    "text": "Lets see all the features we created\n\nget_file_cols_dict(PATH_DATA_FEATURES)\n\n\n!rm data/features/*csv"
  },
  {
    "objectID": "projects/m5/feature_engineering.html#make-all-features",
    "href": "projects/m5/feature_engineering.html#make-all-features",
    "title": "Feature engineering",
    "section": "Make all features",
    "text": "Make all features\n\n\nfe\n\n fe ()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "chrisrichardmiles",
    "section": "",
    "text": "M5 - Accuracy Sales Forecasting - 77th place solution\nOptiver Realized Volatility - 91st place solution (code is not incorporated into the software package, but the solution can still be easily reproduced by following the instructions in the documentation)\nThis package is built with nbdev, so the source code, testing, and documentation are all built in the jupyter notebooks that comprise this repository."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "chrisrichardmiles",
    "section": "Install",
    "text": "Install\npip install chrisrichardmiles"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Core",
    "section": "",
    "text": "def mkdirs_data(data_dir_name: str='data') -> None: \n    \"\"\"Initializes the data directory structure\"\"\"\n    os.makedirs(f'{data_dir_name}/raw', exist_ok=True)\n    os.makedirs(f'{data_dir_name}/interim', exist_ok=True)\n    os.makedirs(f'{data_dir_name}/features', exist_ok=True)\n    os.makedirs(f'{data_dir_name}/models', exist_ok=True)\n    \n@call_parse\ndef cli_mkdirs_data(data_dir_name: Param('Name of data folder', str)='data') -> None: \n    mkdirs_data(data_dir_name)\n\n\n\n\n\n cli_mkdirs_data (data_dir_name:str<Nameofdatafolder>='data')\n\n\n\n\n\n\n mkdirs_data (data_dir_name:str='data')\n\nInitializes the data directory structure"
  },
  {
    "objectID": "core.html#data-directories",
    "href": "core.html#data-directories",
    "title": "Core",
    "section": "Data directories",
    "text": "Data directories\n\ndef mkdirs_data(data_dir_name: str='data') -> None: \n    \"\"\"Initializes the data directory structure\"\"\"\n    os.makedirs(f'{data_dir_name}/raw', exist_ok=True)\n    os.makedirs(f'{data_dir_name}/interim', exist_ok=True)\n    os.makedirs(f'{data_dir_name}/features', exist_ok=True)\n    os.makedirs(f'{data_dir_name}/models', exist_ok=True)\n    \n@call_parse\ndef cli_mkdirs_data(data_dir_name: Param('Name of data folder', str)='data') -> None: \n    mkdirs_data(data_dir_name)\n\n\n\ncli_mkdirs_data\n\n cli_mkdirs_data (data_dir_name:str<Nameofdatafolder>='data')\n\n\n\n\nmkdirs_data\n\n mkdirs_data (data_dir_name:str='data')\n\nInitializes the data directory structure\n\n\n\ncli_download_kaggle_data\n\n cli_download_kaggle_data (comp_name:str<nameofkagglecompetition>=None)\n\n\n\n\ndownload_kaggle_data\n\n download_kaggle_data (comp_name:str=None)\n\nDownloads competition data using the kaggle api"
  },
  {
    "objectID": "core.html#saving-and-loading-flies",
    "href": "core.html#saving-and-loading-flies",
    "title": "Core",
    "section": "Saving and loading flies",
    "text": "Saving and loading flies\n\nPrevent saving over files\nIn order to to make sure we don’t accidentally save over a file with the the same name, we have some functions to ensures that certain strings and paths are unique.\n\ndef make_unique(name: str, names: \"list or set or dict\") -> str: \n    \"\"\"Returns name with (x)_ prefix if `name` already in `names`. \n    This is useful when you want to make sure you don't save over\n    existing data with the same key `name`.\n    \"\"\"\n    if name in names:\n        x = 1\n        while f'({x})_' + name in names: x += 1\n        name = f'({x})_' + name\n    return name\n\n\n\n\nmake_unique\n\n make_unique (name:str, names:list)\n\nReturns name with (x)_ prefix if name already in names. This is useful when you want to make sure you don’t save over existing data with the same key name.\n\nmake_unique('d', ['a', 'b', 'c'])\n\n'd'\n\n\n\nmake_unique('a', ['a', 'b', 'c'])\n\n'(1)_a'\n\n\n\nassert make_unique('d', ['a', 'b', 'c']) == 'd'\nassert make_unique('chris', ['chris', 'dan', 'bill']) == '(1)_chris'\nassert make_unique('chris', ['chris', 'dan', 'bill', '(1)_chris']) == '(2)_chris'\nassert make_unique('chris', set(['chris', 'dan', 'bill', '(1)_chris'])) == '(2)_chris'\nassert make_unique('a', {'a': 1, 'b': 2, 'c': 3}) == '(1)_a'\nassert make_unique('d', {'a': 1, 'b': 2, 'c': 3}) == 'd'\n\n\ndef make_unique_path(path):  \n    \"\"\"Returns path with prefix '(n)_' before the last element in \n    path if it is a duplicate. \n    \"\"\"\n    pre_path, file_name = os.path.split(path)\n    file_name = make_unique(file_name, os.listdir(pre_path or '.'))\n    return os.path.join(pre_path, file_name)\n\n\n\n\nmake_unique_path\n\n make_unique_path (path)\n\nReturns path with prefix ’(n)_’ before the last element in path if it is a duplicate.\n\nos.makedirs('tmp', exist_ok=True)\nprint(make_unique_path('tmp/tmp.csv'))\nopen('tmp/tmp.csv', 'w').close()\nprint(make_unique_path('tmp/tmp.csv'))\nshutil.rmtree('tmp')\n\ntmp/tmp.csv\ntmp/(1)_tmp.csv\n\n\n\n\nSaving and loading pandas dataframes\n\ndef save_file(df: pd.DataFrame, \n              path: str, \n              usecols: list=None,\n              save_index: bool=False, \n              save_dtypes: bool=True, \n              pickle: bool=False) -> None:\n    \"\"\"Saves `df` to `path` with dtypes as top column if `save_dtypes` \n    is set to True. Load a files in this structure with `load_file`\n    \"\"\"\n    if pickle: \n        usecols = usecols if usecols else list(df)\n        path_dir = os.path.split(path)[0] if path.endswith('.csv') else path # For M5 project maintenence\n        for col in list(df): \n            df[[col]].to_pickle(os.path.join(path_dir, col + '.pkl'))\n        return \n    \n    path = make_unique_path(path)\n    if save_dtypes:\n        df_tmp = df.iloc[[0], :]\n        if usecols: df_tmp = df_tmp.loc[:, usecols]\n        if save_index: \n            df_tmp.reset_index(inplace=True)\n        df_dtypes = df_tmp.dtypes.to_frame().T\n        df_dtypes.to_csv(path, index=False)\n        df.to_csv(path, mode='a', index=save_index, header=False, \n                  columns=usecols)\n    else: \n        df.to_csv(path, index=save_index, columns=usecols)\n        \ndef load_file(path: str, load_dtypes=True, usecols: list=None) -> pd.DataFrame:\n    \"\"\"Loads a file into a DataFrame from `path` with dtypes \n    taken from the top column if `load_dtypes` is set to True. \n    Loads a files in the structure created with `save_file`.\n    \"\"\"\n    if path.endswith('pkl'): \n        df = pd.read_pickle(path)\n        return df[usecols] if usecols else df\n    \n    if load_dtypes:\n        dtypes = pd.read_csv(path, nrows=1).iloc[0].to_dict()\n        return pd.read_csv(path, skiprows=[1], dtype=dtypes, usecols=usecols)\n    else:\n        return pd.read_csv(path, usecols=usecols)\n\n\n\n\nload_file\n\n load_file (path:str, load_dtypes=True, usecols:list=None)\n\nLoads a file into a DataFrame from path with dtypes taken from the top column if load_dtypes is set to True. Loads a files in the structure created with save_file.\n\n\n\nsave_file\n\n save_file (df:pandas.core.frame.DataFrame, path:str, usecols:list=None,\n            save_index:bool=False, save_dtypes:bool=True,\n            pickle:bool=False)\n\nSaves df to path with dtypes as top column if save_dtypes is set to True. Load a files in this structure with load_file\n\n# Example\ndf = pd.DataFrame({'a': [1, 2], 'b': ['foo', 'bar'], 'c': [1.2, 3.3]})\ndf = df.astype(dict(zip(['a', 'b', 'c'], ['int32', 'category', np.float16])))\nprint('Saving the the dataframe to csv with the dtypes')\ndisplay(df.dtypes)\nsave_file(df, 'tmp.csv', pickle=False)\nprint('Now the csv has the datatypes as the top line when we read it in')\ndisplay(pd.read_csv('tmp.csv'))\n\nprint('We can use `load_file` to read in the csv with the right dtypes')\ndisplay(load_file('tmp.csv'))\ndisplay(load_file('tmp.csv').dtypes)\n\nSaving the the dataframe to csv with the dtypes\n\n\na       int32\nb    category\nc     float16\ndtype: object\n\n\nNow the csv has the datatypes as the top line when we read it in\n\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      int32\n      category\n      float16\n    \n    \n      1\n      1\n      foo\n      1.2\n    \n    \n      2\n      2\n      bar\n      3.3\n    \n  \n\n\n\n\nWe can use `load_file` to read in the csv with the right dtypes\n\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      foo\n      1.200195\n    \n    \n      1\n      2\n      bar\n      3.300781\n    \n  \n\n\n\n\na       int32\nb    category\nc     float16\ndtype: object\n\n\n\nsave_file(df, '.', pickle=True)\ndisplay(pd.concat([load_file(x + '.pkl') for x in 'abc'], axis=1))\n!rm a.pkl b.pkl c.pkl\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      foo\n      1.200195\n    \n    \n      1\n      2\n      bar\n      3.300781\n    \n  \n\n\n\n\n\nsave_file(df, 'tmp2.csv', usecols=['a', 'c'], save_index=True, pickle=False)\nload_file('tmp2.csv')\n\n\n\n\n\n  \n    \n      \n      index\n      a\n      c\n    \n  \n  \n    \n      0\n      0\n      1\n      1.200195\n    \n    \n      1\n      1\n      2\n      3.300781\n    \n  \n\n\n\n\n\n!rm tmp*.csv\n\n\n\nMaking a dictionary and json with file names as keys and list of column names as values.\n\nfor file in sorted(os.listdir('.')):\n    print(file)\n\n.devcontainer.json\n.git\n.gitattributes\n.gitconfig\n.github\n.gitignore\n.ipynb_checkpoints\n.pypirc\n00_core.ipynb\nCONTRIBUTING.md\nLICENSE\nMANIFEST.in\nMakefile\nREADME.md\nchrisrichardmiles\nchrisrichardmiles.egg-info\ndata\ndocker-compose.yml\ndocs\nindex.ipynb\nlog.log\nprojects\nsettings.ini\nsetup.py\nsmall_data\n\n\n\ndef get_file_cols_dict(path: str='.', \n                       path_json: str='', \n                       ignore_cols: list=['index']):\n    \"\"\"Explores `path` and returns a dictionary of file names and their columns\n    for each file in `path`. Only file names that end with \n    '.csv' and '.pkl' will be considered. Pickle file names\n    will go in the 'pickles' key of the returned dictionary.\n    Csv files will see their file name saved as a key with \n    a list of their column names saved as the corresponding \n    value.\n    \"\"\"\n    \n    d = {}\n    for file in sorted(os.listdir(path)): \n        if file.endswith('.csv'): \n            cols = pd.read_csv(os.path.join(path, file), nrows=0).columns.tolist()\n            d[file] = [c for c in cols if c not in ignore_cols]\n        if file.endswith('.pkl'): \n            d.setdefault('pickles', []).append(file)\n    if path_json: \n        with open(path_json, 'w') as path_json: \n            json.dump(d, path_json, indent=0)\n    return d\n\n@call_parse\ndef fe_dict(path: Param('path to directory with files', str)='data/features', \n            path_json: Param('path to json for saving dict', str)='fe_dict.json'):\n    get_file_cols_dict(path, path_json)\n\n\n\n\nfe_dict\n\n fe_dict (path:str<pathtodirectorywithfiles>='data/features',\n          path_json:str<pathtojsonforsavingdict>='fe_dict.json')\n\n\n\n\nget_file_cols_dict\n\n get_file_cols_dict (path:str='.', path_json:str='',\n                     ignore_cols:list=['index'])\n\nExplores path and returns a dictionary of file names and their columns for each file in path. Only file names that end with ‘.csv’ and ‘.pkl’ will be considered. Pickle file names will go in the ‘pickles’ key of the returned dictionary. Csv files will see their file name saved as a key with a list of their column names saved as the corresponding value.\n\ndf1 = pd.DataFrame({'feat_1': [1,2,2,4], 'feat_2': [1,1,3,3], 'feat_3': [1,4,3,3]})\ndf2 = pd.DataFrame({'shift_feat_4': [1,9,2,4], 'shift_feat_5': [1,1,3,9], 'shift_feat_6': [1,9,3,3]})\ndf3 = pd.DataFrame({'feat_7': [1,7,2,4], 'feat_8': [7,1,3,3], 'feat_9': [1,7,3,3]})\ndf4 = pd.DataFrame({'feat_10': [1,7,2,4], 'feat_11': [7,1,3,3], 'feat_12': [1,7,3,3], \n                    'feat_13': ['a', 'b', 'c', 'd']})\ndf4.feat_10 = df4.feat_10.astype('int8')\ndf4.feat_13 = df4.feat_13.astype('category')\n\nsave_file(df1, 'features_1.csv', pickle=False)\nsave_file(df2, 'shift_features_2.csv', pickle=False)\nsave_file(df3, 'features_3.csv', pickle=False)\nsave_file(df4, 'features_4.csv', save_index=True, pickle=False)\nsave_file(df3, 'features_3_less_cols.csv', usecols=['feat_7'], pickle=False)\n\n\nget_file_cols_dict('.', path_json='tmp_features.json')\n\n{'features_1.csv': ['feat_1', 'feat_2', 'feat_3'],\n 'features_3.csv': ['feat_7', 'feat_8', 'feat_9'],\n 'features_3_less_cols.csv': ['feat_7'],\n 'features_4.csv': ['feat_10', 'feat_11', 'feat_12', 'feat_13'],\n 'shift_features_2.csv': ['shift_feat_4', 'shift_feat_5', 'shift_feat_6']}\n\n\n\nget_file_cols_dict('.')\n\n{'features_1.csv': ['feat_1', 'feat_2', 'feat_3'],\n 'features_3.csv': ['feat_7', 'feat_8', 'feat_9'],\n 'features_3_less_cols.csv': ['feat_7'],\n 'features_4.csv': ['feat_10', 'feat_11', 'feat_12', 'feat_13'],\n 'shift_features_2.csv': ['shift_feat_4', 'shift_feat_5', 'shift_feat_6']}\n\n\n\n\nLoading features\nNow we can easily load in our features with the correct data types\n\nload_features('.', 'tmp_features.json', pickle=False)\n\n\n\n\n\n  \n    \n      \n      feat_1\n      feat_2\n      feat_3\n      feat_7\n      feat_8\n      feat_9\n      feat_7\n      feat_10\n      feat_11\n      feat_12\n      feat_13\n      shift_feat_4\n      shift_feat_5\n      shift_feat_6\n    \n  \n  \n    \n      0\n      1\n      1\n      1\n      1\n      7\n      1\n      1\n      1\n      7\n      1\n      a\n      1\n      1\n      1\n    \n    \n      1\n      2\n      1\n      4\n      7\n      1\n      7\n      7\n      7\n      1\n      7\n      b\n      9\n      1\n      9\n    \n    \n      2\n      2\n      3\n      3\n      2\n      3\n      3\n      2\n      2\n      3\n      3\n      c\n      2\n      3\n      3\n    \n    \n      3\n      4\n      3\n      3\n      4\n      3\n      3\n      4\n      4\n      3\n      3\n      d\n      4\n      9\n      3\n    \n  \n\n\n\n\n\ndf = load_features('.', 'tmp_features.json', features=['feat_3', 'feat_10', 'feat_13'], pickle=False)\ndisplay(df)\ndisplay(df.dtypes)\n\n\n\n\n\n  \n    \n      \n      feat_3\n      feat_10\n      feat_13\n    \n  \n  \n    \n      0\n      1\n      1\n      a\n    \n    \n      1\n      4\n      7\n      b\n    \n    \n      2\n      3\n      2\n      c\n    \n    \n      3\n      3\n      4\n      d\n    \n  \n\n\n\n\nfeat_3        int64\nfeat_10        int8\nfeat_13    category\ndtype: object\n\n\nSometimes we need to shift the index so that our lag features are in the correct allignment.\n\nload_features('.', 'tmp_features.json', shift_index=1, pickle=False)\n\n\n\n\n\n  \n    \n      \n      feat_1\n      feat_2\n      feat_3\n      feat_7\n      feat_8\n      feat_9\n      feat_7\n      feat_10\n      feat_11\n      feat_12\n      feat_13\n      shift_feat_4\n      shift_feat_5\n      shift_feat_6\n    \n  \n  \n    \n      0\n      1.0\n      1.0\n      1.0\n      1.0\n      7.0\n      1.0\n      1.0\n      1.0\n      7.0\n      1.0\n      a\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      2.0\n      1.0\n      4.0\n      7.0\n      1.0\n      7.0\n      7.0\n      7.0\n      1.0\n      7.0\n      b\n      1.0\n      1.0\n      1.0\n    \n    \n      2\n      2.0\n      3.0\n      3.0\n      2.0\n      3.0\n      3.0\n      2.0\n      2.0\n      3.0\n      3.0\n      c\n      9.0\n      1.0\n      9.0\n    \n    \n      3\n      4.0\n      3.0\n      3.0\n      4.0\n      3.0\n      3.0\n      4.0\n      4.0\n      3.0\n      3.0\n      d\n      2.0\n      3.0\n      3.0\n    \n    \n      4\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      4.0\n      9.0\n      3.0\n    \n  \n\n\n\n\nSometimes we are loading features for a subset of the data so we only need to load the rows associated with certain indexes.\n\nload_features('.', 'tmp_features.json', shift_index=1, reindex_with=[1, 3], pickle=False)\n\n\n\n\n\n  \n    \n      \n      feat_1\n      feat_2\n      feat_3\n      feat_7\n      feat_8\n      feat_9\n      feat_7\n      feat_10\n      feat_11\n      feat_12\n      feat_13\n      shift_feat_4\n      shift_feat_5\n      shift_feat_6\n    \n  \n  \n    \n      1\n      2\n      1\n      4\n      7\n      1\n      7\n      7\n      7\n      1\n      7\n      b\n      1\n      1\n      1\n    \n    \n      3\n      4\n      3\n      3\n      4\n      3\n      3\n      4\n      4\n      3\n      3\n      d\n      2\n      3\n      3\n    \n  \n\n\n\n\nWe can use a copy of the feature module, easily comment out features we don’t want, and use this to load features.\n\nshutil.copyfile('tmp_features.json', 'tmp_features_1.json')\n\n'tmp_features_1.json'\n\n\nopen tmp_features_1.json and delete features\n\n!cat tmp_features_1.json\n\n{\n\"features_1.csv\": [\n\"feat_1\",\n\"feat_2\",\n\"feat_3\"\n],\n\"features_3.csv\": [\n\"feat_7\",\n\"feat_8\",\n\"feat_9\"\n],\n\"features_3_less_cols.csv\": [\n\"feat_7\"\n],\n\"features_4.csv\": [\n\"feat_10\",\n\"feat_11\",\n\"feat_12\",\n\"feat_13\"\n],\n\"shift_features_2.csv\": [\n\"shift_feat_4\",\n\"shift_feat_5\",\n\"shift_feat_6\"\n]\n}\n\n\n\nload_features('.', 'tmp_features_1.json', pickle=False)\n\n\n\n\n\n  \n    \n      \n      feat_1\n      feat_2\n      feat_3\n      feat_7\n      feat_8\n      feat_9\n      feat_7\n      feat_10\n      feat_11\n      feat_12\n      feat_13\n      shift_feat_4\n      shift_feat_5\n      shift_feat_6\n    \n  \n  \n    \n      0\n      1\n      1\n      1\n      1\n      7\n      1\n      1\n      1\n      7\n      1\n      a\n      1\n      1\n      1\n    \n    \n      1\n      2\n      1\n      4\n      7\n      1\n      7\n      7\n      7\n      1\n      7\n      b\n      9\n      1\n      9\n    \n    \n      2\n      2\n      3\n      3\n      2\n      3\n      3\n      2\n      2\n      3\n      3\n      c\n      2\n      3\n      3\n    \n    \n      3\n      4\n      3\n      3\n      4\n      3\n      3\n      4\n      4\n      3\n      3\n      d\n      4\n      9\n      3\n    \n  \n\n\n\n\n\n!rm *.csv\n!rm tmp*.json"
  },
  {
    "objectID": "core.html#speed-and-memory-functions",
    "href": "core.html#speed-and-memory-functions",
    "title": "Core",
    "section": "Speed and memory functions",
    "text": "Speed and memory functions\n\nParalel runs\n\n\n\npool_func\n\n pool_func (function, input_list:list, verbose=False, n_cpu=99)\n\nUses the Pool function from the package ‘multiprocessing’ to run function over the list input_list. The function should only take\n\ndef f(x): return x * 5\npool_func(f, list(range(20)), True)\n\n#############################################\nPooling function: \nf\n16 of 16 cpus used\nNumber of function calls:  20\nTime taken: 0.0 minutes\n\n\n[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]\n\n\n\n\nSaving memory\n\n\n\nreduce_mem_usage\n\n reduce_mem_usage (df, verbose=True)\n\nConverts numeric columns to smallest datatype that preserves information\n\n\n\nmerge_by_concat\n\n merge_by_concat (df1, df2, merge_on)\n\n\n\n\nsizeof_fmt\n\n sizeof_fmt (num, suffix='B')\n\nReformats num, which is num bytes\n\n\n\nget_memory_usage\n\n get_memory_usage ()\n\nReturns RAM usage in gigabytes\n\nget_memory_usage()\n\n0.14\n\n\n\n\n\ntime_taken\n\n time_taken (start_time:float=0, time_elapsed:float=None)\n\nReturns a string with the time elapsed from start_time in a nice format. If time_elapsed is provided, we ignore the start time.\nstart_time should come from by calling the time module: start_time = time.time()\n\nstart_time = time.time()\ntime.sleep(2)\ntime_taken(start_time)\n\n'Time taken: 2 seconds'\n\n\n\ntime_taken(time_elapsed=3666)\n\n'Time taken: 1 hours 1 minutes 6 seconds'"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "chrisrichardmiles",
    "section": "",
    "text": "Before anything else, please install the git hooks that run automatic scripts during each commit and merge to strip the notebooks of superfluous metadata (and avoid merge conflicts). After cloning the repository, run the following command inside it:\nnbdev_install_git_hooks\n\n\n\n\nEnsure the bug was not already reported by searching on GitHub under Issues.\nIf you’re unable to find an open issue addressing the problem, open a new one. Be sure to include a title and clear description, as much relevant information as possible, and a code sample or an executable test case demonstrating the expected behavior that is not occurring.\nBe sure to add the complete error messages.\n\n\n\n\nOpen a new GitHub pull request with the patch.\nEnsure that your PR includes a test that fails without your patch, and pass with it.\nEnsure the PR description clearly describes the problem and solution. Include the relevant issue number if applicable.\n\n\n\n\n\n\nKeep each PR focused. While it’s more convenient, do not combine several unrelated fixes together. Create as many branches as needing to keep each PR focused.\nDo not mix style changes/fixes with “functional” changes. It’s very difficult to review such PRs and it most likely get rejected.\nDo not add/remove vertical whitespace. Preserve the original style of the file you edit as much as you can.\nDo not turn an already submitted PR into your development playground. If after you submitted PR, you discovered that more work is needed - close the PR, do the required work and then submit a new PR. Otherwise each of your commits requires attention from maintainers of the project.\nIf, however, you submitted a PR and received a request for changes, you should proceed with commits inside that PR, so that the maintainer can see the incremental fixes and won’t need to review the whole PR again. In the exception case where you realize it’ll take many many commits to complete the requests, then it’s probably best to close the PR, do the work and then submit it again. Use common sense where you’d choose one way over another.\n\n\n\n\n\nDocs are automatically created from the notebooks in the nbs folder."
  },
  {
    "objectID": "core.html#make-data-folder-with-subfolders-raw-interim-features-models",
    "href": "core.html#make-data-folder-with-subfolders-raw-interim-features-models",
    "title": "Core",
    "section": "Make data folder with subfolders raw, interim, features, models",
    "text": "Make data folder with subfolders raw, interim, features, models\n\ndef mkdirs_data(data_dir_name: str='data') -> None: \n    \"\"\"Initializes the data directory structure\"\"\"\n    os.makedirs(f'{data_dir_name}/raw', exist_ok=True)\n    os.makedirs(f'{data_dir_name}/interim', exist_ok=True)\n    os.makedirs(f'{data_dir_name}/features', exist_ok=True)\n    os.makedirs(f'{data_dir_name}/models', exist_ok=True)\n    \n@call_parse\ndef cli_mkdirs_data(data_dir_name: Param('Name of data folder', str)='data') -> None: \n    mkdirs_data(data_dir_name)\n\n\n\ncli_mkdirs_data\n\n cli_mkdirs_data (data_dir_name:str<Nameofdatafolder>='data')\n\n\n\n\nmkdirs_data\n\n mkdirs_data (data_dir_name:str='data')\n\nInitializes the data directory structure"
  },
  {
    "objectID": "core.html#downloading-kaggle-data",
    "href": "core.html#downloading-kaggle-data",
    "title": "Core",
    "section": "Downloading kaggle data",
    "text": "Downloading kaggle data\n\n\ncli_download_kaggle_data\n\n cli_download_kaggle_data (comp_name:str<nameofkagglecompetition>=None)\n\n\n\n\ndownload_kaggle_data\n\n download_kaggle_data (comp_name:str=None)\n\nDownloads competition data using the kaggle api"
  }
]