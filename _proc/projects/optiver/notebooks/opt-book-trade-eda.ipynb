{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: opt-book-trade-eda.html\n",
    "skip_exec: true\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#all_no_test\n",
    "from opt_utils import * \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 7)\n",
    "plt.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "DATA_RAW='../input/optiver-realized-volatility-prediction'\n",
    "stock_id=0\n",
    "train_or_test='train'\n",
    "train = read_train_or_test(DATA_RAW, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "target_mean = train['target'].mean()\n",
    "target_median = train['target'].median()\n",
    "ax = train['target'].hist(bins=1000)\n",
    "plt.suptitle('target distribution showing a positive skew')\n",
    "plt.axvline(x=target_mean, color='red')\n",
    "plt.axvline(x=target_median, color='green')\n",
    "plt.text(x=target_mean, y=-1, s='mean', color='red', rotation=-30)\n",
    "plt.text(x=target_median - .005, y=-1, s='median', color='green', rotation=-30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "train.target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "axes[0].set_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 1, figsize=(15, 28))\n",
    "train.groupby('time_id')['target'].mean().sort_values(\n",
    "    ascending=False)[:15].plot(kind='barh', ax=axes[0])\n",
    "axes[0].set_title('Top 15 most most volatile time periods')\n",
    "axes[0].set_xlabel('Volatility')\n",
    "\n",
    "train.groupby('time_id')['target'].mean().sort_values()[:15]\\\n",
    "    .plot(kind='barh')\n",
    "axes[1].set_title('15 least most volatile time periods')\n",
    "ax.set_xlabel('Volatility')\n",
    "\n",
    "train.groupby('stock_id')['target'].mean().sort_values()[:15]\\\n",
    "    .plot(kind='barh')\n",
    "axes[2].set_title('15 least most volatile stock_ids')\n",
    "ax.set_xlabel('Volatility')\n",
    "\n",
    "train.groupby('stock_id')['target'].mean().sort_values()[:15]\\\n",
    "    .plot(kind='barh')\n",
    "axes[3].set_title('15 least most volatile stock_ids')\n",
    "ax.set_xlabel('Volatility')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = train.groupby('stock_id')['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x.sort_values(ascending=False)[:10].plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "target_max = train['target'].max()\n",
    "ax = train['target'].describe()[1:-1].plot(kind='bar')\n",
    "plt.suptitle(f'statistics of target without max, which is {target_max}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "stats = train.groupby('stock_id')['target'].describe()\n",
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots((2, 2))\n",
    "ax = stats['mean'].hist(bins=1000)\n",
    "plt.suptitle('mean distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "piv = train[['time_id', 'stock_id', 'target']].set_index(['time_id', 'stock_id']).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    ".style.background_gradient(cmap ='viridis')\\\n",
    "    .set_properties(**{'font-size': '20px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "corr = piv.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# import scipy.cluster.hierarchy as sch\n",
    "# import seaborn as sns\n",
    "\n",
    "def cluster_corr(corr_array, inplace=False):\n",
    "    \"\"\"\n",
    "    All credit to Wil Yegelwel for\n",
    "    https://wil.yegelwel.com/cluster-correlation-matrix/#:~:text=Cluster%20a%20Correlation%20Matrix%20%28in%20python%29%20Below%20is,highly%20correlated%20variables%20are%20next%20to%20eachother%20\n",
    "    Rearranges the correlation matrix, corr_array, so that groups of highly \n",
    "    correlated variables are next to eachother \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corr_array : pandas.DataFrame or numpy.ndarray\n",
    "        a NxN correlation matrix \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame or numpy.ndarray\n",
    "        a NxN correlation matrix with the columns and rows rearranged\n",
    "    \"\"\"\n",
    "    pairwise_distances = sch.distance.pdist(corr_array)\n",
    "    linkage = sch.linkage(pairwise_distances, method='complete')\n",
    "    cluster_distance_threshold = pairwise_distances.max()/2\n",
    "    idx_to_cluster_array = sch.fcluster(linkage, cluster_distance_threshold, \n",
    "                                        criterion='distance')\n",
    "    idx = np.argsort(idx_to_cluster_array)\n",
    "    \n",
    "    if not inplace:\n",
    "        corr_array = corr_array.copy()\n",
    "    \n",
    "    if isinstance(corr_array, pd.DataFrame):\n",
    "        return corr_array.iloc[idx, :].T.iloc[idx, :]\n",
    "    return corr_array[idx, :][:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(cluster_corr(corr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "cluster_corr(corr).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "ax = corr.mean().hist(bins=100)\n",
    "plt.suptitle('Distribution of each stock_ids mean correlation with all other stock_ids')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "corr.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "corr.sort_values('mean_corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## price features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df = load_bt(DATA_RAW, stock_id, train_or_test)\n",
    "add_wap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dff = df[df.time_id == 5]\n",
    "dff.wap.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "print(dff.wap.values[-1], dff.wap.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def first(x): return x.values[0]\n",
    "def last(x): return x.values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dfa = df.groupby('time_id').agg({'wap': [first, last, np.min, np.max]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dfa.columns =  ['_'.join(c) for c in dfa.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dfa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "\"\"\"Same as p4 except Im goin to use 10 minutes \n",
    "instead of 5.\"\"\"\n",
    "df = load_bt(DATA_RAW, stock_id, train_or_test)\n",
    "df = add_wap(df)\n",
    "df['log_return'] = df.groupby(['time_id'])['wap'].apply(log_return)\n",
    "df['abs_log_return'] = df['log_return'].abs()\n",
    "df['is_pos_return'] = (df['log_return'] > 0).astype(int)\n",
    "df['is_neg_return'] = (df['log_return'] < 0).astype(int)\n",
    "df['spread_pct'] = (df.ask_price1 - df.bid_price1) / df.wap\n",
    "df['spread_2_pct'] = (df.ask_price2 - df.bid_price2) / df.wap\n",
    "df['spread'] = (df.ask_price1 - df.bid_price1) \n",
    "df['spread_2'] = (df.ask_price2 - df.bid_price2) \n",
    "df['sum_bid'] = (df.bid_size1 + df.bid_size2)\n",
    "df['sum_ask'] = (df.ask_size1 + df.ask_size2)\n",
    "df['bid_ask_ratio'] = df['sum_bid'] / df['sum_ask']\n",
    "df['sum_bid_ask'] = df['sum_bid'] + df['sum_ask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# This shows there is no missing data in the book or trade data\n",
    "bookna = 0\n",
    "tradena = 0\n",
    "for stock_id in train.stock_id.unique():\n",
    "    book = load_bt(DATA_RAW, stock_id, train_or_test, book_only=True)\n",
    "    trade = load_bt(DATA_RAW, stock_id, train_or_test, trade_only=True)\n",
    "    bookna += book.isna().sum().sum()\n",
    "    tradena += trade.isna().sum().sum()\n",
    "print('bookna', bookna, 'tradena', tradena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# for stock_id in train.stock_id.unique():\n",
    "stock_id = train.stock_id.unique()[0]\n",
    "book = load_bt(DATA_RAW, stock_id, train_or_test, book_only=True, add_stock_id=True)\n",
    "trade = load_bt(DATA_RAW, stock_id, train_or_test, trade_only=True, add_stock_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dfs=[]\n",
    "for stock_id in train.stock_id.unique():\n",
    "    book = load_bt(DATA_RAW, stock_id, train_or_test, book_only=True, add_stock_id=True)\n",
    "    trade = load_bt(DATA_RAW, stock_id, train_or_test, trade_only=True, add_stock_id=True)\n",
    "    b = book.groupby(['stock_id', 'time_id'])['seconds_in_bucket'].agg(len).to_frame().rename(columns={'seconds_in_bucket': 'len_book'})\n",
    "    t = trade.groupby(['stock_id', 'time_id'])['seconds_in_bucket'].agg(len).to_frame().rename(columns={'seconds_in_bucket': 'len_trade'})\n",
    "    dfs.append(pd.concat([b, t], axis=1))\n",
    "df_len = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dff = df_len.reset_index()\n",
    "dff['row_id'] = dff['stock_id'].astype(str) + '-' + dff['time_id'].astype(str)\n",
    "dff = dff[['row_id', 'len_book', 'len_trade']].set_index('row_id')\n",
    "dff = dff.join(train).reset_index()\n",
    "dff['diff_len_book_len_trade'] = dff['len_book'] - dff['len_trade']\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dff[['len_book', 'len_trade','diff_len_book_len_trade']]\\\n",
    "    .corrwith(x['target']).to_frame().rename(columns={0: 'target'})\\\n",
    "    .style.background_gradient(cmap ='viridis')\\\n",
    "    .set_properties(**{'font-size': '20px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "plt.plot(title='ladkfj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df_len.len_book.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df_len.len_book.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df_len.len_book.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "f = lambda x: np.isnan(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "df.groupby('time_id')['bid_size1'].agg(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dff = df.groupby('time_id').agg(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dff.bid_size1.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    'log_return': [realized_volatility, 'count', np.std, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n",
    "    'is_pos_return': [np.sum, get_mean_decay(.99, -1), get_mean_decay(.99, 1)], \n",
    "    'is_neg_return': [np.sum, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n",
    "    'abs_log_return': [np.sum, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n",
    "    'sum_bid': [np.sum, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n",
    "    'sum_ask': [np.sum, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n",
    "    'wap': [np.mean, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n",
    "    'spread': [np.mean, np.sum, np.std, get_mean_decay(.99, -1), get_mean_decay(.99, 1), get_mean_decay(.95, -1), get_mean_decay(.95, 1)],\n",
    "    'bid_ask_ratio': [np.mean, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n",
    "    'sum_bid_ask': [np.mean, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n",
    "    'size': [np.mean, np.sum, np.std, get_mean_decay(.99, -1), get_mean_decay(.99, 1), get_mean_decay(.95, -1), get_mean_decay(.95, 1)],\n",
    "    'spread_pct': [np.mean, get_mean_decay(.99, -1), get_mean_decay(.99, 1)],\n",
    "\n",
    "\n",
    "}\n",
    "df_agg = df.groupby(['time_id']).agg(agg_dict).rename(\n",
    "    columns={'<lambda_0>': 'mean_decay', \n",
    "             '<lambda_1>': 'mean_decay_flip', \n",
    "             '<lambda_2>': 'mean_decay_95', \n",
    "             '<lambda_3>': 'mean_decay_flip_95',\n",
    "            }\n",
    ")\n",
    "df_agg.columns = ['_'.join(c) for c in df_agg.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "############ Realized volume for each minute ############\n",
    "for m in range(1, 11): \n",
    "    mask = (df.seconds_in_bucket >= 60 * m - 60) & (df.seconds_in_bucket < 60 * m)\n",
    "    df_agg[f'real_vol_min_{m}'] = df[mask].groupby('time_id')['log_return'].agg(realized_volatility)\n",
    "\n",
    "######### Decay sum of realized volume per minute ########\n",
    "cols = [f'real_vol_min_{minute}' for minute in range(1, 11)]\n",
    "x = df_agg[cols].values\n",
    "for decay, step in product((.99, .95, .9, .85, .75, .65, .55, .45), (1, -1)): \n",
    "    df_agg[f'real_vol_mean_decay_{decay}_{step}'] =  mean_decay(x, decay, step, axis=1)\n",
    "#     df_agg['end_beg_decay_ratio'] = df_agg['real_vol_mean_decay_0.85_-1'] / df_agg['real_vol_mean_decay_0.85_1'] # replaced by next code\n",
    "\n",
    "for c1, c2 in zip(df_agg.columns, df_agg.columns[1:]): \n",
    "    if 'mean_decay_flip' in c2: \n",
    "        pre, suf = c2.split('mean_decay_flip')\n",
    "        df_agg[pre + 'momentum' + suf] = df_agg[c1] / df_agg[c2]\n",
    "    if 'vol_mean_decay' in c2 and '-1' in c2: \n",
    "        pre, suf = c2.split('vol_mean_decay')\n",
    "        df_agg[pre + 'momentum' + suf] = df_agg[c2] / df_agg[c1]\n",
    "\n",
    "df_agg = df_agg.astype('float32')\n",
    "df_agg['no_book'] = (df_agg['log_return_count'] == 0).astype(int)\n",
    "df_agg['no_book'] = df_agg['no_book'].astype('category')\n",
    "################# Adding 'row_id' column ##################\n",
    "df_agg.reset_index(inplace=True)\n",
    "df_agg['time_id'] = df_agg.time_id.apply(lambda x: f\"{stock_id}-{x}\")\n",
    "df_agg.rename({'time_id': 'row_id'}, axis=1, inplace=True)\n",
    "return df_agg.set_index('row_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the feature and target correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../input/generate-train-features-script/p5_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "top_50_corr_cols = train.corrwith(train.target).abs()\\\n",
    "    .sort_values(ascending=False)[:50].index\n",
    "train[top_50_corr_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(train[top_50_corr_cols].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "train[['log_return_realized_volatility']].corrwith(train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "train['time_id_mean_real_vol'] = train.groupby('time_id')['log_return_realized_volatility'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "train[['time_id_mean_real_vol']].corrwith(train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "cols = [c for c in train.columns if 'wap' in c]\n",
    "train[cols].corrwith(train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "load_bt(stock_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
