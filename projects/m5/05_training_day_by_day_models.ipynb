{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: training_day_by_day_models.html\n",
    "title: Train day-by-day models\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#all_no_test\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp m5.daily_models\n",
    "#| export\n",
    "import os\n",
    "import logging\n",
    "import collections\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "from itertools import chain\n",
    "from pathlib import Path \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from lightgbm.callback import record_evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import neptune.new as neptune\n",
    "from neptune.new.integrations.lightgbm import NeptuneCallback, create_booster_summary\n",
    "from fastcore.script import call_parse, Param\n",
    "\n",
    "from chrisrichardmiles.core import load_features, time_taken, load_file\n",
    "from chrisrichardmiles.m5.fe import make_grid_df\n",
    "from chrisrichardmiles.m5.metric import WRMSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def load_cfg(path_cfg): \n",
    "    if type(path_cfg) == str: \n",
    "        with open(path_cfg, 'r') as f: return json.load(f)\n",
    "    else: return  path_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_test': 1942,\n",
       " 'start_train': 140,\n",
       " 'days_to_predict': 'all',\n",
       " 'fobj': None,\n",
       " 'fobj_weight_col': 'total_scaled_weight',\n",
       " 'weight_hess': 1,\n",
       " 'feval': 'mse',\n",
       " 'feval_weight_col': 'scale',\n",
       " 'weight_col': None,\n",
       " 'lgb_params': {'boosting_type': 'gbdt',\n",
       "  'objective': 'regression',\n",
       "  'metric': None,\n",
       "  'subsample': 0.5,\n",
       "  'subsample_freq': 1,\n",
       "  'learning_rate': 0.03,\n",
       "  'num_leaves': 255,\n",
       "  'min_data_in_leaf': 255,\n",
       "  'feature_fraction': 0.8,\n",
       "  'n_estimators': 5000,\n",
       "  'early_stopping_rounds': 50,\n",
       "  'device_type': 'cpu',\n",
       "  'seed': 42,\n",
       "  'verbose': -1},\n",
       " 'target': 'sales',\n",
       " 'p_horizon': 28,\n",
       " 'num_series': 30490,\n",
       " 'features_json': 'final_features.json',\n",
       " 'path_data_raw': '../../../data/raw',\n",
       " 'path_features': '../../../data/features',\n",
       " 'path_models': '../../../data/models',\n",
       " 'use_neptune': 0,\n",
       " 'neptune_project': None,\n",
       " 'neptune_api_token': None}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = load_cfg('final_cfg.json')\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "FINAL_CFG = {'start_test': 1942,\n",
    " 'start_train': 140,\n",
    " 'days_to_predict': 'all',\n",
    " 'fobj': 'mse',\n",
    " 'fobj_weight_col': 'total_scaled_weight',\n",
    " 'weight_hess': 1,\n",
    " 'feval': 'mse',\n",
    " 'feval_weight_col': 'scale',\n",
    " 'weight_col': None,\n",
    " 'lgb_params': {'boosting_type': 'gbdt',\n",
    "  'objective': None,\n",
    "  'metric': None,\n",
    "  'subsample': 0.5,\n",
    "  'subsample_freq': 1,\n",
    "  'learning_rate': 0.03,\n",
    "  'num_leaves': 255,\n",
    "  'min_data_in_leaf': 255,\n",
    "  'feature_fraction': 0.8,\n",
    "  'n_estimators': 5000,\n",
    "  'early_stopping_rounds': 50,\n",
    "  'device_type': 'cpu',\n",
    "  'seed': 42,\n",
    "  'verbose': -1},\n",
    " 'target': 'sales',\n",
    " 'p_horizon': 28,\n",
    " 'num_series': 30490,\n",
    " 'features_json': 'pkl_final_features.json',\n",
    " 'path_data_raw': 'data/raw',\n",
    " 'path_features': 'data/features',\n",
    " 'path_models': 'data/models',\n",
    " 'use_neptune': 0,\n",
    " 'neptune_project': 0,\n",
    " 'neptune_api_token': None}\n",
    "\n",
    "DICT_FEATURES = {\n",
    "\"fe_base.csv\": [\n",
    "\"dept_id\",\n",
    "\"store_id\"\n",
    "],\n",
    "\"fe_cal.csv\": [\n",
    "\"event_name_1\",\n",
    "\"tm_d\",\n",
    "\"tm_w\",\n",
    "\"tm_m\",\n",
    "\"tm_dw\",\n",
    "\"tm_w_end\"\n",
    "],\n",
    "\"fe_price.csv\": [\n",
    "\"sell_price\",\n",
    "\"price_min\",\n",
    "\"price_max\",\n",
    "\"price_median\",\n",
    "\"price_mode\",\n",
    "\"price_mean\",\n",
    "\"price_std\",\n",
    "\"price_norm_max\",\n",
    "\"price_norm_mode\",\n",
    "\"price_norm_mean\",\n",
    "\"price_momentum\",\n",
    "\"price_roll_momentum_4\",\n",
    "\"price_roll_momentum_24\",\n",
    "\"price_end_digits\"\n",
    "],\n",
    "\"fe_snap_event.csv\": [\n",
    "\"snap_transform_1\",\n",
    "\"snap_transform_2\",\n",
    "\"next_event_type_1\",\n",
    "\"last_event_type_1\",\n",
    "\"days_since_event\",\n",
    "\"days_until_event\"\n",
    "],\n",
    "\"shift_fe_dow_means_and_days_since_sale.csv\": [\n",
    "\"mean_4_dow_0\",\n",
    "\"mean_4_dow_1\",\n",
    "\"mean_4_dow_2\",\n",
    "\"mean_4_dow_3\",\n",
    "\"mean_4_dow_4\",\n",
    "\"mean_4_dow_5\",\n",
    "\"mean_4_dow_6\",\n",
    "\"mean_20_dow_0\",\n",
    "\"mean_20_dow_1\",\n",
    "\"mean_20_dow_2\",\n",
    "\"mean_20_dow_3\",\n",
    "\"mean_20_dow_4\",\n",
    "\"mean_20_dow_5\",\n",
    "\"mean_20_dow_6\",\n",
    "\"days_since_sale\"\n",
    "],\n",
    "\"shift_fe_ipca_15_84.csv\": [\n",
    "\"index\",\n",
    "\"ipca_15_84_comp_1\",\n",
    "\"ipca_15_84_comp_2\",\n",
    "\"ipca_15_84_comp_3\",\n",
    "\"ipca_15_84_comp_4\",\n",
    "\"ipca_15_84_comp_5\",\n",
    "\"ipca_15_84_comp_6\",\n",
    "\"ipca_15_84_comp_7\",\n",
    "\"ipca_15_84_comp_8\",\n",
    "\"ipca_15_84_comp_9\",\n",
    "\"ipca_15_84_comp_10\",\n",
    "\"ipca_15_84_comp_11\",\n",
    "\"ipca_15_84_comp_12\",\n",
    "\"ipca_15_84_comp_13\",\n",
    "\"ipca_15_84_comp_14\"\n",
    "],\n",
    "\"shift_fe_lags_1_14.csv\": [\n",
    "\"lag_1\",\n",
    "\"lag_2\",\n",
    "\"lag_3\",\n",
    "\"lag_4\",\n",
    "\"lag_5\",\n",
    "\"lag_6\",\n",
    "\"lag_7\",\n",
    "\"lag_8\",\n",
    "\"lag_9\",\n",
    "\"lag_10\",\n",
    "\"lag_11\",\n",
    "\"lag_12\",\n",
    "\"lag_13\",\n",
    "\"lag_14\"\n",
    "],\n",
    "\"shift_fe_rw_1.csv\": [\n",
    "\"shift_1_rolling_nanmean_3\",\n",
    "\"shift_1_rolling_mean_decay_3\",\n",
    "\"shift_1_rolling_nanmean_7\",\n",
    "\"shift_1_rolling_mean_decay_7\",\n",
    "\"shift_1_rolling_nanstd_7\"\n",
    "],\n",
    "\"shift_fe_rw_2.csv\": [\n",
    "\"shift_1_rolling_nanmean_14\",\n",
    "\"shift_1_rolling_mean_decay_14\",\n",
    "\"shift_1_rolling_diff_nanmean_14\",\n",
    "\"shift_1_rolling_nanstd_14\",\n",
    "\"shift_1_rolling_nanmean_30\",\n",
    "\"shift_1_rolling_mean_decay_30\"\n",
    "],\n",
    "\"shift_fe_rw_3.csv\": [\n",
    "\"shift_1_rolling_nanmean_60\",\n",
    "\"shift_1_rolling_nanmedian_60\",\n",
    "\"shift_1_rolling_mean_decay_60\",\n",
    "\"shift_1_rolling_nanstd_60\",\n",
    "\"shift_1_rolling_nanmean_140\",\n",
    "\"shift_1_rolling_mean_decay_140\",\n",
    "\"shift_1_rolling_nanstd_140\"\n",
    "],\n",
    "\"shift_fe_shifts_mom_1.csv\": [\n",
    "\"shift_8_rolling_nanmean_7\",\n",
    "\"momentum_7_rolling_nanmean_7\",\n",
    "\"shift_8_rolling_mean_decay_7\",\n",
    "\"momentum_7_rolling_mean_decay_7\",\n",
    "\"momentum_7_rolling_diff_nanmean_7\",\n",
    "\"shift_29_rolling_nanmean_7\",\n",
    "\"momentum_28_rolling_nanmean_7\",\n",
    "\"shift_29_rolling_mean_decay_7\",\n",
    "\"momentum_28_rolling_mean_decay_7\",\n",
    "\"shift_29_rolling_diff_nanmean_7\",\n",
    "\"momentum_28_rolling_diff_nanmean_7\"\n",
    "],\n",
    "\"shift_fe_shifts_mom_2.csv\": [\n",
    "\"shift_8_rolling_nanmean_30\",\n",
    "\"momentum_7_rolling_nanmean_30\",\n",
    "\"shift_8_rolling_mean_decay_30\",\n",
    "\"shift_29_rolling_nanmean_30\",\n",
    "\"momentum_28_rolling_nanmean_30\",\n",
    "\"shift_29_rolling_mean_decay_30\"\n",
    "],\n",
    "\"shift_fe_shifts_mom_3.csv\": [\n",
    "\"shift_29_rolling_nanmean_60\",\n",
    "\"shift_91_rolling_nanmean_60\",\n",
    "\"shift_91_rolling_mean_decay_60\"\n",
    "]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_test': 1942,\n",
       " 'start_train': 140,\n",
       " 'days_to_predict': 'all',\n",
       " 'fobj': 'mse',\n",
       " 'fobj_weight_col': 'total_scaled_weight',\n",
       " 'weight_hess': 1,\n",
       " 'feval': 'mse',\n",
       " 'feval_weight_col': 'scale',\n",
       " 'weight_col': None,\n",
       " 'lgb_params': {'boosting_type': 'gbdt',\n",
       "  'objective': None,\n",
       "  'metric': None,\n",
       "  'subsample': 0.5,\n",
       "  'subsample_freq': 1,\n",
       "  'learning_rate': 0.03,\n",
       "  'num_leaves': 255,\n",
       "  'min_data_in_leaf': 255,\n",
       "  'feature_fraction': 0.8,\n",
       "  'n_estimators': 1,\n",
       "  'early_stopping_rounds': 50,\n",
       "  'device_type': 'cpu',\n",
       "  'seed': 42,\n",
       "  'verbose': -1},\n",
       " 'target': 'sales',\n",
       " 'p_horizon': 28,\n",
       " 'num_series': 30490,\n",
       " 'features_json': 'pkl_final_features.json',\n",
       " 'path_data_raw': 'data/raw',\n",
       " 'path_features': 'data/features',\n",
       " 'path_models': 'data/models',\n",
       " 'use_neptune': 0,\n",
       " 'neptune_project': 0,\n",
       " 'neptune_api_token': None}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fe_base.csv': ['dept_id', 'store_id'],\n",
       " 'fe_cal.csv': ['event_name_1', 'tm_d', 'tm_w', 'tm_m', 'tm_dw', 'tm_w_end'],\n",
       " 'fe_price.csv': ['sell_price',\n",
       "  'price_min',\n",
       "  'price_max',\n",
       "  'price_median',\n",
       "  'price_mode',\n",
       "  'price_mean',\n",
       "  'price_std',\n",
       "  'price_norm_max',\n",
       "  'price_norm_mode',\n",
       "  'price_norm_mean',\n",
       "  'price_momentum',\n",
       "  'price_roll_momentum_4',\n",
       "  'price_roll_momentum_24',\n",
       "  'price_end_digits'],\n",
       " 'fe_snap_event.csv': ['snap_transform_1',\n",
       "  'snap_transform_2',\n",
       "  'next_event_type_1',\n",
       "  'last_event_type_1',\n",
       "  'days_since_event',\n",
       "  'days_until_event'],\n",
       " 'shift_fe_dow_means_and_days_since_sale.csv': ['mean_4_dow_0',\n",
       "  'mean_4_dow_1',\n",
       "  'mean_4_dow_2',\n",
       "  'mean_4_dow_3',\n",
       "  'mean_4_dow_4',\n",
       "  'mean_4_dow_5',\n",
       "  'mean_4_dow_6',\n",
       "  'mean_20_dow_0',\n",
       "  'mean_20_dow_1',\n",
       "  'mean_20_dow_2',\n",
       "  'mean_20_dow_3',\n",
       "  'mean_20_dow_4',\n",
       "  'mean_20_dow_5',\n",
       "  'mean_20_dow_6',\n",
       "  'days_since_sale'],\n",
       " 'shift_fe_ipca_15_84.csv': ['index',\n",
       "  'ipca_15_84_comp_1',\n",
       "  'ipca_15_84_comp_2',\n",
       "  'ipca_15_84_comp_3',\n",
       "  'ipca_15_84_comp_4',\n",
       "  'ipca_15_84_comp_5',\n",
       "  'ipca_15_84_comp_6',\n",
       "  'ipca_15_84_comp_7',\n",
       "  'ipca_15_84_comp_8',\n",
       "  'ipca_15_84_comp_9',\n",
       "  'ipca_15_84_comp_10',\n",
       "  'ipca_15_84_comp_11',\n",
       "  'ipca_15_84_comp_12',\n",
       "  'ipca_15_84_comp_13',\n",
       "  'ipca_15_84_comp_14'],\n",
       " 'shift_fe_lags_1_14.csv': ['lag_1',\n",
       "  'lag_2',\n",
       "  'lag_3',\n",
       "  'lag_4',\n",
       "  'lag_5',\n",
       "  'lag_6',\n",
       "  'lag_7',\n",
       "  'lag_8',\n",
       "  'lag_9',\n",
       "  'lag_10',\n",
       "  'lag_11',\n",
       "  'lag_12',\n",
       "  'lag_13',\n",
       "  'lag_14'],\n",
       " 'shift_fe_rw_1.csv': ['shift_1_rolling_nanmean_3',\n",
       "  'shift_1_rolling_mean_decay_3',\n",
       "  'shift_1_rolling_nanmean_7',\n",
       "  'shift_1_rolling_mean_decay_7',\n",
       "  'shift_1_rolling_nanstd_7'],\n",
       " 'shift_fe_rw_2.csv': ['shift_1_rolling_nanmean_14',\n",
       "  'shift_1_rolling_mean_decay_14',\n",
       "  'shift_1_rolling_diff_nanmean_14',\n",
       "  'shift_1_rolling_nanstd_14',\n",
       "  'shift_1_rolling_nanmean_30',\n",
       "  'shift_1_rolling_mean_decay_30'],\n",
       " 'shift_fe_rw_3.csv': ['shift_1_rolling_nanmean_60',\n",
       "  'shift_1_rolling_nanmedian_60',\n",
       "  'shift_1_rolling_mean_decay_60',\n",
       "  'shift_1_rolling_nanstd_60',\n",
       "  'shift_1_rolling_nanmean_140',\n",
       "  'shift_1_rolling_mean_decay_140',\n",
       "  'shift_1_rolling_nanstd_140'],\n",
       " 'shift_fe_shifts_mom_1.csv': ['shift_8_rolling_nanmean_7',\n",
       "  'momentum_7_rolling_nanmean_7',\n",
       "  'shift_8_rolling_mean_decay_7',\n",
       "  'momentum_7_rolling_mean_decay_7',\n",
       "  'momentum_7_rolling_diff_nanmean_7',\n",
       "  'shift_29_rolling_nanmean_7',\n",
       "  'momentum_28_rolling_nanmean_7',\n",
       "  'shift_29_rolling_mean_decay_7',\n",
       "  'momentum_28_rolling_mean_decay_7',\n",
       "  'shift_29_rolling_diff_nanmean_7',\n",
       "  'momentum_28_rolling_diff_nanmean_7'],\n",
       " 'shift_fe_shifts_mom_2.csv': ['shift_8_rolling_nanmean_30',\n",
       "  'momentum_7_rolling_nanmean_30',\n",
       "  'shift_8_rolling_mean_decay_30',\n",
       "  'shift_29_rolling_nanmean_30',\n",
       "  'momentum_28_rolling_nanmean_30',\n",
       "  'shift_29_rolling_mean_decay_30'],\n",
       " 'shift_fe_shifts_mom_3.csv': ['shift_29_rolling_nanmean_60',\n",
       "  'shift_91_rolling_nanmean_60',\n",
       "  'shift_91_rolling_mean_decay_60']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DICT_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def prep_data(cfg): \n",
    "    df_stv = pd.read_csv(os.path.join(cfg['path_data_raw'], 'sales_train_evaluation.csv'))\n",
    "    grid_df, _ = make_grid_df(df_stv)\n",
    "\n",
    "    # Only use items with at least 68 days of sales\n",
    "    first_sale = grid_df[grid_df.sales.notnull()].drop_duplicates('id')\n",
    "    keep_id = first_sale[(cfg['start_test'] - first_sale.d) >= 68].id.tolist()\n",
    "    df_stv_trunc = df_stv[df_stv.id.isin(keep_id)]\n",
    "    grid_df = grid_df[grid_df.id.isin(keep_id)]\n",
    "\n",
    "    #################### full valid and test sets ###################\n",
    "    valid_days = [cfg['start_test'] + d - cfg['p_horizon'] for d in range(cfg['p_horizon'])]\n",
    "    valid_actuals = df_stv_trunc[[f'd_{d}' for d in valid_days]].values\n",
    "    e = WRMSSE(cfg['path_data_raw'], cfg['start_test'], df_stv_trunc=df_stv_trunc)\n",
    "    if cfg['fobj_weight_col'] == 'total_scaled_weight': e.add_total_scaled_weight()\n",
    "    if cfg['start_test'] != 1942: test_actuals = e.actuals.copy() \n",
    "    prediction_df = df_stv_trunc[['id']]\n",
    "    \n",
    "    return grid_df, prediction_df, valid_actuals, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def neptune(cfg): \n",
    "    \"\"\"Not implemented\"\"\"\n",
    "    if os.getenv('NEPTUNE_API_KEY'): \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def lgb_daily(path_cfg: str='cfg.json'):\n",
    "    \"\"\"Train 1 model for each day of prediction accoring to `path_cfg`.\"\"\"\n",
    "     \n",
    "    if os.path.exists(path_cfg):\n",
    "        cfg = load_cfg(path_cfg)\n",
    "    else: \n",
    "        cfg = FINAL_CFG\n",
    "        path_cfg = 'final_cfg'\n",
    "    full_grid_df, prediction_df, valid_actuals, e = prep_data(cfg)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    dict_eval_logs = [] # For experiment tracking\n",
    "    ############### Day by day training and predicting #############\n",
    "    if cfg['days_to_predict'] == \"all\": cfg['days_to_predict'] = range(28)\n",
    "    for day_of_horizon in cfg['days_to_predict']:\n",
    "        \n",
    "        # Starting with full data and filtering for same day of week\n",
    "        grid_df = full_grid_df.copy() \n",
    "        test_day = cfg['start_test'] + day_of_horizon\n",
    "        valid_day = test_day - 28\n",
    "        same_day_of_week = [d for d in range(cfg['start_train'], test_day + 1) if d%7 == (test_day)%7]\n",
    "        grid_df = grid_df[grid_df.d.isin(same_day_of_week)]\n",
    "        \n",
    "        if os.path.exists(path_cfg):\n",
    "            with open(cfg['features_json'], 'r') as f: \n",
    "                dict_features = json.load(f)\n",
    "        else: \n",
    "            dict_features = DICT_FEATURES\n",
    "            \n",
    "        index = grid_df.index\n",
    "        grid_df = pd.concat([\n",
    "                    grid_df, \n",
    "                    load_features(cfg['path_features'], dict_features, reindex_with=index, \n",
    "                                  shift_index=cfg['num_series'] * day_of_horizon)\n",
    "                ], axis=1)\n",
    "\n",
    "        remove_features = ['id', 'd', cfg['target']]\n",
    "        feature_cols = [col for col in list(grid_df) if col not in remove_features]\n",
    "\n",
    "        ################## test, train and valid set ####################\n",
    "        valid_mask = (grid_df.d == valid_day) \n",
    "        train_mask = (grid_df.d >= cfg['start_train']) & (grid_df.d < valid_day) & (grid_df[cfg['target']].notnull())\n",
    "        test_mask = (grid_df.d == test_day)\n",
    "\n",
    "        train_x, train_y = grid_df[train_mask][feature_cols], grid_df[train_mask][cfg['target']]\n",
    "        valid_x, valid_y = grid_df[valid_mask][feature_cols], grid_df[valid_mask][cfg['target']]\n",
    "        test_x, test_y = grid_df[test_mask][feature_cols], grid_df[test_mask][cfg['target']]\n",
    "\n",
    "        ################## Fit custom objective and metric ##################\n",
    "        w_12_train = e.w_12.reindex(grid_df[train_mask].id)\n",
    "        w_12_eval = e.w_12.reindex(grid_df[valid_mask].id)\n",
    "        w_12_test = e.w_12.reindex(grid_df[test_mask].id)\n",
    "\n",
    "        if cfg['fobj']: \n",
    "            get_fobj = getattr(e, f'get_weighted_{cfg[\"fobj\"]}_fobj')\n",
    "            fobj = get_fobj(w_12_train, cfg['fobj_weight_col'], cfg['weight_hess'])\n",
    "        else: \n",
    "            fobj = None\n",
    "\n",
    "        if cfg['feval']:\n",
    "            if cfg['feval'] == 'feval': \n",
    "                feval = e.feval\n",
    "            else: \n",
    "                get_feval = getattr(e, f'get_weighted_{cfg[\"feval\"]}_feval')\n",
    "                feval = get_feval(w_12_eval, cfg['feval_weight_col'])  \n",
    "        else: \n",
    "            feval = None\n",
    "\n",
    "        # Set evaluator actuals to valid day for early stopping\n",
    "        e.actuals = valid_actuals[:, day_of_horizon].reshape((-1,1))\n",
    "\n",
    "        ############# lightgbm datasets for training #############\n",
    "        if cfg['weight_col']: \n",
    "            weight_train = w_12_train[cfg['weight_col']].values\n",
    "            weight_eval = w_12_eval[cfg['weight_col']].values\n",
    "            weight_test = w_12_test[cfg['weight_col']].values\n",
    "        else: \n",
    "            weight_train, weight_eval, weight_test = None, None, None\n",
    "        train_data = lgb.Dataset(train_x, label=train_y, weight=weight_train)\n",
    "        valid_data = lgb.Dataset(valid_x, label=valid_y, weight=weight_eval)\n",
    "        test_data = lgb.Dataset(test_x, label=test_y, weight=weight_test)\n",
    "\n",
    "        ####################### Training ##########################\n",
    "        dict_eval_log = {}\n",
    "        estimator = lgb.train(\n",
    "            cfg['lgb_params'],\n",
    "            train_set=train_data,\n",
    "            valid_sets=[valid_data],\n",
    "            valid_names=['valid'],\n",
    "            fobj = fobj,\n",
    "            feval = feval,\n",
    "            callbacks=[record_evaluation(dict_eval_log)],\n",
    "        )\n",
    "        booster_summary = create_booster_summary(booster=estimator, max_num_features=25)\n",
    "        cfg[f'bs_{day_of_horizon}'] = booster_summary\n",
    "        dict_eval_logs.append(dict_eval_log)\n",
    "\n",
    "        preds = estimator.predict(test_x)\n",
    "        prediction_df.loc[:, f'F{day_of_horizon + 1}'] = preds\n",
    "        gc.collect()    \n",
    "\n",
    "    # Saving predictions in submission ready format\n",
    "    tmp = prediction_df.copy()\n",
    "    prediction_df.id = prediction_df.id.str.replace('evaluation', 'validation')\n",
    "    prediction_df = pd.concat([prediction_df, tmp])\n",
    "    path = 'lgb_daily' + '_' + Path(path_cfg).stem + '_' + 'submission.csv'\n",
    "    prediction_df.to_csv(path, index=False)\n",
    "    \n",
    "    neptune(cfg)\n",
    "    time_taken(start_time)\n",
    "    \n",
    "@call_parse\n",
    "def cli_lgb_daily(path_cfg: Param('path to the configuration json', str)='cfg.json'):\n",
    "    lgb_daily(path_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "# lgb_daily('../../../final_cfg.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
