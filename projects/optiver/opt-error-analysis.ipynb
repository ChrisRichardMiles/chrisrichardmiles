{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-28T08:10:08.234011Z",
     "iopub.status.busy": "2021-08-28T08:10:08.233431Z",
     "iopub.status.idle": "2021-08-28T08:10:11.02404Z",
     "shell.execute_reply": "2021-08-28T08:10:11.023159Z",
     "shell.execute_reply.started": "2021-08-28T08:10:08.233898Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6593/805758017.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopt_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopt_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/optiver/chrisrichardmiles/projects/optiver/opt_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroupKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import opt_utils as opt\n",
    "from opt_utils import * \n",
    "\n",
    "DATA_RAW = '../input/optiver-realized-volatility-prediction'\n",
    "MODEL = '../dart_model'\n",
    "TRAIN = '../dart_model/enc_p13_train.pkl'\n",
    "sns.set()\n",
    "\n",
    "def rdf(train): \n",
    "    train['spe'] = ((train['target'] - train['pred']) / train['target']) ** 2\n",
    "    return np.sqrt((train['spe'].sum()) / train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:54:12.669148Z",
     "iopub.status.busy": "2021-08-28T05:54:12.668831Z",
     "iopub.status.idle": "2021-08-28T05:54:18.502142Z",
     "shell.execute_reply": "2021-08-28T05:54:18.50115Z",
     "shell.execute_reply.started": "2021-08-28T05:54:12.669118Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(TRAIN)\n",
    "oof_preds = np.load(os.path.join(MODEL, 'oof_predictions.npy'))\n",
    "train['pred'] = oof_preds\n",
    "train['spe'] = ((train['target'] - train['pred']) / train['target']) ** 2\n",
    "train['raw_error'] = train['pred'] - train['target']\n",
    "train['rv'] = train['log_return_realized_volatility']\n",
    "print(rdf(train))\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:54:58.217294Z",
     "iopub.status.busy": "2021-08-28T05:54:58.216889Z",
     "iopub.status.idle": "2021-08-28T05:54:59.846081Z",
     "shell.execute_reply": "2021-08-28T05:54:59.844964Z",
     "shell.execute_reply.started": "2021-08-28T05:54:58.217259Z"
    }
   },
   "outputs": [],
   "source": [
    "top_err = train.sort_values('spe', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:55:06.432994Z",
     "iopub.status.busy": "2021-08-28T05:55:06.432445Z",
     "iopub.status.idle": "2021-08-28T05:55:06.728465Z",
     "shell.execute_reply": "2021-08-28T05:55:06.727399Z",
     "shell.execute_reply.started": "2021-08-28T05:55:06.432958Z"
    }
   },
   "outputs": [],
   "source": [
    "top_err[:100].raw_error.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:55:14.275386Z",
     "iopub.status.busy": "2021-08-28T05:55:14.274993Z",
     "iopub.status.idle": "2021-08-28T05:55:14.282868Z",
     "shell.execute_reply": "2021-08-28T05:55:14.281803Z",
     "shell.execute_reply.started": "2021-08-28T05:55:14.275351Z"
    }
   },
   "outputs": [],
   "source": [
    "top_err[:100]['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T19:42:03.218119Z",
     "iopub.status.busy": "2021-08-27T19:42:03.217532Z",
     "iopub.status.idle": "2021-08-27T19:42:03.232598Z",
     "shell.execute_reply": "2021-08-27T19:42:03.231354Z",
     "shell.execute_reply.started": "2021-08-27T19:42:03.218066Z"
    }
   },
   "outputs": [],
   "source": [
    "train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:55:24.6388Z",
     "iopub.status.busy": "2021-08-28T05:55:24.638416Z",
     "iopub.status.idle": "2021-08-28T05:55:24.669384Z",
     "shell.execute_reply": "2021-08-28T05:55:24.668069Z",
     "shell.execute_reply.started": "2021-08-28T05:55:24.638759Z"
    }
   },
   "outputs": [],
   "source": [
    "train[['ratio', 'target']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T19:45:06.98881Z",
     "iopub.status.busy": "2021-08-27T19:45:06.98843Z",
     "iopub.status.idle": "2021-08-27T19:45:07.003257Z",
     "shell.execute_reply": "2021-08-27T19:45:07.002011Z",
     "shell.execute_reply.started": "2021-08-27T19:45:06.988777Z"
    }
   },
   "outputs": [],
   "source": [
    "top_err[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T19:43:40.342007Z",
     "iopub.status.busy": "2021-08-27T19:43:40.341622Z",
     "iopub.status.idle": "2021-08-27T19:43:40.35631Z",
     "shell.execute_reply": "2021-08-27T19:43:40.355021Z",
     "shell.execute_reply.started": "2021-08-27T19:43:40.341961Z"
    }
   },
   "outputs": [],
   "source": [
    "top_err[:100][['ratio', 'target']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T19:47:37.457471Z",
     "iopub.status.busy": "2021-08-27T19:47:37.457087Z",
     "iopub.status.idle": "2021-08-27T19:47:37.465489Z",
     "shell.execute_reply": "2021-08-27T19:47:37.464043Z",
     "shell.execute_reply.started": "2021-08-27T19:47:37.457439Z"
    }
   },
   "outputs": [],
   "source": [
    "top_err[:100].sum_bid_ask_mean.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T19:48:33.602416Z",
     "iopub.status.busy": "2021-08-27T19:48:33.601865Z",
     "iopub.status.idle": "2021-08-27T19:48:33.893375Z",
     "shell.execute_reply": "2021-08-27T19:48:33.892167Z",
     "shell.execute_reply.started": "2021-08-27T19:48:33.60238Z"
    }
   },
   "outputs": [],
   "source": [
    "train.sum_bid_ask_mean.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T21:55:22.07668Z",
     "iopub.status.busy": "2021-08-27T21:55:22.076239Z",
     "iopub.status.idle": "2021-08-27T21:55:22.154402Z",
     "shell.execute_reply": "2021-08-27T21:55:22.152729Z",
     "shell.execute_reply.started": "2021-08-27T21:55:22.076582Z"
    }
   },
   "outputs": [],
   "source": [
    "train.corrwith(train['target']).abs().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T09:02:26.952081Z",
     "iopub.status.busy": "2021-08-26T09:02:26.951687Z",
     "iopub.status.idle": "2021-08-26T09:02:28.898595Z",
     "shell.execute_reply": "2021-08-26T09:02:28.897374Z",
     "shell.execute_reply.started": "2021-08-26T09:02:26.952049Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(train['spe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the heck. This looks like I have one or a few large errors and most near zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T09:02:33.05947Z",
     "iopub.status.busy": "2021-08-26T09:02:33.059095Z",
     "iopub.status.idle": "2021-08-26T09:02:33.261488Z",
     "shell.execute_reply": "2021-08-26T09:02:33.260378Z",
     "shell.execute_reply.started": "2021-08-26T09:02:33.059437Z"
    }
   },
   "outputs": [],
   "source": [
    "train['spe'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T09:02:33.552558Z",
     "iopub.status.busy": "2021-08-26T09:02:33.552183Z",
     "iopub.status.idle": "2021-08-26T09:02:33.559725Z",
     "shell.execute_reply": "2021-08-26T09:02:33.558496Z",
     "shell.execute_reply.started": "2021-08-26T09:02:33.552523Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train['spe'].max(), train['spe'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T09:02:34.572799Z",
     "iopub.status.busy": "2021-08-26T09:02:34.572427Z",
     "iopub.status.idle": "2021-08-26T09:02:34.663166Z",
     "shell.execute_reply": "2021-08-26T09:02:34.662128Z",
     "shell.execute_reply.started": "2021-08-26T09:02:34.572765Z"
    }
   },
   "outputs": [],
   "source": [
    "train['spe'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the cumulative sum of errors to see how spread out the errors are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T09:02:40.244806Z",
     "iopub.status.busy": "2021-08-26T09:02:40.24444Z",
     "iopub.status.idle": "2021-08-26T09:02:40.564249Z",
     "shell.execute_reply": "2021-08-26T09:02:40.563123Z",
     "shell.execute_reply.started": "2021-08-26T09:02:40.244776Z"
    }
   },
   "outputs": [],
   "source": [
    "df = train['spe'].sort_values().cumsum().reset_index(drop=True)\n",
    "df.index /= df.index.values[-1]\n",
    "df /= df.max()\n",
    "df.plot()\n",
    "plt.suptitle('Cumulative sum of sorted errors')\n",
    "plt.xlabel('fraction of rows')\n",
    "plt.ylabel('fraction of error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the last 20% of the rows carry about 75% of the error. \n",
    "Lets see if the error is balanced accross stock_ids and time_ids. \n",
    "\n",
    "we can see whats going on with the bad erros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T00:30:13.673196Z",
     "iopub.status.busy": "2021-08-27T00:30:13.672817Z",
     "iopub.status.idle": "2021-08-27T00:30:13.6933Z",
     "shell.execute_reply": "2021-08-27T00:30:13.692159Z",
     "shell.execute_reply.started": "2021-08-27T00:30:13.673166Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Errors by stock_id sorted in descending order')\n",
    "stock = train.groupby('stock_id')['spe'].sum()\n",
    "stock.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T00:31:39.649404Z",
     "iopub.status.busy": "2021-08-27T00:31:39.649095Z",
     "iopub.status.idle": "2021-08-27T00:31:39.670704Z",
     "shell.execute_reply": "2021-08-27T00:31:39.668843Z",
     "shell.execute_reply.started": "2021-08-27T00:31:39.649379Z"
    }
   },
   "outputs": [],
   "source": [
    "train[train.stock_id == 31][['log_return_realized_volatility', 'target']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was expecting the minimum to be much much lower compared to the maximum spe stock_id. The worst offender, stock_id 31 is only about 3 times worse than the second at 380 and gradually goes down to around 100 for the lowest stock. So stock 31 needs a little special attention, but we need to look at all stocks erros. I am guessing that the time_id aggregations won't be as balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T00:28:03.180811Z",
     "iopub.status.busy": "2021-08-27T00:28:03.180452Z",
     "iopub.status.idle": "2021-08-27T00:28:03.206041Z",
     "shell.execute_reply": "2021-08-27T00:28:03.205117Z",
     "shell.execute_reply.started": "2021-08-27T00:28:03.18078Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Errors by time_id sorted in descending order')\n",
    "time = train.groupby('time_id')['spe'].sum()\n",
    "worst_times = time.sort_values(ascending=False)\n",
    "worst_times[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T00:32:52.18931Z",
     "iopub.status.busy": "2021-08-27T00:32:52.188938Z",
     "iopub.status.idle": "2021-08-27T00:32:52.203842Z",
     "shell.execute_reply": "2021-08-27T00:32:52.202336Z",
     "shell.execute_reply.started": "2021-08-27T00:32:52.189281Z"
    }
   },
   "outputs": [],
   "source": [
    "train[train.time_id == 25504][['log_return_realized_volatility', 'target']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T00:34:05.548849Z",
     "iopub.status.busy": "2021-08-27T00:34:05.548525Z",
     "iopub.status.idle": "2021-08-27T00:34:05.553216Z",
     "shell.execute_reply": "2021-08-27T00:34:05.552362Z",
     "shell.execute_reply.started": "2021-08-27T00:34:05.548824Z"
    }
   },
   "outputs": [],
   "source": [
    "top_5_worst_times = worst_times[:5].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a much greater imbalance here, with the top time_id accruing about 200 time the error of the bottom. If we can identify the reason for these errors in the hardest hit time ids, we have the best chance to improve our models. \n",
    "\n",
    "I am suspecting that either the first 10 minute window is low volatitliy, followed by a second 10 minute window with high volatility, or vica versa. For the top time_id, 25504, lets see how the realized volatility compares to the average of the first 10 minutes, and then how the target compares to the average target.\n",
    "\n",
    "Lets normalize the realized the target and realized volatility of the the first 10 minutes. Then we can compare in the same scale that correlation is calculated in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T00:35:00.313906Z",
     "iopub.status.busy": "2021-08-27T00:35:00.31353Z",
     "iopub.status.idle": "2021-08-27T00:35:00.32854Z",
     "shell.execute_reply": "2021-08-27T00:35:00.32725Z",
     "shell.execute_reply.started": "2021-08-27T00:35:00.313876Z"
    }
   },
   "outputs": [],
   "source": [
    "tar_mean = train['target'].mean()\n",
    "rv_mean = train.log_return_realized_volatility.mean()\n",
    "tar_std = train['target'].std()\n",
    "rv_std = train.log_return_realized_volatility.std()\n",
    "train['nrv'] = (train.log_return_realized_volatility - rv_mean) / rv_std\n",
    "train['ntar'] = (train.target - tar_mean) / tar_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the top 3 worst scoring time_ids, and then the best scoring time_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T00:35:02.427441Z",
     "iopub.status.busy": "2021-08-27T00:35:02.427137Z",
     "iopub.status.idle": "2021-08-27T00:35:03.212583Z",
     "shell.execute_reply": "2021-08-27T00:35:03.211475Z",
     "shell.execute_reply.started": "2021-08-27T00:35:02.427416Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(15, 20))\n",
    "train[train.time_id == 25504][['nrv', 'ntar']].plot(ax=axes[0])\n",
    "axes[0].set_title('Worst scoring time_id, 25504 normalized target and realized variance')\n",
    "\n",
    "train[train.time_id == 27174][['nrv', 'ntar']].plot(ax=axes[1])\n",
    "axes[1].set_title('2nd worst scoring time_id, 27174 normalized target and realized variance')\n",
    "\n",
    "train[train.time_id == 24034][['nrv', 'ntar']].plot(ax=axes[2])\n",
    "axes[2].set_title('3rd worst scoring time_id, 24034 normalized target and realized variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T00:35:08.786047Z",
     "iopub.status.busy": "2021-08-27T00:35:08.785739Z",
     "iopub.status.idle": "2021-08-27T00:35:09.324574Z",
     "shell.execute_reply": "2021-08-27T00:35:09.323353Z",
     "shell.execute_reply.started": "2021-08-27T00:35:08.786007Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(15, 20))\n",
    "train[train.time_id == 29850][['nrv', 'ntar']].plot(ax=axes[0])\n",
    "axes[0].set_title('Best scoring time_id, 29850 normalized target and realized variance')\n",
    "\n",
    "train[train.time_id == 4432][['nrv', 'ntar']].plot(ax=axes[1])\n",
    "axes[1].set_title('2nd best scoring time_id, 4432 normalized target and realized variance')\n",
    "\n",
    "train[train.time_id == 21116][['nrv', 'ntar']].plot(ax=axes[2])\n",
    "axes[2].set_title('3rd best scoring time_id, 21116 normalized target and realized variance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am a bit confused. The 3rd worst scoring time_id looks really bad, but the first 2 look almost like best scoring time_ids. Maybe there is something I can't see yet that is huring my model. Lets plot the same plots again, along with our predictions. We will have to scale the predictions with the the same mean and std of the target to put them on the same scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T09:03:40.971874Z",
     "iopub.status.busy": "2021-08-26T09:03:40.971501Z",
     "iopub.status.idle": "2021-08-26T09:03:41.635502Z",
     "shell.execute_reply": "2021-08-26T09:03:41.628648Z",
     "shell.execute_reply.started": "2021-08-26T09:03:40.971843Z"
    }
   },
   "outputs": [],
   "source": [
    "train['norm_pred'] = (train.pred - tar_mean) / tar_std\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 20))\n",
    "train[train.time_id == 25504][['nrv', 'ntar', 'norm_pred']].plot(ax=axes[0])\n",
    "axes[0].set_title('Worst scoring time_id, 25504 normalized target and realized variance')\n",
    "\n",
    "train[train.time_id == 27174][['nrv', 'ntar', 'norm_pred']].plot(ax=axes[1])\n",
    "axes[1].set_title('2nd worst scoring time_id, 27174 normalized target and realized variance')\n",
    "\n",
    "train[train.time_id == 24034][['nrv', 'ntar', 'norm_pred']].plot(ax=axes[2])\n",
    "axes[2].set_title('3rd worst scoring time_id, 24034 normalized target and realized variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T09:03:42.310414Z",
     "iopub.status.busy": "2021-08-26T09:03:42.309982Z",
     "iopub.status.idle": "2021-08-26T09:03:43.079193Z",
     "shell.execute_reply": "2021-08-26T09:03:43.077818Z",
     "shell.execute_reply.started": "2021-08-26T09:03:42.310377Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(15, 20))\n",
    "train[train.time_id == 29850][['nrv', 'ntar', 'norm_pred']].plot(ax=axes[0])\n",
    "axes[0].set_title('Best scoring time_id, 29850 normalized target and realized variance')\n",
    "\n",
    "train[train.time_id == 4432][['nrv', 'ntar', 'norm_pred']].plot(ax=axes[1])\n",
    "axes[1].set_title('2nd best scoring time_id, 4432 normalized target and realized variance')\n",
    "\n",
    "train[train.time_id == 21116][['nrv', 'ntar', 'norm_pred']].plot(ax=axes[2])\n",
    "axes[2].set_title('3rd best scoring time_id, 21116 normalized target and realized variance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am still confused about the third worst time_id. It looks like the predictions follow the first 10 minute volatility, and should be far off. Maybe I am missing something by normalizing. Lets just look at the raw values of preds and the target, along with the error plotted underneath for reference. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T09:05:47.939167Z",
     "iopub.status.busy": "2021-08-26T09:05:47.938765Z",
     "iopub.status.idle": "2021-08-26T09:05:49.278516Z",
     "shell.execute_reply": "2021-08-26T09:05:49.277332Z",
     "shell.execute_reply.started": "2021-08-26T09:05:47.939132Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 1, figsize=(15, 35))\n",
    "train[train.time_id == 25504][['target', 'pred']].plot(ax=axes[0])\n",
    "axes[0].set_title('Worst scoring time_id, 25504 normalized target and realized variance')\n",
    "train[train.time_id == 25504][['spe']].plot(ax=axes[1])\n",
    "\n",
    "train[train.time_id == 27174][['target', 'pred']].plot(ax=axes[2])\n",
    "axes[2].set_title('2nd worst scoring time_id, 27174 normalized target and realized variance')\n",
    "train[train.time_id == 27174][['spe']].plot(ax=axes[3])\n",
    "\n",
    "train[train.time_id == 24034][['target', 'pred']].plot(ax=axes[4])\n",
    "axes[4].set_title('3rd worst scoring time_id, 24034 normalized target and realized variance')\n",
    "train[train.time_id == 24034][['spe']].plot(ax=axes[5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is finally clear. The 3rd worst time_id has a consistent error accross all stocks. However, the target value is higher, so the squared percentage error does not blow up as it does in the first and second worst time_ids. Those time_ids only have one error each. The asolute value of the error is not very large, but since are dividing by the square of the true value, the fact that the target is small results in a huge error around 200 spe.\n",
    "\n",
    "Lets look at top errors in general and see if they all share this quality of an extremely low target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with the top 50 errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T09:06:08.166923Z",
     "iopub.status.busy": "2021-08-26T09:06:08.166549Z",
     "iopub.status.idle": "2021-08-26T09:06:09.421142Z",
     "shell.execute_reply": "2021-08-26T09:06:09.420081Z",
     "shell.execute_reply.started": "2021-08-26T09:06:08.166891Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "top = train.sort_values('spe', ascending=False).head(50).reset_index()\n",
    "top[['target', 'pred', 'log_return_realized_volatility']].plot(ax=axes[0])\n",
    "axes[0].set_title('Top 25 squared percentage errors')\n",
    "top[['spe']].plot(ax=axes[1])\n",
    "axes[1].set_title('spe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It definitely seems that the largest errors are coming from overpredicting the target, along with an especially small target. \n",
    "I think overprediction could be the only times when we have a large penalty from the metric. Lets look at the largest losses where we underpredict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T09:06:49.339504Z",
     "iopub.status.busy": "2021-08-26T09:06:49.339083Z",
     "iopub.status.idle": "2021-08-26T09:06:49.887591Z",
     "shell.execute_reply": "2021-08-26T09:06:49.886408Z",
     "shell.execute_reply.started": "2021-08-26T09:06:49.339467Z"
    }
   },
   "outputs": [],
   "source": [
    "df = train[train.pred < train.target]\n",
    "df.sort_values('spe', ascending=False)[['pred', 'target', 'spe']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest spe is less than .92. For reference, if we predicted 0 for all targets our average spe and overall metric would be 1. Given that the underpredicted errors gave spe penalties in the 5,6, and 7 range at the high end (highest about 200) with relatively small absolute error, and these underpredictions give a max penalty less than 1, I am certain that overpredicting especially small targets is the largest source of error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at some of the book and trade data for the top losses. Maybe we can find some features that show that we are about to enter a low volatility period, even if the previous 10 minutes was high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to see from which part of the distributio coming from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:56:07.629803Z",
     "iopub.status.busy": "2021-08-28T05:56:07.62939Z",
     "iopub.status.idle": "2021-08-28T05:56:07.636767Z",
     "shell.execute_reply": "2021-08-28T05:56:07.635658Z",
     "shell.execute_reply.started": "2021-08-28T05:56:07.629771Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_percentile(df, col): \n",
    "    \"\"\"\"\"\"\n",
    "    if type(col) == list: \n",
    "        for c in col: df = add_percentile(df, c)\n",
    "    else: \n",
    "        df[col + '_percentile'] = (df[col].rank(pct=True) * 100).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:56:08.180712Z",
     "iopub.status.busy": "2021-08-28T05:56:08.180293Z",
     "iopub.status.idle": "2021-08-28T05:56:09.418814Z",
     "shell.execute_reply": "2021-08-28T05:56:09.417588Z",
     "shell.execute_reply.started": "2021-08-28T05:56:08.180674Z"
    }
   },
   "outputs": [],
   "source": [
    "add_percentile(train, ['pred', 'target', 'log_return_realized_volatility'])\n",
    "top_spe = train.sort_values('spe', ascending=False)\n",
    "# [\n",
    "#     ['stock_id', 'time_id', 'rv',\n",
    "#      'target', 'pred', 'spe', 'log_return_realized_volatility_percentile', 'target_percentile', 'pred_percentile']\n",
    "# ]\n",
    "top_spe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the ratio of the volume of shares traded to the average total bid_size and ask_size because I think it could be important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T04:13:21.699416Z",
     "iopub.status.busy": "2021-08-28T04:13:21.698985Z",
     "iopub.status.idle": "2021-08-28T04:13:21.723542Z",
     "shell.execute_reply": "2021-08-28T04:13:21.722375Z",
     "shell.execute_reply.started": "2021-08-28T04:13:21.699374Z"
    }
   },
   "outputs": [],
   "source": [
    "train['ratio'] = train.size_sum / train.sum_bid_ask_mean\n",
    "train[['ratio']].corrwith(train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T23:09:45.578911Z",
     "iopub.status.busy": "2021-08-27T23:09:45.578543Z",
     "iopub.status.idle": "2021-08-27T23:09:54.214654Z",
     "shell.execute_reply": "2021-08-27T23:09:54.2135Z",
     "shell.execute_reply.started": "2021-08-27T23:09:45.578882Z"
    }
   },
   "outputs": [],
   "source": [
    "df = load_bt(DATA_RAW, 31, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T23:10:03.693834Z",
     "iopub.status.busy": "2021-08-27T23:10:03.693304Z",
     "iopub.status.idle": "2021-08-27T23:10:03.715083Z",
     "shell.execute_reply": "2021-08-27T23:10:03.713881Z",
     "shell.execute_reply.started": "2021-08-27T23:10:03.693801Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T23:17:47.6235Z",
     "iopub.status.busy": "2021-08-27T23:17:47.623088Z",
     "iopub.status.idle": "2021-08-27T23:17:49.275294Z",
     "shell.execute_reply": "2021-08-27T23:17:49.274077Z",
     "shell.execute_reply.started": "2021-08-27T23:17:47.623468Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('time_id')['bid_price1', 'ask_price1'].transform('diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T08:10:18.79109Z",
     "iopub.status.busy": "2021-08-28T08:10:18.790687Z",
     "iopub.status.idle": "2021-08-28T08:10:25.829508Z",
     "shell.execute_reply": "2021-08-28T08:10:25.828663Z",
     "shell.execute_reply.started": "2021-08-28T08:10:18.79104Z"
    }
   },
   "outputs": [],
   "source": [
    "df = load_bt(DATA_RAW, 31, 'train')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T08:10:30.719034Z",
     "iopub.status.busy": "2021-08-28T08:10:30.718706Z",
     "iopub.status.idle": "2021-08-28T08:10:31.790945Z",
     "shell.execute_reply": "2021-08-28T08:10:31.790039Z",
     "shell.execute_reply.started": "2021-08-28T08:10:30.719002Z"
    }
   },
   "outputs": [],
   "source": [
    "df['bid_price_diff'] = df.groupby('time_id')['bid_price1'].diff()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T08:14:08.432702Z",
     "iopub.status.busy": "2021-08-28T08:14:08.432359Z",
     "iopub.status.idle": "2021-08-28T08:14:08.674851Z",
     "shell.execute_reply": "2021-08-28T08:14:08.673825Z",
     "shell.execute_reply.started": "2021-08-28T08:14:08.432667Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('time_id')['bid_price_diff'].agg(count_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:57:15.598137Z",
     "iopub.status.busy": "2021-08-28T05:57:15.597678Z",
     "iopub.status.idle": "2021-08-28T05:57:15.61504Z",
     "shell.execute_reply": "2021-08-28T05:57:15.614097Z",
     "shell.execute_reply.started": "2021-08-28T05:57:15.598097Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_book(stock_id, time_id, train=train): \n",
    "    mask = (train.stock_id == stock_id) & (train.time_id == time_id)\n",
    "    target, pred, spe, realized_volatitlity, pred_percentile, target_percentile, \\\n",
    "    realized_volatitlity_percentile, size_sum, ratio \\\n",
    "        = train.loc[mask, ['target', 'pred', 'spe', \n",
    "                           'log_return_realized_volatility',\n",
    "                           'pred_percentile', \n",
    "                           'target_percentile', \n",
    "                           'log_return_realized_volatility_percentile', \n",
    "                           'size_sum', \n",
    "                           'ratio'\n",
    "                          ]].values[0].round(5)\n",
    "    \n",
    "    bt = load_bt(DATA_RAW, stock_id, 'train')\n",
    "    bt['wap'] = (bt['bid_price1'] * bt['ask_size1'] + bt['ask_price1'] * bt['bid_size1']) /\\\n",
    "                          (bt['bid_size1'] + bt['ask_size1'])\n",
    "    bt['total_bid_size'] = bt['bid_size1'] + bt['bid_size2']\n",
    "    bt['total_ask_size'] = bt['ask_size1'] + bt['ask_size2']\n",
    "    book = bt[bt.time_id == time_id].set_index('seconds_in_bucket')\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 15))\n",
    "    \n",
    "    cmap = {'ask_price1': 'yellow', \n",
    "            'ask_price2': 'khaki',\n",
    "            'ask_size1': 'yellow', \n",
    "            'ask_size2': 'khaki',\n",
    "            'bid_price1': 'blue', \n",
    "            'bid_price2': 'lightblue', \n",
    "            'bid_size1': 'blue', \n",
    "            'bid_size2': 'lightblue',\n",
    "            'total_ask_size': 'yellow', \n",
    "            'total_bid_size': 'blue', \n",
    "            'wap': 'green', \n",
    "            'size': 'red', \n",
    "            'price': 'red', \n",
    "           }\n",
    "    \n",
    "    book[['ask_price2', 'ask_price1', 'bid_price1',  'bid_price2', 'wap', 'price']].plot(ax=axes[0], color=cmap)\n",
    "    book[['bid_size1', 'ask_size1', 'bid_size2','ask_size2']].plot(ax=axes[1], color=cmap)\n",
    "    book[['total_bid_size', 'total_ask_size']].plot(ax=axes[2], color=cmap)\n",
    "    book[['size']].plot(marker='o', ax=axes[1], color=cmap)\n",
    "\n",
    "    \n",
    "    axes[0].set_title('Price info')\n",
    "    axes[1].set_title('Size info')\n",
    "    axes[2].set_title('Total size info')\n",
    "    axes[0].legend(loc='upper left')\n",
    "    axes[1].legend(loc='upper left')\n",
    "    axes[2].legend(loc='upper left')\n",
    "    \n",
    "    fig.suptitle(f'\\\n",
    "        Stock: {stock_id}         missing seconds: {600 - len(book)}\\n\\\n",
    "        Time_id: {time_id}\\n\\\n",
    "        spe: {spe} \\n\\\n",
    "        target: {target} \\n\\\n",
    "        pred: {pred} \\n\\\n",
    "        realized_volatitlity: {realized_volatitlity},\\n\\n\\\n",
    "        error: {round(pred - target, 5)} \\n\\\n",
    "        target_percentile: {target_percentile} \\n\\\n",
    "        pred_percentile: {pred_percentile} \\n\\\n",
    "        realized_volatitlity_percentile: {realized_volatitlity_percentile}           total sales: {size_sum}         ratio: {ratio}\\n')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:57:19.806633Z",
     "iopub.status.busy": "2021-08-28T05:57:19.80613Z",
     "iopub.status.idle": "2021-08-28T05:57:19.815321Z",
     "shell.execute_reply": "2021-08-28T05:57:19.814165Z",
     "shell.execute_reply.started": "2021-08-28T05:57:19.806598Z"
    }
   },
   "outputs": [],
   "source": [
    "train['d'] = train['pred'] - train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-08-28T04:23:45.002733Z",
     "iopub.status.busy": "2021-08-28T04:23:45.00219Z",
     "iopub.status.idle": "2021-08-28T04:25:15.713823Z",
     "shell.execute_reply": "2021-08-28T04:25:15.712861Z",
     "shell.execute_reply.started": "2021-08-28T04:23:45.00269Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for stock_id, time_id in train.sort_values('d', ascending=False)[['stock_id', 'time_id']].values[: 10]: \n",
    "    plot_book(stock_id, time_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T08:33:39.684426Z",
     "iopub.status.busy": "2021-08-28T08:33:39.684095Z",
     "iopub.status.idle": "2021-08-28T08:33:39.689156Z",
     "shell.execute_reply": "2021-08-28T08:33:39.688249Z",
     "shell.execute_reply.started": "2021-08-28T08:33:39.684399Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_decay(x, decay=.9, step=-1, axis=0): \n",
    "    \"\"\"Returns sum with exponential decay, step = -1\n",
    "    for the end of the array to matter the most.\"\"\"\n",
    "    weights = np.power(decay, np.arange(x.shape[axis])[::step]).astype(np.float32)\n",
    "    return np.sum(weights * x, axis=axis) / weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T08:33:43.147927Z",
     "iopub.status.busy": "2021-08-28T08:33:43.147458Z",
     "iopub.status.idle": "2021-08-28T08:33:43.153907Z",
     "shell.execute_reply": "2021-08-28T08:33:43.15297Z",
     "shell.execute_reply.started": "2021-08-28T08:33:43.147887Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_decay(np.array([1,1,1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let look at the top 3 instances for each of the ftop 5 lowest scoring time_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T00:38:04.761677Z",
     "iopub.status.busy": "2021-08-27T00:38:04.761333Z",
     "iopub.status.idle": "2021-08-27T00:41:08.89047Z",
     "shell.execute_reply": "2021-08-27T00:41:08.889233Z",
     "shell.execute_reply.started": "2021-08-27T00:38:04.761646Z"
    }
   },
   "outputs": [],
   "source": [
    "for t in top_5_worst_times: \n",
    "    tmp = train[train.time_id == t].sort_values('spe', ascending=False)\n",
    "    for stock_id, time_id in tmp[['stock_id', 'time_id']].values[: 3]: \n",
    "        plot_book(stock_id, time_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the most penalized instances and see if we can see a pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T23:13:05.769134Z",
     "iopub.status.busy": "2021-08-26T23:13:05.76875Z",
     "iopub.status.idle": "2021-08-26T23:13:06.829901Z",
     "shell.execute_reply": "2021-08-26T23:13:06.828836Z",
     "shell.execute_reply.started": "2021-08-26T23:13:05.769101Z"
    }
   },
   "outputs": [],
   "source": [
    "top = train.sort_values('spe', ascending=False)\n",
    "display(train.sum_bid_ask_mean.mean())\n",
    "display(top.iloc[:int(top.shape[0] * .2)].sum_bid_ask_mean.mean())\n",
    "display(top.iloc[:int(top.shape[0] * .05)].sum_bid_ask_mean.mean())\n",
    "display(top.iloc[:int(top.shape[0] * .01)].sum_bid_ask_mean.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T23:13:44.398574Z",
     "iopub.status.busy": "2021-08-26T23:13:44.398132Z",
     "iopub.status.idle": "2021-08-26T23:13:45.68654Z",
     "shell.execute_reply": "2021-08-26T23:13:45.685296Z",
     "shell.execute_reply.started": "2021-08-26T23:13:44.398533Z"
    }
   },
   "outputs": [],
   "source": [
    "top = train.sort_values('spe', ascending=False)\n",
    "display(train.ratio.mean())\n",
    "display(top.iloc[:int(top.shape[0] * .2)].ratio.mean())\n",
    "display(top.iloc[:int(top.shape[0] * .05)].ratio.mean())\n",
    "display(top.iloc[:int(top.shape[0] * .01)].ratio.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T23:14:03.664935Z",
     "iopub.status.busy": "2021-08-26T23:14:03.664544Z",
     "iopub.status.idle": "2021-08-26T23:14:03.755774Z",
     "shell.execute_reply": "2021-08-26T23:14:03.754566Z",
     "shell.execute_reply.started": "2021-08-26T23:14:03.664902Z"
    }
   },
   "outputs": [],
   "source": [
    "display(train[['sum_bid_ask_mean']].corrwith(train['spe']))\n",
    "display(train[['sum_bid_ask_mean']].corrwith(train['target']))\n",
    "display(train[['size_sum']].corrwith(train['spe']))\n",
    "display(train[['size_sum']].corrwith(train['target']))\n",
    "display(train[['ratio']].corrwith(train['spe']))\n",
    "display(train[['ratio']].corrwith(train['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T23:14:35.867213Z",
     "iopub.status.busy": "2021-08-26T23:14:35.866769Z",
     "iopub.status.idle": "2021-08-26T23:14:37.132923Z",
     "shell.execute_reply": "2021-08-26T23:14:37.131765Z",
     "shell.execute_reply.started": "2021-08-26T23:14:35.867172Z"
    }
   },
   "outputs": [],
   "source": [
    "low = train.sort_values('log_return_realized_volatility')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what the lowest volatility instances look like before looking at the instances where we went from high volatility to a low target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-26T23:16:08.279604Z",
     "iopub.status.busy": "2021-08-26T23:16:08.279187Z",
     "iopub.status.idle": "2021-08-26T23:18:20.183752Z",
     "shell.execute_reply": "2021-08-26T23:18:20.182893Z",
     "shell.execute_reply.started": "2021-08-26T23:16:08.279561Z"
    }
   },
   "outputs": [],
   "source": [
    "for stock_id, time_id in low[['stock_id', 'time_id']].values[: 10]: \n",
    "    plot_book(stock_id, time_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They all have a very low ratio of sales to ask and bid size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T05:57:39.167845Z",
     "iopub.status.busy": "2021-08-28T05:57:39.167438Z",
     "iopub.status.idle": "2021-08-28T05:59:12.93337Z",
     "shell.execute_reply": "2021-08-28T05:59:12.932465Z",
     "shell.execute_reply.started": "2021-08-28T05:57:39.167813Z"
    }
   },
   "outputs": [],
   "source": [
    "for stock_id, time_id in top_spe[top_spe.stock_id != 31][['stock_id', 'time_id']].values[: 10]: \n",
    "    plot_book(stock_id, time_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T22:07:23.894405Z",
     "iopub.status.busy": "2021-08-27T22:07:23.893985Z",
     "iopub.status.idle": "2021-08-27T22:09:00.68329Z",
     "shell.execute_reply": "2021-08-27T22:09:00.681928Z",
     "shell.execute_reply.started": "2021-08-27T22:07:23.894373Z"
    }
   },
   "outputs": [],
   "source": [
    "for stock_id, time_id in train[train.stock_id == 31][['stock_id', 'time_id']].values[: 10]: \n",
    "    plot_book(stock_id, time_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-28T04:41:53.640798Z",
     "iopub.status.busy": "2021-08-28T04:41:53.640426Z",
     "iopub.status.idle": "2021-08-28T04:43:20.454845Z",
     "shell.execute_reply": "2021-08-28T04:43:20.453805Z",
     "shell.execute_reply.started": "2021-08-28T04:41:53.640767Z"
    }
   },
   "outputs": [],
   "source": [
    "comp = train[(train.log_return_realized_volatility_percentile < 60) & (train.log_return_realized_volatility_percentile > 40)]\n",
    "for stock_id, time_id in comp[['stock_id', 'time_id']].values[:10]: \n",
    "    plot_book(stock_id, time_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T00:45:45.811662Z",
     "iopub.status.busy": "2021-08-24T00:45:45.811341Z",
     "iopub.status.idle": "2021-08-24T00:45:45.874401Z",
     "shell.execute_reply": "2021-08-24T00:45:45.871972Z",
     "shell.execute_reply.started": "2021-08-24T00:45:45.811635Z"
    }
   },
   "outputs": [],
   "source": [
    "d = train.copy()\n",
    "d.loc[d.ratio < 1, 'pred'] /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T00:47:10.438856Z",
     "iopub.status.busy": "2021-08-24T00:47:10.438459Z",
     "iopub.status.idle": "2021-08-24T00:47:24.724392Z",
     "shell.execute_reply": "2021-08-24T00:47:24.723566Z",
     "shell.execute_reply.started": "2021-08-24T00:47:10.438831Z"
    }
   },
   "outputs": [],
   "source": [
    "for stock_id, time_id in train[train.ratio < 1][['stock_id', 'time_id']].values[:12]: \n",
    "    plot_book(stock_id, time_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T00:45:47.253265Z",
     "iopub.status.busy": "2021-08-24T00:45:47.252913Z",
     "iopub.status.idle": "2021-08-24T00:45:47.263248Z",
     "shell.execute_reply": "2021-08-24T00:45:47.262306Z",
     "shell.execute_reply.started": "2021-08-24T00:45:47.253236Z"
    }
   },
   "outputs": [],
   "source": [
    "rmspe(d['target'], d['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-24T00:32:01.210442Z",
     "iopub.status.busy": "2021-08-24T00:32:01.210141Z",
     "iopub.status.idle": "2021-08-24T00:32:01.219877Z",
     "shell.execute_reply": "2021-08-24T00:32:01.218466Z",
     "shell.execute_reply.started": "2021-08-24T00:32:01.210418Z"
    }
   },
   "outputs": [],
   "source": [
    "train[train.ratio < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T22:13:15.590828Z",
     "iopub.status.busy": "2021-08-23T22:13:15.590509Z",
     "iopub.status.idle": "2021-08-23T22:13:15.613564Z",
     "shell.execute_reply": "2021-08-23T22:13:15.612303Z",
     "shell.execute_reply.started": "2021-08-23T22:13:15.590799Z"
    }
   },
   "outputs": [],
   "source": [
    "top_spe['vdiff'] = top_spe['log_return_realized_volatility'] - top_spe['target']\n",
    "top_spe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T09:45:30.132068Z",
     "iopub.status.busy": "2021-08-23T09:45:30.131654Z",
     "iopub.status.idle": "2021-08-23T09:45:30.282534Z",
     "shell.execute_reply": "2021-08-23T09:45:30.28112Z",
     "shell.execute_reply.started": "2021-08-23T09:45:30.132035Z"
    }
   },
   "outputs": [],
   "source": [
    "top_spe.sort_values('vdiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T08:56:09.270406Z",
     "iopub.status.busy": "2021-08-23T08:56:09.270003Z",
     "iopub.status.idle": "2021-08-23T08:56:09.463692Z",
     "shell.execute_reply": "2021-08-23T08:56:09.462589Z",
     "shell.execute_reply.started": "2021-08-23T08:56:09.270368Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def visualize_book_time_bucket(stock_id, time_id):\n",
    "    \n",
    "    time_bucket = (df_train['stock_id'] == stock_id) & (df_train['time_id'] == time_id)\n",
    "    \n",
    "    target = df_train.loc[time_bucket, 'target'].iloc[0]\n",
    "    realized_volatility = df_train.loc[time_bucket, 'realized_volatility_from_wap1'].iloc[0]\n",
    "    df_book = read_book_data('train', stock_id, sort=True, forward_fill=True)\n",
    "    df_book = df_book.set_index('seconds_in_bucket')\n",
    "    \n",
    "    df_book['wap1'] = (df_book['bid_price1'] * df_book['ask_size1'] + df_book['ask_price1'] * df_book['bid_size1']) /\\\n",
    "                      (df_book['bid_size1'] + df_book['ask_size1'])\n",
    "    df_book['wap2'] = (df_book['bid_price2'] * df_book['ask_size2'] + df_book['ask_price2'] * df_book['bid_size2']) /\\\n",
    "                      (df_book['bid_size2'] + df_book['ask_size2'])\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize=(32, 30), nrows=2)\n",
    "    \n",
    "    axes[0].plot(df_book.loc[df_book['time_id'] == time_id, 'bid_price1'], label='bid_price1', lw=2, color='tab:green')\n",
    "    axes[0].plot(df_book.loc[df_book['time_id'] == time_id, 'ask_price1'], label='ask_price1', lw=2, color='tab:red')\n",
    "    axes[0].plot(df_book.loc[df_book['time_id'] == time_id, 'bid_price2'], label='bid_price2', alpha=0.3, color='tab:green')\n",
    "    axes[0].plot(df_book.loc[df_book['time_id'] == time_id, 'ask_price2'], label='ask_price2', alpha=0.3, color='tab:red')\n",
    "    axes[0].plot(df_book.loc[df_book['time_id'] == time_id, 'wap1'], label='wap1', lw=2, linestyle='--', color='tab:blue')\n",
    "    axes[0].plot(df_book.loc[df_book['time_id'] == time_id, 'wap2'], label='wap2', alpha=0.3, linestyle='--',  color='tab:blue')\n",
    "    \n",
    "    axes[1].plot(df_book.loc[df_book['time_id'] == time_id, 'bid_size1'], label='bid_size1', lw=2, color='tab:green')\n",
    "    axes[1].plot(df_book.loc[df_book['time_id'] == time_id, 'ask_size1'], label='ask_size1', lw=2, color='tab:red')\n",
    "    axes[1].plot(df_book.loc[df_book['time_id'] == time_id, 'bid_size2'], label='bid_size2', alpha=0.3, color='tab:green')\n",
    "    axes[1].plot(df_book.loc[df_book['time_id'] == time_id, 'ask_size2'], label='ask_size2', alpha=0.3, color='tab:red')\n",
    "    \n",
    "    for i in range(2):\n",
    "        axes[i].legend(prop={'size': 18})\n",
    "        axes[i].tick_params(axis='x', labelsize=20, pad=10)\n",
    "        axes[i].tick_params(axis='y', labelsize=20, pad=10)\n",
    "    axes[0].set_ylabel('price', size=20, labelpad=15)\n",
    "    axes[1].set_ylabel('size', size=20, labelpad=15)\n",
    "    \n",
    "    axes[0].set_title(\n",
    "        f'Prices of stock_id {stock_id} time_id {time_id} - Current Realized Volatility: {realized_volatility:.6f} - Next 10 minute Realized Volatility: {target:.6f}',\n",
    "        size=25,\n",
    "        pad=15\n",
    "    )\n",
    "    axes[1].set_title(\n",
    "        f'Sizes of stock_id {stock_id} time_id {time_id} - Current Realized Volatility: {realized_volatility:.6f} - Next 10 minute Realized Volatility: {target:.6f}',\n",
    "        size=25,\n",
    "        pad=15\n",
    "    )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "std = train['log_return_realized_volatility'].std()\n",
    "# mean = train['log_return_realized_volatility'].mean()\n",
    "# clip = mean + 3 * std\n",
    "# clipped = train[train.]\n",
    "\n",
    "# for x in [.99, .95, .9, .85, .80, .75.65]: \n",
    "#     tmp = train.copy()\n",
    "#     tmp.loc[tmp.stock_id == 31, 'pred'] *= x\n",
    "#     print(x, rmspe(tmp))\n",
    "\n",
    "# for x in [.99, .95, .9, .85, .80, .75, .65]: \n",
    "#     tmp = train.copy()\n",
    "#     tmp.loc[:, 'pred'] *= x\n",
    "#     print(x, rmspe(tmp))\n",
    "\n",
    "# # Lets see if we can make simple groupings to improve the baseline prediction of real volatility\n",
    "\n",
    "# df = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n",
    "# df = df.merge(train[['stock_id', 'time_id', 'log_return_realized_volatility']], on=['stock_id', 'time_id'])\n",
    "# df.columns = ['stock_id', 'time_id', 'target', 'rv']\n",
    "# df['pred'] = df['rv']\n",
    "# display(rmspe(df))\n",
    "\n",
    "# df['stock_mean'] = df.groupby('stock_id')['rv'].transform('mean')\n",
    "# df['time_mean'] = df.groupby('time_id')['rv'].transform('mean')\n",
    "# df['pred'] = df['stock_mean']\n",
    "# display(rmspe(df))\n",
    "\n",
    "# m = df.rv.mean()\n",
    "# df['time_ratio'] = df['time_mean'] / m\n",
    "# df['pred'] = df['stock_mean'] * df['time_ratio']\n",
    "# display(rmspe(df))\n",
    "\n",
    "# df['rv_ratio'] = df['rv'] / df['stock_mean']\n",
    "# df['pred'] = (df['rv_ratio'] + df['time_ratio']) * df['stock_mean'] / 2\n",
    "# display(rmspe(df))\n",
    "\n",
    "# None of the ideas could improve the baseline\n",
    "\n",
    "# train.columns.tolist()\n",
    "\n",
    "# c = np.power(.99, np.arange(10)[::-1]).sum()\n",
    "# c = train['real_vol_mean_decay_0.85_-1'].mean() / m\n",
    "# train['pred'] = train['real_vol_mean_decay_0.85_-1'] / (c * 1.2)\n",
    "# rmspe(train)\n",
    "\n",
    "# p = pd.read_pickle('../input/opt-feature-gen-p5-v2/p5_v2_train.pkl')\n",
    "\n",
    "# c = np.power(.99, np.arange(10)[::-1]).sum()\n",
    "# c = p['log_return_rv_99'].mean() / m \n",
    "# p['pred'] = p['log_return_rv_99'] / (c * 1.3) \n",
    "# rmspe(p)\n",
    "\n",
    "# piv = df.pivot('time_id', 'stock_id', 'rv')\n",
    "# print('columns in order: ', (all(piv.columns == sorted(piv.columns))))\n",
    "# corr = piv.corr()\n",
    "\n",
    "# for n in range(1, 15):\n",
    "#     km = KMeans(n)\n",
    "#     km.fit(corr)\n",
    "#     mapper = dict(zip(corr.columns, km.labels_))\n",
    "#     df['km_lab'] = df['stock_id'].map(mapper)\n",
    "#     df['pred'] = df.groupby('km_lab')['rv'].transform('mean') * df['time_ratio']\n",
    "#     print(n, rmspe(df))\n",
    "\n",
    "\n",
    "\n",
    "# Verifying that the RMSPE is same as cv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
