{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c813e9b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T21:43:41.604568Z",
     "iopub.status.busy": "2021-08-18T21:43:41.599429Z",
     "iopub.status.idle": "2021-08-18T21:43:43.034635Z",
     "shell.execute_reply": "2021-08-18T21:43:43.033874Z",
     "shell.execute_reply.started": "2021-08-18T21:40:39.581772Z"
    },
    "papermill": {
     "duration": 1.547396,
     "end_time": "2021-08-18T21:43:43.034812",
     "exception": false,
     "start_time": "2021-08-18T21:43:41.487416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Cell\n",
    "#export\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# Cell\n",
    "def load_bt(DATA_RAW, stock_id, train_or_test='train'):\n",
    "    \"\"\"Loads the book and trade data into a single dataframe.\"\"\"\n",
    "    book = pd.read_parquet(os.path.join(DATA_RAW, f'book_{train_or_test}.parquet/stock_id={stock_id}'))\n",
    "    trade =  pd.read_parquet(os.path.join(DATA_RAW, f'trade_{train_or_test}.parquet/stock_id={stock_id}'))\n",
    "    return book.merge(trade, on=['time_id', 'seconds_in_bucket'], how='outer')\n",
    "\n",
    "# Cell\n",
    "def add_wap(df):\n",
    "    \"\"\"Adds the weighted average price to a book df.\"\"\"\n",
    "    df['wap'] = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1']+ df['ask_size1'])\n",
    "    return df\n",
    "\n",
    "# Cell\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "# Cell\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "# Cell\n",
    "def realized_volatility_per_time_id(file_path, prediction_column_name):\n",
    "    df_book_data = pd.read_parquet(file_path)\n",
    "    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  / (\n",
    "                                      df_book_data['bid_size1']+ df_book_data['ask_size1'])\n",
    "    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
    "    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n",
    "    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n",
    "    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    return df_realized_vol_per_stock[['row_id',prediction_column_name]]\n",
    "\n",
    "# Cell\n",
    "def past_realized_volatility_per_stock(list_file,prediction_column_name):\n",
    "    df_past_realized = pd.DataFrame()\n",
    "    for file in list_file:\n",
    "        df_past_realized = pd.concat([df_past_realized,\n",
    "                                     realized_volatility_per_time_id(file,prediction_column_name)])\n",
    "    return df_past_realized\n",
    "\n",
    "# Cell\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "def make_folds(DATA_RAW, DATA_INTERIM=None):\n",
    "    train = pd.read_csv(os.path.join(DATA_RAW, 'train.csv'))\n",
    "    g = GroupKFold()\n",
    "    for fold, (_, test_idx) in enumerate(g.split(train, groups=train['time_id'])):\n",
    "        train.loc[test_idx, 'fold'] = fold\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    if not DATA_INTERIM: return train\n",
    "    train.to_csv(os.path.join(DATA_INTERIM, 'folds.csv'), index=False)\n",
    "    \n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def mean_decay(x, decay=.9, step=-1, axis=1): \n",
    "    \"\"\"Returns sum with exponential decay, step = -1\n",
    "    for the end of the array to matter the most.\"\"\"\n",
    "    \n",
    "    weights = np.power(decay, np.arange(x.shape[axis])[::step]).astype(np.float32)\n",
    "    return np.sum(weights * x, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538c7351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T21:43:43.055612Z",
     "iopub.status.busy": "2021-08-18T21:43:43.054789Z",
     "iopub.status.idle": "2021-08-18T21:43:44.019114Z",
     "shell.execute_reply": "2021-08-18T21:43:44.018524Z",
     "shell.execute_reply.started": "2021-08-18T21:38:43.039526Z"
    },
    "papermill": {
     "duration": 0.976728,
     "end_time": "2021-08-18T21:43:44.019257",
     "exception": false,
     "start_time": "2021-08-18T21:43:43.042529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from fastcore.script import call_parse\n",
    "import glob\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a335d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T21:43:44.038845Z",
     "iopub.status.busy": "2021-08-18T21:43:44.037811Z",
     "iopub.status.idle": "2021-08-18T21:43:44.041238Z",
     "shell.execute_reply": "2021-08-18T21:43:44.040572Z",
     "shell.execute_reply.started": "2021-08-18T21:38:43.462833Z"
    },
    "papermill": {
     "duration": 0.014845,
     "end_time": "2021-08-18T21:43:44.041379",
     "exception": false,
     "start_time": "2021-08-18T21:43:44.026534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_RAW = '../input/optiver-realized-volatility-prediction'\n",
    "DATA_INTERIM = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945e3098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T21:43:44.073908Z",
     "iopub.status.busy": "2021-08-18T21:43:44.073033Z",
     "iopub.status.idle": "2021-08-18T21:43:44.076256Z",
     "shell.execute_reply": "2021-08-18T21:43:44.076698Z",
     "shell.execute_reply.started": "2021-08-18T21:38:43.469470Z"
    },
    "papermill": {
     "duration": 0.028239,
     "end_time": "2021-08-18T21:43:44.076872",
     "exception": false,
     "start_time": "2021-08-18T21:43:44.048633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_fe1(DATA_RAW,train_or_test):\n",
    "    \n",
    "    if train_or_test == 'test': \n",
    "        df_fe = pd.read_csv(os.path.join(DATA_RAW, 'test.csv')).set_index('row_id')\n",
    "    else: \n",
    "        df_fe = make_folds(DATA_RAW).set_index('row_id')\n",
    "    df_all = pd.DataFrame()\n",
    "    \n",
    "    for stock_id in df_fe.stock_id.unique():\n",
    "        df = load_bt(DATA_RAW, stock_id, train_or_test)\n",
    "        df = add_wap(df)\n",
    "        df['log_return'] = df.groupby(['time_id'])['wap'].apply(log_return)\n",
    "        df['abs_log_return'] = df['log_return'].abs()\n",
    "        df['is_pos_return'] = df['log_return'] > 0\n",
    "        df['is_neg_return'] = df['log_return'] < 0\n",
    "        df['minute'] = np.ceil((df.seconds_in_bucket + .1) / 120).astype(int)\n",
    "\n",
    "        df_agg = pd.DataFrame()\n",
    "        df_agg['real_vol'] = df.groupby('time_id')['log_return'].agg(realized_volatility)\n",
    "        df_agg['is_pos_return_sum'] = df.groupby('time_id')['is_pos_return'].agg(sum).astype(np.float32)\n",
    "        df_agg['is_neg_return_sum'] = df.groupby('time_id')['is_neg_return'].agg(sum).astype(np.float32)\n",
    "\n",
    "        ############ Realized volume for each minute ############\n",
    "        for minute in df.minute.unique():\n",
    "            tmp = df[df['minute'] == minute]\n",
    "            df_agg[f'real_vol_min_{minute}'] = tmp.groupby('time_id')['log_return'].agg(realized_volatility)\n",
    "\n",
    "        ######### Decay sum of realized volume per minute ########\n",
    "        cols = [f'real_vol_min_{minute}' for minute in df.minute.unique()]\n",
    "        x = df_agg[cols].values\n",
    "        for decay, step in product((.99, .95, .9, .85), (1, -1)): \n",
    "            df_agg[f'real_vol_mean_decay_{decay}_{step}'] =  mean_decay(x, decay, step)\n",
    "        df_agg['end_beg_decay_ratio'] = df_agg['real_vol_mean_decay_0.85_-1'] / df_agg['real_vol_mean_decay_0.85_1']\n",
    "\n",
    "        ################# Adding 'row_id' column ##################\n",
    "        df_agg.reset_index(inplace=True)\n",
    "        df_agg['time_id'] = df_agg.time_id.apply(lambda x: f\"{stock_id}-{x}\")\n",
    "        df_agg.rename({'time_id': 'row_id'}, axis=1, inplace=True)\n",
    "\n",
    "        ############### Add df_agg to all features #################\n",
    "        df_all = pd.concat([df_all, df_agg])\n",
    "\n",
    "    ################### Merge with train or test file ###############\n",
    "    return df_fe.join(df_all.set_index('row_id')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5464439a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T21:43:44.095698Z",
     "iopub.status.busy": "2021-08-18T21:43:44.094638Z",
     "iopub.status.idle": "2021-08-18T22:01:44.292055Z",
     "shell.execute_reply": "2021-08-18T22:01:44.292587Z",
     "shell.execute_reply.started": "2021-08-18T21:38:43.488478Z"
    },
    "papermill": {
     "duration": 1080.208612,
     "end_time": "2021-08-18T22:01:44.292773",
     "exception": false,
     "start_time": "2021-08-18T21:43:44.084161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 428932 entries, 0 to 428931\n",
      "Data columns (total 22 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   row_id                       428932 non-null  object \n",
      " 1   stock_id                     428932 non-null  int64  \n",
      " 2   time_id                      428932 non-null  int64  \n",
      " 3   target                       428932 non-null  float64\n",
      " 4   fold                         428932 non-null  float64\n",
      " 5   real_vol                     428932 non-null  float64\n",
      " 6   is_pos_return_sum            428932 non-null  float32\n",
      " 7   is_neg_return_sum            428932 non-null  float32\n",
      " 8   real_vol_min_1               428932 non-null  float64\n",
      " 9   real_vol_min_2               428932 non-null  float64\n",
      " 10  real_vol_min_3               428931 non-null  float64\n",
      " 11  real_vol_min_4               428931 non-null  float64\n",
      " 12  real_vol_min_5               428931 non-null  float64\n",
      " 13  real_vol_mean_decay_0.99_1   428929 non-null  float64\n",
      " 14  real_vol_mean_decay_0.99_-1  428929 non-null  float64\n",
      " 15  real_vol_mean_decay_0.95_1   428929 non-null  float64\n",
      " 16  real_vol_mean_decay_0.95_-1  428929 non-null  float64\n",
      " 17  real_vol_mean_decay_0.9_1    428929 non-null  float64\n",
      " 18  real_vol_mean_decay_0.9_-1   428929 non-null  float64\n",
      " 19  real_vol_mean_decay_0.85_1   428929 non-null  float64\n",
      " 20  real_vol_mean_decay_0.85_-1  428929 non-null  float64\n",
      " 21  end_beg_decay_ratio          428929 non-null  float64\n",
      "dtypes: float32(2), float64(17), int64(2), object(1)\n",
      "memory usage: 68.7+ MB\n"
     ]
    }
   ],
   "source": [
    "fe1_train = make_fe1(DATA_RAW, 'train')\n",
    "fe1_train.to_pickle('fe1_train.pkl')\n",
    "fe1_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d0cbbf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T22:01:44.311359Z",
     "iopub.status.busy": "2021-08-18T22:01:44.310340Z",
     "iopub.status.idle": "2021-08-18T22:01:44.313941Z",
     "shell.execute_reply": "2021-08-18T22:01:44.314481Z"
    },
    "papermill": {
     "duration": 0.014472,
     "end_time": "2021-08-18T22:01:44.314652",
     "exception": false,
     "start_time": "2021-08-18T22:01:44.300180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################### Ideas not used yet ######################\n",
    "# df['spread_pct'] = (df.ask_price1 - df.bid_price1) / df.wap\n",
    "# df['spread_2_pct'] = (df.ask_price2 - df.bid_price2) / df.wap\n",
    "# df['spread'] = (df.ask_price1 - df.bid_price1) \n",
    "# df['spread_2'] = (df.ask_price2 - df.bid_price2) \n",
    "# df['sum_bid'] = df[['bid_size1', 'bid_size2']].sum(axis=1)\n",
    "# df['sum_ask'] = df[['ask_size1', 'ask_size2']].sum(axis=1)\n",
    "# df['sum_bid_ask'] = df[['bid_size1', 'ask_size1', 'bid_size2', 'ask_size2']].sum(axis=1)\n",
    "# df['bid_ask_ratio'] = df['sum_bid'] / df['sum_ask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aca501",
   "metadata": {
    "papermill": {
     "duration": 0.007129,
     "end_time": "2021-08-18T22:01:44.329324",
     "exception": false,
     "start_time": "2021-08-18T22:01:44.322195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1091.827027,
   "end_time": "2021-08-18T22:01:45.147195",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-18T21:43:33.320168",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
